{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"07-BERT_multilabel-acd_TODO.ipynb","provenance":[{"file_id":"17ayXzmmmpzSSa0VQ4TPjIn7OBiqPsGgt","timestamp":1646220637572},{"file_id":"https://github.com/rap12391/transformers_multilabel_toxic/blob/master/toxic_multilabel.ipynb","timestamp":1643213922247}],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"},"widgets":{"application/vnd.jupyter.widget-state+json":{"74775eb164d34fe7a5d05c9cc10a7601":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_25c1be47214b45d48d96b0bfce4e0425","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_c46f04badde74bd386012d55a406cd24","IPY_MODEL_35339d2e0c534c7695475c0ad1af3414","IPY_MODEL_4bc493d090df47549f908ed9163d7c2a"]}},"25c1be47214b45d48d96b0bfce4e0425":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"c46f04badde74bd386012d55a406cd24":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_316576ac139d4b118f7561935cb67633","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_86b70845e28e43c0b222a233174129c9"}},"35339d2e0c534c7695475c0ad1af3414":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_3d480310193a41c1912f3702c58a38e4","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":440473133,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":440473133,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_c881011353c24dd5938f0d2d6efd67a2"}},"4bc493d090df47549f908ed9163d7c2a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_ae6847bf0d2947a7bce6c7cffc054cb9","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 420M/420M [00:15&lt;00:00, 37.3MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_aa09584d3447455b879f4055c4972e37"}},"316576ac139d4b118f7561935cb67633":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"86b70845e28e43c0b222a233174129c9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"3d480310193a41c1912f3702c58a38e4":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"c881011353c24dd5938f0d2d6efd67a2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"ae6847bf0d2947a7bce6c7cffc054cb9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"aa09584d3447455b879f4055c4972e37":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"markdown","metadata":{"id":"m5tUoHe9FRhs"},"source":["## Import Libraries"]},{"cell_type":"code","metadata":{"id":"Dr7BCHS-nIRW","scrolled":true,"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1646221217249,"user_tz":-60,"elapsed":27773,"user":{"displayName":"Rodrigo Agerri","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhW2M3VpBFpNNhe0tx607nu7jJN85RXoeaB4nSw=s64","userId":"18226337086247956839"}},"outputId":"5e7cb342-6a8f-43b5-f3c9-b48c02b754ea"},"source":["!pip install transformers\n","import pandas as pd\n","import numpy as np\n","import tensorflow as tf\n","import torch\n","from torch.nn import BCEWithLogitsLoss, BCELoss\n","from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n","from keras.preprocessing.sequence import pad_sequences\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import MultiLabelBinarizer\n","from sklearn.metrics import classification_report, confusion_matrix, multilabel_confusion_matrix, f1_score, accuracy_score\n","import pickle\n","import transformers\n","from tqdm import tqdm, trange\n","from ast import literal_eval"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting transformers\n","  Downloading transformers-4.16.2-py3-none-any.whl (3.5 MB)\n","\u001b[K     |████████████████████████████████| 3.5 MB 4.1 MB/s \n","\u001b[?25hCollecting sacremoses\n","  Downloading sacremoses-0.0.47-py2.py3-none-any.whl (895 kB)\n","\u001b[K     |████████████████████████████████| 895 kB 43.4 MB/s \n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.3)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.1)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Collecting huggingface-hub<1.0,>=0.1.0\n","  Downloading huggingface_hub-0.4.0-py3-none-any.whl (67 kB)\n","\u001b[K     |████████████████████████████████| 67 kB 5.5 MB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.5)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n","Collecting pyyaml>=5.1\n","  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n","\u001b[K     |████████████████████████████████| 596 kB 44.3 MB/s \n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.6.0)\n","Collecting tokenizers!=0.11.3,>=0.10.1\n","  Downloading tokenizers-0.11.6-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.5 MB)\n","\u001b[K     |████████████████████████████████| 6.5 MB 29.8 MB/s \n","\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.7)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.7.0)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n","Installing collected packages: pyyaml, tokenizers, sacremoses, huggingface-hub, transformers\n","  Attempting uninstall: pyyaml\n","    Found existing installation: PyYAML 3.13\n","    Uninstalling PyYAML-3.13:\n","      Successfully uninstalled PyYAML-3.13\n","Successfully installed huggingface-hub-0.4.0 pyyaml-6.0 sacremoses-0.0.47 tokenizers-0.11.6 transformers-4.16.2\n"]}]},{"cell_type":"code","metadata":{"id":"zB5Dij6JuItX","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1646221276126,"user_tz":-60,"elapsed":20425,"user":{"displayName":"Rodrigo Agerri","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhW2M3VpBFpNNhe0tx607nu7jJN85RXoeaB4nSw=s64","userId":"18226337086247956839"}},"outputId":"41bc3554-cfe5-4fe8-ddb8-b80e293ee9b4"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","metadata":{"id":"UhjnJEwKnISB","colab":{"base_uri":"https://localhost:8080/"},"outputId":"a7c21e7d-9d6c-4419-9d2c-cd91a2d3dd09","executionInfo":{"status":"ok","timestamp":1646221280807,"user_tz":-60,"elapsed":2909,"user":{"displayName":"Rodrigo Agerri","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhW2M3VpBFpNNhe0tx607nu7jJN85RXoeaB4nSw=s64","userId":"18226337086247956839"}}},"source":["device_name = tf.test.gpu_device_name()\n","if device_name != '/device:GPU:0':\n","  raise SystemError('GPU device not found')\n","print('Found GPU at: {}'.format(device_name))"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Found GPU at: /device:GPU:0\n"]}]},{"cell_type":"code","metadata":{"id":"uorMX_zrnISM","scrolled":true,"colab":{"base_uri":"https://localhost:8080/","height":35},"outputId":"f9cc7885-6529-47f9-d5e9-56aa532e1c43","executionInfo":{"status":"ok","timestamp":1646221289880,"user_tz":-60,"elapsed":8064,"user":{"displayName":"Rodrigo Agerri","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhW2M3VpBFpNNhe0tx607nu7jJN85RXoeaB4nSw=s64","userId":"18226337086247956839"}}},"source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","n_gpu = torch.cuda.device_count()\n","torch.cuda.get_device_name(0)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'Tesla K80'"]},"metadata":{},"execution_count":4}]},{"cell_type":"markdown","metadata":{"id":"dLcetMjZFjSH"},"source":["## Load and Preprocess Training Data"]},{"cell_type":"markdown","metadata":{"id":"2dal0ggBcYdD"},"source":["Dataset will be tokenized then split into training and validation sets. The validation set will be used to monitor training. For testing a separate test set will be loaded for analysis."]},{"cell_type":"code","source":["train_set = \"/content/drive/My Drive/Colab Notebooks/2022-ILTAPP/datasets/absa2016/en-train-acd-multilabel-transformers.csv\""],"metadata":{"id":"XSEBjz4EeVRf"},"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0ecREc7GnISW","scrolled":true,"colab":{"base_uri":"https://localhost:8080/","height":702},"outputId":"498c74ab-dfb1-4080-ff91-4634b7e5a458","executionInfo":{"status":"ok","timestamp":1646221377263,"user_tz":-60,"elapsed":897,"user":{"displayName":"Rodrigo Agerri","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhW2M3VpBFpNNhe0tx607nu7jJN85RXoeaB4nSw=s64","userId":"18226337086247956839"}}},"source":["# the file might have to be called train.csv\n","df = pd.read_csv(train_set)\n","df.info()\n","df.head()"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 1708 entries, 0 to 1707\n","Data columns (total 14 columns):\n"," #   Column                    Non-Null Count  Dtype \n","---  ------                    --------------  ----- \n"," 0   id                        1708 non-null   int64 \n"," 1   comment_text              1708 non-null   object\n"," 2   AMBIENCE#GENERAL          1708 non-null   int64 \n"," 3   DRINKS#PRICES             1708 non-null   int64 \n"," 4   DRINKS#QUALITY            1708 non-null   int64 \n"," 5   DRINKS#STYLE_OPTIONS      1708 non-null   int64 \n"," 6   FOOD#PRICES               1708 non-null   int64 \n"," 7   FOOD#QUALITY              1708 non-null   int64 \n"," 8   FOOD#STYLE_OPTIONS        1708 non-null   int64 \n"," 9   LOCATION#GENERAL          1708 non-null   int64 \n"," 10  RESTAURANT#GENERAL        1708 non-null   int64 \n"," 11  RESTAURANT#MISCELLANEOUS  1708 non-null   int64 \n"," 12  RESTAURANT#PRICES         1708 non-null   int64 \n"," 13  SERVICE#GENERAL           1708 non-null   int64 \n","dtypes: int64(13), object(1)\n","memory usage: 186.9+ KB\n"]},{"output_type":"execute_result","data":{"text/html":["\n","  <div id=\"df-80bd8d4e-dc48-4d2c-b195-e86fcf1b8c2d\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>comment_text</th>\n","      <th>AMBIENCE#GENERAL</th>\n","      <th>DRINKS#PRICES</th>\n","      <th>DRINKS#QUALITY</th>\n","      <th>DRINKS#STYLE_OPTIONS</th>\n","      <th>FOOD#PRICES</th>\n","      <th>FOOD#QUALITY</th>\n","      <th>FOOD#STYLE_OPTIONS</th>\n","      <th>LOCATION#GENERAL</th>\n","      <th>RESTAURANT#GENERAL</th>\n","      <th>RESTAURANT#MISCELLANEOUS</th>\n","      <th>RESTAURANT#PRICES</th>\n","      <th>SERVICE#GENERAL</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>2202</td>\n","      <td>Judging from previous posts this used to be a ...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>9326</td>\n","      <td>We, there were four of us, arrived at noon - t...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1034</td>\n","      <td>They never brought us complimentary noodles, i...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>4180</td>\n","      <td>The food was lousy - too sweet or too salty an...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1932</td>\n","      <td>After all that, they complained to me about th...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-80bd8d4e-dc48-4d2c-b195-e86fcf1b8c2d')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-80bd8d4e-dc48-4d2c-b195-e86fcf1b8c2d button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-80bd8d4e-dc48-4d2c-b195-e86fcf1b8c2d');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["     id  ... SERVICE#GENERAL\n","0  2202  ...               0\n","1  9326  ...               1\n","2  1034  ...               1\n","3  4180  ...               0\n","4  1932  ...               1\n","\n","[5 rows x 14 columns]"]},"metadata":{},"execution_count":11}]},{"cell_type":"code","metadata":{"id":"6AhWrzX7nITB","colab":{"base_uri":"https://localhost:8080/"},"outputId":"24d0b6d8-1335-4f4c-8922-0563fb14cc01","executionInfo":{"status":"ok","timestamp":1646221391110,"user_tz":-60,"elapsed":393,"user":{"displayName":"Rodrigo Agerri","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhW2M3VpBFpNNhe0tx607nu7jJN85RXoeaB4nSw=s64","userId":"18226337086247956839"}}},"source":["print('Unique comments: ', df.comment_text.nunique() == df.shape[0])\n","print('Null values: ', df.isnull().values.any())\n","# df[df.isna().any(axis=1)]"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Unique comments:  False\n","Null values:  False\n"]}]},{"cell_type":"code","metadata":{"id":"OkKpz_9eJRt7","colab":{"base_uri":"https://localhost:8080/"},"outputId":"c04012e2-d693-4441-8881-e9564f87d971","executionInfo":{"status":"ok","timestamp":1646221395251,"user_tz":-60,"elapsed":528,"user":{"displayName":"Rodrigo Agerri","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhW2M3VpBFpNNhe0tx607nu7jJN85RXoeaB4nSw=s64","userId":"18226337086247956839"}}},"source":["print('average sentence length: ', df.comment_text.str.split().str.len().mean())\n","print('stdev sentence length: ', df.comment_text.str.split().str.len().std())"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["average sentence length:  12.507611241217798\n","stdev sentence length:  8.285011666209963\n"]}]},{"cell_type":"code","metadata":{"id":"UVI59S9VaAfB","colab":{"base_uri":"https://localhost:8080/"},"outputId":"46befc44-fd85-407f-d84b-6938c9e63f85","executionInfo":{"status":"ok","timestamp":1646221403041,"user_tz":-60,"elapsed":533,"user":{"displayName":"Rodrigo Agerri","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhW2M3VpBFpNNhe0tx607nu7jJN85RXoeaB4nSw=s64","userId":"18226337086247956839"}}},"source":["cols = df.columns\n","label_cols = list(cols[2:])\n","num_labels = len(label_cols)\n","print('Label columns: ', label_cols)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Label columns:  ['AMBIENCE#GENERAL', 'DRINKS#PRICES', 'DRINKS#QUALITY', 'DRINKS#STYLE_OPTIONS', 'FOOD#PRICES', 'FOOD#QUALITY', 'FOOD#STYLE_OPTIONS', 'LOCATION#GENERAL', 'RESTAURANT#GENERAL', 'RESTAURANT#MISCELLANEOUS', 'RESTAURANT#PRICES', 'SERVICE#GENERAL']\n"]}]},{"cell_type":"code","metadata":{"id":"xzgA5qQgYIBZ","colab":{"base_uri":"https://localhost:8080/"},"outputId":"0195d7ed-e69b-41f3-c666-c4c94b27fe5e","executionInfo":{"status":"ok","timestamp":1646221410010,"user_tz":-60,"elapsed":400,"user":{"displayName":"Rodrigo Agerri","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhW2M3VpBFpNNhe0tx607nu7jJN85RXoeaB4nSw=s64","userId":"18226337086247956839"}}},"source":["print('Count of 1 per label: \\n', df[label_cols].sum(), '\\n') # Label counts, may need to downsample or upsample\n","print('Count of 0 per label: \\n', df[label_cols].eq(0).sum())"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Count of 1 per label: \n"," AMBIENCE#GENERAL            226\n","DRINKS#PRICES                20\n","DRINKS#QUALITY               46\n","DRINKS#STYLE_OPTIONS         30\n","FOOD#PRICES                  82\n","FOOD#QUALITY                681\n","FOOD#STYLE_OPTIONS          128\n","LOCATION#GENERAL             28\n","RESTAURANT#GENERAL          421\n","RESTAURANT#MISCELLANEOUS     97\n","RESTAURANT#PRICES            80\n","SERVICE#GENERAL             419\n","dtype: int64 \n","\n","Count of 0 per label: \n"," AMBIENCE#GENERAL            1482\n","DRINKS#PRICES               1688\n","DRINKS#QUALITY              1662\n","DRINKS#STYLE_OPTIONS        1678\n","FOOD#PRICES                 1626\n","FOOD#QUALITY                1027\n","FOOD#STYLE_OPTIONS          1580\n","LOCATION#GENERAL            1680\n","RESTAURANT#GENERAL          1287\n","RESTAURANT#MISCELLANEOUS    1611\n","RESTAURANT#PRICES           1628\n","SERVICE#GENERAL             1289\n","dtype: int64\n"]}]},{"cell_type":"code","metadata":{"id":"uFpSd4JzaAae"},"source":["df = df.sample(frac=1).reset_index(drop=True) #shuffle rows"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## ASSIGNMENT 1 \n","\n","+ TODO: Generate an extra column in the pandas dataframe containing:\n","++ one_hot_labels as header.\n","++ the list of aspect values extracted from each aspect column.\n","\n","The dataframe obtained should be as follows:"],"metadata":{"id":"VScwqXXfv_40"}},{"cell_type":"code","metadata":{"id":"0DF3ddjej5vd","colab":{"base_uri":"https://localhost:8080/","height":372},"outputId":"aa53c2e6-738b-4c16-c5f0-3f6727f96266","executionInfo":{"status":"ok","timestamp":1646221426610,"user_tz":-60,"elapsed":393,"user":{"displayName":"Rodrigo Agerri","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhW2M3VpBFpNNhe0tx607nu7jJN85RXoeaB4nSw=s64","userId":"18226337086247956839"}}},"source":["## TODO generate one_hot_labels column"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["\n","  <div id=\"df-aaba4e48-2ff1-4dfb-8b4a-a663f09c3647\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>comment_text</th>\n","      <th>AMBIENCE#GENERAL</th>\n","      <th>DRINKS#PRICES</th>\n","      <th>DRINKS#QUALITY</th>\n","      <th>DRINKS#STYLE_OPTIONS</th>\n","      <th>FOOD#PRICES</th>\n","      <th>FOOD#QUALITY</th>\n","      <th>FOOD#STYLE_OPTIONS</th>\n","      <th>LOCATION#GENERAL</th>\n","      <th>RESTAURANT#GENERAL</th>\n","      <th>RESTAURANT#MISCELLANEOUS</th>\n","      <th>RESTAURANT#PRICES</th>\n","      <th>SERVICE#GENERAL</th>\n","      <th>one_hot_labels</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>737</td>\n","      <td>Great sushi experience.</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>[0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0]</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>9253</td>\n","      <td>The brioche and lollies as party favors is a c...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>[0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0]</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>7900</td>\n","      <td>Indoor was very cozy and cute.</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>2278</td>\n","      <td>Good Experience</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0]</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>2572</td>\n","      <td>The have over 100 different beers to offer thi...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>[0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0]</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-aaba4e48-2ff1-4dfb-8b4a-a663f09c3647')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-aaba4e48-2ff1-4dfb-8b4a-a663f09c3647 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-aaba4e48-2ff1-4dfb-8b4a-a663f09c3647');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["     id  ...                        one_hot_labels\n","0   737  ...  [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0]\n","1  9253  ...  [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0]\n","2  7900  ...  [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n","3  2278  ...  [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0]\n","4  2572  ...  [0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0]\n","\n","[5 rows x 15 columns]"]},"metadata":{},"execution_count":17}]},{"cell_type":"code","metadata":{"id":"MlhHifh5bW7e"},"source":["labels = list(df.one_hot_labels.values)\n","comments = list(df.comment_text.values)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"IlMHfElhGJzc"},"source":["Load the pretrained tokenizer that corresponds to your choice in model. e.g.,\n","\n","```\n","BERT:\n","tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True) \n","\n","\n","RoBERTa:\n","tokenizer = RobertaTokenizer.from_pretrained('roberta-base', do_lower_case=False)\n","```\n"]},{"cell_type":"markdown","metadata":{"id":"IhVr8SziL_PY"},"source":["NOTE: In order to avoid memory issues with Google Colab, I enforce a max_length of 100 tokens. Note that some sentences may not adequately represent each label because of this.\n","\n","## ASSIGNMENT 2 \n","\n","+ TODO: Instantiate the tokenizer from \"bert-base-uncased\" model in lowercase mode. HINT: Check huggingface course on tokenizers.\n","+ TODO: Investigate how defining different max_lengths affect performance on the test set evaluation. You may try values of 64, 128 (in addition to 100).\n"]},{"cell_type":"code","metadata":{"id":"HNsEu-vUur-4","colab":{"base_uri":"https://localhost:8080/"},"outputId":"5a5e8dda-ffed-4e2f-d2dc-f07f56275eb4","executionInfo":{"status":"ok","timestamp":1646221633973,"user_tz":-60,"elapsed":7808,"user":{"displayName":"Rodrigo Agerri","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhW2M3VpBFpNNhe0tx607nu7jJN85RXoeaB4nSw=s64","userId":"18226337086247956839"}}},"source":["# TODO instantiate tokenizer\n","encodings = tokenizer.batch_encode_plus(comments, truncation=True, max_length=max_length, pad_to_max_length=True) # tokenizer's encoding method\n","print('tokenizer outputs: ', encodings.keys())"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2257: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n"]},{"output_type":"stream","name":"stdout","text":["tokenizer outputs:  dict_keys(['input_ids', 'token_type_ids', 'attention_mask'])\n"]}]},{"cell_type":"code","metadata":{"id":"l6CCLSjfur-9"},"source":["input_ids = encodings['input_ids'] # tokenized and encoded sentences\n","token_type_ids = encodings['token_type_ids'] # token type ids\n","attention_masks = encodings['attention_mask'] # attention masks"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vSOFbThlYcpb","colab":{"base_uri":"https://localhost:8080/"},"outputId":"b84761e7-2d5c-4881-a868-c7140ba152b9","executionInfo":{"status":"ok","timestamp":1646221644676,"user_tz":-60,"elapsed":716,"user":{"displayName":"Rodrigo Agerri","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhW2M3VpBFpNNhe0tx607nu7jJN85RXoeaB4nSw=s64","userId":"18226337086247956839"}}},"source":["# Identifying indices of 'one_hot_labels' entries that only occur once - this will allow us to stratify split our training data later\n","label_counts = df.one_hot_labels.astype(str).value_counts()\n","one_freq = label_counts[label_counts==1].keys()\n","one_freq_idxs = sorted(list(df[df.one_hot_labels.astype(str).isin(one_freq)].index), reverse=True)\n","print('df label indices with only one instance: ', one_freq_idxs)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["df label indices with only one instance:  [1696, 1614, 1580, 1577, 1568, 1545, 1542, 1538, 1486, 1434, 1389, 1377, 1334, 1262, 1255, 1208, 1202, 1175, 1070, 994, 977, 931, 927, 892, 870, 842, 760, 739, 725, 721, 679, 677, 580, 538, 520, 481, 459, 437, 421, 393, 375, 301, 280, 228, 149]\n"]}]},{"cell_type":"code","metadata":{"id":"CQQ7CoOag_r7"},"source":["# Gathering single instance inputs to force into the training set after stratified split\n","one_freq_input_ids = [input_ids.pop(i) for i in one_freq_idxs]\n","one_freq_token_types = [token_type_ids.pop(i) for i in one_freq_idxs]\n","one_freq_attention_masks = [attention_masks.pop(i) for i in one_freq_idxs]\n","one_freq_labels = [labels.pop(i) for i in one_freq_idxs]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"r9PxAt48HRRj"},"source":["Be sure to handle all classes during validation using \"stratify\" during train/validation split:"]},{"cell_type":"code","metadata":{"id":"WPFaq4ufnIT2","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1646221692479,"user_tz":-60,"elapsed":391,"user":{"displayName":"Rodrigo Agerri","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhW2M3VpBFpNNhe0tx607nu7jJN85RXoeaB4nSw=s64","userId":"18226337086247956839"}},"outputId":"c02c9bd1-14f7-47f1-f549-7e37e533ad97"},"source":["# Use train_test_split to split our data into train and validation sets\n","\n","train_inputs, validation_inputs, train_labels, validation_labels, train_token_types, validation_token_types, train_masks, validation_masks = train_test_split(input_ids, labels, token_type_ids,attention_masks,\n","                                                            random_state=2020, test_size=0.10, stratify = labels)\n","\n","# Add one frequency data to train data\n","train_inputs.extend(one_freq_input_ids)\n","train_labels.extend(one_freq_labels)\n","train_masks.extend(one_freq_attention_masks)\n","train_token_types.extend(one_freq_token_types)\n","\n","# Convert all of our data into torch tensors, the required datatype for our model\n","train_inputs = torch.tensor(train_inputs)\n","train_labels = torch.tensor(train_labels)\n","train_masks = torch.tensor(train_masks)\n","train_token_types = torch.tensor(train_token_types)\n","\n","validation_inputs = torch.tensor(validation_inputs)\n","validation_labels = torch.tensor(validation_labels)\n","validation_masks = torch.tensor(validation_masks)\n","validation_token_types = torch.tensor(validation_token_types)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:14: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n","  \n"]}]},{"cell_type":"code","metadata":{"id":"ZRnuLna-nIT4"},"source":["# Select a batch size for training.\n","batch_size = 16\n","\n","# Create an iterator of our data with torch DataLoader. This helps save on memory during training because, unlike a for loop, \n","# with an iterator the entire dataset does not need to be loaded into memory\n","\n","train_data = TensorDataset(train_inputs, train_masks, train_labels, train_token_types)\n","train_sampler = RandomSampler(train_data)\n","train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n","\n","validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels, validation_token_types)\n","validation_sampler = SequentialSampler(validation_data)\n","validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"iiFRnP_ZTBFa"},"source":["torch.save(validation_dataloader,'validation_data_loader')\n","torch.save(train_dataloader,'train_data_loader')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ncGteBuSFuZM"},"source":["## Load Model & Set Params"]},{"cell_type":"markdown","metadata":{"id":"Z0dL-Bz_NrGj"},"source":["Load the appropriate model below, each model already contains a single dense layer for classification on top.\n","\n","\n","\n","```\n","BERT:\n","model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=num_labels)\n","\n","RoBERTa:\n","model = RobertaForSequenceClassification.from_pretrained('roberta-base', num_labels=num_labels)\n","```\n","\n"]},{"cell_type":"markdown","source":["## ASSIGNMENT 3\n","\n","+ TODO: load the model for SequenceClassification corresponding to the tokenizer instantiated above."],"metadata":{"id":"C1tDgPE6xf6u"}},{"cell_type":"code","metadata":{"id":"Ujk4k16DnIT6","colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["74775eb164d34fe7a5d05c9cc10a7601","25c1be47214b45d48d96b0bfce4e0425","c46f04badde74bd386012d55a406cd24","35339d2e0c534c7695475c0ad1af3414","4bc493d090df47549f908ed9163d7c2a","316576ac139d4b118f7561935cb67633","86b70845e28e43c0b222a233174129c9","3d480310193a41c1912f3702c58a38e4","c881011353c24dd5938f0d2d6efd67a2","ae6847bf0d2947a7bce6c7cffc054cb9","aa09584d3447455b879f4055c4972e37"]},"executionInfo":{"status":"ok","timestamp":1646221795631,"user_tz":-60,"elapsed":19727,"user":{"displayName":"Rodrigo Agerri","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhW2M3VpBFpNNhe0tx607nu7jJN85RXoeaB4nSw=s64","userId":"18226337086247956839"}},"outputId":"7a73dc80-52f7-4b56-a7fe-e3ea7929b236"},"source":["# TODO Load model, the pretrained model will include a single linear classification layer on top for classification. \n","\n","model.cuda()"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"74775eb164d34fe7a5d05c9cc10a7601","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/420M [00:00<?, ?B/s]"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias']\n","- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"execute_result","data":{"text/plain":["BertForSequenceClassification(\n","  (bert): BertModel(\n","    (embeddings): BertEmbeddings(\n","      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n","      (position_embeddings): Embedding(512, 768)\n","      (token_type_embeddings): Embedding(2, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): BertEncoder(\n","      (layer): ModuleList(\n","        (0): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (1): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (2): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (3): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (4): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (5): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (6): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (7): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (8): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (9): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (10): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (11): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (pooler): BertPooler(\n","      (dense): Linear(in_features=768, out_features=768, bias=True)\n","      (activation): Tanh()\n","    )\n","  )\n","  (dropout): Dropout(p=0.1, inplace=False)\n","  (classifier): Linear(in_features=768, out_features=12, bias=True)\n",")"]},"metadata":{},"execution_count":29}]},{"cell_type":"markdown","metadata":{"id":"jGE4gv9qfhRG"},"source":["Setting custom optimization parameters for the AdamW optimizer https://huggingface.co/transformers/main_classes/optimizer_schedules.html"]},{"cell_type":"code","metadata":{"id":"GsV8zwWYnIT9"},"source":["# setting custom optimization parameters. You may implement a scheduler here as well.\n","param_optimizer = list(model.named_parameters())\n","no_decay = ['bias', 'gamma', 'beta']\n","optimizer_grouped_parameters = [\n","    {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n","     'weight_decay_rate': 0.01},\n","    {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\n","     'weight_decay_rate': 0.0}\n","]"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#pip install tensorflow_addons"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4sOyXXDCnxR4","executionInfo":{"status":"ok","timestamp":1644746149635,"user_tz":-60,"elapsed":3398,"user":{"displayName":"Rosa Ryhänen","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04493503792992534699"}},"outputId":"e63d50cf-2803-4562-e82a-f48654316aaa"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting tensorflow_addons\n","  Downloading tensorflow_addons-0.15.0-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n","\u001b[?25l\r\u001b[K     |▎                               | 10 kB 21.8 MB/s eta 0:00:01\r\u001b[K     |▋                               | 20 kB 30.8 MB/s eta 0:00:01\r\u001b[K     |▉                               | 30 kB 35.5 MB/s eta 0:00:01\r\u001b[K     |█▏                              | 40 kB 39.4 MB/s eta 0:00:01\r\u001b[K     |█▌                              | 51 kB 35.0 MB/s eta 0:00:01\r\u001b[K     |█▊                              | 61 kB 38.0 MB/s eta 0:00:01\r\u001b[K     |██                              | 71 kB 25.3 MB/s eta 0:00:01\r\u001b[K     |██▍                             | 81 kB 27.3 MB/s eta 0:00:01\r\u001b[K     |██▋                             | 92 kB 29.2 MB/s eta 0:00:01\r\u001b[K     |███                             | 102 kB 29.4 MB/s eta 0:00:01\r\u001b[K     |███▎                            | 112 kB 29.4 MB/s eta 0:00:01\r\u001b[K     |███▌                            | 122 kB 29.4 MB/s eta 0:00:01\r\u001b[K     |███▉                            | 133 kB 29.4 MB/s eta 0:00:01\r\u001b[K     |████▏                           | 143 kB 29.4 MB/s eta 0:00:01\r\u001b[K     |████▍                           | 153 kB 29.4 MB/s eta 0:00:01\r\u001b[K     |████▊                           | 163 kB 29.4 MB/s eta 0:00:01\r\u001b[K     |█████                           | 174 kB 29.4 MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 184 kB 29.4 MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 194 kB 29.4 MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 204 kB 29.4 MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 215 kB 29.4 MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 225 kB 29.4 MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 235 kB 29.4 MB/s eta 0:00:01\r\u001b[K     |███████                         | 245 kB 29.4 MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 256 kB 29.4 MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 266 kB 29.4 MB/s eta 0:00:01\r\u001b[K     |████████                        | 276 kB 29.4 MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 286 kB 29.4 MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 296 kB 29.4 MB/s eta 0:00:01\r\u001b[K     |████████▉                       | 307 kB 29.4 MB/s eta 0:00:01\r\u001b[K     |█████████                       | 317 kB 29.4 MB/s eta 0:00:01\r\u001b[K     |█████████▍                      | 327 kB 29.4 MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 337 kB 29.4 MB/s eta 0:00:01\r\u001b[K     |██████████                      | 348 kB 29.4 MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 358 kB 29.4 MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 368 kB 29.4 MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 378 kB 29.4 MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 389 kB 29.4 MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 399 kB 29.4 MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 409 kB 29.4 MB/s eta 0:00:01\r\u001b[K     |████████████                    | 419 kB 29.4 MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 430 kB 29.4 MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 440 kB 29.4 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 450 kB 29.4 MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 460 kB 29.4 MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 471 kB 29.4 MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 481 kB 29.4 MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 491 kB 29.4 MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 501 kB 29.4 MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 512 kB 29.4 MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 522 kB 29.4 MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 532 kB 29.4 MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 542 kB 29.4 MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 552 kB 29.4 MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 563 kB 29.4 MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 573 kB 29.4 MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 583 kB 29.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 593 kB 29.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 604 kB 29.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 614 kB 29.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 624 kB 29.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 634 kB 29.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 645 kB 29.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████▉             | 655 kB 29.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 665 kB 29.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 675 kB 29.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 686 kB 29.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 696 kB 29.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 706 kB 29.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 716 kB 29.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 727 kB 29.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 737 kB 29.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▌          | 747 kB 29.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 757 kB 29.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 768 kB 29.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 778 kB 29.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 788 kB 29.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 798 kB 29.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 808 kB 29.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 819 kB 29.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 829 kB 29.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 839 kB 29.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 849 kB 29.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 860 kB 29.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 870 kB 29.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▎      | 880 kB 29.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 890 kB 29.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 901 kB 29.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 911 kB 29.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 921 kB 29.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 931 kB 29.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 942 kB 29.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 952 kB 29.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▋    | 962 kB 29.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 972 kB 29.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 983 kB 29.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 993 kB 29.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 1.0 MB 29.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 1.0 MB 29.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 1.0 MB 29.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 1.0 MB 29.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 1.0 MB 29.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 1.1 MB 29.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▋ | 1.1 MB 29.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 1.1 MB 29.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 1.1 MB 29.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 1.1 MB 29.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 1.1 MB 29.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.1 MB 29.4 MB/s \n","\u001b[?25hRequirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow_addons) (2.7.1)\n","Installing collected packages: tensorflow-addons\n","Successfully installed tensorflow-addons-0.15.0\n"]}]},{"cell_type":"code","metadata":{"id":"aOomZIEIoHOL"},"source":["#import tensorflow as tf\n","#import tensorflow_addons as tfa\n","\n","#optimizer = tfa.optimizers.AdamW(optimizer_grouped_parameters,lr=2e-5)\n","#optimizer = tfa.optimizers.AdamW(model.parameters(),lr=2e-5)  # Default optimization\n","optimizer = torch.optim.AdamW(optimizer_grouped_parameters,lr=2e-5)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"JRQQZ8zIFzLW"},"source":["## Train Model"]},{"cell_type":"code","metadata":{"id":"uDLZmEC_oKo3","colab":{"base_uri":"https://localhost:8080/"},"outputId":"fb56b413-c718-4b10-b5d1-9ad97bac8880","executionInfo":{"status":"ok","timestamp":1646222178215,"user_tz":-60,"elapsed":229092,"user":{"displayName":"Rodrigo Agerri","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhW2M3VpBFpNNhe0tx607nu7jJN85RXoeaB4nSw=s64","userId":"18226337086247956839"}}},"source":["# Store our loss and accuracy for plotting\n","train_loss_set = []\n","\n","# Number of training epochs (authors recommend between 2 and 4)\n","epochs = 4\n","\n","# trange is a tqdm wrapper around the normal python range\n","for _ in trange(epochs, desc=\"Epoch\"):\n","\n","  # Training\n","  \n","  # Set our model to training mode (as opposed to evaluation mode)\n","  model.train()\n","\n","  # Tracking variables\n","  tr_loss = 0 #running loss\n","  nb_tr_examples, nb_tr_steps = 0, 0\n","  \n","  # Train the data for one epoch\n","  for step, batch in enumerate(train_dataloader):\n","    # Add batch to GPU\n","    batch = tuple(t.to(device) for t in batch)\n","    # Unpack the inputs from our dataloader\n","    b_input_ids, b_input_mask, b_labels, b_token_types = batch\n","    # Clear out the gradients (by default they accumulate)\n","    optimizer.zero_grad()\n","\n","    # # Forward pass for multiclass classification\n","    # outputs = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask, labels=b_labels)\n","    # loss = outputs[0]\n","    # logits = outputs[1]\n","\n","    # Forward pass for multilabel classification\n","    outputs = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)\n","    logits = outputs[0]\n","    loss_func = BCEWithLogitsLoss() \n","    loss = loss_func(logits.view(-1,num_labels),b_labels.type_as(logits).view(-1,num_labels)) #convert labels to float for calculation\n","    # loss_func = BCELoss() \n","    # loss = loss_func(torch.sigmoid(logits.view(-1,num_labels)),b_labels.type_as(logits).view(-1,num_labels)) #convert labels to float for calculation\n","    train_loss_set.append(loss.item())    \n","\n","    # Backward pass\n","    loss.backward()\n","    # Update parameters and take a step using the computed gradient\n","    optimizer.step()\n","    # scheduler.step()\n","    # Update tracking variables\n","    tr_loss += loss.item()\n","    nb_tr_examples += b_input_ids.size(0)\n","    nb_tr_steps += 1\n","\n","  print(\"Train loss: {}\".format(tr_loss/nb_tr_steps))\n","\n","###############################################################################\n","\n","  # Validation\n","\n","  # Put model in evaluation mode to evaluate loss on the validation set\n","  model.eval()\n","\n","  # Variables to gather full output\n","  logit_preds,true_labels,pred_labels,tokenized_texts = [],[],[],[]\n","\n","  # Predict\n","  for i, batch in enumerate(validation_dataloader):\n","    batch = tuple(t.to(device) for t in batch)\n","    # Unpack the inputs from our dataloader\n","    b_input_ids, b_input_mask, b_labels, b_token_types = batch\n","    with torch.no_grad():\n","      # Forward pass\n","      outs = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)\n","      b_logit_pred = outs[0]\n","      pred_label = torch.sigmoid(b_logit_pred)\n","\n","      b_logit_pred = b_logit_pred.detach().cpu().numpy()\n","      pred_label = pred_label.to('cpu').numpy()\n","      b_labels = b_labels.to('cpu').numpy()\n","\n","    tokenized_texts.append(b_input_ids)\n","    logit_preds.append(b_logit_pred)\n","    true_labels.append(b_labels)\n","    pred_labels.append(pred_label)\n","\n","  # Flatten outputs\n","  pred_labels = [item for sublist in pred_labels for item in sublist]\n","  true_labels = [item for sublist in true_labels for item in sublist]\n","\n","  # Calculate Accuracy\n","  threshold = 0.50\n","  pred_bools = [pl>threshold for pl in pred_labels]\n","  true_bools = [tl==1 for tl in true_labels]\n","  val_f1_accuracy = f1_score(true_bools,pred_bools,average='micro')*100\n","  val_flat_accuracy = accuracy_score(true_bools, pred_bools)*100\n","\n","  print('F1 Validation Accuracy: ', val_f1_accuracy)\n","  print('F1 Macro Validation Accuracy: ', val_flat_accuracy)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["\rEpoch:   0%|          | 0/4 [00:00<?, ?it/s]"]},{"output_type":"stream","name":"stdout","text":["Train loss: 0.212693580800725\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:  25%|██▌       | 1/4 [00:57<02:51, 57.20s/it]"]},{"output_type":"stream","name":"stdout","text":["F1 Validation Accuracy:  71.79487179487178\n","F1 Macro Validation Accuracy:  56.886227544910184\n","Train loss: 0.1637338823878888\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:  50%|█████     | 2/4 [01:54<01:54, 57.15s/it]"]},{"output_type":"stream","name":"stdout","text":["F1 Validation Accuracy:  75.13513513513513\n","F1 Macro Validation Accuracy:  62.874251497005986\n","Train loss: 0.13025602068483216\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:  75%|███████▌  | 3/4 [02:51<00:57, 57.14s/it]"]},{"output_type":"stream","name":"stdout","text":["F1 Validation Accuracy:  76.1904761904762\n","F1 Macro Validation Accuracy:  65.26946107784431\n","Train loss: 0.10558721837923699\n"]},{"output_type":"stream","name":"stderr","text":["Epoch: 100%|██████████| 4/4 [03:48<00:00, 57.15s/it]"]},{"output_type":"stream","name":"stdout","text":["F1 Validation Accuracy:  80.20833333333334\n","F1 Macro Validation Accuracy:  68.8622754491018\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}]},{"cell_type":"code","metadata":{"id":"aiBeiBSRoOuz"},"source":["torch.save(model.state_dict(), '/content/drive/My Drive/Colab Notebooks/2022-ILTAPP/bert-multilable-acd-en')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_7dd2GE3F4yK"},"source":["## Load and Preprocess Test Data"]},{"cell_type":"code","source":["test_set = \"/content/drive/My Drive/Colab Notebooks/2022-ILTAPP/datasets/absa2016/en-test-acd-multilabel-transformers.csv\""],"metadata":{"id":"C_BOfaL0zwXa"},"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"G5Q7hC4GFOLJ","colab":{"base_uri":"https://localhost:8080/","height":250},"outputId":"6f26ca1a-f38b-4ba9-f02c-7cea5198367a","executionInfo":{"status":"ok","timestamp":1646222300350,"user_tz":-60,"elapsed":1125,"user":{"displayName":"Rodrigo Agerri","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhW2M3VpBFpNNhe0tx607nu7jJN85RXoeaB4nSw=s64","userId":"18226337086247956839"}}},"source":["test_df = pd.read_csv(test_set)\n","test_df.head()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["\n","  <div id=\"df-fda21a18-e727-461a-b1da-8c5f4dafe157\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>comment_text</th>\n","      <th>AMBIENCE#GENERAL</th>\n","      <th>DRINKS#PRICES</th>\n","      <th>DRINKS#QUALITY</th>\n","      <th>DRINKS#STYLE_OPTIONS</th>\n","      <th>FOOD#PRICES</th>\n","      <th>FOOD#QUALITY</th>\n","      <th>FOOD#STYLE_OPTIONS</th>\n","      <th>LOCATION#GENERAL</th>\n","      <th>RESTAURANT#GENERAL</th>\n","      <th>RESTAURANT#MISCELLANEOUS</th>\n","      <th>RESTAURANT#PRICES</th>\n","      <th>SERVICE#GENERAL</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>12201</td>\n","      <td>Yum!</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>19325</td>\n","      <td>Serves really good sushi.</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>11033</td>\n","      <td>Not the biggest portions but adequate.</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>14179</td>\n","      <td>Green Tea creme brulee is a must!</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>11931</td>\n","      <td>Don't leave the restaurant without it.</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fda21a18-e727-461a-b1da-8c5f4dafe157')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-fda21a18-e727-461a-b1da-8c5f4dafe157 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-fda21a18-e727-461a-b1da-8c5f4dafe157');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["      id  ... SERVICE#GENERAL\n","0  12201  ...               0\n","1  19325  ...               0\n","2  11033  ...               0\n","3  14179  ...               0\n","4  11931  ...               0\n","\n","[5 rows x 14 columns]"]},"metadata":{},"execution_count":38}]},{"cell_type":"markdown","source":["## ASSIGNMENT 4\n","\n","+ TODO add one_hot_labels column to test data as for ASSIGNMENT 1."],"metadata":{"id":"L0UukVPlyM9_"}},{"cell_type":"code","metadata":{"id":"77rjCrMGpYxz","colab":{"base_uri":"https://localhost:8080/","height":372},"outputId":"1a3a0db0-db28-4456-ee06-1d126a99d242","executionInfo":{"status":"ok","timestamp":1646222305380,"user_tz":-60,"elapsed":399,"user":{"displayName":"Rodrigo Agerri","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhW2M3VpBFpNNhe0tx607nu7jJN85RXoeaB4nSw=s64","userId":"18226337086247956839"}}},"source":["cols_test = test_df.columns\n","label_cols_test = list(cols_test[2:])\n","num_labels_test = len(label_cols_test)\n","# TODO add one_hot_labels column to test set\n","test_df.head()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["\n","  <div id=\"df-1635c8b8-cfe2-48cc-a289-031758be43a8\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>comment_text</th>\n","      <th>AMBIENCE#GENERAL</th>\n","      <th>DRINKS#PRICES</th>\n","      <th>DRINKS#QUALITY</th>\n","      <th>DRINKS#STYLE_OPTIONS</th>\n","      <th>FOOD#PRICES</th>\n","      <th>FOOD#QUALITY</th>\n","      <th>FOOD#STYLE_OPTIONS</th>\n","      <th>LOCATION#GENERAL</th>\n","      <th>RESTAURANT#GENERAL</th>\n","      <th>RESTAURANT#MISCELLANEOUS</th>\n","      <th>RESTAURANT#PRICES</th>\n","      <th>SERVICE#GENERAL</th>\n","      <th>one_hot_labels</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>12201</td>\n","      <td>Yum!</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>[0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0]</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>19325</td>\n","      <td>Serves really good sushi.</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>[0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0]</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>11033</td>\n","      <td>Not the biggest portions but adequate.</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>[0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0]</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>14179</td>\n","      <td>Green Tea creme brulee is a must!</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>[0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0]</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>11931</td>\n","      <td>Don't leave the restaurant without it.</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>[0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0]</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1635c8b8-cfe2-48cc-a289-031758be43a8')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-1635c8b8-cfe2-48cc-a289-031758be43a8 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-1635c8b8-cfe2-48cc-a289-031758be43a8');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["      id  ...                        one_hot_labels\n","0  12201  ...  [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0]\n","1  19325  ...  [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0]\n","2  11033  ...  [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0]\n","3  14179  ...  [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0]\n","4  11931  ...  [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0]\n","\n","[5 rows x 15 columns]"]},"metadata":{},"execution_count":39}]},{"cell_type":"code","metadata":{"id":"1a41OmU2i7qp"},"source":["# Gathering input data\n","test_labels = list(test_df.one_hot_labels.values)\n","test_comments = list(test_df.comment_text.values)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"amySMO8EQzf2","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1646222343074,"user_tz":-60,"elapsed":1405,"user":{"displayName":"Rodrigo Agerri","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhW2M3VpBFpNNhe0tx607nu7jJN85RXoeaB4nSw=s64","userId":"18226337086247956839"}},"outputId":"438a810d-cd4d-40c8-faf4-2d6a30fc5858"},"source":["# Encoding input data\n","test_encodings = tokenizer.batch_encode_plus(test_comments,truncation=True, max_length=max_length,pad_to_max_length=True)\n","test_input_ids = test_encodings['input_ids']\n","test_token_type_ids = test_encodings['token_type_ids']\n","test_attention_masks = test_encodings['attention_mask']"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2257: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n"]}]},{"cell_type":"code","metadata":{"id":"hqOfi9fkRaRN"},"source":["# Make tensors out of data\n","test_inputs = torch.tensor(test_input_ids)\n","test_labels = torch.tensor(test_labels)\n","test_masks = torch.tensor(test_attention_masks)\n","test_token_types = torch.tensor(test_token_type_ids)\n","# Create test dataloader\n","test_data = TensorDataset(test_inputs, test_masks, test_labels, test_token_types)\n","test_sampler = SequentialSampler(test_data)\n","test_dataloader = DataLoader(test_data, sampler=test_sampler, batch_size=batch_size)\n","# Save test dataloader\n","torch.save(test_dataloader,'test_data_loader')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"PFTWxCA_GBau"},"source":["## Prediction and Evaluation"]},{"cell_type":"code","metadata":{"id":"NPvrL6OFSQvf"},"source":["# Test\n","\n","# Put model in evaluation mode to evaluate loss on the validation set\n","model.eval()\n","\n","#track variables\n","logit_preds,true_labels,pred_labels,tokenized_texts = [],[],[],[]\n","\n","# Predict\n","for i, batch in enumerate(test_dataloader):\n","  batch = tuple(t.to(device) for t in batch)\n","  # Unpack the inputs from our dataloader\n","  b_input_ids, b_input_mask, b_labels, b_token_types = batch\n","  with torch.no_grad():\n","    # Forward pass\n","    outs = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)\n","    b_logit_pred = outs[0]\n","    pred_label = torch.sigmoid(b_logit_pred)\n","\n","    b_logit_pred = b_logit_pred.detach().cpu().numpy()\n","    pred_label = pred_label.to('cpu').numpy()\n","    b_labels = b_labels.to('cpu').numpy()\n","\n","  tokenized_texts.append(b_input_ids)\n","  logit_preds.append(b_logit_pred)\n","  true_labels.append(b_labels)\n","  pred_labels.append(pred_label)\n","\n","# Flatten outputs\n","tokenized_texts = [item for sublist in tokenized_texts for item in sublist]\n","pred_labels = [item for sublist in pred_labels for item in sublist]\n","true_labels = [item for sublist in true_labels for item in sublist]\n","# Converting flattened binary values to boolean values\n","true_bools = [tl==1 for tl in true_labels]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"bQeGWqeMzAoZ"},"source":["We need to threshold our sigmoid function outputs which range from [0, 1]. Below I use 0.50 as a threshold."]},{"cell_type":"markdown","source":["## ASSIGNMENT 5\n","\n","+ TODO use scikit-learn functions to calculate F1 micro and Accuracy scores. HINT: you need to use true_bools and pred_bools from above.\n","+ TODO: use scikit-learn function to provide a classification report.\n","\n","Output should be similar to the following:"],"metadata":{"id":"4ZMzAQ0ozEec"}},{"cell_type":"code","metadata":{"id":"BZcZUcYOxxmM","colab":{"base_uri":"https://localhost:8080/"},"outputId":"1c2a90a4-6e6e-4d61-ac8f-5751c4a9356b","executionInfo":{"status":"ok","timestamp":1646222378604,"user_tz":-60,"elapsed":455,"user":{"displayName":"Rodrigo Agerri","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhW2M3VpBFpNNhe0tx607nu7jJN85RXoeaB4nSw=s64","userId":"18226337086247956839"}}},"source":["pred_bools = [pl>0.50 for pl in pred_labels] #boolean output after thresholding\n","\n","# TODO Print and save classification report\n","\n","pickle.dump(clf_report, open('classification_report_original_10.txt','wb')) #save report\n","print(clf_report)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Test F1 Accuracy:  0.7581120943952803\n","Test F1 Macro Accuracy:  0.6303236797274276 \n","\n","                          precision    recall  f1-score   support\n","\n","        AMBIENCE#GENERAL       0.59      0.91      0.72        57\n","           DRINKS#PRICES       0.00      0.00      0.00         3\n","          DRINKS#QUALITY       0.00      0.00      0.00        21\n","    DRINKS#STYLE_OPTIONS       0.00      0.00      0.00        12\n","             FOOD#PRICES       1.00      0.18      0.31        22\n","            FOOD#QUALITY       0.85      0.96      0.90       226\n","      FOOD#STYLE_OPTIONS       0.67      0.12      0.21        48\n","        LOCATION#GENERAL       0.00      0.00      0.00        13\n","      RESTAURANT#GENERAL       0.89      0.72      0.80       142\n","RESTAURANT#MISCELLANEOUS       0.67      0.06      0.11        33\n","       RESTAURANT#PRICES       1.00      0.19      0.32        21\n","         SERVICE#GENERAL       0.93      0.88      0.90       145\n","\n","               micro avg       0.84      0.69      0.76       743\n","               macro avg       0.55      0.34      0.36       743\n","            weighted avg       0.79      0.69      0.69       743\n","             samples avg       0.77      0.73      0.74       743\n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]}]},{"cell_type":"markdown","metadata":{"id":"5rLqrHK87eir"},"source":["## Output Dataframe"]},{"cell_type":"code","metadata":{"id":"CJBkRdGN1hzx","colab":{"base_uri":"https://localhost:8080/"},"outputId":"254e6003-4b0a-4440-c7e4-a842c4db2be4","executionInfo":{"status":"ok","timestamp":1646222396800,"user_tz":-60,"elapsed":477,"user":{"displayName":"Rodrigo Agerri","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhW2M3VpBFpNNhe0tx607nu7jJN85RXoeaB4nSw=s64","userId":"18226337086247956839"}}},"source":["idx2label = dict(zip(range(12),label_cols))\n","print(idx2label)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["{0: 'AMBIENCE#GENERAL', 1: 'DRINKS#PRICES', 2: 'DRINKS#QUALITY', 3: 'DRINKS#STYLE_OPTIONS', 4: 'FOOD#PRICES', 5: 'FOOD#QUALITY', 6: 'FOOD#STYLE_OPTIONS', 7: 'LOCATION#GENERAL', 8: 'RESTAURANT#GENERAL', 9: 'RESTAURANT#MISCELLANEOUS', 10: 'RESTAURANT#PRICES', 11: 'SERVICE#GENERAL'}\n"]}]},{"cell_type":"code","metadata":{"id":"QZUglV_A4BF_"},"source":["# Getting indices of where boolean one hot vector true_bools is True so we can use idx2label to gather label names\n","true_label_idxs, pred_label_idxs=[],[]\n","for vals in true_bools:\n","  true_label_idxs.append(np.where(vals)[0].flatten().tolist())\n","for vals in pred_bools:\n","  pred_label_idxs.append(np.where(vals)[0].flatten().tolist())"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"OOGhXM3R4a91"},"source":["# Gathering vectors of label names using idx2label\n","true_label_texts, pred_label_texts = [], []\n","for vals in true_label_idxs:\n","  if vals:\n","    true_label_texts.append([idx2label[val] for val in vals])\n","  else:\n","    true_label_texts.append(vals)\n","\n","for vals in pred_label_idxs:\n","  if vals:\n","    pred_label_texts.append([idx2label[val] for val in vals])\n","  else:\n","    pred_label_texts.append(vals)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# BONUS ASSIGNMENT 6\n","\n","In this assignment we will decode the input ids from the tokenized texts using the tokenizer instantiated above and will use them to generate a dataframe in which to add the text of the review, the true labels and the predicted labels. We will then save this dataframe to a csv which could be used to manually inspect the predictions of the model with respect to the gold standard.\n","\n","+ TODO: decode the texts.\n","+ TODO: create a dataframe containing three columns: the texts, the true labels and the predicted labels.\n","+ TODO: save it into a csv.\n","\n","The result should be something like the following:"],"metadata":{"id":"c9YEXhWMzzHc"}},{"cell_type":"code","metadata":{"id":"5HaqV6pn_HCG"},"source":["# TODO Decoding input ids to comment text\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"R7kk0Mgl1L-T","colab":{"base_uri":"https://localhost:8080/","height":206},"outputId":"2e34931c-3e77-4ff2-dc6d-66407063a48c","executionInfo":{"status":"ok","timestamp":1646222424519,"user_tz":-60,"elapsed":417,"user":{"displayName":"Rodrigo Agerri","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhW2M3VpBFpNNhe0tx607nu7jJN85RXoeaB4nSw=s64","userId":"18226337086247956839"}}},"source":["# TODO Converting lists to df\n","\n","comparisons_df.head()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["\n","  <div id=\"df-cc9918cc-9afa-4bf7-89f9-5d8db4a5cfdd\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>comment_text</th>\n","      <th>true_labels</th>\n","      <th>pred_labels</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>yum !</td>\n","      <td>[FOOD#QUALITY]</td>\n","      <td>[FOOD#QUALITY]</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>serves really good sushi .</td>\n","      <td>[FOOD#QUALITY]</td>\n","      <td>[FOOD#QUALITY]</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>not the biggest portions but adequate .</td>\n","      <td>[FOOD#STYLE_OPTIONS]</td>\n","      <td>[FOOD#QUALITY]</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>green tea creme brulee is a must !</td>\n","      <td>[FOOD#QUALITY]</td>\n","      <td>[FOOD#QUALITY]</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>don ' t leave the restaurant without it .</td>\n","      <td>[FOOD#QUALITY]</td>\n","      <td>[RESTAURANT#GENERAL]</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cc9918cc-9afa-4bf7-89f9-5d8db4a5cfdd')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-cc9918cc-9afa-4bf7-89f9-5d8db4a5cfdd button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-cc9918cc-9afa-4bf7-89f9-5d8db4a5cfdd');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["                                comment_text  ...           pred_labels\n","0                                      yum !  ...        [FOOD#QUALITY]\n","1                 serves really good sushi .  ...        [FOOD#QUALITY]\n","2    not the biggest portions but adequate .  ...        [FOOD#QUALITY]\n","3         green tea creme brulee is a must !  ...        [FOOD#QUALITY]\n","4  don ' t leave the restaurant without it .  ...  [RESTAURANT#GENERAL]\n","\n","[5 rows x 3 columns]"]},"metadata":{},"execution_count":50}]},{"cell_type":"markdown","source":["# BONUS ASSIGNMENT 7\n","\n","+ TODO: Can you generate the required data for multilabel aspect category detection using the \"acb\" datasets available for other languages?"],"metadata":{"id":"Rx1ztJMl8IQu"}}]}