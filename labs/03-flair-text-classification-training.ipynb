{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"03-flair-text-classification-training.ipynb","provenance":[],"toc_visible":true},"kernelspec":{"display_name":"Python 3","name":"python3"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"x8UEeL963baI","executionInfo":{"status":"ok","timestamp":1645038365020,"user_tz":-60,"elapsed":26067,"user":{"displayName":"Julen Etxaniz Aragoneses","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GilpYDAmorj7KFdjK26TlsyH_HhFWhLqmESeKoCGsI=s64","userId":"06956422670240182492"}},"outputId":"d3840df4-902e-4171-a9b4-323b73bb9064"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["%cd /content/drive/MyDrive/LAP/Subjects/AP1/labs"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IW_abWkWsKzY","executionInfo":{"status":"ok","timestamp":1645038365022,"user_tz":-60,"elapsed":50,"user":{"displayName":"Julen Etxaniz Aragoneses","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GilpYDAmorj7KFdjK26TlsyH_HhFWhLqmESeKoCGsI=s64","userId":"06956422670240182492"}},"outputId":"08f7444d-c641-40e1-9509-c61f60eb8a4a"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/LAP/Subjects/AP1/labs\n"]}]},{"cell_type":"markdown","metadata":{"id":"Hb0el2_68Zhq"},"source":["# PREPROCESSING\n","\n","Functions to load and cleanup the data for training with Flair.\n","\n"]},{"cell_type":"code","metadata":{"id":"TvjWbWcwZf1W","executionInfo":{"status":"ok","timestamp":1645038365028,"user_tz":-60,"elapsed":22,"user":{"displayName":"Julen Etxaniz Aragoneses","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GilpYDAmorj7KFdjK26TlsyH_HhFWhLqmESeKoCGsI=s64","userId":"06956422670240182492"}}},"source":["import csv\n","import re\n","import sys\n","import pandas as pd\n","\n","# load data\n","def load_data(fnames):\n","    data = []\n","    for fname in fnames:\n","        data.append(pd.read_csv(fname, sep='\\t', encoding='utf-8'))\n","    data = pd.concat(data)\n","    targets = set(data['Target'])\n","    return data, list(targets)\n","\n","# pre-process tweets\n","def cleanup(tweet):\n","    \"\"\"we remove urls, hashtags and user symbols\"\"\"\n","    tweet = re.sub(r\"http\\S+\", \"\", tweet.replace(\"#\", \"\").replace(\"@\", \"\").replace('\\n', ' ').replace('\\t', ' '))\n","    return tweet\n","\n","def format_label_to_flair(label):\n","    return \"__label__\" + label"],"execution_count":3,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ECydcLTg9xRV"},"source":["# Loading and Pre-processing the datasets\n","\n","\n","We load and cleanup the data using the functions defined above.\n","\n"]},{"cell_type":"markdown","metadata":{"id":"tlGilGPV-Ipl"},"source":["## ASSIGNMENT 1\n","\n","+ TODO: Write the format_label_to_flair(label) function above to obtain the label column in the format shown below.\n","+ TODO: Write the required code to load, cleanup and format the labels for both the training and test sets obtaining the output shown below."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":467},"id":"z-SKnx5F8hjP","executionInfo":{"status":"ok","timestamp":1645038368561,"user_tz":-60,"elapsed":3552,"user":{"displayName":"Julen Etxaniz Aragoneses","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GilpYDAmorj7KFdjK26TlsyH_HhFWhLqmESeKoCGsI=s64","userId":"06956422670240182492"}},"outputId":"a9d1aecf-8049-4acc-cd0d-70a71dd98059"},"source":["# data path. trial data used as training too.\n","folder = \"stance-semeval2016\"\n","trial_file = f\"../datasets/{folder}/semeval2016-task6-trialdata.utf-8.txt\"\n","train_file = f\"../datasets/{folder}/semeval2016-task6-trainingdata.utf-8.txt\"\n","test_file = f\"../datasets/{folder}/SemEval2016-Task6-subtaskA-testdata-gold.txt\"\n","\n","# TODO write your code here\n","def preprocess_data(fnames):\n","    data, targets = load_data(fnames)\n","    data[\"Clean_tweet\"] = data[\"Tweet\"].apply(cleanup)\n","    data[\"Stance\"] = data[\"Stance\"].apply(format_label_to_flair)\n","    return data, targets\n","\n","training_data, targets = preprocess_data([trial_file, train_file])\n","testing_data, targets = preprocess_data([test_file])\n","\n","display(training_data)"],"execution_count":4,"outputs":[{"output_type":"display_data","data":{"text/html":["\n","  <div id=\"df-d68f26ba-2c03-468d-adc0-553b87eb3346\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>ID</th>\n","      <th>Target</th>\n","      <th>Tweet</th>\n","      <th>Stance</th>\n","      <th>Clean_tweet</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>Hillary Clinton</td>\n","      <td>@tedcruz And, #HandOverTheServer she wiped cle...</td>\n","      <td>__label__AGAINST</td>\n","      <td>tedcruz And, HandOverTheServer she wiped clean...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2</td>\n","      <td>Hillary Clinton</td>\n","      <td>Hillary is our best choice if we truly want to...</td>\n","      <td>__label__FAVOR</td>\n","      <td>Hillary is our best choice if we truly want to...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3</td>\n","      <td>Hillary Clinton</td>\n","      <td>@TheView I think our country is ready for a fe...</td>\n","      <td>__label__AGAINST</td>\n","      <td>TheView I think our country is ready for a fem...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>4</td>\n","      <td>Hillary Clinton</td>\n","      <td>I just gave an unhealthy amount of my hard-ear...</td>\n","      <td>__label__AGAINST</td>\n","      <td>I just gave an unhealthy amount of my hard-ear...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>5</td>\n","      <td>Hillary Clinton</td>\n","      <td>@PortiaABoulger Thank you for adding me to you...</td>\n","      <td>__label__NONE</td>\n","      <td>PortiaABoulger Thank you for adding me to your...</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>2809</th>\n","      <td>2910</td>\n","      <td>Legalization of Abortion</td>\n","      <td>There's a law protecting unborn eagles, but no...</td>\n","      <td>__label__AGAINST</td>\n","      <td>There's a law protecting unborn eagles, but no...</td>\n","    </tr>\n","    <tr>\n","      <th>2810</th>\n","      <td>2911</td>\n","      <td>Legalization of Abortion</td>\n","      <td>I am 1 in 3... I have had an abortion #Abortio...</td>\n","      <td>__label__AGAINST</td>\n","      <td>I am 1 in 3... I have had an abortion Abortion...</td>\n","    </tr>\n","    <tr>\n","      <th>2811</th>\n","      <td>2912</td>\n","      <td>Legalization of Abortion</td>\n","      <td>How dare you say my sexual preference is a cho...</td>\n","      <td>__label__AGAINST</td>\n","      <td>How dare you say my sexual preference is a cho...</td>\n","    </tr>\n","    <tr>\n","      <th>2812</th>\n","      <td>2913</td>\n","      <td>Legalization of Abortion</td>\n","      <td>Equal rights for those 'born that way', no rig...</td>\n","      <td>__label__AGAINST</td>\n","      <td>Equal rights for those 'born that way', no rig...</td>\n","    </tr>\n","    <tr>\n","      <th>2813</th>\n","      <td>2914</td>\n","      <td>Legalization of Abortion</td>\n","      <td>#POTUS seals his legacy w/ 1/2 doz wins. The #...</td>\n","      <td>__label__AGAINST</td>\n","      <td>POTUS seals his legacy w/ 1/2 doz wins. The GO...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>2914 rows Ã— 5 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d68f26ba-2c03-468d-adc0-553b87eb3346')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-d68f26ba-2c03-468d-adc0-553b87eb3346 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-d68f26ba-2c03-468d-adc0-553b87eb3346');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["        ID  ...                                        Clean_tweet\n","0        1  ...  tedcruz And, HandOverTheServer she wiped clean...\n","1        2  ...  Hillary is our best choice if we truly want to...\n","2        3  ...  TheView I think our country is ready for a fem...\n","3        4  ...  I just gave an unhealthy amount of my hard-ear...\n","4        5  ...  PortiaABoulger Thank you for adding me to your...\n","...    ...  ...                                                ...\n","2809  2910  ...  There's a law protecting unborn eagles, but no...\n","2810  2911  ...  I am 1 in 3... I have had an abortion Abortion...\n","2811  2912  ...  How dare you say my sexual preference is a cho...\n","2812  2913  ...  Equal rights for those 'born that way', no rig...\n","2813  2914  ...  POTUS seals his legacy w/ 1/2 doz wins. The GO...\n","\n","[2914 rows x 5 columns]"]},"metadata":{}}]},{"cell_type":"markdown","metadata":{"id":"WIT3p9vL-BLv"},"source":["## ASSIGNMENT 2\n","\n","From the training_data and testing_data dataframes obtained in the previous step, perform the following steps:\n","\n","+ TODO: Iterate over the targets to write a training and test set in the format required by Flair to train a text classifier:\n","\n","```\n","__label__AGAINST first_tweet_in_dataframe\n","__label__NONE second_tweet_in_dataframe\n","__label__FAVOR third_tweet_in_dataframe\n","```\n","*NOTE: One tweet per line*\n","\n","The result should be a training set and test set in files for each target. For example:\n","\n","\n","\n","```\n","train.Feminist Movement.txt\n","test.Feminist Movement.txt\n","```\n","\n","HINT: You just need to use the Stance and Clean_tweet columns from the training_data and test_data dataframes and write them to a csv with \"\\t\" as separator.\n","\n","https://github.com/flairNLP/flair/blob/master/resources/docs/TUTORIAL_6_CORPUS.md#reading-a-text-classification-dataset\n"]},{"cell_type":"code","metadata":{"id":"pc-5nX2DESYy","executionInfo":{"status":"ok","timestamp":1645038368569,"user_tz":-60,"elapsed":186,"user":{"displayName":"Julen Etxaniz Aragoneses","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GilpYDAmorj7KFdjK26TlsyH_HhFWhLqmESeKoCGsI=s64","userId":"06956422670240182492"}}},"source":["# TODO Write your code here\n","def save_targets(data, targets, pre):\n","    for target in targets:\n","        data_target = data[data[\"Target\"]==target]\n","        fname = f\"../resources/{folder}/{pre}.{target}.txt\"\n","        data_target.to_csv(fname, sep='\\t', columns=[\"Stance\", \"Clean_tweet\"], index=False)\n","\n","save_targets(training_data, targets, pre='train')\n","save_targets(testing_data, targets, pre='test')"],"execution_count":5,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"CsMM5WnpA_i0"},"source":["# INSTALL FLAIR"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"8okVUTM6W513","executionInfo":{"status":"ok","timestamp":1645038420265,"user_tz":-60,"elapsed":51870,"user":{"displayName":"Julen Etxaniz Aragoneses","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GilpYDAmorj7KFdjK26TlsyH_HhFWhLqmESeKoCGsI=s64","userId":"06956422670240182492"}},"outputId":"1f3d32bf-5f59-4e7b-9cc5-f758ef87ebf0"},"source":["!pip install flair==0.8"],"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting flair==0.8\n","  Downloading flair-0.8-py3-none-any.whl (277 kB)\n","\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 277 kB 5.3 MB/s \n","\u001b[?25hCollecting deprecated>=1.2.4\n","  Downloading Deprecated-1.2.13-py2.py3-none-any.whl (9.6 kB)\n","Collecting transformers>=4.0.0\n","  Downloading transformers-4.16.2-py3-none-any.whl (3.5 MB)\n","\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3.5 MB 21.4 MB/s \n","\u001b[?25hCollecting segtok>=1.5.7\n","  Downloading segtok-1.5.11-py3-none-any.whl (24 kB)\n","Collecting mpld3==0.3\n","  Downloading mpld3-0.3.tar.gz (788 kB)\n","\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 788 kB 48.2 MB/s \n","\u001b[?25hCollecting gdown==3.12.2\n","  Downloading gdown-3.12.2.tar.gz (8.2 kB)\n","  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n","Collecting langdetect\n","  Downloading langdetect-1.0.9.tar.gz (981 kB)\n","\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 981 kB 48.0 MB/s \n","\u001b[?25hRequirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.7/dist-packages (from flair==0.8) (2.8.2)\n","Collecting ftfy\n","  Downloading ftfy-6.1.1-py3-none-any.whl (53 kB)\n","\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 53 kB 1.6 MB/s \n","\u001b[?25hRequirement already satisfied: torch>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from flair==0.8) (1.10.0+cu111)\n","Collecting sentencepiece==0.1.95\n","  Downloading sentencepiece-0.1.95-cp37-cp37m-manylinux2014_x86_64.whl (1.2 MB)\n","\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.2 MB 43.0 MB/s \n","\u001b[?25hRequirement already satisfied: matplotlib>=2.2.3 in /usr/local/lib/python3.7/dist-packages (from flair==0.8) (3.2.2)\n","Collecting konoha<5.0.0,>=4.0.0\n","  Downloading konoha-4.6.5-py3-none-any.whl (20 kB)\n","Collecting huggingface-hub\n","  Downloading huggingface_hub-0.4.0-py3-none-any.whl (67 kB)\n","\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 67 kB 5.2 MB/s \n","\u001b[?25hRequirement already satisfied: tabulate in /usr/local/lib/python3.7/dist-packages (from flair==0.8) (0.8.9)\n","Collecting janome\n","  Downloading Janome-0.4.1-py2.py3-none-any.whl (19.7 MB)\n","\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19.7 MB 1.2 MB/s \n","\u001b[?25hCollecting sqlitedict>=1.6.0\n","  Downloading sqlitedict-1.7.0.tar.gz (28 kB)\n","Requirement already satisfied: gensim<=3.8.3,>=3.4.0 in /usr/local/lib/python3.7/dist-packages (from flair==0.8) (3.6.0)\n","Requirement already satisfied: hyperopt>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from flair==0.8) (0.1.2)\n","Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from flair==0.8) (2019.12.20)\n","Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.7/dist-packages (from flair==0.8) (1.0.2)\n","Collecting numpy<1.20.0\n","  Downloading numpy-1.19.5-cp37-cp37m-manylinux2010_x86_64.whl (14.8 MB)\n","\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14.8 MB 35.8 MB/s \n","\u001b[?25hCollecting bpemb>=0.3.2\n","  Downloading bpemb-0.3.3-py3-none-any.whl (19 kB)\n","Requirement already satisfied: tqdm>=4.26.0 in /usr/local/lib/python3.7/dist-packages (from flair==0.8) (4.62.3)\n","Requirement already satisfied: lxml in /usr/local/lib/python3.7/dist-packages (from flair==0.8) (4.2.6)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from gdown==3.12.2->flair==0.8) (3.4.2)\n","Requirement already satisfied: requests[socks] in /usr/local/lib/python3.7/dist-packages (from gdown==3.12.2->flair==0.8) (2.23.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from gdown==3.12.2->flair==0.8) (1.15.0)\n","Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.7/dist-packages (from deprecated>=1.2.4->flair==0.8) (1.13.3)\n","Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.7/dist-packages (from gensim<=3.8.3,>=3.4.0->flair==0.8) (1.4.1)\n","Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.7/dist-packages (from gensim<=3.8.3,>=3.4.0->flair==0.8) (5.2.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.7/dist-packages (from hyperopt>=0.1.1->flair==0.8) (2.6.3)\n","Requirement already satisfied: pymongo in /usr/local/lib/python3.7/dist-packages (from hyperopt>=0.1.1->flair==0.8) (4.0.1)\n","Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from hyperopt>=0.1.1->flair==0.8) (0.16.0)\n","Collecting importlib-metadata<4.0.0,>=3.7.0\n","  Downloading importlib_metadata-3.10.1-py3-none-any.whl (14 kB)\n","Collecting overrides<4.0.0,>=3.0.0\n","  Downloading overrides-3.1.0.tar.gz (11 kB)\n","Collecting requests\n","  Downloading requests-2.27.1-py2.py3-none-any.whl (63 kB)\n","\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 63 kB 1.7 MB/s \n","\u001b[?25hRequirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata<4.0.0,>=3.7.0->konoha<5.0.0,>=4.0.0->flair==0.8) (3.7.0)\n","Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata<4.0.0,>=3.7.0->konoha<5.0.0,>=4.0.0->flair==0.8) (3.10.0.2)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.2.3->flair==0.8) (0.11.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.2.3->flair==0.8) (1.3.2)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.2.3->flair==0.8) (3.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->bpemb>=0.3.2->flair==0.8) (2021.10.8)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.7/dist-packages (from requests->bpemb>=0.3.2->flair==0.8) (2.0.11)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->bpemb>=0.3.2->flair==0.8) (2.10)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->bpemb>=0.3.2->flair==0.8) (1.24.3)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->flair==0.8) (1.1.0)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->flair==0.8) (3.1.0)\n","Collecting pyyaml>=5.1\n","  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n","\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 596 kB 46.1 MB/s \n","\u001b[?25hCollecting tokenizers!=0.11.3,>=0.10.1\n","  Downloading tokenizers-0.11.5-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.8 MB)\n","\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6.8 MB 45.8 MB/s \n","\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers>=4.0.0->flair==0.8) (21.3)\n","Collecting sacremoses\n","  Downloading sacremoses-0.0.47-py2.py3-none-any.whl (895 kB)\n","\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 895 kB 51.2 MB/s \n","\u001b[?25hRequirement already satisfied: wcwidth>=0.2.5 in /usr/local/lib/python3.7/dist-packages (from ftfy->flair==0.8) (0.2.5)\n","Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.7/dist-packages (from requests->bpemb>=0.3.2->flair==0.8) (1.7.1)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers>=4.0.0->flair==0.8) (7.1.2)\n","Building wheels for collected packages: gdown, mpld3, overrides, sqlitedict, langdetect\n","  Building wheel for gdown (PEP 517) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for gdown: filename=gdown-3.12.2-py3-none-any.whl size=9692 sha256=0a0fae8c0075adce106defa91ec3bef66897f90553983a85eb95b02776a163fa\n","  Stored in directory: /root/.cache/pip/wheels/ba/e0/7e/726e872a53f7358b4b96a9975b04e98113b005cd8609a63abc\n","  Building wheel for mpld3 (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for mpld3: filename=mpld3-0.3-py3-none-any.whl size=116702 sha256=6ab0c28995ba653e9fc07bf20f4cb1daf3c968154ed06ccb8616acbc671a3dbe\n","  Stored in directory: /root/.cache/pip/wheels/26/70/6a/1c79e59951a41b4045497da187b2724f5659ca64033cf4548e\n","  Building wheel for overrides (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for overrides: filename=overrides-3.1.0-py3-none-any.whl size=10187 sha256=e2fcfb2c206ff1654e14711adc4190ab4fc21ae2d9f8895a07a3eec5a7a96a2e\n","  Stored in directory: /root/.cache/pip/wheels/3a/0d/38/01a9bc6e20dcfaf0a6a7b552d03137558ba1c38aea47644682\n","  Building wheel for sqlitedict (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for sqlitedict: filename=sqlitedict-1.7.0-py3-none-any.whl size=14393 sha256=8866455c9c6b65784334a5456abce6283a03a6ec166ec209c7b38e1d35eaf5a8\n","  Stored in directory: /root/.cache/pip/wheels/af/94/06/18c0e83e9e227da8f3582810b51f319bbfd181e508676a56c8\n","  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for langdetect: filename=langdetect-1.0.9-py3-none-any.whl size=993242 sha256=0d058f11dfd40787a290d0e352c77a5caa8c5682a549faf5fe3f50e42e0e1d0a\n","  Stored in directory: /root/.cache/pip/wheels/c5/96/8a/f90c59ed25d75e50a8c10a1b1c2d4c402e4dacfa87f3aff36a\n","Successfully built gdown mpld3 overrides sqlitedict langdetect\n","Installing collected packages: numpy, requests, pyyaml, importlib-metadata, tokenizers, sentencepiece, sacremoses, overrides, huggingface-hub, transformers, sqlitedict, segtok, mpld3, langdetect, konoha, janome, gdown, ftfy, deprecated, bpemb, flair\n","  Attempting uninstall: numpy\n","    Found existing installation: numpy 1.21.5\n","    Uninstalling numpy-1.21.5:\n","      Successfully uninstalled numpy-1.21.5\n","  Attempting uninstall: requests\n","    Found existing installation: requests 2.23.0\n","    Uninstalling requests-2.23.0:\n","      Successfully uninstalled requests-2.23.0\n","  Attempting uninstall: pyyaml\n","    Found existing installation: PyYAML 3.13\n","    Uninstalling PyYAML-3.13:\n","      Successfully uninstalled PyYAML-3.13\n","  Attempting uninstall: importlib-metadata\n","    Found existing installation: importlib-metadata 4.11.0\n","    Uninstalling importlib-metadata-4.11.0:\n","      Successfully uninstalled importlib-metadata-4.11.0\n","  Attempting uninstall: gdown\n","    Found existing installation: gdown 4.2.1\n","    Uninstalling gdown-4.2.1:\n","      Successfully uninstalled gdown-4.2.1\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","tensorflow 2.8.0 requires tf-estimator-nightly==2.8.0.dev2021122109, which is not installed.\n","tensorflow 2.8.0 requires numpy>=1.20, but you have numpy 1.19.5 which is incompatible.\n","markdown 3.3.6 requires importlib-metadata>=4.4; python_version < \"3.10\", but you have importlib-metadata 3.10.1 which is incompatible.\n","google-colab 1.0.0 requires requests~=2.23.0, but you have requests 2.27.1 which is incompatible.\n","datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\n","albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n","Successfully installed bpemb-0.3.3 deprecated-1.2.13 flair-0.8 ftfy-6.1.1 gdown-3.12.2 huggingface-hub-0.4.0 importlib-metadata-3.10.1 janome-0.4.1 konoha-4.6.5 langdetect-1.0.9 mpld3-0.3 numpy-1.19.5 overrides-3.1.0 pyyaml-6.0 requests-2.27.1 sacremoses-0.0.47 segtok-1.5.11 sentencepiece-0.1.95 sqlitedict-1.7.0 tokenizers-0.11.5 transformers-4.16.2\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["numpy"]}}},"metadata":{}}]},{"cell_type":"markdown","metadata":{"id":"gve0M5UeBFKb"},"source":["# Load the training data created in ASSIGNMENT 2"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZmZ9QqxJYkzi","executionInfo":{"status":"ok","timestamp":1645038437882,"user_tz":-60,"elapsed":17320,"user":{"displayName":"Julen Etxaniz Aragoneses","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GilpYDAmorj7KFdjK26TlsyH_HhFWhLqmESeKoCGsI=s64","userId":"06956422670240182492"}},"outputId":"3c4db5c6-5826-4d3b-97bd-819cfbdf818f"},"source":["from flair.data import Corpus                                                                                                                                                           \n","from flair.datasets import ClassificationCorpus\n","from flair.embeddings import WordEmbeddings, FlairEmbeddings, FastTextEmbeddings, DocumentRNNEmbeddings                                                             \n","from flair.models import TextClassifier                                                                                                                                                 \n","from flair.trainers import ModelTrainer\n","\n","# 1. get the corpus\n","target = \"Feminist Movement\"\n","corpus_folder = f\"../resources/{folder}/\"\n","corpus: Corpus = ClassificationCorpus(corpus_folder,\n","                                      train_file=f'train.{target}.txt',\n","                                      #dev_file=f'train.{target}.txt',\n","                                      test_file=f'test.{target}.txt'\n",")\n","\n","# 2. create the label dictionary\n","label_dict = corpus.make_label_dictionary()"],"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["2022-02-16 19:07:16,316 Reading data from ../resources/stance-semeval2016\n","2022-02-16 19:07:16,318 Train: ../resources/stance-semeval2016/train.Feminist Movement.txt\n","2022-02-16 19:07:16,331 Dev: None\n","2022-02-16 19:07:16,337 Test: ../resources/stance-semeval2016/test.Feminist Movement.txt\n","2022-02-16 19:07:16,389 Computing label dictionary. Progress:\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n","100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 883/883 [00:01<00:00, 503.83it/s]"]},{"output_type":"stream","name":"stdout","text":["2022-02-16 19:07:18,600 [b'FAVOR', b'AGAINST', b'NONE']\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}]},{"cell_type":"markdown","metadata":{"id":"qr1lylJjBRNk"},"source":["# INSTALL Word Embeddings and instantiate the TextClassifier"]},{"cell_type":"code","metadata":{"id":"Ec3MkXzBgxVa","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1645038527900,"user_tz":-60,"elapsed":90058,"user":{"displayName":"Julen Etxaniz Aragoneses","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GilpYDAmorj7KFdjK26TlsyH_HhFWhLqmESeKoCGsI=s64","userId":"06956422670240182492"}},"outputId":"a088f244-d776-4b8f-92f3-522777ca3eaa"},"source":["# 3. make a list of word embeddings\n","word_embeddings = [\n","                   WordEmbeddings('en-crawl'),\n","                   #FlairEmbeddings('news-forward'),\n","                   #FlairEmbeddings('news-backward'),\n","]\n","\n","# 4. initialize document embedding by passing list of word embeddings                                                                                                                   \n","# Can choose between many RNN types (GRU by default, to change use rnn_type parameter)                                                                                                  \n","document_embeddings: DocumentRNNEmbeddings = DocumentRNNEmbeddings(word_embeddings,\n","                                                                   hidden_size=512,\n","                                                                   reproject_words=True,\n","                                                                   reproject_words_dimension=256,\n","                                                                   rnn_type='LSTM',\n",")\n","                                                                                                                                                                                         \n","# 5. create the text classifier\n","classifier = TextClassifier(document_embeddings, label_dictionary=label_dict)\n","# 6. initialize the text classifier trainer\n","trainer = ModelTrainer(classifier, corpus)"],"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["2022-02-16 19:07:19,238 https://flair.informatik.hu-berlin.de/resources/embeddings/token/en-fasttext-crawl-300d-1M.vectors.npy not found in cache, downloading to /tmp/tmp5frvevn9\n"]},{"output_type":"stream","name":"stderr","text":["100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1200000128/1200000128 [01:05<00:00, 18376460.44B/s]"]},{"output_type":"stream","name":"stdout","text":["2022-02-16 19:08:24,960 copying /tmp/tmp5frvevn9 to cache at /root/.flair/embeddings/en-fasttext-crawl-300d-1M.vectors.npy\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["2022-02-16 19:08:29,297 removing temp file /tmp/tmp5frvevn9\n","2022-02-16 19:08:30,046 https://flair.informatik.hu-berlin.de/resources/embeddings/token/en-fasttext-crawl-300d-1M not found in cache, downloading to /tmp/tmp9a54p6me\n"]},{"output_type":"stream","name":"stderr","text":["100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 39323680/39323680 [00:02<00:00, 13236596.28B/s]"]},{"output_type":"stream","name":"stdout","text":["2022-02-16 19:08:33,402 copying /tmp/tmp9a54p6me to cache at /root/.flair/embeddings/en-fasttext-crawl-300d-1M\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["2022-02-16 19:08:33,505 removing temp file /tmp/tmp9a54p6me\n"]}]},{"cell_type":"markdown","metadata":{"id":"Y5c9Fz6-BZq6"},"source":["# Run the trainer for feminism target"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IZK1jIkVbl8L","executionInfo":{"status":"ok","timestamp":1645038889857,"user_tz":-60,"elapsed":362043,"user":{"displayName":"Julen Etxaniz Aragoneses","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GilpYDAmorj7KFdjK26TlsyH_HhFWhLqmESeKoCGsI=s64","userId":"06956422670240182492"}},"outputId":"677c7d4c-af34-44c9-a5e4-41d0da0b9ce8"},"source":["# 7. start the training\n","trainer.train(f\"../resources/{folder}/flair_{target}\",\n","              train_with_dev=False,\n","              max_epochs=50)"],"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["2022-02-16 19:08:48,602 ----------------------------------------------------------------------------------------------------\n","2022-02-16 19:08:48,611 Model: \"TextClassifier(\n","  (document_embeddings): DocumentRNNEmbeddings(\n","    (embeddings): StackedEmbeddings(\n","      (list_embedding_0): WordEmbeddings('en-crawl')\n","    )\n","    (word_reprojection_map): Linear(in_features=300, out_features=256, bias=True)\n","    (rnn): LSTM(256, 512, batch_first=True)\n","    (dropout): Dropout(p=0.5, inplace=False)\n","  )\n","  (decoder): Linear(in_features=512, out_features=3, bias=True)\n","  (loss_function): CrossEntropyLoss()\n","  (beta): 1.0\n","  (weights): None\n","  (weight_tensor) None\n",")\"\n","2022-02-16 19:08:48,614 ----------------------------------------------------------------------------------------------------\n","2022-02-16 19:08:48,618 Corpus: \"Corpus: 598 train + 66 dev + 285 test sentences\"\n","2022-02-16 19:08:48,622 ----------------------------------------------------------------------------------------------------\n","2022-02-16 19:08:48,624 Parameters:\n","2022-02-16 19:08:48,626  - learning_rate: \"0.1\"\n","2022-02-16 19:08:48,629  - mini_batch_size: \"32\"\n","2022-02-16 19:08:48,631  - patience: \"3\"\n","2022-02-16 19:08:48,635  - anneal_factor: \"0.5\"\n","2022-02-16 19:08:48,637  - max_epochs: \"50\"\n","2022-02-16 19:08:48,640  - shuffle: \"True\"\n","2022-02-16 19:08:48,642  - train_with_dev: \"False\"\n","2022-02-16 19:08:48,686  - batch_growth_annealing: \"False\"\n","2022-02-16 19:08:48,687 ----------------------------------------------------------------------------------------------------\n","2022-02-16 19:08:48,694 Model training base path: \"../resources/stance-semeval2016/flair-Feminist Movement\"\n","2022-02-16 19:08:48,700 ----------------------------------------------------------------------------------------------------\n","2022-02-16 19:08:48,703 Device: cuda:0\n","2022-02-16 19:08:48,704 ----------------------------------------------------------------------------------------------------\n","2022-02-16 19:08:48,708 Embeddings storage mode: cpu\n","2022-02-16 19:08:48,724 ----------------------------------------------------------------------------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"output_type":"stream","name":"stdout","text":["2022-02-16 19:08:49,775 epoch 1 - iter 1/19 - loss 1.11264050 - samples/sec: 77.75 - lr: 0.100000\n","2022-02-16 19:08:49,873 epoch 1 - iter 2/19 - loss 1.09319001 - samples/sec: 346.44 - lr: 0.100000\n","2022-02-16 19:08:49,989 epoch 1 - iter 3/19 - loss 1.09458951 - samples/sec: 300.27 - lr: 0.100000\n","2022-02-16 19:08:50,107 epoch 1 - iter 4/19 - loss 1.09637159 - samples/sec: 281.02 - lr: 0.100000\n","2022-02-16 19:08:50,210 epoch 1 - iter 5/19 - loss 1.09796343 - samples/sec: 374.09 - lr: 0.100000\n","2022-02-16 19:08:50,334 epoch 1 - iter 6/19 - loss 1.09091008 - samples/sec: 264.35 - lr: 0.100000\n","2022-02-16 19:08:50,436 epoch 1 - iter 7/19 - loss 1.07861509 - samples/sec: 363.44 - lr: 0.100000\n","2022-02-16 19:08:50,532 epoch 1 - iter 8/19 - loss 1.07153738 - samples/sec: 345.40 - lr: 0.100000\n","2022-02-16 19:08:50,665 epoch 1 - iter 9/19 - loss 1.08065359 - samples/sec: 343.02 - lr: 0.100000\n","2022-02-16 19:08:50,764 epoch 1 - iter 10/19 - loss 1.08951925 - samples/sec: 340.51 - lr: 0.100000\n","2022-02-16 19:08:50,862 epoch 1 - iter 11/19 - loss 1.09176061 - samples/sec: 338.04 - lr: 0.100000\n","2022-02-16 19:08:50,952 epoch 1 - iter 12/19 - loss 1.09296687 - samples/sec: 385.54 - lr: 0.100000\n","2022-02-16 19:08:51,047 epoch 1 - iter 13/19 - loss 1.09165812 - samples/sec: 342.04 - lr: 0.100000\n","2022-02-16 19:08:51,147 epoch 1 - iter 14/19 - loss 1.09214727 - samples/sec: 359.39 - lr: 0.100000\n","2022-02-16 19:08:51,244 epoch 1 - iter 15/19 - loss 1.08066499 - samples/sec: 369.82 - lr: 0.100000\n","2022-02-16 19:08:51,343 epoch 1 - iter 16/19 - loss 1.06141976 - samples/sec: 330.99 - lr: 0.100000\n","2022-02-16 19:08:51,436 epoch 1 - iter 17/19 - loss 1.04280653 - samples/sec: 354.39 - lr: 0.100000\n","2022-02-16 19:08:51,538 epoch 1 - iter 18/19 - loss 1.03343357 - samples/sec: 338.39 - lr: 0.100000\n","2022-02-16 19:08:51,616 epoch 1 - iter 19/19 - loss 1.00810038 - samples/sec: 425.61 - lr: 0.100000\n","2022-02-16 19:08:51,786 ----------------------------------------------------------------------------------------------------\n","2022-02-16 19:08:51,788 EPOCH 1 done: loss 1.0081 - lr 0.1000000\n","2022-02-16 19:08:52,562 DEV : loss 0.8625979423522949 - score 0.5152\n","2022-02-16 19:08:52,634 BAD EPOCHS (no improvement): 0\n","saving best model\n","2022-02-16 19:09:08,601 ----------------------------------------------------------------------------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"output_type":"stream","name":"stdout","text":["2022-02-16 19:09:09,602 epoch 2 - iter 1/19 - loss 1.03745973 - samples/sec: 197.02 - lr: 0.100000\n","2022-02-16 19:09:09,719 epoch 2 - iter 2/19 - loss 1.20534033 - samples/sec: 289.90 - lr: 0.100000\n","2022-02-16 19:09:09,847 epoch 2 - iter 3/19 - loss 1.14768593 - samples/sec: 278.41 - lr: 0.100000\n","2022-02-16 19:09:10,854 epoch 2 - iter 4/19 - loss 1.12323478 - samples/sec: 440.35 - lr: 0.100000\n","2022-02-16 19:09:10,927 epoch 2 - iter 5/19 - loss 1.10132554 - samples/sec: 469.49 - lr: 0.100000\n","2022-02-16 19:09:11,012 epoch 2 - iter 6/19 - loss 1.08623743 - samples/sec: 413.88 - lr: 0.100000\n","2022-02-16 19:09:11,115 epoch 2 - iter 7/19 - loss 1.06407122 - samples/sec: 475.01 - lr: 0.100000\n","2022-02-16 19:09:11,179 epoch 2 - iter 8/19 - loss 1.05649654 - samples/sec: 547.56 - lr: 0.100000\n","2022-02-16 19:09:11,242 epoch 2 - iter 9/19 - loss 1.06662196 - samples/sec: 527.43 - lr: 0.100000\n","2022-02-16 19:09:11,319 epoch 2 - iter 10/19 - loss 1.06202506 - samples/sec: 428.81 - lr: 0.100000\n","2022-02-16 19:09:11,385 epoch 2 - iter 11/19 - loss 1.05691096 - samples/sec: 503.71 - lr: 0.100000\n","2022-02-16 19:09:11,461 epoch 2 - iter 12/19 - loss 1.04786141 - samples/sec: 444.20 - lr: 0.100000\n","2022-02-16 19:09:11,535 epoch 2 - iter 13/19 - loss 1.04890493 - samples/sec: 508.58 - lr: 0.100000\n","2022-02-16 19:09:11,604 epoch 2 - iter 14/19 - loss 1.04508598 - samples/sec: 477.28 - lr: 0.100000\n","2022-02-16 19:09:11,674 epoch 2 - iter 15/19 - loss 1.04687467 - samples/sec: 469.07 - lr: 0.100000\n","2022-02-16 19:09:11,737 epoch 2 - iter 16/19 - loss 1.04870984 - samples/sec: 572.87 - lr: 0.100000\n","2022-02-16 19:09:11,802 epoch 2 - iter 17/19 - loss 1.04699700 - samples/sec: 541.98 - lr: 0.100000\n","2022-02-16 19:09:11,878 epoch 2 - iter 18/19 - loss 1.03894297 - samples/sec: 448.02 - lr: 0.100000\n","2022-02-16 19:09:11,937 epoch 2 - iter 19/19 - loss 1.02894081 - samples/sec: 658.30 - lr: 0.100000\n","2022-02-16 19:09:12,357 ----------------------------------------------------------------------------------------------------\n","2022-02-16 19:09:12,362 EPOCH 2 done: loss 1.0289 - lr 0.1000000\n","2022-02-16 19:09:13,568 DEV : loss 0.8878387808799744 - score 0.5152\n","2022-02-16 19:09:13,649 BAD EPOCHS (no improvement): 1\n","2022-02-16 19:09:13,657 ----------------------------------------------------------------------------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"output_type":"stream","name":"stdout","text":["2022-02-16 19:09:14,522 epoch 3 - iter 1/19 - loss 1.03396440 - samples/sec: 179.65 - lr: 0.100000\n","2022-02-16 19:09:14,609 epoch 3 - iter 2/19 - loss 0.99638322 - samples/sec: 430.49 - lr: 0.100000\n","2022-02-16 19:09:14,723 epoch 3 - iter 3/19 - loss 0.99443352 - samples/sec: 311.30 - lr: 0.100000\n","2022-02-16 19:09:15,005 epoch 3 - iter 4/19 - loss 0.99020629 - samples/sec: 160.11 - lr: 0.100000\n","2022-02-16 19:09:15,236 epoch 3 - iter 5/19 - loss 0.98743252 - samples/sec: 144.88 - lr: 0.100000\n","2022-02-16 19:09:15,422 epoch 3 - iter 6/19 - loss 0.99995765 - samples/sec: 180.73 - lr: 0.100000\n","2022-02-16 19:09:15,565 epoch 3 - iter 7/19 - loss 1.01091762 - samples/sec: 275.56 - lr: 0.100000\n","2022-02-16 19:09:15,692 epoch 3 - iter 8/19 - loss 1.00430142 - samples/sec: 267.49 - lr: 0.100000\n","2022-02-16 19:09:15,832 epoch 3 - iter 9/19 - loss 1.01346050 - samples/sec: 241.15 - lr: 0.100000\n","2022-02-16 19:09:15,957 epoch 3 - iter 10/19 - loss 1.01716706 - samples/sec: 337.06 - lr: 0.100000\n","2022-02-16 19:09:16,095 epoch 3 - iter 11/19 - loss 1.01842941 - samples/sec: 243.36 - lr: 0.100000\n","2022-02-16 19:09:16,246 epoch 3 - iter 12/19 - loss 1.02056698 - samples/sec: 225.69 - lr: 0.100000\n","2022-02-16 19:09:16,404 epoch 3 - iter 13/19 - loss 1.01304682 - samples/sec: 213.24 - lr: 0.100000\n","2022-02-16 19:09:16,540 epoch 3 - iter 14/19 - loss 1.01631569 - samples/sec: 281.49 - lr: 0.100000\n","2022-02-16 19:09:16,661 epoch 3 - iter 15/19 - loss 1.00855234 - samples/sec: 281.06 - lr: 0.100000\n","2022-02-16 19:09:16,791 epoch 3 - iter 16/19 - loss 1.01320166 - samples/sec: 309.62 - lr: 0.100000\n","2022-02-16 19:09:16,926 epoch 3 - iter 17/19 - loss 1.01692268 - samples/sec: 251.89 - lr: 0.100000\n","2022-02-16 19:09:17,057 epoch 3 - iter 18/19 - loss 1.01794012 - samples/sec: 252.11 - lr: 0.100000\n","2022-02-16 19:09:17,186 epoch 3 - iter 19/19 - loss 1.01936624 - samples/sec: 256.70 - lr: 0.100000\n","2022-02-16 19:09:17,874 ----------------------------------------------------------------------------------------------------\n","2022-02-16 19:09:17,881 EPOCH 3 done: loss 1.0194 - lr 0.1000000\n","2022-02-16 19:09:19,906 DEV : loss 0.9137055277824402 - score 0.5152\n","2022-02-16 19:09:20,076 BAD EPOCHS (no improvement): 2\n","2022-02-16 19:09:20,086 ----------------------------------------------------------------------------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"output_type":"stream","name":"stdout","text":["2022-02-16 19:09:21,709 epoch 4 - iter 1/19 - loss 1.01758766 - samples/sec: 119.42 - lr: 0.100000\n","2022-02-16 19:09:21,917 epoch 4 - iter 2/19 - loss 0.99555206 - samples/sec: 165.93 - lr: 0.100000\n","2022-02-16 19:09:22,102 epoch 4 - iter 3/19 - loss 0.98813272 - samples/sec: 227.98 - lr: 0.100000\n","2022-02-16 19:09:22,278 epoch 4 - iter 4/19 - loss 0.98288642 - samples/sec: 183.93 - lr: 0.100000\n","2022-02-16 19:09:22,483 epoch 4 - iter 5/19 - loss 0.98374065 - samples/sec: 180.02 - lr: 0.100000\n","2022-02-16 19:09:22,638 epoch 4 - iter 6/19 - loss 0.98616657 - samples/sec: 214.83 - lr: 0.100000\n","2022-02-16 19:09:22,927 epoch 4 - iter 7/19 - loss 0.98711644 - samples/sec: 228.76 - lr: 0.100000\n","2022-02-16 19:09:23,052 epoch 4 - iter 8/19 - loss 1.00463127 - samples/sec: 276.12 - lr: 0.100000\n","2022-02-16 19:09:23,195 epoch 4 - iter 9/19 - loss 1.00415801 - samples/sec: 231.47 - lr: 0.100000\n","2022-02-16 19:09:23,321 epoch 4 - iter 10/19 - loss 1.00031556 - samples/sec: 279.88 - lr: 0.100000\n","2022-02-16 19:09:23,424 epoch 4 - iter 11/19 - loss 0.99560513 - samples/sec: 334.50 - lr: 0.100000\n","2022-02-16 19:09:23,553 epoch 4 - iter 12/19 - loss 0.99887194 - samples/sec: 251.13 - lr: 0.100000\n","2022-02-16 19:09:23,760 epoch 4 - iter 13/19 - loss 1.00019842 - samples/sec: 225.27 - lr: 0.100000\n","2022-02-16 19:09:23,891 epoch 4 - iter 14/19 - loss 1.00081987 - samples/sec: 258.43 - lr: 0.100000\n","2022-02-16 19:09:24,000 epoch 4 - iter 15/19 - loss 1.00499703 - samples/sec: 314.49 - lr: 0.100000\n","2022-02-16 19:09:24,099 epoch 4 - iter 16/19 - loss 1.00833574 - samples/sec: 337.81 - lr: 0.100000\n","2022-02-16 19:09:24,228 epoch 4 - iter 17/19 - loss 1.01002421 - samples/sec: 258.57 - lr: 0.100000\n","2022-02-16 19:09:24,307 epoch 4 - iter 18/19 - loss 1.00795625 - samples/sec: 452.89 - lr: 0.100000\n","2022-02-16 19:09:24,396 epoch 4 - iter 19/19 - loss 1.00889617 - samples/sec: 379.88 - lr: 0.100000\n","2022-02-16 19:09:24,988 ----------------------------------------------------------------------------------------------------\n","2022-02-16 19:09:24,996 EPOCH 4 done: loss 1.0089 - lr 0.1000000\n","2022-02-16 19:09:26,824 DEV : loss 0.9216321706771851 - score 0.5152\n","2022-02-16 19:09:26,947 BAD EPOCHS (no improvement): 3\n","2022-02-16 19:09:26,961 ----------------------------------------------------------------------------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"output_type":"stream","name":"stdout","text":["2022-02-16 19:09:28,268 epoch 5 - iter 1/19 - loss 1.01046336 - samples/sec: 115.98 - lr: 0.100000\n","2022-02-16 19:09:28,493 epoch 5 - iter 2/19 - loss 1.01066989 - samples/sec: 152.63 - lr: 0.100000\n","2022-02-16 19:09:28,732 epoch 5 - iter 3/19 - loss 0.96881640 - samples/sec: 144.57 - lr: 0.100000\n","2022-02-16 19:09:28,965 epoch 5 - iter 4/19 - loss 0.96953586 - samples/sec: 158.92 - lr: 0.100000\n","2022-02-16 19:09:29,259 epoch 5 - iter 5/19 - loss 0.98247271 - samples/sec: 117.87 - lr: 0.100000\n","2022-02-16 19:09:29,473 epoch 5 - iter 6/19 - loss 0.98752822 - samples/sec: 173.84 - lr: 0.100000\n","2022-02-16 19:09:29,676 epoch 5 - iter 7/19 - loss 0.98901489 - samples/sec: 194.39 - lr: 0.100000\n","2022-02-16 19:09:29,814 epoch 5 - iter 8/19 - loss 0.98006742 - samples/sec: 259.73 - lr: 0.100000\n","2022-02-16 19:09:29,952 epoch 5 - iter 9/19 - loss 0.98911743 - samples/sec: 314.15 - lr: 0.100000\n","2022-02-16 19:09:30,068 epoch 5 - iter 10/19 - loss 0.98780048 - samples/sec: 295.72 - lr: 0.100000\n","2022-02-16 19:09:30,187 epoch 5 - iter 11/19 - loss 0.98795610 - samples/sec: 274.55 - lr: 0.100000\n","2022-02-16 19:09:30,313 epoch 5 - iter 12/19 - loss 0.99372523 - samples/sec: 269.17 - lr: 0.100000\n","2022-02-16 19:09:30,415 epoch 5 - iter 13/19 - loss 0.99692852 - samples/sec: 497.24 - lr: 0.100000\n","2022-02-16 19:09:30,501 epoch 5 - iter 14/19 - loss 0.99791990 - samples/sec: 400.91 - lr: 0.100000\n","2022-02-16 19:09:30,583 epoch 5 - iter 15/19 - loss 0.99925425 - samples/sec: 510.92 - lr: 0.100000\n","2022-02-16 19:09:30,674 epoch 5 - iter 16/19 - loss 1.00257080 - samples/sec: 376.90 - lr: 0.100000\n","2022-02-16 19:09:30,767 epoch 5 - iter 17/19 - loss 1.00104782 - samples/sec: 355.86 - lr: 0.100000\n","2022-02-16 19:09:30,875 epoch 5 - iter 18/19 - loss 1.00225497 - samples/sec: 304.00 - lr: 0.100000\n","2022-02-16 19:09:30,953 epoch 5 - iter 19/19 - loss 1.00223017 - samples/sec: 460.91 - lr: 0.100000\n","2022-02-16 19:09:31,336 ----------------------------------------------------------------------------------------------------\n","2022-02-16 19:09:31,342 EPOCH 5 done: loss 1.0022 - lr 0.1000000\n","2022-02-16 19:09:32,531 DEV : loss 0.9424606561660767 - score 0.5606\n","2022-02-16 19:09:32,608 BAD EPOCHS (no improvement): 0\n","saving best model\n","2022-02-16 19:09:47,843 ----------------------------------------------------------------------------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"output_type":"stream","name":"stdout","text":["2022-02-16 19:09:48,955 epoch 6 - iter 1/19 - loss 1.07454729 - samples/sec: 227.20 - lr: 0.100000\n","2022-02-16 19:09:49,063 epoch 6 - iter 2/19 - loss 1.04723060 - samples/sec: 334.26 - lr: 0.100000\n","2022-02-16 19:09:49,172 epoch 6 - iter 3/19 - loss 1.04402351 - samples/sec: 338.06 - lr: 0.100000\n","2022-02-16 19:09:49,274 epoch 6 - iter 4/19 - loss 1.06917229 - samples/sec: 328.49 - lr: 0.100000\n","2022-02-16 19:09:49,376 epoch 6 - iter 5/19 - loss 1.06397030 - samples/sec: 335.90 - lr: 0.100000\n","2022-02-16 19:09:49,505 epoch 6 - iter 6/19 - loss 1.04493775 - samples/sec: 308.81 - lr: 0.100000\n","2022-02-16 19:09:49,616 epoch 6 - iter 7/19 - loss 1.03320561 - samples/sec: 292.79 - lr: 0.100000\n","2022-02-16 19:09:49,709 epoch 6 - iter 8/19 - loss 1.03313005 - samples/sec: 544.60 - lr: 0.100000\n","2022-02-16 19:09:49,805 epoch 6 - iter 9/19 - loss 1.02521064 - samples/sec: 343.34 - lr: 0.100000\n","2022-02-16 19:09:49,888 epoch 6 - iter 10/19 - loss 1.01725134 - samples/sec: 399.50 - lr: 0.100000\n","2022-02-16 19:09:49,973 epoch 6 - iter 11/19 - loss 1.00596832 - samples/sec: 393.79 - lr: 0.100000\n","2022-02-16 19:09:50,071 epoch 6 - iter 12/19 - loss 0.99923664 - samples/sec: 391.44 - lr: 0.100000\n","2022-02-16 19:09:50,152 epoch 6 - iter 13/19 - loss 0.99307887 - samples/sec: 406.67 - lr: 0.100000\n","2022-02-16 19:09:50,238 epoch 6 - iter 14/19 - loss 0.99082293 - samples/sec: 381.40 - lr: 0.100000\n","2022-02-16 19:09:50,321 epoch 6 - iter 15/19 - loss 0.98684359 - samples/sec: 439.93 - lr: 0.100000\n","2022-02-16 19:09:50,417 epoch 6 - iter 16/19 - loss 0.98256209 - samples/sec: 343.12 - lr: 0.100000\n","2022-02-16 19:09:50,507 epoch 6 - iter 17/19 - loss 0.98653375 - samples/sec: 366.60 - lr: 0.100000\n","2022-02-16 19:09:50,608 epoch 6 - iter 18/19 - loss 0.98955598 - samples/sec: 338.77 - lr: 0.100000\n","2022-02-16 19:09:50,677 epoch 6 - iter 19/19 - loss 0.99727298 - samples/sec: 503.80 - lr: 0.100000\n","2022-02-16 19:09:51,171 ----------------------------------------------------------------------------------------------------\n","2022-02-16 19:09:51,179 EPOCH 6 done: loss 0.9973 - lr 0.1000000\n","2022-02-16 19:09:52,572 DEV : loss 0.9258679747581482 - score 0.5606\n","2022-02-16 19:09:52,648 BAD EPOCHS (no improvement): 0\n","saving best model\n","2022-02-16 19:10:07,818 ----------------------------------------------------------------------------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"output_type":"stream","name":"stdout","text":["2022-02-16 19:10:08,972 epoch 7 - iter 1/19 - loss 0.99051869 - samples/sec: 151.12 - lr: 0.100000\n","2022-02-16 19:10:09,083 epoch 7 - iter 2/19 - loss 0.96955398 - samples/sec: 335.88 - lr: 0.100000\n","2022-02-16 19:10:09,190 epoch 7 - iter 3/19 - loss 0.96486646 - samples/sec: 349.08 - lr: 0.100000\n","2022-02-16 19:10:09,302 epoch 7 - iter 4/19 - loss 0.96458818 - samples/sec: 310.37 - lr: 0.100000\n","2022-02-16 19:10:09,400 epoch 7 - iter 5/19 - loss 0.95933369 - samples/sec: 393.24 - lr: 0.100000\n","2022-02-16 19:10:09,519 epoch 7 - iter 6/19 - loss 0.96192254 - samples/sec: 293.69 - lr: 0.100000\n","2022-02-16 19:10:09,608 epoch 7 - iter 7/19 - loss 0.97784888 - samples/sec: 371.93 - lr: 0.100000\n","2022-02-16 19:10:09,731 epoch 7 - iter 8/19 - loss 0.97353803 - samples/sec: 345.64 - lr: 0.100000\n","2022-02-16 19:10:09,833 epoch 7 - iter 9/19 - loss 0.97601643 - samples/sec: 376.52 - lr: 0.100000\n","2022-02-16 19:10:09,931 epoch 7 - iter 10/19 - loss 0.97728331 - samples/sec: 337.83 - lr: 0.100000\n","2022-02-16 19:10:09,994 epoch 7 - iter 11/19 - loss 0.97096727 - samples/sec: 566.22 - lr: 0.100000\n","2022-02-16 19:10:10,084 epoch 7 - iter 12/19 - loss 0.96406974 - samples/sec: 379.68 - lr: 0.100000\n","2022-02-16 19:10:10,179 epoch 7 - iter 13/19 - loss 0.96236701 - samples/sec: 348.92 - lr: 0.100000\n","2022-02-16 19:10:10,270 epoch 7 - iter 14/19 - loss 0.95805451 - samples/sec: 360.45 - lr: 0.100000\n","2022-02-16 19:10:10,342 epoch 7 - iter 15/19 - loss 0.96839650 - samples/sec: 552.14 - lr: 0.100000\n","2022-02-16 19:10:10,436 epoch 7 - iter 16/19 - loss 0.97486644 - samples/sec: 344.37 - lr: 0.100000\n","2022-02-16 19:10:10,514 epoch 7 - iter 17/19 - loss 0.98751987 - samples/sec: 481.00 - lr: 0.100000\n","2022-02-16 19:10:10,596 epoch 7 - iter 18/19 - loss 0.98284318 - samples/sec: 401.88 - lr: 0.100000\n","2022-02-16 19:10:10,665 epoch 7 - iter 19/19 - loss 0.98868207 - samples/sec: 491.68 - lr: 0.100000\n","2022-02-16 19:10:11,110 ----------------------------------------------------------------------------------------------------\n","2022-02-16 19:10:11,116 EPOCH 7 done: loss 0.9887 - lr 0.1000000\n","2022-02-16 19:10:12,533 DEV : loss 0.9380063414573669 - score 0.5303\n","2022-02-16 19:10:12,600 BAD EPOCHS (no improvement): 1\n","2022-02-16 19:10:12,609 ----------------------------------------------------------------------------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"output_type":"stream","name":"stdout","text":["2022-02-16 19:10:13,545 epoch 8 - iter 1/19 - loss 1.01914907 - samples/sec: 130.69 - lr: 0.100000\n","2022-02-16 19:10:13,665 epoch 8 - iter 2/19 - loss 1.02822775 - samples/sec: 303.49 - lr: 0.100000\n","2022-02-16 19:10:13,759 epoch 8 - iter 3/19 - loss 1.02476613 - samples/sec: 405.85 - lr: 0.100000\n","2022-02-16 19:10:13,879 epoch 8 - iter 4/19 - loss 1.00970834 - samples/sec: 324.85 - lr: 0.100000\n","2022-02-16 19:10:13,984 epoch 8 - iter 5/19 - loss 0.99443305 - samples/sec: 311.18 - lr: 0.100000\n","2022-02-16 19:10:14,104 epoch 8 - iter 6/19 - loss 0.99636394 - samples/sec: 438.94 - lr: 0.100000\n","2022-02-16 19:10:14,207 epoch 8 - iter 7/19 - loss 0.99620792 - samples/sec: 326.31 - lr: 0.100000\n","2022-02-16 19:10:14,292 epoch 8 - iter 8/19 - loss 0.99830990 - samples/sec: 392.20 - lr: 0.100000\n","2022-02-16 19:10:14,391 epoch 8 - iter 9/19 - loss 0.99674157 - samples/sec: 345.47 - lr: 0.100000\n","2022-02-16 19:10:14,488 epoch 8 - iter 10/19 - loss 0.98521292 - samples/sec: 347.90 - lr: 0.100000\n","2022-02-16 19:10:14,585 epoch 8 - iter 11/19 - loss 0.99009954 - samples/sec: 338.08 - lr: 0.100000\n","2022-02-16 19:10:14,646 epoch 8 - iter 12/19 - loss 0.97733468 - samples/sec: 598.23 - lr: 0.100000\n","2022-02-16 19:10:14,737 epoch 8 - iter 13/19 - loss 0.97971425 - samples/sec: 376.12 - lr: 0.100000\n","2022-02-16 19:10:14,912 epoch 8 - iter 14/19 - loss 0.98509182 - samples/sec: 184.75 - lr: 0.100000\n","2022-02-16 19:10:15,088 epoch 8 - iter 15/19 - loss 0.98437945 - samples/sec: 188.21 - lr: 0.100000\n","2022-02-16 19:10:15,278 epoch 8 - iter 16/19 - loss 0.98253572 - samples/sec: 172.69 - lr: 0.100000\n","2022-02-16 19:10:15,477 epoch 8 - iter 17/19 - loss 0.98850227 - samples/sec: 165.78 - lr: 0.100000\n","2022-02-16 19:10:15,660 epoch 8 - iter 18/19 - loss 0.98394544 - samples/sec: 213.31 - lr: 0.100000\n","2022-02-16 19:10:15,860 epoch 8 - iter 19/19 - loss 0.98337150 - samples/sec: 179.15 - lr: 0.100000\n","2022-02-16 19:10:16,511 ----------------------------------------------------------------------------------------------------\n","2022-02-16 19:10:16,513 EPOCH 8 done: loss 0.9834 - lr 0.1000000\n","2022-02-16 19:10:18,749 DEV : loss 0.8849154710769653 - score 0.5152\n","2022-02-16 19:10:18,891 BAD EPOCHS (no improvement): 2\n","2022-02-16 19:10:18,904 ----------------------------------------------------------------------------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"output_type":"stream","name":"stdout","text":["2022-02-16 19:10:20,637 epoch 9 - iter 1/19 - loss 0.99546641 - samples/sec: 86.23 - lr: 0.100000\n","2022-02-16 19:10:25,235 epoch 9 - iter 2/19 - loss 1.02869007 - samples/sec: 208.62 - lr: 0.100000\n","2022-02-16 19:10:25,462 epoch 9 - iter 3/19 - loss 1.04102645 - samples/sec: 152.82 - lr: 0.100000\n","2022-02-16 19:10:25,784 epoch 9 - iter 4/19 - loss 1.02927917 - samples/sec: 105.99 - lr: 0.100000\n","2022-02-16 19:10:26,354 epoch 9 - iter 5/19 - loss 1.02146013 - samples/sec: 59.34 - lr: 0.100000\n","2022-02-16 19:10:31,091 epoch 9 - iter 6/19 - loss 1.02720936 - samples/sec: 260.27 - lr: 0.100000\n","2022-02-16 19:10:31,207 epoch 9 - iter 7/19 - loss 1.01259191 - samples/sec: 335.38 - lr: 0.100000\n","2022-02-16 19:10:31,305 epoch 9 - iter 8/19 - loss 1.00802738 - samples/sec: 395.53 - lr: 0.100000\n","2022-02-16 19:10:31,398 epoch 9 - iter 9/19 - loss 0.99237299 - samples/sec: 396.64 - lr: 0.100000\n","2022-02-16 19:10:31,495 epoch 9 - iter 10/19 - loss 0.98570346 - samples/sec: 357.76 - lr: 0.100000\n","2022-02-16 19:10:31,624 epoch 9 - iter 11/19 - loss 0.99368192 - samples/sec: 355.39 - lr: 0.100000\n","2022-02-16 19:10:32,295 epoch 9 - iter 12/19 - loss 0.98700965 - samples/sec: 471.58 - lr: 0.100000\n","2022-02-16 19:10:32,360 epoch 9 - iter 13/19 - loss 0.98464837 - samples/sec: 516.25 - lr: 0.100000\n","2022-02-16 19:10:32,445 epoch 9 - iter 14/19 - loss 0.97998468 - samples/sec: 397.97 - lr: 0.100000\n","2022-02-16 19:10:32,515 epoch 9 - iter 15/19 - loss 0.97129556 - samples/sec: 475.89 - lr: 0.100000\n","2022-02-16 19:10:32,581 epoch 9 - iter 16/19 - loss 0.97387005 - samples/sec: 534.27 - lr: 0.100000\n","2022-02-16 19:10:32,648 epoch 9 - iter 17/19 - loss 0.97352930 - samples/sec: 532.77 - lr: 0.100000\n","2022-02-16 19:10:32,717 epoch 9 - iter 18/19 - loss 0.97926494 - samples/sec: 527.23 - lr: 0.100000\n","2022-02-16 19:10:32,767 epoch 9 - iter 19/19 - loss 0.98307633 - samples/sec: 686.50 - lr: 0.100000\n","2022-02-16 19:10:33,179 ----------------------------------------------------------------------------------------------------\n","2022-02-16 19:10:33,180 EPOCH 9 done: loss 0.9831 - lr 0.1000000\n","2022-02-16 19:10:34,261 DEV : loss 0.8967999219894409 - score 0.5606\n","2022-02-16 19:10:34,331 BAD EPOCHS (no improvement): 0\n","saving best model\n","2022-02-16 19:10:49,778 ----------------------------------------------------------------------------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"output_type":"stream","name":"stdout","text":["2022-02-16 19:10:50,977 epoch 10 - iter 1/19 - loss 0.93296933 - samples/sec: 167.45 - lr: 0.100000\n","2022-02-16 19:10:51,070 epoch 10 - iter 2/19 - loss 0.87374014 - samples/sec: 417.07 - lr: 0.100000\n","2022-02-16 19:10:51,149 epoch 10 - iter 3/19 - loss 0.94176575 - samples/sec: 451.19 - lr: 0.100000\n","2022-02-16 19:10:51,263 epoch 10 - iter 4/19 - loss 0.94671258 - samples/sec: 341.75 - lr: 0.100000\n","2022-02-16 19:10:51,337 epoch 10 - iter 5/19 - loss 0.97687991 - samples/sec: 478.14 - lr: 0.100000\n","2022-02-16 19:10:51,425 epoch 10 - iter 6/19 - loss 0.96457736 - samples/sec: 403.87 - lr: 0.100000\n","2022-02-16 19:10:51,498 epoch 10 - iter 7/19 - loss 0.97452944 - samples/sec: 458.29 - lr: 0.100000\n","2022-02-16 19:10:51,592 epoch 10 - iter 8/19 - loss 0.97686528 - samples/sec: 563.88 - lr: 0.100000\n","2022-02-16 19:10:51,660 epoch 10 - iter 9/19 - loss 0.97822726 - samples/sec: 487.22 - lr: 0.100000\n","2022-02-16 19:10:51,748 epoch 10 - iter 10/19 - loss 0.97368624 - samples/sec: 479.93 - lr: 0.100000\n","2022-02-16 19:10:51,821 epoch 10 - iter 11/19 - loss 0.97524249 - samples/sec: 452.96 - lr: 0.100000\n","2022-02-16 19:10:51,891 epoch 10 - iter 12/19 - loss 0.97698243 - samples/sec: 476.74 - lr: 0.100000\n","2022-02-16 19:10:51,960 epoch 10 - iter 13/19 - loss 0.96731015 - samples/sec: 473.44 - lr: 0.100000\n","2022-02-16 19:10:52,045 epoch 10 - iter 14/19 - loss 0.97187351 - samples/sec: 434.95 - lr: 0.100000\n","2022-02-16 19:10:52,121 epoch 10 - iter 15/19 - loss 0.96751673 - samples/sec: 518.89 - lr: 0.100000\n","2022-02-16 19:10:52,192 epoch 10 - iter 16/19 - loss 0.97292289 - samples/sec: 507.69 - lr: 0.100000\n","2022-02-16 19:10:52,266 epoch 10 - iter 17/19 - loss 0.97225646 - samples/sec: 465.29 - lr: 0.100000\n","2022-02-16 19:10:52,333 epoch 10 - iter 18/19 - loss 0.97480736 - samples/sec: 510.49 - lr: 0.100000\n","2022-02-16 19:10:52,398 epoch 10 - iter 19/19 - loss 0.96803761 - samples/sec: 545.08 - lr: 0.100000\n","2022-02-16 19:10:52,855 ----------------------------------------------------------------------------------------------------\n","2022-02-16 19:10:52,857 EPOCH 10 done: loss 0.9680 - lr 0.1000000\n","2022-02-16 19:10:54,256 DEV : loss 0.8867483139038086 - score 0.5606\n","2022-02-16 19:10:54,338 BAD EPOCHS (no improvement): 0\n","saving best model\n","2022-02-16 19:11:09,007 ----------------------------------------------------------------------------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"output_type":"stream","name":"stdout","text":["2022-02-16 19:11:10,125 epoch 11 - iter 1/19 - loss 0.89202106 - samples/sec: 145.05 - lr: 0.100000\n","2022-02-16 19:11:10,214 epoch 11 - iter 2/19 - loss 0.92263100 - samples/sec: 431.01 - lr: 0.100000\n","2022-02-16 19:11:10,299 epoch 11 - iter 3/19 - loss 0.96687927 - samples/sec: 438.85 - lr: 0.100000\n","2022-02-16 19:11:10,396 epoch 11 - iter 4/19 - loss 0.96258129 - samples/sec: 422.84 - lr: 0.100000\n","2022-02-16 19:11:10,465 epoch 11 - iter 5/19 - loss 0.98250912 - samples/sec: 498.90 - lr: 0.100000\n","2022-02-16 19:11:10,547 epoch 11 - iter 6/19 - loss 0.97248899 - samples/sec: 501.70 - lr: 0.100000\n","2022-02-16 19:11:10,630 epoch 11 - iter 7/19 - loss 0.96204860 - samples/sec: 409.09 - lr: 0.100000\n","2022-02-16 19:11:10,701 epoch 11 - iter 8/19 - loss 0.95584661 - samples/sec: 541.95 - lr: 0.100000\n","2022-02-16 19:11:10,776 epoch 11 - iter 9/19 - loss 0.95946984 - samples/sec: 498.15 - lr: 0.100000\n","2022-02-16 19:11:10,855 epoch 11 - iter 10/19 - loss 0.95787508 - samples/sec: 495.19 - lr: 0.100000\n","2022-02-16 19:11:10,924 epoch 11 - iter 11/19 - loss 0.95731965 - samples/sec: 479.18 - lr: 0.100000\n","2022-02-16 19:11:11,004 epoch 11 - iter 12/19 - loss 0.96166833 - samples/sec: 490.10 - lr: 0.100000\n","2022-02-16 19:11:11,081 epoch 11 - iter 13/19 - loss 0.95642104 - samples/sec: 434.01 - lr: 0.100000\n","2022-02-16 19:11:11,149 epoch 11 - iter 14/19 - loss 0.96336142 - samples/sec: 539.19 - lr: 0.100000\n","2022-02-16 19:11:11,223 epoch 11 - iter 15/19 - loss 0.97358770 - samples/sec: 502.43 - lr: 0.100000\n","2022-02-16 19:11:11,297 epoch 11 - iter 16/19 - loss 0.96762208 - samples/sec: 528.57 - lr: 0.100000\n","2022-02-16 19:11:11,368 epoch 11 - iter 17/19 - loss 0.96613931 - samples/sec: 465.58 - lr: 0.100000\n","2022-02-16 19:11:11,442 epoch 11 - iter 18/19 - loss 0.96534121 - samples/sec: 514.14 - lr: 0.100000\n","2022-02-16 19:11:11,498 epoch 11 - iter 19/19 - loss 0.96289286 - samples/sec: 589.33 - lr: 0.100000\n","2022-02-16 19:11:11,942 ----------------------------------------------------------------------------------------------------\n","2022-02-16 19:11:11,951 EPOCH 11 done: loss 0.9629 - lr 0.1000000\n","2022-02-16 19:11:13,354 DEV : loss 0.888887345790863 - score 0.5303\n","2022-02-16 19:11:13,422 BAD EPOCHS (no improvement): 1\n","2022-02-16 19:11:13,430 ----------------------------------------------------------------------------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"output_type":"stream","name":"stdout","text":["2022-02-16 19:11:14,411 epoch 12 - iter 1/19 - loss 0.96598184 - samples/sec: 173.36 - lr: 0.100000\n","2022-02-16 19:11:14,489 epoch 12 - iter 2/19 - loss 0.99658680 - samples/sec: 485.18 - lr: 0.100000\n","2022-02-16 19:11:14,585 epoch 12 - iter 3/19 - loss 0.98926836 - samples/sec: 427.64 - lr: 0.100000\n","2022-02-16 19:11:14,706 epoch 12 - iter 4/19 - loss 0.95509011 - samples/sec: 340.54 - lr: 0.100000\n","2022-02-16 19:11:14,783 epoch 12 - iter 5/19 - loss 0.94124217 - samples/sec: 442.19 - lr: 0.100000\n","2022-02-16 19:11:14,858 epoch 12 - iter 6/19 - loss 0.93147156 - samples/sec: 439.65 - lr: 0.100000\n","2022-02-16 19:11:14,935 epoch 12 - iter 7/19 - loss 0.92253854 - samples/sec: 462.65 - lr: 0.100000\n","2022-02-16 19:11:15,006 epoch 12 - iter 8/19 - loss 0.92669529 - samples/sec: 464.59 - lr: 0.100000\n","2022-02-16 19:11:15,095 epoch 12 - iter 9/19 - loss 0.92505758 - samples/sec: 457.91 - lr: 0.100000\n","2022-02-16 19:11:15,163 epoch 12 - iter 10/19 - loss 0.92244743 - samples/sec: 522.61 - lr: 0.100000\n","2022-02-16 19:11:15,259 epoch 12 - iter 11/19 - loss 0.93268428 - samples/sec: 505.28 - lr: 0.100000\n","2022-02-16 19:11:15,514 epoch 12 - iter 12/19 - loss 0.93487936 - samples/sec: 127.38 - lr: 0.100000\n","2022-02-16 19:11:15,684 epoch 12 - iter 13/19 - loss 0.93068999 - samples/sec: 202.28 - lr: 0.100000\n","2022-02-16 19:11:15,906 epoch 12 - iter 14/19 - loss 0.94118394 - samples/sec: 153.82 - lr: 0.100000\n","2022-02-16 19:11:16,045 epoch 12 - iter 15/19 - loss 0.94619581 - samples/sec: 244.24 - lr: 0.100000\n","2022-02-16 19:11:16,228 epoch 12 - iter 16/19 - loss 0.94395197 - samples/sec: 185.69 - lr: 0.100000\n","2022-02-16 19:11:16,473 epoch 12 - iter 17/19 - loss 0.94146284 - samples/sec: 148.69 - lr: 0.100000\n","2022-02-16 19:11:16,655 epoch 12 - iter 18/19 - loss 0.94897573 - samples/sec: 197.77 - lr: 0.100000\n","2022-02-16 19:11:16,759 epoch 12 - iter 19/19 - loss 0.94557630 - samples/sec: 317.63 - lr: 0.100000\n","2022-02-16 19:11:17,457 ----------------------------------------------------------------------------------------------------\n","2022-02-16 19:11:17,465 EPOCH 12 done: loss 0.9456 - lr 0.1000000\n","2022-02-16 19:11:20,185 DEV : loss 0.9009777903556824 - score 0.5455\n","2022-02-16 19:11:20,390 BAD EPOCHS (no improvement): 2\n","2022-02-16 19:11:20,412 ----------------------------------------------------------------------------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"output_type":"stream","name":"stdout","text":["2022-02-16 19:11:22,236 epoch 13 - iter 1/19 - loss 0.91894865 - samples/sec: 200.37 - lr: 0.100000\n","2022-02-16 19:11:22,404 epoch 13 - iter 2/19 - loss 0.94730395 - samples/sec: 203.29 - lr: 0.100000\n","2022-02-16 19:11:22,556 epoch 13 - iter 3/19 - loss 0.97763944 - samples/sec: 235.50 - lr: 0.100000\n","2022-02-16 19:11:22,731 epoch 13 - iter 4/19 - loss 0.96872289 - samples/sec: 190.80 - lr: 0.100000\n","2022-02-16 19:11:22,944 epoch 13 - iter 5/19 - loss 0.94816481 - samples/sec: 157.12 - lr: 0.100000\n","2022-02-16 19:11:23,168 epoch 13 - iter 6/19 - loss 0.95249937 - samples/sec: 145.75 - lr: 0.100000\n","2022-02-16 19:11:23,360 epoch 13 - iter 7/19 - loss 0.96762768 - samples/sec: 225.54 - lr: 0.100000\n","2022-02-16 19:11:23,488 epoch 13 - iter 8/19 - loss 0.96454033 - samples/sec: 267.46 - lr: 0.100000\n","2022-02-16 19:11:23,644 epoch 13 - iter 9/19 - loss 0.96804439 - samples/sec: 212.26 - lr: 0.100000\n","2022-02-16 19:11:23,803 epoch 13 - iter 10/19 - loss 0.95746620 - samples/sec: 213.17 - lr: 0.100000\n","2022-02-16 19:11:23,961 epoch 13 - iter 11/19 - loss 0.94608540 - samples/sec: 213.28 - lr: 0.100000\n","2022-02-16 19:11:24,175 epoch 13 - iter 12/19 - loss 0.93837296 - samples/sec: 193.42 - lr: 0.100000\n","2022-02-16 19:11:24,377 epoch 13 - iter 13/19 - loss 0.94265125 - samples/sec: 164.87 - lr: 0.100000\n","2022-02-16 19:11:24,541 epoch 13 - iter 14/19 - loss 0.93582554 - samples/sec: 202.79 - lr: 0.100000\n","2022-02-16 19:11:24,698 epoch 13 - iter 15/19 - loss 0.93729140 - samples/sec: 216.85 - lr: 0.100000\n","2022-02-16 19:11:24,835 epoch 13 - iter 16/19 - loss 0.93547919 - samples/sec: 258.42 - lr: 0.100000\n","2022-02-16 19:11:25,011 epoch 13 - iter 17/19 - loss 0.94060993 - samples/sec: 192.61 - lr: 0.100000\n","2022-02-16 19:11:25,174 epoch 13 - iter 18/19 - loss 0.94108142 - samples/sec: 239.00 - lr: 0.100000\n","2022-02-16 19:11:25,269 epoch 13 - iter 19/19 - loss 0.94245716 - samples/sec: 372.01 - lr: 0.100000\n","2022-02-16 19:11:25,948 ----------------------------------------------------------------------------------------------------\n","2022-02-16 19:11:25,956 EPOCH 13 done: loss 0.9425 - lr 0.1000000\n","2022-02-16 19:11:28,293 DEV : loss 0.9561647176742554 - score 0.5152\n","2022-02-16 19:11:28,362 BAD EPOCHS (no improvement): 3\n","2022-02-16 19:11:28,372 ----------------------------------------------------------------------------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"output_type":"stream","name":"stdout","text":["2022-02-16 19:11:29,392 epoch 14 - iter 1/19 - loss 1.00908327 - samples/sec: 324.35 - lr: 0.100000\n","2022-02-16 19:11:29,471 epoch 14 - iter 2/19 - loss 1.00835770 - samples/sec: 465.77 - lr: 0.100000\n","2022-02-16 19:11:29,561 epoch 14 - iter 3/19 - loss 0.96074021 - samples/sec: 428.38 - lr: 0.100000\n","2022-02-16 19:11:29,638 epoch 14 - iter 4/19 - loss 0.98836461 - samples/sec: 472.80 - lr: 0.100000\n","2022-02-16 19:11:29,721 epoch 14 - iter 5/19 - loss 0.96920279 - samples/sec: 440.44 - lr: 0.100000\n","2022-02-16 19:11:29,796 epoch 14 - iter 6/19 - loss 0.95275532 - samples/sec: 470.48 - lr: 0.100000\n","2022-02-16 19:11:29,906 epoch 14 - iter 7/19 - loss 0.95042799 - samples/sec: 475.46 - lr: 0.100000\n","2022-02-16 19:11:29,980 epoch 14 - iter 8/19 - loss 0.95054425 - samples/sec: 466.35 - lr: 0.100000\n","2022-02-16 19:11:30,050 epoch 14 - iter 9/19 - loss 0.95356017 - samples/sec: 491.07 - lr: 0.100000\n","2022-02-16 19:11:30,120 epoch 14 - iter 10/19 - loss 0.95920973 - samples/sec: 482.49 - lr: 0.100000\n","2022-02-16 19:11:30,184 epoch 14 - iter 11/19 - loss 0.94512589 - samples/sec: 541.12 - lr: 0.100000\n","2022-02-16 19:11:30,256 epoch 14 - iter 12/19 - loss 0.94231193 - samples/sec: 475.14 - lr: 0.100000\n","2022-02-16 19:11:30,326 epoch 14 - iter 13/19 - loss 0.95455060 - samples/sec: 512.89 - lr: 0.100000\n","2022-02-16 19:11:30,390 epoch 14 - iter 14/19 - loss 0.95205832 - samples/sec: 544.70 - lr: 0.100000\n","2022-02-16 19:11:30,468 epoch 14 - iter 15/19 - loss 0.94944688 - samples/sec: 461.96 - lr: 0.100000\n","2022-02-16 19:11:30,549 epoch 14 - iter 16/19 - loss 0.94303165 - samples/sec: 470.13 - lr: 0.100000\n","2022-02-16 19:11:30,619 epoch 14 - iter 17/19 - loss 0.95292696 - samples/sec: 486.10 - lr: 0.100000\n","2022-02-16 19:11:30,699 epoch 14 - iter 18/19 - loss 0.94802683 - samples/sec: 426.65 - lr: 0.100000\n","2022-02-16 19:11:30,757 epoch 14 - iter 19/19 - loss 0.94432942 - samples/sec: 671.03 - lr: 0.100000\n","2022-02-16 19:11:31,206 ----------------------------------------------------------------------------------------------------\n","2022-02-16 19:11:31,208 EPOCH 14 done: loss 0.9443 - lr 0.1000000\n","2022-02-16 19:11:32,537 DEV : loss 0.876319408416748 - score 0.5303\n","Epoch    14: reducing learning rate of group 0 to 5.0000e-02.\n","2022-02-16 19:11:32,609 BAD EPOCHS (no improvement): 4\n","2022-02-16 19:11:32,620 ----------------------------------------------------------------------------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"output_type":"stream","name":"stdout","text":["2022-02-16 19:11:33,576 epoch 15 - iter 1/19 - loss 0.80608231 - samples/sec: 179.54 - lr: 0.050000\n","2022-02-16 19:11:33,670 epoch 15 - iter 2/19 - loss 0.84506398 - samples/sec: 461.08 - lr: 0.050000\n","2022-02-16 19:11:33,741 epoch 15 - iter 3/19 - loss 0.85433853 - samples/sec: 477.74 - lr: 0.050000\n","2022-02-16 19:11:33,819 epoch 15 - iter 4/19 - loss 0.88123047 - samples/sec: 440.55 - lr: 0.050000\n","2022-02-16 19:11:33,915 epoch 15 - iter 5/19 - loss 0.87904489 - samples/sec: 421.25 - lr: 0.050000\n","2022-02-16 19:11:33,997 epoch 15 - iter 6/19 - loss 0.89461514 - samples/sec: 474.09 - lr: 0.050000\n","2022-02-16 19:11:34,072 epoch 15 - iter 7/19 - loss 0.91050156 - samples/sec: 455.07 - lr: 0.050000\n","2022-02-16 19:11:34,152 epoch 15 - iter 8/19 - loss 0.92459286 - samples/sec: 521.47 - lr: 0.050000\n","2022-02-16 19:11:34,240 epoch 15 - iter 9/19 - loss 0.93063882 - samples/sec: 486.42 - lr: 0.050000\n","2022-02-16 19:11:34,320 epoch 15 - iter 10/19 - loss 0.91917890 - samples/sec: 506.86 - lr: 0.050000\n","2022-02-16 19:11:35,812 epoch 15 - iter 11/19 - loss 0.90536917 - samples/sec: 21.49 - lr: 0.050000\n","2022-02-16 19:11:35,880 epoch 15 - iter 12/19 - loss 0.89881315 - samples/sec: 487.48 - lr: 0.050000\n","2022-02-16 19:11:35,949 epoch 15 - iter 13/19 - loss 0.91109869 - samples/sec: 484.39 - lr: 0.050000\n","2022-02-16 19:11:36,013 epoch 15 - iter 14/19 - loss 0.91244087 - samples/sec: 524.89 - lr: 0.050000\n","2022-02-16 19:11:36,078 epoch 15 - iter 15/19 - loss 0.90891850 - samples/sec: 574.83 - lr: 0.050000\n","2022-02-16 19:11:36,145 epoch 15 - iter 16/19 - loss 0.92179396 - samples/sec: 557.75 - lr: 0.050000\n","2022-02-16 19:11:36,205 epoch 15 - iter 17/19 - loss 0.91599900 - samples/sec: 583.58 - lr: 0.050000\n","2022-02-16 19:11:36,269 epoch 15 - iter 18/19 - loss 0.91882226 - samples/sec: 512.17 - lr: 0.050000\n","2022-02-16 19:11:36,320 epoch 15 - iter 19/19 - loss 0.92621518 - samples/sec: 686.94 - lr: 0.050000\n","2022-02-16 19:11:36,762 ----------------------------------------------------------------------------------------------------\n","2022-02-16 19:11:36,764 EPOCH 15 done: loss 0.9262 - lr 0.0500000\n","2022-02-16 19:11:38,109 DEV : loss 0.908562421798706 - score 0.5455\n","2022-02-16 19:11:38,195 BAD EPOCHS (no improvement): 1\n","2022-02-16 19:11:38,202 ----------------------------------------------------------------------------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"output_type":"stream","name":"stdout","text":["2022-02-16 19:11:39,175 epoch 16 - iter 1/19 - loss 0.94575232 - samples/sec: 116.66 - lr: 0.050000\n","2022-02-16 19:11:39,327 epoch 16 - iter 2/19 - loss 0.94830030 - samples/sec: 308.83 - lr: 0.050000\n","2022-02-16 19:11:39,411 epoch 16 - iter 3/19 - loss 0.88087561 - samples/sec: 405.37 - lr: 0.050000\n","2022-02-16 19:11:39,491 epoch 16 - iter 4/19 - loss 0.88163987 - samples/sec: 426.06 - lr: 0.050000\n","2022-02-16 19:11:39,589 epoch 16 - iter 5/19 - loss 0.89322531 - samples/sec: 432.37 - lr: 0.050000\n","2022-02-16 19:11:39,673 epoch 16 - iter 6/19 - loss 0.88758136 - samples/sec: 440.43 - lr: 0.050000\n","2022-02-16 19:11:39,750 epoch 16 - iter 7/19 - loss 0.88041449 - samples/sec: 445.28 - lr: 0.050000\n","2022-02-16 19:11:39,849 epoch 16 - iter 8/19 - loss 0.89239967 - samples/sec: 443.80 - lr: 0.050000\n","2022-02-16 19:11:39,920 epoch 16 - iter 9/19 - loss 0.90149422 - samples/sec: 468.31 - lr: 0.050000\n","2022-02-16 19:11:39,996 epoch 16 - iter 10/19 - loss 0.88668005 - samples/sec: 452.50 - lr: 0.050000\n","2022-02-16 19:11:40,064 epoch 16 - iter 11/19 - loss 0.88088887 - samples/sec: 509.48 - lr: 0.050000\n","2022-02-16 19:11:40,142 epoch 16 - iter 12/19 - loss 0.87595351 - samples/sec: 472.37 - lr: 0.050000\n","2022-02-16 19:11:40,219 epoch 16 - iter 13/19 - loss 0.89057594 - samples/sec: 426.61 - lr: 0.050000\n","2022-02-16 19:11:40,300 epoch 16 - iter 14/19 - loss 0.89457042 - samples/sec: 515.99 - lr: 0.050000\n","2022-02-16 19:11:40,369 epoch 16 - iter 15/19 - loss 0.89667503 - samples/sec: 483.71 - lr: 0.050000\n","2022-02-16 19:11:40,452 epoch 16 - iter 16/19 - loss 0.90426981 - samples/sec: 395.30 - lr: 0.050000\n","2022-02-16 19:11:40,529 epoch 16 - iter 17/19 - loss 0.90418724 - samples/sec: 502.48 - lr: 0.050000\n","2022-02-16 19:11:40,597 epoch 16 - iter 18/19 - loss 0.91227744 - samples/sec: 553.15 - lr: 0.050000\n","2022-02-16 19:11:40,658 epoch 16 - iter 19/19 - loss 0.92469461 - samples/sec: 540.07 - lr: 0.050000\n","2022-02-16 19:11:41,110 ----------------------------------------------------------------------------------------------------\n","2022-02-16 19:11:41,116 EPOCH 16 done: loss 0.9247 - lr 0.0500000\n","2022-02-16 19:11:42,415 DEV : loss 0.9388964176177979 - score 0.5455\n","2022-02-16 19:11:42,492 BAD EPOCHS (no improvement): 2\n","2022-02-16 19:11:42,502 ----------------------------------------------------------------------------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"output_type":"stream","name":"stdout","text":["2022-02-16 19:11:43,427 epoch 17 - iter 1/19 - loss 0.95295876 - samples/sec: 127.16 - lr: 0.050000\n","2022-02-16 19:11:43,542 epoch 17 - iter 2/19 - loss 0.90363821 - samples/sec: 424.82 - lr: 0.050000\n","2022-02-16 19:11:43,635 epoch 17 - iter 3/19 - loss 0.88336559 - samples/sec: 370.85 - lr: 0.050000\n","2022-02-16 19:11:43,721 epoch 17 - iter 4/19 - loss 0.87611468 - samples/sec: 443.31 - lr: 0.050000\n","2022-02-16 19:11:43,799 epoch 17 - iter 5/19 - loss 0.91077589 - samples/sec: 441.16 - lr: 0.050000\n","2022-02-16 19:11:43,878 epoch 17 - iter 6/19 - loss 0.91822921 - samples/sec: 422.98 - lr: 0.050000\n","2022-02-16 19:11:43,953 epoch 17 - iter 7/19 - loss 0.91547292 - samples/sec: 457.82 - lr: 0.050000\n","2022-02-16 19:11:44,046 epoch 17 - iter 8/19 - loss 0.91887218 - samples/sec: 448.12 - lr: 0.050000\n","2022-02-16 19:11:44,114 epoch 17 - iter 9/19 - loss 0.91774437 - samples/sec: 486.70 - lr: 0.050000\n","2022-02-16 19:11:44,186 epoch 17 - iter 10/19 - loss 0.92701696 - samples/sec: 456.40 - lr: 0.050000\n","2022-02-16 19:11:44,260 epoch 17 - iter 11/19 - loss 0.92458690 - samples/sec: 446.60 - lr: 0.050000\n","2022-02-16 19:11:44,337 epoch 17 - iter 12/19 - loss 0.91651551 - samples/sec: 428.25 - lr: 0.050000\n","2022-02-16 19:11:44,424 epoch 17 - iter 13/19 - loss 0.91150862 - samples/sec: 401.69 - lr: 0.050000\n","2022-02-16 19:11:44,510 epoch 17 - iter 14/19 - loss 0.91618084 - samples/sec: 523.47 - lr: 0.050000\n","2022-02-16 19:11:44,581 epoch 17 - iter 15/19 - loss 0.91407162 - samples/sec: 516.89 - lr: 0.050000\n","2022-02-16 19:11:44,651 epoch 17 - iter 16/19 - loss 0.91104756 - samples/sec: 483.87 - lr: 0.050000\n","2022-02-16 19:11:44,730 epoch 17 - iter 17/19 - loss 0.91396064 - samples/sec: 427.87 - lr: 0.050000\n","2022-02-16 19:11:44,801 epoch 17 - iter 18/19 - loss 0.91412083 - samples/sec: 489.04 - lr: 0.050000\n","2022-02-16 19:11:44,857 epoch 17 - iter 19/19 - loss 0.91457684 - samples/sec: 583.73 - lr: 0.050000\n","2022-02-16 19:11:45,297 ----------------------------------------------------------------------------------------------------\n","2022-02-16 19:11:45,302 EPOCH 17 done: loss 0.9146 - lr 0.0500000\n","2022-02-16 19:11:46,586 DEV : loss 0.9433361887931824 - score 0.5303\n","2022-02-16 19:11:46,667 BAD EPOCHS (no improvement): 3\n","2022-02-16 19:11:46,675 ----------------------------------------------------------------------------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"output_type":"stream","name":"stdout","text":["2022-02-16 19:11:47,594 epoch 18 - iter 1/19 - loss 0.91576493 - samples/sec: 135.22 - lr: 0.050000\n","2022-02-16 19:11:47,701 epoch 18 - iter 2/19 - loss 0.91129610 - samples/sec: 356.25 - lr: 0.050000\n","2022-02-16 19:11:47,787 epoch 18 - iter 3/19 - loss 0.89831775 - samples/sec: 461.28 - lr: 0.050000\n","2022-02-16 19:11:47,879 epoch 18 - iter 4/19 - loss 0.92347634 - samples/sec: 415.28 - lr: 0.050000\n","2022-02-16 19:11:47,951 epoch 18 - iter 5/19 - loss 0.91751053 - samples/sec: 466.02 - lr: 0.050000\n","2022-02-16 19:11:48,040 epoch 18 - iter 6/19 - loss 0.93572408 - samples/sec: 406.81 - lr: 0.050000\n","2022-02-16 19:11:48,116 epoch 18 - iter 7/19 - loss 0.92913460 - samples/sec: 442.92 - lr: 0.050000\n","2022-02-16 19:11:48,226 epoch 18 - iter 8/19 - loss 0.92987763 - samples/sec: 503.70 - lr: 0.050000\n","2022-02-16 19:11:48,297 epoch 18 - iter 9/19 - loss 0.91860476 - samples/sec: 482.68 - lr: 0.050000\n","2022-02-16 19:11:48,364 epoch 18 - iter 10/19 - loss 0.90386010 - samples/sec: 496.95 - lr: 0.050000\n","2022-02-16 19:11:48,435 epoch 18 - iter 11/19 - loss 0.90227020 - samples/sec: 477.47 - lr: 0.050000\n","2022-02-16 19:11:48,512 epoch 18 - iter 12/19 - loss 0.90023896 - samples/sec: 436.11 - lr: 0.050000\n","2022-02-16 19:11:48,578 epoch 18 - iter 13/19 - loss 0.89884371 - samples/sec: 528.09 - lr: 0.050000\n","2022-02-16 19:11:48,651 epoch 18 - iter 14/19 - loss 0.89293617 - samples/sec: 490.87 - lr: 0.050000\n","2022-02-16 19:11:48,732 epoch 18 - iter 15/19 - loss 0.89318198 - samples/sec: 405.36 - lr: 0.050000\n","2022-02-16 19:11:48,805 epoch 18 - iter 16/19 - loss 0.88929521 - samples/sec: 453.19 - lr: 0.050000\n","2022-02-16 19:11:48,874 epoch 18 - iter 17/19 - loss 0.89531182 - samples/sec: 564.76 - lr: 0.050000\n","2022-02-16 19:11:48,949 epoch 18 - iter 18/19 - loss 0.90207338 - samples/sec: 440.08 - lr: 0.050000\n","2022-02-16 19:11:49,001 epoch 18 - iter 19/19 - loss 0.91413579 - samples/sec: 641.36 - lr: 0.050000\n","2022-02-16 19:11:49,423 ----------------------------------------------------------------------------------------------------\n","2022-02-16 19:11:49,429 EPOCH 18 done: loss 0.9141 - lr 0.0500000\n","2022-02-16 19:11:50,736 DEV : loss 0.9197553992271423 - score 0.5606\n","Epoch    18: reducing learning rate of group 0 to 2.5000e-02.\n","2022-02-16 19:11:50,816 BAD EPOCHS (no improvement): 4\n","2022-02-16 19:11:50,824 ----------------------------------------------------------------------------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"output_type":"stream","name":"stdout","text":["2022-02-16 19:11:51,764 epoch 19 - iter 1/19 - loss 0.80472195 - samples/sec: 193.78 - lr: 0.025000\n","2022-02-16 19:11:51,869 epoch 19 - iter 2/19 - loss 0.85837263 - samples/sec: 423.00 - lr: 0.025000\n","2022-02-16 19:11:51,955 epoch 19 - iter 3/19 - loss 0.91360915 - samples/sec: 462.31 - lr: 0.025000\n","2022-02-16 19:11:52,047 epoch 19 - iter 4/19 - loss 0.84620860 - samples/sec: 396.13 - lr: 0.025000\n","2022-02-16 19:11:52,126 epoch 19 - iter 5/19 - loss 0.87722785 - samples/sec: 419.62 - lr: 0.025000\n","2022-02-16 19:11:52,212 epoch 19 - iter 6/19 - loss 0.89962818 - samples/sec: 465.48 - lr: 0.025000\n","2022-02-16 19:11:52,299 epoch 19 - iter 7/19 - loss 0.89279069 - samples/sec: 432.76 - lr: 0.025000\n","2022-02-16 19:11:52,375 epoch 19 - iter 8/19 - loss 0.89077892 - samples/sec: 491.08 - lr: 0.025000\n","2022-02-16 19:11:52,454 epoch 19 - iter 9/19 - loss 0.90391765 - samples/sec: 494.77 - lr: 0.025000\n","2022-02-16 19:11:52,531 epoch 19 - iter 10/19 - loss 0.90728751 - samples/sec: 466.00 - lr: 0.025000\n","2022-02-16 19:11:52,602 epoch 19 - iter 11/19 - loss 0.89881368 - samples/sec: 460.51 - lr: 0.025000\n","2022-02-16 19:11:52,678 epoch 19 - iter 12/19 - loss 0.90064974 - samples/sec: 514.61 - lr: 0.025000\n","2022-02-16 19:11:52,756 epoch 19 - iter 13/19 - loss 0.90026136 - samples/sec: 453.50 - lr: 0.025000\n","2022-02-16 19:11:52,842 epoch 19 - iter 14/19 - loss 0.89410859 - samples/sec: 402.27 - lr: 0.025000\n","2022-02-16 19:11:52,922 epoch 19 - iter 15/19 - loss 0.89786470 - samples/sec: 486.54 - lr: 0.025000\n","2022-02-16 19:11:52,995 epoch 19 - iter 16/19 - loss 0.89771767 - samples/sec: 495.76 - lr: 0.025000\n","2022-02-16 19:11:53,069 epoch 19 - iter 17/19 - loss 0.89287260 - samples/sec: 444.93 - lr: 0.025000\n","2022-02-16 19:11:53,143 epoch 19 - iter 18/19 - loss 0.90198485 - samples/sec: 476.94 - lr: 0.025000\n","2022-02-16 19:11:53,203 epoch 19 - iter 19/19 - loss 0.89347690 - samples/sec: 605.10 - lr: 0.025000\n","2022-02-16 19:11:53,650 ----------------------------------------------------------------------------------------------------\n","2022-02-16 19:11:53,656 EPOCH 19 done: loss 0.8935 - lr 0.0250000\n","2022-02-16 19:11:55,004 DEV : loss 0.9180063009262085 - score 0.5606\n","2022-02-16 19:11:55,076 BAD EPOCHS (no improvement): 1\n","2022-02-16 19:11:55,084 ----------------------------------------------------------------------------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"output_type":"stream","name":"stdout","text":["2022-02-16 19:11:56,036 epoch 20 - iter 1/19 - loss 0.93161386 - samples/sec: 256.77 - lr: 0.025000\n","2022-02-16 19:11:56,122 epoch 20 - iter 2/19 - loss 0.95565456 - samples/sec: 434.78 - lr: 0.025000\n","2022-02-16 19:11:56,205 epoch 20 - iter 3/19 - loss 0.94506711 - samples/sec: 472.55 - lr: 0.025000\n","2022-02-16 19:11:56,298 epoch 20 - iter 4/19 - loss 0.92423396 - samples/sec: 380.10 - lr: 0.025000\n","2022-02-16 19:11:56,376 epoch 20 - iter 5/19 - loss 0.90791181 - samples/sec: 424.62 - lr: 0.025000\n","2022-02-16 19:11:56,463 epoch 20 - iter 6/19 - loss 0.90862888 - samples/sec: 463.73 - lr: 0.025000\n","2022-02-16 19:11:56,550 epoch 20 - iter 7/19 - loss 0.91683577 - samples/sec: 423.04 - lr: 0.025000\n","2022-02-16 19:11:56,620 epoch 20 - iter 8/19 - loss 0.92528366 - samples/sec: 475.46 - lr: 0.025000\n","2022-02-16 19:11:56,708 epoch 20 - iter 9/19 - loss 0.91292046 - samples/sec: 460.59 - lr: 0.025000\n","2022-02-16 19:11:56,790 epoch 20 - iter 10/19 - loss 0.90663700 - samples/sec: 402.48 - lr: 0.025000\n","2022-02-16 19:11:56,869 epoch 20 - iter 11/19 - loss 0.89530549 - samples/sec: 555.55 - lr: 0.025000\n","2022-02-16 19:11:56,937 epoch 20 - iter 12/19 - loss 0.89650155 - samples/sec: 514.13 - lr: 0.025000\n","2022-02-16 19:11:57,012 epoch 20 - iter 13/19 - loss 0.89978446 - samples/sec: 449.71 - lr: 0.025000\n","2022-02-16 19:11:57,088 epoch 20 - iter 14/19 - loss 0.89688674 - samples/sec: 438.08 - lr: 0.025000\n","2022-02-16 19:11:57,162 epoch 20 - iter 15/19 - loss 0.90145782 - samples/sec: 523.81 - lr: 0.025000\n","2022-02-16 19:11:57,228 epoch 20 - iter 16/19 - loss 0.89479341 - samples/sec: 512.63 - lr: 0.025000\n","2022-02-16 19:11:57,299 epoch 20 - iter 17/19 - loss 0.89275935 - samples/sec: 463.10 - lr: 0.025000\n","2022-02-16 19:11:57,375 epoch 20 - iter 18/19 - loss 0.89931316 - samples/sec: 473.18 - lr: 0.025000\n","2022-02-16 19:11:57,432 epoch 20 - iter 19/19 - loss 0.89442442 - samples/sec: 625.95 - lr: 0.025000\n","2022-02-16 19:11:57,871 ----------------------------------------------------------------------------------------------------\n","2022-02-16 19:11:57,873 EPOCH 20 done: loss 0.8944 - lr 0.0250000\n","2022-02-16 19:11:59,135 DEV : loss 0.9345412254333496 - score 0.5606\n","2022-02-16 19:11:59,215 BAD EPOCHS (no improvement): 2\n","2022-02-16 19:11:59,224 ----------------------------------------------------------------------------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"output_type":"stream","name":"stdout","text":["2022-02-16 19:12:00,177 epoch 21 - iter 1/19 - loss 0.79240465 - samples/sec: 129.90 - lr: 0.025000\n","2022-02-16 19:12:00,275 epoch 21 - iter 2/19 - loss 0.86162940 - samples/sec: 429.13 - lr: 0.025000\n","2022-02-16 19:12:00,372 epoch 21 - iter 3/19 - loss 0.88204652 - samples/sec: 414.12 - lr: 0.025000\n","2022-02-16 19:12:00,462 epoch 21 - iter 4/19 - loss 0.87971553 - samples/sec: 370.05 - lr: 0.025000\n","2022-02-16 19:12:00,547 epoch 21 - iter 5/19 - loss 0.88657961 - samples/sec: 389.98 - lr: 0.025000\n","2022-02-16 19:12:00,628 epoch 21 - iter 6/19 - loss 0.90570883 - samples/sec: 477.27 - lr: 0.025000\n","2022-02-16 19:12:00,707 epoch 21 - iter 7/19 - loss 0.92671202 - samples/sec: 443.83 - lr: 0.025000\n","2022-02-16 19:12:00,778 epoch 21 - iter 8/19 - loss 0.91892748 - samples/sec: 515.81 - lr: 0.025000\n","2022-02-16 19:12:00,864 epoch 21 - iter 9/19 - loss 0.91646629 - samples/sec: 496.53 - lr: 0.025000\n","2022-02-16 19:12:00,954 epoch 21 - iter 10/19 - loss 0.91386140 - samples/sec: 503.86 - lr: 0.025000\n","2022-02-16 19:12:01,019 epoch 21 - iter 11/19 - loss 0.91253863 - samples/sec: 538.30 - lr: 0.025000\n","2022-02-16 19:12:01,082 epoch 21 - iter 12/19 - loss 0.91780015 - samples/sec: 541.84 - lr: 0.025000\n","2022-02-16 19:12:01,152 epoch 21 - iter 13/19 - loss 0.91666670 - samples/sec: 488.34 - lr: 0.025000\n","2022-02-16 19:12:01,223 epoch 21 - iter 14/19 - loss 0.91530606 - samples/sec: 477.99 - lr: 0.025000\n","2022-02-16 19:12:01,294 epoch 21 - iter 15/19 - loss 0.90883568 - samples/sec: 471.94 - lr: 0.025000\n","2022-02-16 19:12:01,369 epoch 21 - iter 16/19 - loss 0.90467785 - samples/sec: 476.39 - lr: 0.025000\n","2022-02-16 19:12:01,439 epoch 21 - iter 17/19 - loss 0.90362069 - samples/sec: 483.81 - lr: 0.025000\n","2022-02-16 19:12:01,502 epoch 21 - iter 18/19 - loss 0.90223880 - samples/sec: 524.79 - lr: 0.025000\n","2022-02-16 19:12:01,555 epoch 21 - iter 19/19 - loss 0.89309286 - samples/sec: 611.82 - lr: 0.025000\n","2022-02-16 19:12:01,962 ----------------------------------------------------------------------------------------------------\n","2022-02-16 19:12:01,966 EPOCH 21 done: loss 0.8931 - lr 0.0250000\n","2022-02-16 19:12:03,258 DEV : loss 0.9248957633972168 - score 0.5606\n","2022-02-16 19:12:03,339 BAD EPOCHS (no improvement): 3\n","2022-02-16 19:12:03,348 ----------------------------------------------------------------------------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"output_type":"stream","name":"stdout","text":["2022-02-16 19:12:04,287 epoch 22 - iter 1/19 - loss 0.76790953 - samples/sec: 139.98 - lr: 0.025000\n","2022-02-16 19:12:04,387 epoch 22 - iter 2/19 - loss 0.86687747 - samples/sec: 471.76 - lr: 0.025000\n","2022-02-16 19:12:04,485 epoch 22 - iter 3/19 - loss 0.92930983 - samples/sec: 398.26 - lr: 0.025000\n","2022-02-16 19:12:04,563 epoch 22 - iter 4/19 - loss 0.93185513 - samples/sec: 443.44 - lr: 0.025000\n","2022-02-16 19:12:04,642 epoch 22 - iter 5/19 - loss 0.95231224 - samples/sec: 427.51 - lr: 0.025000\n","2022-02-16 19:12:06,195 epoch 22 - iter 6/19 - loss 0.92909808 - samples/sec: 449.77 - lr: 0.025000\n","2022-02-16 19:12:06,265 epoch 22 - iter 7/19 - loss 0.91806128 - samples/sec: 490.92 - lr: 0.025000\n","2022-02-16 19:12:06,331 epoch 22 - iter 8/19 - loss 0.92280091 - samples/sec: 494.38 - lr: 0.025000\n","2022-02-16 19:12:06,399 epoch 22 - iter 9/19 - loss 0.91042714 - samples/sec: 484.21 - lr: 0.025000\n","2022-02-16 19:12:06,464 epoch 22 - iter 10/19 - loss 0.90400426 - samples/sec: 518.91 - lr: 0.025000\n","2022-02-16 19:12:06,534 epoch 22 - iter 11/19 - loss 0.90224216 - samples/sec: 479.48 - lr: 0.025000\n","2022-02-16 19:12:06,612 epoch 22 - iter 12/19 - loss 0.90891573 - samples/sec: 531.34 - lr: 0.025000\n","2022-02-16 19:12:06,684 epoch 22 - iter 13/19 - loss 0.90020953 - samples/sec: 459.70 - lr: 0.025000\n","2022-02-16 19:12:06,749 epoch 22 - iter 14/19 - loss 0.90496552 - samples/sec: 514.38 - lr: 0.025000\n","2022-02-16 19:12:06,816 epoch 22 - iter 15/19 - loss 0.90233146 - samples/sec: 518.16 - lr: 0.025000\n","2022-02-16 19:12:06,884 epoch 22 - iter 16/19 - loss 0.90102711 - samples/sec: 490.90 - lr: 0.025000\n","2022-02-16 19:12:06,950 epoch 22 - iter 17/19 - loss 0.89834527 - samples/sec: 501.27 - lr: 0.025000\n","2022-02-16 19:12:07,023 epoch 22 - iter 18/19 - loss 0.89434487 - samples/sec: 529.16 - lr: 0.025000\n","2022-02-16 19:12:07,079 epoch 22 - iter 19/19 - loss 0.89329881 - samples/sec: 599.51 - lr: 0.025000\n","2022-02-16 19:12:07,533 ----------------------------------------------------------------------------------------------------\n","2022-02-16 19:12:07,541 EPOCH 22 done: loss 0.8933 - lr 0.0250000\n","2022-02-16 19:12:08,858 DEV : loss 0.9041862487792969 - score 0.5455\n","Epoch    22: reducing learning rate of group 0 to 1.2500e-02.\n","2022-02-16 19:12:08,932 BAD EPOCHS (no improvement): 4\n","2022-02-16 19:12:08,941 ----------------------------------------------------------------------------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"output_type":"stream","name":"stdout","text":["2022-02-16 19:12:09,896 epoch 23 - iter 1/19 - loss 0.79585248 - samples/sec: 167.02 - lr: 0.012500\n","2022-02-16 19:12:09,995 epoch 23 - iter 2/19 - loss 0.83492243 - samples/sec: 413.75 - lr: 0.012500\n","2022-02-16 19:12:10,086 epoch 23 - iter 3/19 - loss 0.88430689 - samples/sec: 434.45 - lr: 0.012500\n","2022-02-16 19:12:10,182 epoch 23 - iter 4/19 - loss 0.88262358 - samples/sec: 353.52 - lr: 0.012500\n","2022-02-16 19:12:10,267 epoch 23 - iter 5/19 - loss 0.90074887 - samples/sec: 397.29 - lr: 0.012500\n","2022-02-16 19:12:10,358 epoch 23 - iter 6/19 - loss 0.89818305 - samples/sec: 433.55 - lr: 0.012500\n","2022-02-16 19:12:10,434 epoch 23 - iter 7/19 - loss 0.90727139 - samples/sec: 448.34 - lr: 0.012500\n","2022-02-16 19:12:10,514 epoch 23 - iter 8/19 - loss 0.89099770 - samples/sec: 504.46 - lr: 0.012500\n","2022-02-16 19:12:10,597 epoch 23 - iter 9/19 - loss 0.87998038 - samples/sec: 478.80 - lr: 0.012500\n","2022-02-16 19:12:10,677 epoch 23 - iter 10/19 - loss 0.87814583 - samples/sec: 488.23 - lr: 0.012500\n","2022-02-16 19:12:10,746 epoch 23 - iter 11/19 - loss 0.89993403 - samples/sec: 499.49 - lr: 0.012500\n","2022-02-16 19:12:10,815 epoch 23 - iter 12/19 - loss 0.90135910 - samples/sec: 487.82 - lr: 0.012500\n","2022-02-16 19:12:10,882 epoch 23 - iter 13/19 - loss 0.89614798 - samples/sec: 492.08 - lr: 0.012500\n","2022-02-16 19:12:10,963 epoch 23 - iter 14/19 - loss 0.89637907 - samples/sec: 537.27 - lr: 0.012500\n","2022-02-16 19:12:11,037 epoch 23 - iter 15/19 - loss 0.88520767 - samples/sec: 548.88 - lr: 0.012500\n","2022-02-16 19:12:11,113 epoch 23 - iter 16/19 - loss 0.89069631 - samples/sec: 481.08 - lr: 0.012500\n","2022-02-16 19:12:11,184 epoch 23 - iter 17/19 - loss 0.88866559 - samples/sec: 464.26 - lr: 0.012500\n","2022-02-16 19:12:11,261 epoch 23 - iter 18/19 - loss 0.88780618 - samples/sec: 429.80 - lr: 0.012500\n","2022-02-16 19:12:11,314 epoch 23 - iter 19/19 - loss 0.88894489 - samples/sec: 625.94 - lr: 0.012500\n","2022-02-16 19:12:11,771 ----------------------------------------------------------------------------------------------------\n","2022-02-16 19:12:11,775 EPOCH 23 done: loss 0.8889 - lr 0.0125000\n","2022-02-16 19:12:13,100 DEV : loss 0.9185274839401245 - score 0.5606\n","2022-02-16 19:12:13,170 BAD EPOCHS (no improvement): 1\n","2022-02-16 19:12:13,178 ----------------------------------------------------------------------------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"output_type":"stream","name":"stdout","text":["2022-02-16 19:12:14,168 epoch 24 - iter 1/19 - loss 0.85428190 - samples/sec: 373.89 - lr: 0.012500\n","2022-02-16 19:12:14,253 epoch 24 - iter 2/19 - loss 0.84945104 - samples/sec: 398.62 - lr: 0.012500\n","2022-02-16 19:12:14,332 epoch 24 - iter 3/19 - loss 0.85388480 - samples/sec: 434.43 - lr: 0.012500\n","2022-02-16 19:12:14,414 epoch 24 - iter 4/19 - loss 0.85728188 - samples/sec: 406.51 - lr: 0.012500\n","2022-02-16 19:12:14,506 epoch 24 - iter 5/19 - loss 0.87896196 - samples/sec: 368.33 - lr: 0.012500\n","2022-02-16 19:12:14,587 epoch 24 - iter 6/19 - loss 0.85307908 - samples/sec: 424.45 - lr: 0.012500\n","2022-02-16 19:12:14,705 epoch 24 - iter 7/19 - loss 0.85874822 - samples/sec: 400.22 - lr: 0.012500\n","2022-02-16 19:12:14,776 epoch 24 - iter 8/19 - loss 0.87123723 - samples/sec: 476.29 - lr: 0.012500\n","2022-02-16 19:12:14,874 epoch 24 - iter 9/19 - loss 0.88751422 - samples/sec: 488.78 - lr: 0.012500\n","2022-02-16 19:12:14,945 epoch 24 - iter 10/19 - loss 0.90022027 - samples/sec: 490.44 - lr: 0.012500\n","2022-02-16 19:12:15,016 epoch 24 - iter 11/19 - loss 0.90116148 - samples/sec: 466.50 - lr: 0.012500\n","2022-02-16 19:12:15,086 epoch 24 - iter 12/19 - loss 0.90991946 - samples/sec: 468.69 - lr: 0.012500\n","2022-02-16 19:12:15,164 epoch 24 - iter 13/19 - loss 0.90642137 - samples/sec: 424.16 - lr: 0.012500\n","2022-02-16 19:12:15,239 epoch 24 - iter 14/19 - loss 0.90449777 - samples/sec: 467.38 - lr: 0.012500\n","2022-02-16 19:12:15,318 epoch 24 - iter 15/19 - loss 0.89222626 - samples/sec: 480.73 - lr: 0.012500\n","2022-02-16 19:12:15,390 epoch 24 - iter 16/19 - loss 0.89718622 - samples/sec: 469.66 - lr: 0.012500\n","2022-02-16 19:12:15,467 epoch 24 - iter 17/19 - loss 0.89261210 - samples/sec: 427.66 - lr: 0.012500\n","2022-02-16 19:12:15,541 epoch 24 - iter 18/19 - loss 0.89778081 - samples/sec: 525.09 - lr: 0.012500\n","2022-02-16 19:12:15,596 epoch 24 - iter 19/19 - loss 0.90012416 - samples/sec: 609.06 - lr: 0.012500\n","2022-02-16 19:12:16,043 ----------------------------------------------------------------------------------------------------\n","2022-02-16 19:12:16,049 EPOCH 24 done: loss 0.9001 - lr 0.0125000\n","2022-02-16 19:12:17,388 DEV : loss 0.9254951477050781 - score 0.5606\n","2022-02-16 19:12:17,457 BAD EPOCHS (no improvement): 2\n","2022-02-16 19:12:17,465 ----------------------------------------------------------------------------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"output_type":"stream","name":"stdout","text":["2022-02-16 19:12:18,413 epoch 25 - iter 1/19 - loss 0.99143946 - samples/sec: 146.79 - lr: 0.012500\n","2022-02-16 19:12:18,512 epoch 25 - iter 2/19 - loss 0.94855359 - samples/sec: 406.53 - lr: 0.012500\n","2022-02-16 19:12:18,604 epoch 25 - iter 3/19 - loss 0.88033593 - samples/sec: 449.87 - lr: 0.012500\n","2022-02-16 19:12:18,697 epoch 25 - iter 4/19 - loss 0.90131393 - samples/sec: 358.57 - lr: 0.012500\n","2022-02-16 19:12:18,768 epoch 25 - iter 5/19 - loss 0.88947457 - samples/sec: 479.21 - lr: 0.012500\n","2022-02-16 19:12:18,852 epoch 25 - iter 6/19 - loss 0.90805629 - samples/sec: 440.61 - lr: 0.012500\n","2022-02-16 19:12:18,938 epoch 25 - iter 7/19 - loss 0.91959560 - samples/sec: 392.13 - lr: 0.012500\n","2022-02-16 19:12:19,019 epoch 25 - iter 8/19 - loss 0.91942864 - samples/sec: 516.69 - lr: 0.012500\n","2022-02-16 19:12:19,110 epoch 25 - iter 9/19 - loss 0.91913711 - samples/sec: 452.99 - lr: 0.012500\n","2022-02-16 19:12:19,187 epoch 25 - iter 10/19 - loss 0.91443413 - samples/sec: 432.10 - lr: 0.012500\n","2022-02-16 19:12:19,254 epoch 25 - iter 11/19 - loss 0.90559937 - samples/sec: 494.91 - lr: 0.012500\n","2022-02-16 19:12:19,328 epoch 25 - iter 12/19 - loss 0.89965279 - samples/sec: 460.92 - lr: 0.012500\n","2022-02-16 19:12:19,414 epoch 25 - iter 13/19 - loss 0.90167989 - samples/sec: 574.91 - lr: 0.012500\n","2022-02-16 19:12:19,486 epoch 25 - iter 14/19 - loss 0.89605572 - samples/sec: 457.08 - lr: 0.012500\n","2022-02-16 19:12:19,558 epoch 25 - iter 15/19 - loss 0.89306256 - samples/sec: 458.95 - lr: 0.012500\n","2022-02-16 19:12:19,627 epoch 25 - iter 16/19 - loss 0.89696840 - samples/sec: 508.11 - lr: 0.012500\n","2022-02-16 19:12:19,703 epoch 25 - iter 17/19 - loss 0.89845973 - samples/sec: 427.50 - lr: 0.012500\n","2022-02-16 19:12:19,774 epoch 25 - iter 18/19 - loss 0.89602812 - samples/sec: 488.05 - lr: 0.012500\n","2022-02-16 19:12:19,833 epoch 25 - iter 19/19 - loss 0.89340206 - samples/sec: 667.15 - lr: 0.012500\n","2022-02-16 19:12:20,281 ----------------------------------------------------------------------------------------------------\n","2022-02-16 19:12:20,283 EPOCH 25 done: loss 0.8934 - lr 0.0125000\n","2022-02-16 19:12:21,614 DEV : loss 0.9159201979637146 - score 0.5455\n","2022-02-16 19:12:21,688 BAD EPOCHS (no improvement): 3\n","2022-02-16 19:12:21,699 ----------------------------------------------------------------------------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"output_type":"stream","name":"stdout","text":["2022-02-16 19:12:22,700 epoch 26 - iter 1/19 - loss 0.84821153 - samples/sec: 178.65 - lr: 0.012500\n","2022-02-16 19:12:22,802 epoch 26 - iter 2/19 - loss 0.85649589 - samples/sec: 410.89 - lr: 0.012500\n","2022-02-16 19:12:22,877 epoch 26 - iter 3/19 - loss 0.84677289 - samples/sec: 459.10 - lr: 0.012500\n","2022-02-16 19:12:22,959 epoch 26 - iter 4/19 - loss 0.95821778 - samples/sec: 417.89 - lr: 0.012500\n","2022-02-16 19:12:23,055 epoch 26 - iter 5/19 - loss 0.93608062 - samples/sec: 379.94 - lr: 0.012500\n","2022-02-16 19:12:23,137 epoch 26 - iter 6/19 - loss 0.92684301 - samples/sec: 460.17 - lr: 0.012500\n","2022-02-16 19:12:23,219 epoch 26 - iter 7/19 - loss 0.92330577 - samples/sec: 437.18 - lr: 0.012500\n","2022-02-16 19:12:23,297 epoch 26 - iter 8/19 - loss 0.91655505 - samples/sec: 517.99 - lr: 0.012500\n","2022-02-16 19:12:23,365 epoch 26 - iter 9/19 - loss 0.92773632 - samples/sec: 482.11 - lr: 0.012500\n","2022-02-16 19:12:23,473 epoch 26 - iter 10/19 - loss 0.91369815 - samples/sec: 457.75 - lr: 0.012500\n","2022-02-16 19:12:23,550 epoch 26 - iter 11/19 - loss 0.91837439 - samples/sec: 425.79 - lr: 0.012500\n","2022-02-16 19:12:23,619 epoch 26 - iter 12/19 - loss 0.90551195 - samples/sec: 471.87 - lr: 0.012500\n","2022-02-16 19:12:23,708 epoch 26 - iter 13/19 - loss 0.89940639 - samples/sec: 368.25 - lr: 0.012500\n","2022-02-16 19:12:23,793 epoch 26 - iter 14/19 - loss 0.89165847 - samples/sec: 386.12 - lr: 0.012500\n","2022-02-16 19:12:23,857 epoch 26 - iter 15/19 - loss 0.90314972 - samples/sec: 524.84 - lr: 0.012500\n","2022-02-16 19:12:23,927 epoch 26 - iter 16/19 - loss 0.90052499 - samples/sec: 546.76 - lr: 0.012500\n","2022-02-16 19:12:23,997 epoch 26 - iter 17/19 - loss 0.88893093 - samples/sec: 468.69 - lr: 0.012500\n","2022-02-16 19:12:24,084 epoch 26 - iter 18/19 - loss 0.89352048 - samples/sec: 379.10 - lr: 0.012500\n","2022-02-16 19:12:24,140 epoch 26 - iter 19/19 - loss 0.89514884 - samples/sec: 600.03 - lr: 0.012500\n","2022-02-16 19:12:24,560 ----------------------------------------------------------------------------------------------------\n","2022-02-16 19:12:24,564 EPOCH 26 done: loss 0.8951 - lr 0.0125000\n","2022-02-16 19:12:25,903 DEV : loss 0.9282150268554688 - score 0.5606\n","Epoch    26: reducing learning rate of group 0 to 6.2500e-03.\n","2022-02-16 19:12:25,983 BAD EPOCHS (no improvement): 4\n","2022-02-16 19:12:25,993 ----------------------------------------------------------------------------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"output_type":"stream","name":"stdout","text":["2022-02-16 19:12:26,987 epoch 27 - iter 1/19 - loss 0.69161743 - samples/sec: 301.00 - lr: 0.006250\n","2022-02-16 19:12:27,068 epoch 27 - iter 2/19 - loss 0.83003590 - samples/sec: 421.19 - lr: 0.006250\n","2022-02-16 19:12:27,150 epoch 27 - iter 3/19 - loss 0.91397657 - samples/sec: 420.07 - lr: 0.006250\n","2022-02-16 19:12:27,233 epoch 27 - iter 4/19 - loss 0.96376072 - samples/sec: 401.05 - lr: 0.006250\n","2022-02-16 19:12:27,312 epoch 27 - iter 5/19 - loss 0.93388535 - samples/sec: 438.28 - lr: 0.006250\n","2022-02-16 19:12:27,408 epoch 27 - iter 6/19 - loss 0.91450063 - samples/sec: 443.77 - lr: 0.006250\n","2022-02-16 19:12:27,518 epoch 27 - iter 7/19 - loss 0.90871863 - samples/sec: 421.24 - lr: 0.006250\n","2022-02-16 19:12:27,586 epoch 27 - iter 8/19 - loss 0.89450098 - samples/sec: 485.94 - lr: 0.006250\n","2022-02-16 19:12:27,660 epoch 27 - iter 9/19 - loss 0.88743216 - samples/sec: 501.44 - lr: 0.006250\n","2022-02-16 19:12:27,734 epoch 27 - iter 10/19 - loss 0.88786709 - samples/sec: 448.02 - lr: 0.006250\n","2022-02-16 19:12:27,804 epoch 27 - iter 11/19 - loss 0.90315503 - samples/sec: 467.20 - lr: 0.006250\n","2022-02-16 19:12:27,876 epoch 27 - iter 12/19 - loss 0.89186064 - samples/sec: 478.63 - lr: 0.006250\n","2022-02-16 19:12:27,961 epoch 27 - iter 13/19 - loss 0.88426541 - samples/sec: 516.20 - lr: 0.006250\n","2022-02-16 19:12:28,033 epoch 27 - iter 14/19 - loss 0.89541980 - samples/sec: 453.84 - lr: 0.006250\n","2022-02-16 19:12:28,106 epoch 27 - iter 15/19 - loss 0.89393527 - samples/sec: 521.03 - lr: 0.006250\n","2022-02-16 19:12:28,177 epoch 27 - iter 16/19 - loss 0.89607500 - samples/sec: 461.93 - lr: 0.006250\n","2022-02-16 19:12:28,239 epoch 27 - iter 17/19 - loss 0.89486724 - samples/sec: 554.58 - lr: 0.006250\n","2022-02-16 19:12:28,317 epoch 27 - iter 18/19 - loss 0.89370528 - samples/sec: 460.92 - lr: 0.006250\n","2022-02-16 19:12:28,385 epoch 27 - iter 19/19 - loss 0.88499668 - samples/sec: 548.32 - lr: 0.006250\n","2022-02-16 19:12:28,825 ----------------------------------------------------------------------------------------------------\n","2022-02-16 19:12:28,833 EPOCH 27 done: loss 0.8850 - lr 0.0062500\n","2022-02-16 19:12:30,182 DEV : loss 0.921781063079834 - score 0.5606\n","2022-02-16 19:12:30,255 BAD EPOCHS (no improvement): 1\n","2022-02-16 19:12:30,262 ----------------------------------------------------------------------------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"output_type":"stream","name":"stdout","text":["2022-02-16 19:12:31,221 epoch 28 - iter 1/19 - loss 0.85771120 - samples/sec: 181.43 - lr: 0.006250\n","2022-02-16 19:12:31,309 epoch 28 - iter 2/19 - loss 0.80959213 - samples/sec: 415.25 - lr: 0.006250\n","2022-02-16 19:12:31,402 epoch 28 - iter 3/19 - loss 0.85148354 - samples/sec: 424.09 - lr: 0.006250\n","2022-02-16 19:12:31,489 epoch 28 - iter 4/19 - loss 0.87131846 - samples/sec: 420.95 - lr: 0.006250\n","2022-02-16 19:12:31,598 epoch 28 - iter 5/19 - loss 0.86543220 - samples/sec: 391.86 - lr: 0.006250\n","2022-02-16 19:12:31,686 epoch 28 - iter 6/19 - loss 0.85598768 - samples/sec: 399.25 - lr: 0.006250\n","2022-02-16 19:12:31,766 epoch 28 - iter 7/19 - loss 0.87219008 - samples/sec: 424.85 - lr: 0.006250\n","2022-02-16 19:12:31,832 epoch 28 - iter 8/19 - loss 0.86217085 - samples/sec: 501.19 - lr: 0.006250\n","2022-02-16 19:12:31,910 epoch 28 - iter 9/19 - loss 0.87168027 - samples/sec: 508.65 - lr: 0.006250\n","2022-02-16 19:12:31,982 epoch 28 - iter 10/19 - loss 0.87339530 - samples/sec: 500.64 - lr: 0.006250\n","2022-02-16 19:12:32,067 epoch 28 - iter 11/19 - loss 0.87276114 - samples/sec: 463.41 - lr: 0.006250\n","2022-02-16 19:12:32,137 epoch 28 - iter 12/19 - loss 0.87304818 - samples/sec: 534.12 - lr: 0.006250\n","2022-02-16 19:12:32,218 epoch 28 - iter 13/19 - loss 0.87709423 - samples/sec: 492.56 - lr: 0.006250\n","2022-02-16 19:12:32,293 epoch 28 - iter 14/19 - loss 0.87872324 - samples/sec: 451.07 - lr: 0.006250\n","2022-02-16 19:12:32,360 epoch 28 - iter 15/19 - loss 0.88416139 - samples/sec: 498.93 - lr: 0.006250\n","2022-02-16 19:12:32,440 epoch 28 - iter 16/19 - loss 0.88513000 - samples/sec: 411.14 - lr: 0.006250\n","2022-02-16 19:12:32,526 epoch 28 - iter 17/19 - loss 0.88442269 - samples/sec: 466.47 - lr: 0.006250\n","2022-02-16 19:12:32,637 epoch 28 - iter 18/19 - loss 0.88397922 - samples/sec: 300.10 - lr: 0.006250\n","2022-02-16 19:12:32,709 epoch 28 - iter 19/19 - loss 0.88596011 - samples/sec: 453.07 - lr: 0.006250\n","2022-02-16 19:12:33,138 ----------------------------------------------------------------------------------------------------\n","2022-02-16 19:12:33,144 EPOCH 28 done: loss 0.8860 - lr 0.0062500\n","2022-02-16 19:12:37,712 DEV : loss 0.9181589484214783 - score 0.5606\n","2022-02-16 19:12:37,796 BAD EPOCHS (no improvement): 2\n","2022-02-16 19:12:37,801 ----------------------------------------------------------------------------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"output_type":"stream","name":"stdout","text":["2022-02-16 19:12:38,746 epoch 29 - iter 1/19 - loss 0.73285609 - samples/sec: 188.15 - lr: 0.006250\n","2022-02-16 19:12:38,833 epoch 29 - iter 2/19 - loss 0.77359131 - samples/sec: 389.26 - lr: 0.006250\n","2022-02-16 19:12:38,928 epoch 29 - iter 3/19 - loss 0.76577445 - samples/sec: 380.60 - lr: 0.006250\n","2022-02-16 19:12:39,039 epoch 29 - iter 4/19 - loss 0.86985800 - samples/sec: 349.22 - lr: 0.006250\n","2022-02-16 19:12:39,141 epoch 29 - iter 5/19 - loss 0.88260027 - samples/sec: 432.39 - lr: 0.006250\n","2022-02-16 19:12:39,223 epoch 29 - iter 6/19 - loss 0.85246552 - samples/sec: 403.37 - lr: 0.006250\n","2022-02-16 19:12:39,320 epoch 29 - iter 7/19 - loss 0.85589561 - samples/sec: 341.77 - lr: 0.006250\n","2022-02-16 19:12:39,393 epoch 29 - iter 8/19 - loss 0.85405504 - samples/sec: 453.85 - lr: 0.006250\n","2022-02-16 19:12:39,465 epoch 29 - iter 9/19 - loss 0.85907941 - samples/sec: 463.32 - lr: 0.006250\n","2022-02-16 19:12:39,552 epoch 29 - iter 10/19 - loss 0.86313010 - samples/sec: 489.59 - lr: 0.006250\n","2022-02-16 19:12:39,622 epoch 29 - iter 11/19 - loss 0.85871117 - samples/sec: 469.31 - lr: 0.006250\n","2022-02-16 19:12:39,699 epoch 29 - iter 12/19 - loss 0.86254352 - samples/sec: 432.07 - lr: 0.006250\n","2022-02-16 19:12:39,770 epoch 29 - iter 13/19 - loss 0.86523192 - samples/sec: 462.09 - lr: 0.006250\n","2022-02-16 19:12:39,851 epoch 29 - iter 14/19 - loss 0.87835026 - samples/sec: 512.58 - lr: 0.006250\n","2022-02-16 19:12:39,933 epoch 29 - iter 15/19 - loss 0.88758987 - samples/sec: 399.43 - lr: 0.006250\n","2022-02-16 19:12:40,012 epoch 29 - iter 16/19 - loss 0.88466347 - samples/sec: 504.05 - lr: 0.006250\n","2022-02-16 19:12:40,096 epoch 29 - iter 17/19 - loss 0.88429762 - samples/sec: 403.72 - lr: 0.006250\n","2022-02-16 19:12:40,176 epoch 29 - iter 18/19 - loss 0.87788043 - samples/sec: 419.93 - lr: 0.006250\n","2022-02-16 19:12:40,236 epoch 29 - iter 19/19 - loss 0.87419605 - samples/sec: 561.36 - lr: 0.006250\n","2022-02-16 19:12:40,626 ----------------------------------------------------------------------------------------------------\n","2022-02-16 19:12:40,634 EPOCH 29 done: loss 0.8742 - lr 0.0062500\n","2022-02-16 19:12:41,895 DEV : loss 0.919507622718811 - score 0.5606\n","2022-02-16 19:12:41,966 BAD EPOCHS (no improvement): 3\n","2022-02-16 19:12:41,974 ----------------------------------------------------------------------------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"output_type":"stream","name":"stdout","text":["2022-02-16 19:12:42,926 epoch 30 - iter 1/19 - loss 0.86471194 - samples/sec: 120.74 - lr: 0.006250\n","2022-02-16 19:12:43,020 epoch 30 - iter 2/19 - loss 0.87649125 - samples/sec: 424.01 - lr: 0.006250\n","2022-02-16 19:12:43,140 epoch 30 - iter 3/19 - loss 0.87994413 - samples/sec: 422.03 - lr: 0.006250\n","2022-02-16 19:12:43,234 epoch 30 - iter 4/19 - loss 0.91814923 - samples/sec: 380.35 - lr: 0.006250\n","2022-02-16 19:12:43,321 epoch 30 - iter 5/19 - loss 0.90373322 - samples/sec: 417.09 - lr: 0.006250\n","2022-02-16 19:12:43,415 epoch 30 - iter 6/19 - loss 0.89497837 - samples/sec: 352.47 - lr: 0.006250\n","2022-02-16 19:12:43,492 epoch 30 - iter 7/19 - loss 0.88113391 - samples/sec: 464.73 - lr: 0.006250\n","2022-02-16 19:12:43,563 epoch 30 - iter 8/19 - loss 0.89655717 - samples/sec: 465.98 - lr: 0.006250\n","2022-02-16 19:12:43,636 epoch 30 - iter 9/19 - loss 0.90591578 - samples/sec: 510.11 - lr: 0.006250\n","2022-02-16 19:12:43,715 epoch 30 - iter 10/19 - loss 0.88792393 - samples/sec: 416.40 - lr: 0.006250\n","2022-02-16 19:12:43,783 epoch 30 - iter 11/19 - loss 0.88375187 - samples/sec: 569.36 - lr: 0.006250\n","2022-02-16 19:12:43,852 epoch 30 - iter 12/19 - loss 0.88575485 - samples/sec: 473.81 - lr: 0.006250\n","2022-02-16 19:12:43,930 epoch 30 - iter 13/19 - loss 0.89057245 - samples/sec: 432.28 - lr: 0.006250\n","2022-02-16 19:12:43,998 epoch 30 - iter 14/19 - loss 0.89978832 - samples/sec: 479.07 - lr: 0.006250\n","2022-02-16 19:12:44,068 epoch 30 - iter 15/19 - loss 0.89168481 - samples/sec: 551.87 - lr: 0.006250\n","2022-02-16 19:12:44,149 epoch 30 - iter 16/19 - loss 0.88532856 - samples/sec: 436.05 - lr: 0.006250\n","2022-02-16 19:12:44,227 epoch 30 - iter 17/19 - loss 0.87897144 - samples/sec: 534.44 - lr: 0.006250\n","2022-02-16 19:12:44,300 epoch 30 - iter 18/19 - loss 0.87908862 - samples/sec: 453.31 - lr: 0.006250\n","2022-02-16 19:12:44,359 epoch 30 - iter 19/19 - loss 0.88317272 - samples/sec: 616.33 - lr: 0.006250\n","2022-02-16 19:12:44,758 ----------------------------------------------------------------------------------------------------\n","2022-02-16 19:12:44,765 EPOCH 30 done: loss 0.8832 - lr 0.0062500\n","2022-02-16 19:12:46,012 DEV : loss 0.9146279096603394 - score 0.5455\n","Epoch    30: reducing learning rate of group 0 to 3.1250e-03.\n","2022-02-16 19:12:46,082 BAD EPOCHS (no improvement): 4\n","2022-02-16 19:12:46,091 ----------------------------------------------------------------------------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"output_type":"stream","name":"stdout","text":["2022-02-16 19:12:47,064 epoch 31 - iter 1/19 - loss 0.91149956 - samples/sec: 269.94 - lr: 0.003125\n","2022-02-16 19:12:47,154 epoch 31 - iter 2/19 - loss 0.91337523 - samples/sec: 403.19 - lr: 0.003125\n","2022-02-16 19:12:47,233 epoch 31 - iter 3/19 - loss 0.91550084 - samples/sec: 455.17 - lr: 0.003125\n","2022-02-16 19:12:47,319 epoch 31 - iter 4/19 - loss 0.92775366 - samples/sec: 386.48 - lr: 0.003125\n","2022-02-16 19:12:47,407 epoch 31 - iter 5/19 - loss 0.93223224 - samples/sec: 386.94 - lr: 0.003125\n","2022-02-16 19:12:47,488 epoch 31 - iter 6/19 - loss 0.91604686 - samples/sec: 429.58 - lr: 0.003125\n","2022-02-16 19:12:47,611 epoch 31 - iter 7/19 - loss 0.89331469 - samples/sec: 412.71 - lr: 0.003125\n","2022-02-16 19:12:47,694 epoch 31 - iter 8/19 - loss 0.89196771 - samples/sec: 399.66 - lr: 0.003125\n","2022-02-16 19:12:47,775 epoch 31 - iter 9/19 - loss 0.90559166 - samples/sec: 505.16 - lr: 0.003125\n","2022-02-16 19:12:47,852 epoch 31 - iter 10/19 - loss 0.89966268 - samples/sec: 448.00 - lr: 0.003125\n","2022-02-16 19:12:47,924 epoch 31 - iter 11/19 - loss 0.89468178 - samples/sec: 479.33 - lr: 0.003125\n","2022-02-16 19:12:47,997 epoch 31 - iter 12/19 - loss 0.88412680 - samples/sec: 451.75 - lr: 0.003125\n","2022-02-16 19:12:48,071 epoch 31 - iter 13/19 - loss 0.87950804 - samples/sec: 440.45 - lr: 0.003125\n","2022-02-16 19:12:48,147 epoch 31 - iter 14/19 - loss 0.87756274 - samples/sec: 517.79 - lr: 0.003125\n","2022-02-16 19:12:48,217 epoch 31 - iter 15/19 - loss 0.87684116 - samples/sec: 484.97 - lr: 0.003125\n","2022-02-16 19:12:48,287 epoch 31 - iter 16/19 - loss 0.87541101 - samples/sec: 470.02 - lr: 0.003125\n","2022-02-16 19:12:48,358 epoch 31 - iter 17/19 - loss 0.86504155 - samples/sec: 502.01 - lr: 0.003125\n","2022-02-16 19:12:48,440 epoch 31 - iter 18/19 - loss 0.87677861 - samples/sec: 397.17 - lr: 0.003125\n","2022-02-16 19:12:48,500 epoch 31 - iter 19/19 - loss 0.87749988 - samples/sec: 565.72 - lr: 0.003125\n","2022-02-16 19:12:48,898 ----------------------------------------------------------------------------------------------------\n","2022-02-16 19:12:48,900 EPOCH 31 done: loss 0.8775 - lr 0.0031250\n","2022-02-16 19:12:50,199 DEV : loss 0.9167970418930054 - score 0.5455\n","2022-02-16 19:12:50,274 BAD EPOCHS (no improvement): 1\n","2022-02-16 19:12:50,283 ----------------------------------------------------------------------------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"output_type":"stream","name":"stdout","text":["2022-02-16 19:12:51,234 epoch 32 - iter 1/19 - loss 0.92692465 - samples/sec: 153.30 - lr: 0.003125\n","2022-02-16 19:12:51,337 epoch 32 - iter 2/19 - loss 0.94319767 - samples/sec: 392.71 - lr: 0.003125\n","2022-02-16 19:12:51,418 epoch 32 - iter 3/19 - loss 0.88572772 - samples/sec: 436.78 - lr: 0.003125\n","2022-02-16 19:12:51,501 epoch 32 - iter 4/19 - loss 0.88622336 - samples/sec: 452.95 - lr: 0.003125\n","2022-02-16 19:12:51,588 epoch 32 - iter 5/19 - loss 0.84711074 - samples/sec: 424.46 - lr: 0.003125\n","2022-02-16 19:12:51,705 epoch 32 - iter 6/19 - loss 0.85678029 - samples/sec: 437.37 - lr: 0.003125\n","2022-02-16 19:12:51,781 epoch 32 - iter 7/19 - loss 0.85243063 - samples/sec: 436.34 - lr: 0.003125\n","2022-02-16 19:12:51,862 epoch 32 - iter 8/19 - loss 0.84494469 - samples/sec: 422.21 - lr: 0.003125\n","2022-02-16 19:12:51,939 epoch 32 - iter 9/19 - loss 0.84272552 - samples/sec: 452.06 - lr: 0.003125\n","2022-02-16 19:12:52,023 epoch 32 - iter 10/19 - loss 0.83322446 - samples/sec: 508.01 - lr: 0.003125\n","2022-02-16 19:12:52,088 epoch 32 - iter 11/19 - loss 0.83979709 - samples/sec: 506.29 - lr: 0.003125\n","2022-02-16 19:12:52,156 epoch 32 - iter 12/19 - loss 0.83945550 - samples/sec: 485.75 - lr: 0.003125\n","2022-02-16 19:12:52,228 epoch 32 - iter 13/19 - loss 0.84944555 - samples/sec: 460.04 - lr: 0.003125\n","2022-02-16 19:12:52,300 epoch 32 - iter 14/19 - loss 0.85569151 - samples/sec: 463.64 - lr: 0.003125\n","2022-02-16 19:12:52,365 epoch 32 - iter 15/19 - loss 0.86756948 - samples/sec: 510.95 - lr: 0.003125\n","2022-02-16 19:12:52,435 epoch 32 - iter 16/19 - loss 0.87034882 - samples/sec: 600.52 - lr: 0.003125\n","2022-02-16 19:12:52,515 epoch 32 - iter 17/19 - loss 0.86978011 - samples/sec: 414.39 - lr: 0.003125\n","2022-02-16 19:12:52,585 epoch 32 - iter 18/19 - loss 0.86660951 - samples/sec: 480.41 - lr: 0.003125\n","2022-02-16 19:12:52,638 epoch 32 - iter 19/19 - loss 0.88173107 - samples/sec: 644.59 - lr: 0.003125\n","2022-02-16 19:12:53,039 ----------------------------------------------------------------------------------------------------\n","2022-02-16 19:12:53,045 EPOCH 32 done: loss 0.8817 - lr 0.0031250\n","2022-02-16 19:12:54,303 DEV : loss 0.9186007380485535 - score 0.5606\n","2022-02-16 19:12:54,375 BAD EPOCHS (no improvement): 2\n","2022-02-16 19:12:54,383 ----------------------------------------------------------------------------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"output_type":"stream","name":"stdout","text":["2022-02-16 19:12:55,368 epoch 33 - iter 1/19 - loss 0.87398684 - samples/sec: 335.35 - lr: 0.003125\n","2022-02-16 19:12:55,459 epoch 33 - iter 2/19 - loss 0.90576655 - samples/sec: 388.77 - lr: 0.003125\n","2022-02-16 19:12:55,547 epoch 33 - iter 3/19 - loss 0.88016758 - samples/sec: 387.75 - lr: 0.003125\n","2022-02-16 19:12:55,631 epoch 33 - iter 4/19 - loss 0.88438436 - samples/sec: 412.62 - lr: 0.003125\n","2022-02-16 19:12:55,713 epoch 33 - iter 5/19 - loss 0.86524349 - samples/sec: 437.28 - lr: 0.003125\n","2022-02-16 19:12:55,801 epoch 33 - iter 6/19 - loss 0.86906781 - samples/sec: 429.67 - lr: 0.003125\n","2022-02-16 19:12:55,925 epoch 33 - iter 7/19 - loss 0.86327559 - samples/sec: 425.00 - lr: 0.003125\n","2022-02-16 19:12:55,998 epoch 33 - iter 8/19 - loss 0.87490549 - samples/sec: 477.59 - lr: 0.003125\n","2022-02-16 19:12:56,071 epoch 33 - iter 9/19 - loss 0.86534214 - samples/sec: 464.75 - lr: 0.003125\n","2022-02-16 19:12:56,153 epoch 33 - iter 10/19 - loss 0.88421959 - samples/sec: 396.57 - lr: 0.003125\n","2022-02-16 19:12:56,222 epoch 33 - iter 11/19 - loss 0.88501098 - samples/sec: 482.34 - lr: 0.003125\n","2022-02-16 19:12:56,291 epoch 33 - iter 12/19 - loss 0.87820521 - samples/sec: 475.59 - lr: 0.003125\n","2022-02-16 19:12:56,364 epoch 33 - iter 13/19 - loss 0.88295174 - samples/sec: 492.42 - lr: 0.003125\n","2022-02-16 19:12:56,438 epoch 33 - iter 14/19 - loss 0.88969849 - samples/sec: 468.20 - lr: 0.003125\n","2022-02-16 19:12:56,511 epoch 33 - iter 15/19 - loss 0.89172187 - samples/sec: 536.10 - lr: 0.003125\n","2022-02-16 19:12:56,577 epoch 33 - iter 16/19 - loss 0.89191914 - samples/sec: 503.44 - lr: 0.003125\n","2022-02-16 19:12:56,646 epoch 33 - iter 17/19 - loss 0.88334760 - samples/sec: 476.82 - lr: 0.003125\n","2022-02-16 19:12:56,718 epoch 33 - iter 18/19 - loss 0.87759544 - samples/sec: 461.63 - lr: 0.003125\n","2022-02-16 19:12:56,777 epoch 33 - iter 19/19 - loss 0.87990814 - samples/sec: 673.95 - lr: 0.003125\n","2022-02-16 19:12:57,183 ----------------------------------------------------------------------------------------------------\n","2022-02-16 19:12:57,189 EPOCH 33 done: loss 0.8799 - lr 0.0031250\n","2022-02-16 19:12:58,458 DEV : loss 0.9212898015975952 - score 0.5606\n","2022-02-16 19:12:58,537 BAD EPOCHS (no improvement): 3\n","2022-02-16 19:12:58,545 ----------------------------------------------------------------------------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"output_type":"stream","name":"stdout","text":["2022-02-16 19:12:59,492 epoch 34 - iter 1/19 - loss 0.96114576 - samples/sec: 161.48 - lr: 0.003125\n","2022-02-16 19:12:59,582 epoch 34 - iter 2/19 - loss 1.00331873 - samples/sec: 423.61 - lr: 0.003125\n","2022-02-16 19:12:59,674 epoch 34 - iter 3/19 - loss 0.91701841 - samples/sec: 401.24 - lr: 0.003125\n","2022-02-16 19:12:59,759 epoch 34 - iter 4/19 - loss 0.89213729 - samples/sec: 431.19 - lr: 0.003125\n","2022-02-16 19:12:59,836 epoch 34 - iter 5/19 - loss 0.90196099 - samples/sec: 497.33 - lr: 0.003125\n","2022-02-16 19:12:59,926 epoch 34 - iter 6/19 - loss 0.87242754 - samples/sec: 458.12 - lr: 0.003125\n","2022-02-16 19:13:00,012 epoch 34 - iter 7/19 - loss 0.88638806 - samples/sec: 481.57 - lr: 0.003125\n","2022-02-16 19:13:00,085 epoch 34 - iter 8/19 - loss 0.88922516 - samples/sec: 473.25 - lr: 0.003125\n","2022-02-16 19:13:00,184 epoch 34 - iter 9/19 - loss 0.89648333 - samples/sec: 413.52 - lr: 0.003125\n","2022-02-16 19:13:00,253 epoch 34 - iter 10/19 - loss 0.90674077 - samples/sec: 536.03 - lr: 0.003125\n","2022-02-16 19:13:00,343 epoch 34 - iter 11/19 - loss 0.89529302 - samples/sec: 367.27 - lr: 0.003125\n","2022-02-16 19:13:00,412 epoch 34 - iter 12/19 - loss 0.89228470 - samples/sec: 484.83 - lr: 0.003125\n","2022-02-16 19:13:00,475 epoch 34 - iter 13/19 - loss 0.88956700 - samples/sec: 545.31 - lr: 0.003125\n","2022-02-16 19:13:00,545 epoch 34 - iter 14/19 - loss 0.88880570 - samples/sec: 497.03 - lr: 0.003125\n","2022-02-16 19:13:00,628 epoch 34 - iter 15/19 - loss 0.88269506 - samples/sec: 534.25 - lr: 0.003125\n","2022-02-16 19:13:00,705 epoch 34 - iter 16/19 - loss 0.87197362 - samples/sec: 428.69 - lr: 0.003125\n","2022-02-16 19:13:00,773 epoch 34 - iter 17/19 - loss 0.87163243 - samples/sec: 482.69 - lr: 0.003125\n","2022-02-16 19:13:00,847 epoch 34 - iter 18/19 - loss 0.87326651 - samples/sec: 448.74 - lr: 0.003125\n","2022-02-16 19:13:00,902 epoch 34 - iter 19/19 - loss 0.88162083 - samples/sec: 599.48 - lr: 0.003125\n","2022-02-16 19:13:01,298 ----------------------------------------------------------------------------------------------------\n","2022-02-16 19:13:01,307 EPOCH 34 done: loss 0.8816 - lr 0.0031250\n","2022-02-16 19:13:02,566 DEV : loss 0.9196454882621765 - score 0.5606\n","Epoch    34: reducing learning rate of group 0 to 1.5625e-03.\n","2022-02-16 19:13:02,636 BAD EPOCHS (no improvement): 4\n","2022-02-16 19:13:02,653 ----------------------------------------------------------------------------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"output_type":"stream","name":"stdout","text":["2022-02-16 19:13:03,590 epoch 35 - iter 1/19 - loss 0.96715826 - samples/sec: 142.06 - lr: 0.001563\n","2022-02-16 19:13:03,703 epoch 35 - iter 2/19 - loss 0.92931366 - samples/sec: 396.95 - lr: 0.001563\n","2022-02-16 19:13:03,779 epoch 35 - iter 3/19 - loss 0.91518941 - samples/sec: 432.39 - lr: 0.001563\n","2022-02-16 19:13:03,857 epoch 35 - iter 4/19 - loss 0.91140652 - samples/sec: 474.77 - lr: 0.001563\n","2022-02-16 19:13:03,936 epoch 35 - iter 5/19 - loss 0.93370256 - samples/sec: 465.07 - lr: 0.001563\n","2022-02-16 19:13:04,021 epoch 35 - iter 6/19 - loss 0.92931575 - samples/sec: 416.27 - lr: 0.001563\n","2022-02-16 19:13:04,097 epoch 35 - iter 7/19 - loss 0.90659847 - samples/sec: 449.12 - lr: 0.001563\n","2022-02-16 19:13:04,196 epoch 35 - iter 8/19 - loss 0.90961834 - samples/sec: 528.90 - lr: 0.001563\n","2022-02-16 19:13:04,270 epoch 35 - iter 9/19 - loss 0.89710779 - samples/sec: 445.57 - lr: 0.001563\n","2022-02-16 19:13:04,350 epoch 35 - iter 10/19 - loss 0.88712029 - samples/sec: 413.52 - lr: 0.001563\n","2022-02-16 19:13:04,422 epoch 35 - iter 11/19 - loss 0.88590115 - samples/sec: 478.04 - lr: 0.001563\n","2022-02-16 19:13:04,492 epoch 35 - iter 12/19 - loss 0.90161590 - samples/sec: 473.42 - lr: 0.001563\n","2022-02-16 19:13:06,003 epoch 35 - iter 13/19 - loss 0.89586824 - samples/sec: 489.79 - lr: 0.001563\n","2022-02-16 19:13:06,075 epoch 35 - iter 14/19 - loss 0.88467367 - samples/sec: 586.51 - lr: 0.001563\n","2022-02-16 19:13:06,142 epoch 35 - iter 15/19 - loss 0.88494498 - samples/sec: 521.23 - lr: 0.001563\n","2022-02-16 19:13:06,208 epoch 35 - iter 16/19 - loss 0.88089642 - samples/sec: 502.84 - lr: 0.001563\n","2022-02-16 19:13:06,274 epoch 35 - iter 17/19 - loss 0.87667356 - samples/sec: 505.79 - lr: 0.001563\n","2022-02-16 19:13:06,357 epoch 35 - iter 18/19 - loss 0.87770496 - samples/sec: 447.77 - lr: 0.001563\n","2022-02-16 19:13:06,406 epoch 35 - iter 19/19 - loss 0.87161849 - samples/sec: 693.91 - lr: 0.001563\n","2022-02-16 19:13:06,823 ----------------------------------------------------------------------------------------------------\n","2022-02-16 19:13:06,831 EPOCH 35 done: loss 0.8716 - lr 0.0015625\n","2022-02-16 19:13:08,121 DEV : loss 0.9206643104553223 - score 0.5606\n","2022-02-16 19:13:08,207 BAD EPOCHS (no improvement): 1\n","2022-02-16 19:13:08,214 ----------------------------------------------------------------------------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"output_type":"stream","name":"stdout","text":["2022-02-16 19:13:09,157 epoch 36 - iter 1/19 - loss 0.72449648 - samples/sec: 154.68 - lr: 0.001563\n","2022-02-16 19:13:09,268 epoch 36 - iter 2/19 - loss 0.87571496 - samples/sec: 387.20 - lr: 0.001563\n","2022-02-16 19:13:09,379 epoch 36 - iter 3/19 - loss 0.92120882 - samples/sec: 402.43 - lr: 0.001563\n","2022-02-16 19:13:09,471 epoch 36 - iter 4/19 - loss 0.90097582 - samples/sec: 366.18 - lr: 0.001563\n","2022-02-16 19:13:09,563 epoch 36 - iter 5/19 - loss 0.89897950 - samples/sec: 354.90 - lr: 0.001563\n","2022-02-16 19:13:09,647 epoch 36 - iter 6/19 - loss 0.88595541 - samples/sec: 430.38 - lr: 0.001563\n","2022-02-16 19:13:09,726 epoch 36 - iter 7/19 - loss 0.87665411 - samples/sec: 421.09 - lr: 0.001563\n","2022-02-16 19:13:09,796 epoch 36 - iter 8/19 - loss 0.90330429 - samples/sec: 469.08 - lr: 0.001563\n","2022-02-16 19:13:09,880 epoch 36 - iter 9/19 - loss 0.89123344 - samples/sec: 458.23 - lr: 0.001563\n","2022-02-16 19:13:09,952 epoch 36 - iter 10/19 - loss 0.90233656 - samples/sec: 465.87 - lr: 0.001563\n","2022-02-16 19:13:10,024 epoch 36 - iter 11/19 - loss 0.89132225 - samples/sec: 453.02 - lr: 0.001563\n","2022-02-16 19:13:10,106 epoch 36 - iter 12/19 - loss 0.88020945 - samples/sec: 442.82 - lr: 0.001563\n","2022-02-16 19:13:10,175 epoch 36 - iter 13/19 - loss 0.88861615 - samples/sec: 484.54 - lr: 0.001563\n","2022-02-16 19:13:10,251 epoch 36 - iter 14/19 - loss 0.88561602 - samples/sec: 545.62 - lr: 0.001563\n","2022-02-16 19:13:10,330 epoch 36 - iter 15/19 - loss 0.88214450 - samples/sec: 466.72 - lr: 0.001563\n","2022-02-16 19:13:10,410 epoch 36 - iter 16/19 - loss 0.87636298 - samples/sec: 436.07 - lr: 0.001563\n","2022-02-16 19:13:10,483 epoch 36 - iter 17/19 - loss 0.87586601 - samples/sec: 499.25 - lr: 0.001563\n","2022-02-16 19:13:10,579 epoch 36 - iter 18/19 - loss 0.87849693 - samples/sec: 387.48 - lr: 0.001563\n","2022-02-16 19:13:10,641 epoch 36 - iter 19/19 - loss 0.87703038 - samples/sec: 538.51 - lr: 0.001563\n","2022-02-16 19:13:11,021 ----------------------------------------------------------------------------------------------------\n","2022-02-16 19:13:11,029 EPOCH 36 done: loss 0.8770 - lr 0.0015625\n","2022-02-16 19:13:12,298 DEV : loss 0.9201185703277588 - score 0.5606\n","2022-02-16 19:13:12,388 BAD EPOCHS (no improvement): 2\n","2022-02-16 19:13:12,411 ----------------------------------------------------------------------------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"output_type":"stream","name":"stdout","text":["2022-02-16 19:13:13,517 epoch 37 - iter 1/19 - loss 1.00721860 - samples/sec: 149.43 - lr: 0.001563\n","2022-02-16 19:13:13,609 epoch 37 - iter 2/19 - loss 0.90456057 - samples/sec: 431.80 - lr: 0.001563\n","2022-02-16 19:13:13,688 epoch 37 - iter 3/19 - loss 0.93735882 - samples/sec: 432.99 - lr: 0.001563\n","2022-02-16 19:13:13,815 epoch 37 - iter 4/19 - loss 0.91716208 - samples/sec: 399.99 - lr: 0.001563\n","2022-02-16 19:13:13,896 epoch 37 - iter 5/19 - loss 0.92144245 - samples/sec: 406.14 - lr: 0.001563\n","2022-02-16 19:13:13,977 epoch 37 - iter 6/19 - loss 0.91680532 - samples/sec: 409.55 - lr: 0.001563\n","2022-02-16 19:13:14,054 epoch 37 - iter 7/19 - loss 0.92603972 - samples/sec: 435.01 - lr: 0.001563\n","2022-02-16 19:13:14,130 epoch 37 - iter 8/19 - loss 0.91605839 - samples/sec: 533.72 - lr: 0.001563\n","2022-02-16 19:13:14,206 epoch 37 - iter 9/19 - loss 0.91633885 - samples/sec: 451.90 - lr: 0.001563\n","2022-02-16 19:13:14,281 epoch 37 - iter 10/19 - loss 0.90989968 - samples/sec: 453.32 - lr: 0.001563\n","2022-02-16 19:13:14,353 epoch 37 - iter 11/19 - loss 0.90835677 - samples/sec: 457.82 - lr: 0.001563\n","2022-02-16 19:13:14,455 epoch 37 - iter 12/19 - loss 0.89906710 - samples/sec: 426.13 - lr: 0.001563\n","2022-02-16 19:13:14,528 epoch 37 - iter 13/19 - loss 0.88109882 - samples/sec: 451.02 - lr: 0.001563\n","2022-02-16 19:13:14,601 epoch 37 - iter 14/19 - loss 0.87411402 - samples/sec: 450.85 - lr: 0.001563\n","2022-02-16 19:13:14,671 epoch 37 - iter 15/19 - loss 0.88150705 - samples/sec: 474.53 - lr: 0.001563\n","2022-02-16 19:13:14,748 epoch 37 - iter 16/19 - loss 0.87959499 - samples/sec: 425.79 - lr: 0.001563\n","2022-02-16 19:13:14,832 epoch 37 - iter 17/19 - loss 0.88121341 - samples/sec: 401.08 - lr: 0.001563\n","2022-02-16 19:13:14,899 epoch 37 - iter 18/19 - loss 0.88026570 - samples/sec: 528.18 - lr: 0.001563\n","2022-02-16 19:13:14,955 epoch 37 - iter 19/19 - loss 0.88129236 - samples/sec: 609.82 - lr: 0.001563\n","2022-02-16 19:13:15,370 ----------------------------------------------------------------------------------------------------\n","2022-02-16 19:13:15,372 EPOCH 37 done: loss 0.8813 - lr 0.0015625\n","2022-02-16 19:13:16,659 DEV : loss 0.920545220375061 - score 0.5606\n","2022-02-16 19:13:16,734 BAD EPOCHS (no improvement): 3\n","2022-02-16 19:13:16,742 ----------------------------------------------------------------------------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"output_type":"stream","name":"stdout","text":["2022-02-16 19:13:17,709 epoch 38 - iter 1/19 - loss 0.67495656 - samples/sec: 131.55 - lr: 0.001563\n","2022-02-16 19:13:17,840 epoch 38 - iter 2/19 - loss 0.79326457 - samples/sec: 396.03 - lr: 0.001563\n","2022-02-16 19:13:17,928 epoch 38 - iter 3/19 - loss 0.83927558 - samples/sec: 410.71 - lr: 0.001563\n","2022-02-16 19:13:18,021 epoch 38 - iter 4/19 - loss 0.82610662 - samples/sec: 394.25 - lr: 0.001563\n","2022-02-16 19:13:18,103 epoch 38 - iter 5/19 - loss 0.84206556 - samples/sec: 407.75 - lr: 0.001563\n","2022-02-16 19:13:18,187 epoch 38 - iter 6/19 - loss 0.84097792 - samples/sec: 398.86 - lr: 0.001563\n","2022-02-16 19:13:18,264 epoch 38 - iter 7/19 - loss 0.83373800 - samples/sec: 434.99 - lr: 0.001563\n","2022-02-16 19:13:18,336 epoch 38 - iter 8/19 - loss 0.83455899 - samples/sec: 498.11 - lr: 0.001563\n","2022-02-16 19:13:18,423 epoch 38 - iter 9/19 - loss 0.84021066 - samples/sec: 434.81 - lr: 0.001563\n","2022-02-16 19:13:18,490 epoch 38 - iter 10/19 - loss 0.85342001 - samples/sec: 514.06 - lr: 0.001563\n","2022-02-16 19:13:18,561 epoch 38 - iter 11/19 - loss 0.85885403 - samples/sec: 465.21 - lr: 0.001563\n","2022-02-16 19:13:18,634 epoch 38 - iter 12/19 - loss 0.85785127 - samples/sec: 536.89 - lr: 0.001563\n","2022-02-16 19:13:18,716 epoch 38 - iter 13/19 - loss 0.85913494 - samples/sec: 440.63 - lr: 0.001563\n","2022-02-16 19:13:18,809 epoch 38 - iter 14/19 - loss 0.86644793 - samples/sec: 488.12 - lr: 0.001563\n","2022-02-16 19:13:18,879 epoch 38 - iter 15/19 - loss 0.86762484 - samples/sec: 468.65 - lr: 0.001563\n","2022-02-16 19:13:18,956 epoch 38 - iter 16/19 - loss 0.87291516 - samples/sec: 427.22 - lr: 0.001563\n","2022-02-16 19:13:19,036 epoch 38 - iter 17/19 - loss 0.87553342 - samples/sec: 416.39 - lr: 0.001563\n","2022-02-16 19:13:19,108 epoch 38 - iter 18/19 - loss 0.87413387 - samples/sec: 510.46 - lr: 0.001563\n","2022-02-16 19:13:19,158 epoch 38 - iter 19/19 - loss 0.87343887 - samples/sec: 656.99 - lr: 0.001563\n","2022-02-16 19:13:19,580 ----------------------------------------------------------------------------------------------------\n","2022-02-16 19:13:19,588 EPOCH 38 done: loss 0.8734 - lr 0.0015625\n","2022-02-16 19:13:20,876 DEV : loss 0.9205406904220581 - score 0.5606\n","Epoch    38: reducing learning rate of group 0 to 7.8125e-04.\n","2022-02-16 19:13:20,958 BAD EPOCHS (no improvement): 4\n","2022-02-16 19:13:20,968 ----------------------------------------------------------------------------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"output_type":"stream","name":"stdout","text":["2022-02-16 19:13:21,932 epoch 39 - iter 1/19 - loss 0.80494291 - samples/sec: 119.12 - lr: 0.000781\n","2022-02-16 19:13:22,038 epoch 39 - iter 2/19 - loss 0.85641024 - samples/sec: 409.36 - lr: 0.000781\n","2022-02-16 19:13:22,158 epoch 39 - iter 3/19 - loss 0.88336207 - samples/sec: 420.99 - lr: 0.000781\n","2022-02-16 19:13:22,240 epoch 39 - iter 4/19 - loss 0.88790418 - samples/sec: 407.05 - lr: 0.000781\n","2022-02-16 19:13:22,331 epoch 39 - iter 5/19 - loss 0.88991811 - samples/sec: 376.72 - lr: 0.000781\n","2022-02-16 19:13:22,417 epoch 39 - iter 6/19 - loss 0.86505003 - samples/sec: 398.08 - lr: 0.000781\n","2022-02-16 19:13:22,504 epoch 39 - iter 7/19 - loss 0.86288526 - samples/sec: 381.88 - lr: 0.000781\n","2022-02-16 19:13:22,576 epoch 39 - iter 8/19 - loss 0.84789450 - samples/sec: 455.23 - lr: 0.000781\n","2022-02-16 19:13:22,657 epoch 39 - iter 9/19 - loss 0.83665250 - samples/sec: 443.71 - lr: 0.000781\n","2022-02-16 19:13:22,725 epoch 39 - iter 10/19 - loss 0.85017962 - samples/sec: 485.96 - lr: 0.000781\n","2022-02-16 19:13:22,798 epoch 39 - iter 11/19 - loss 0.85321360 - samples/sec: 448.94 - lr: 0.000781\n","2022-02-16 19:13:22,867 epoch 39 - iter 12/19 - loss 0.85830994 - samples/sec: 477.22 - lr: 0.000781\n","2022-02-16 19:13:22,943 epoch 39 - iter 13/19 - loss 0.86161591 - samples/sec: 438.91 - lr: 0.000781\n","2022-02-16 19:13:23,016 epoch 39 - iter 14/19 - loss 0.87289803 - samples/sec: 454.42 - lr: 0.000781\n","2022-02-16 19:13:23,088 epoch 39 - iter 15/19 - loss 0.87590870 - samples/sec: 490.14 - lr: 0.000781\n","2022-02-16 19:13:23,163 epoch 39 - iter 16/19 - loss 0.87352107 - samples/sec: 509.91 - lr: 0.000781\n","2022-02-16 19:13:23,241 epoch 39 - iter 17/19 - loss 0.87533872 - samples/sec: 466.61 - lr: 0.000781\n","2022-02-16 19:13:23,327 epoch 39 - iter 18/19 - loss 0.87409890 - samples/sec: 436.61 - lr: 0.000781\n","2022-02-16 19:13:23,387 epoch 39 - iter 19/19 - loss 0.88401253 - samples/sec: 623.54 - lr: 0.000781\n","2022-02-16 19:13:23,773 ----------------------------------------------------------------------------------------------------\n","2022-02-16 19:13:23,778 EPOCH 39 done: loss 0.8840 - lr 0.0007813\n","2022-02-16 19:13:25,088 DEV : loss 0.9204387068748474 - score 0.5606\n","2022-02-16 19:13:25,161 BAD EPOCHS (no improvement): 1\n","2022-02-16 19:13:25,170 ----------------------------------------------------------------------------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"output_type":"stream","name":"stdout","text":["2022-02-16 19:13:26,137 epoch 40 - iter 1/19 - loss 0.93567431 - samples/sec: 169.81 - lr: 0.000781\n","2022-02-16 19:13:26,227 epoch 40 - iter 2/19 - loss 0.89760327 - samples/sec: 448.46 - lr: 0.000781\n","2022-02-16 19:13:26,306 epoch 40 - iter 3/19 - loss 0.91300746 - samples/sec: 436.16 - lr: 0.000781\n","2022-02-16 19:13:26,410 epoch 40 - iter 4/19 - loss 0.87922451 - samples/sec: 435.74 - lr: 0.000781\n","2022-02-16 19:13:26,491 epoch 40 - iter 5/19 - loss 0.87480016 - samples/sec: 408.04 - lr: 0.000781\n","2022-02-16 19:13:26,586 epoch 40 - iter 6/19 - loss 0.88160599 - samples/sec: 469.66 - lr: 0.000781\n","2022-02-16 19:13:26,660 epoch 40 - iter 7/19 - loss 0.88903062 - samples/sec: 501.02 - lr: 0.000781\n","2022-02-16 19:13:26,769 epoch 40 - iter 8/19 - loss 0.88072202 - samples/sec: 511.68 - lr: 0.000781\n","2022-02-16 19:13:26,842 epoch 40 - iter 9/19 - loss 0.87205223 - samples/sec: 466.31 - lr: 0.000781\n","2022-02-16 19:13:26,907 epoch 40 - iter 10/19 - loss 0.86955072 - samples/sec: 514.32 - lr: 0.000781\n","2022-02-16 19:13:26,972 epoch 40 - iter 11/19 - loss 0.88092407 - samples/sec: 511.15 - lr: 0.000781\n","2022-02-16 19:13:27,043 epoch 40 - iter 12/19 - loss 0.88613556 - samples/sec: 468.94 - lr: 0.000781\n","2022-02-16 19:13:27,114 epoch 40 - iter 13/19 - loss 0.89666576 - samples/sec: 480.72 - lr: 0.000781\n","2022-02-16 19:13:27,191 epoch 40 - iter 14/19 - loss 0.91138715 - samples/sec: 486.58 - lr: 0.000781\n","2022-02-16 19:13:27,259 epoch 40 - iter 15/19 - loss 0.92198733 - samples/sec: 505.99 - lr: 0.000781\n","2022-02-16 19:13:27,339 epoch 40 - iter 16/19 - loss 0.91726303 - samples/sec: 427.76 - lr: 0.000781\n","2022-02-16 19:13:27,412 epoch 40 - iter 17/19 - loss 0.90329806 - samples/sec: 457.84 - lr: 0.000781\n","2022-02-16 19:13:27,486 epoch 40 - iter 18/19 - loss 0.90446995 - samples/sec: 442.78 - lr: 0.000781\n","2022-02-16 19:13:27,553 epoch 40 - iter 19/19 - loss 0.89585438 - samples/sec: 575.56 - lr: 0.000781\n","2022-02-16 19:13:27,954 ----------------------------------------------------------------------------------------------------\n","2022-02-16 19:13:27,956 EPOCH 40 done: loss 0.8959 - lr 0.0007813\n","2022-02-16 19:13:29,228 DEV : loss 0.9207660555839539 - score 0.5606\n","2022-02-16 19:13:29,304 BAD EPOCHS (no improvement): 2\n","2022-02-16 19:13:29,311 ----------------------------------------------------------------------------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"output_type":"stream","name":"stdout","text":["2022-02-16 19:13:30,315 epoch 41 - iter 1/19 - loss 0.82023627 - samples/sec: 148.33 - lr: 0.000781\n","2022-02-16 19:13:30,398 epoch 41 - iter 2/19 - loss 0.77387831 - samples/sec: 466.89 - lr: 0.000781\n","2022-02-16 19:13:30,500 epoch 41 - iter 3/19 - loss 0.84266474 - samples/sec: 410.73 - lr: 0.000781\n","2022-02-16 19:13:30,580 epoch 41 - iter 4/19 - loss 0.84206639 - samples/sec: 433.42 - lr: 0.000781\n","2022-02-16 19:13:30,679 epoch 41 - iter 5/19 - loss 0.86446060 - samples/sec: 376.11 - lr: 0.000781\n","2022-02-16 19:13:30,774 epoch 41 - iter 6/19 - loss 0.86344551 - samples/sec: 426.78 - lr: 0.000781\n","2022-02-16 19:13:30,852 epoch 41 - iter 7/19 - loss 0.85675223 - samples/sec: 448.43 - lr: 0.000781\n","2022-02-16 19:13:30,924 epoch 41 - iter 8/19 - loss 0.88121375 - samples/sec: 461.67 - lr: 0.000781\n","2022-02-16 19:13:31,007 epoch 41 - iter 9/19 - loss 0.87179606 - samples/sec: 507.89 - lr: 0.000781\n","2022-02-16 19:13:31,086 epoch 41 - iter 10/19 - loss 0.87263519 - samples/sec: 540.30 - lr: 0.000781\n","2022-02-16 19:13:31,159 epoch 41 - iter 11/19 - loss 0.86778919 - samples/sec: 471.07 - lr: 0.000781\n","2022-02-16 19:13:31,224 epoch 41 - iter 12/19 - loss 0.85678314 - samples/sec: 508.04 - lr: 0.000781\n","2022-02-16 19:13:31,302 epoch 41 - iter 13/19 - loss 0.87160780 - samples/sec: 423.77 - lr: 0.000781\n","2022-02-16 19:13:31,377 epoch 41 - iter 14/19 - loss 0.87756658 - samples/sec: 433.89 - lr: 0.000781\n","2022-02-16 19:13:31,459 epoch 41 - iter 15/19 - loss 0.86543660 - samples/sec: 488.94 - lr: 0.000781\n","2022-02-16 19:13:31,535 epoch 41 - iter 16/19 - loss 0.86036233 - samples/sec: 512.79 - lr: 0.000781\n","2022-02-16 19:13:31,603 epoch 41 - iter 17/19 - loss 0.86738528 - samples/sec: 489.93 - lr: 0.000781\n","2022-02-16 19:13:31,695 epoch 41 - iter 18/19 - loss 0.87173975 - samples/sec: 356.01 - lr: 0.000781\n","2022-02-16 19:13:31,752 epoch 41 - iter 19/19 - loss 0.86709060 - samples/sec: 581.81 - lr: 0.000781\n","2022-02-16 19:13:32,158 ----------------------------------------------------------------------------------------------------\n","2022-02-16 19:13:32,159 EPOCH 41 done: loss 0.8671 - lr 0.0007813\n","2022-02-16 19:13:33,441 DEV : loss 0.9206703901290894 - score 0.5606\n","2022-02-16 19:13:33,515 BAD EPOCHS (no improvement): 3\n","2022-02-16 19:13:33,545 ----------------------------------------------------------------------------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"output_type":"stream","name":"stdout","text":["2022-02-16 19:13:34,523 epoch 42 - iter 1/19 - loss 0.97010517 - samples/sec: 220.22 - lr: 0.000781\n","2022-02-16 19:13:34,608 epoch 42 - iter 2/19 - loss 0.85601711 - samples/sec: 400.10 - lr: 0.000781\n","2022-02-16 19:13:34,700 epoch 42 - iter 3/19 - loss 0.91712789 - samples/sec: 426.56 - lr: 0.000781\n","2022-02-16 19:13:36,276 epoch 42 - iter 4/19 - loss 0.92797717 - samples/sec: 407.27 - lr: 0.000781\n","2022-02-16 19:13:36,359 epoch 42 - iter 5/19 - loss 0.90805711 - samples/sec: 415.84 - lr: 0.000781\n","2022-02-16 19:13:36,442 epoch 42 - iter 6/19 - loss 0.86949670 - samples/sec: 395.84 - lr: 0.000781\n","2022-02-16 19:13:36,513 epoch 42 - iter 7/19 - loss 0.86940596 - samples/sec: 522.63 - lr: 0.000781\n","2022-02-16 19:13:36,580 epoch 42 - iter 8/19 - loss 0.86181972 - samples/sec: 504.41 - lr: 0.000781\n","2022-02-16 19:13:36,650 epoch 42 - iter 9/19 - loss 0.86979685 - samples/sec: 470.80 - lr: 0.000781\n","2022-02-16 19:13:36,722 epoch 42 - iter 10/19 - loss 0.88029323 - samples/sec: 484.50 - lr: 0.000781\n","2022-02-16 19:13:36,783 epoch 42 - iter 11/19 - loss 0.87157678 - samples/sec: 553.91 - lr: 0.000781\n","2022-02-16 19:13:36,856 epoch 42 - iter 12/19 - loss 0.86884141 - samples/sec: 450.32 - lr: 0.000781\n","2022-02-16 19:13:36,926 epoch 42 - iter 13/19 - loss 0.86619523 - samples/sec: 469.47 - lr: 0.000781\n","2022-02-16 19:13:36,995 epoch 42 - iter 14/19 - loss 0.86974060 - samples/sec: 478.53 - lr: 0.000781\n","2022-02-16 19:13:37,063 epoch 42 - iter 15/19 - loss 0.87302022 - samples/sec: 485.33 - lr: 0.000781\n","2022-02-16 19:13:37,129 epoch 42 - iter 16/19 - loss 0.87528434 - samples/sec: 544.16 - lr: 0.000781\n","2022-02-16 19:13:37,197 epoch 42 - iter 17/19 - loss 0.86925529 - samples/sec: 536.02 - lr: 0.000781\n","2022-02-16 19:13:37,270 epoch 42 - iter 18/19 - loss 0.87529750 - samples/sec: 482.93 - lr: 0.000781\n","2022-02-16 19:13:37,328 epoch 42 - iter 19/19 - loss 0.88432479 - samples/sec: 669.47 - lr: 0.000781\n","2022-02-16 19:13:37,744 ----------------------------------------------------------------------------------------------------\n","2022-02-16 19:13:37,751 EPOCH 42 done: loss 0.8843 - lr 0.0007813\n","2022-02-16 19:13:39,047 DEV : loss 0.921105146408081 - score 0.5606\n","Epoch    42: reducing learning rate of group 0 to 3.9063e-04.\n","2022-02-16 19:13:39,131 BAD EPOCHS (no improvement): 4\n","2022-02-16 19:13:39,139 ----------------------------------------------------------------------------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"output_type":"stream","name":"stdout","text":["2022-02-16 19:13:40,117 epoch 43 - iter 1/19 - loss 1.00513983 - samples/sec: 139.15 - lr: 0.000391\n","2022-02-16 19:13:40,235 epoch 43 - iter 2/19 - loss 0.93912753 - samples/sec: 346.07 - lr: 0.000391\n","2022-02-16 19:13:40,353 epoch 43 - iter 3/19 - loss 0.90920250 - samples/sec: 415.58 - lr: 0.000391\n","2022-02-16 19:13:40,431 epoch 43 - iter 4/19 - loss 0.90820745 - samples/sec: 429.86 - lr: 0.000391\n","2022-02-16 19:13:40,518 epoch 43 - iter 5/19 - loss 0.88838279 - samples/sec: 378.18 - lr: 0.000391\n","2022-02-16 19:13:40,612 epoch 43 - iter 6/19 - loss 0.86857271 - samples/sec: 349.06 - lr: 0.000391\n","2022-02-16 19:13:40,695 epoch 43 - iter 7/19 - loss 0.86183533 - samples/sec: 402.18 - lr: 0.000391\n","2022-02-16 19:13:40,775 epoch 43 - iter 8/19 - loss 0.86653187 - samples/sec: 426.00 - lr: 0.000391\n","2022-02-16 19:13:40,865 epoch 43 - iter 9/19 - loss 0.86969534 - samples/sec: 481.44 - lr: 0.000391\n","2022-02-16 19:13:40,937 epoch 43 - iter 10/19 - loss 0.87046533 - samples/sec: 457.98 - lr: 0.000391\n","2022-02-16 19:13:41,018 epoch 43 - iter 11/19 - loss 0.86585604 - samples/sec: 407.51 - lr: 0.000391\n","2022-02-16 19:13:41,089 epoch 43 - iter 12/19 - loss 0.86422093 - samples/sec: 467.28 - lr: 0.000391\n","2022-02-16 19:13:41,162 epoch 43 - iter 13/19 - loss 0.86761940 - samples/sec: 467.41 - lr: 0.000391\n","2022-02-16 19:13:41,231 epoch 43 - iter 14/19 - loss 0.87278025 - samples/sec: 480.76 - lr: 0.000391\n","2022-02-16 19:13:41,321 epoch 43 - iter 15/19 - loss 0.87215039 - samples/sec: 488.96 - lr: 0.000391\n","2022-02-16 19:13:41,393 epoch 43 - iter 16/19 - loss 0.87256660 - samples/sec: 457.22 - lr: 0.000391\n","2022-02-16 19:13:41,464 epoch 43 - iter 17/19 - loss 0.86880246 - samples/sec: 461.88 - lr: 0.000391\n","2022-02-16 19:13:41,546 epoch 43 - iter 18/19 - loss 0.86749608 - samples/sec: 404.19 - lr: 0.000391\n","2022-02-16 19:13:41,609 epoch 43 - iter 19/19 - loss 0.87124478 - samples/sec: 529.50 - lr: 0.000391\n","2022-02-16 19:13:42,026 ----------------------------------------------------------------------------------------------------\n","2022-02-16 19:13:42,028 EPOCH 43 done: loss 0.8712 - lr 0.0003906\n","2022-02-16 19:13:43,391 DEV : loss 0.9215011596679688 - score 0.5606\n","2022-02-16 19:13:43,472 BAD EPOCHS (no improvement): 1\n","2022-02-16 19:13:43,480 ----------------------------------------------------------------------------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"output_type":"stream","name":"stdout","text":["2022-02-16 19:13:44,425 epoch 44 - iter 1/19 - loss 0.86586535 - samples/sec: 168.02 - lr: 0.000391\n","2022-02-16 19:13:44,517 epoch 44 - iter 2/19 - loss 0.88728639 - samples/sec: 419.93 - lr: 0.000391\n","2022-02-16 19:13:44,604 epoch 44 - iter 3/19 - loss 0.84667887 - samples/sec: 427.88 - lr: 0.000391\n","2022-02-16 19:13:44,718 epoch 44 - iter 4/19 - loss 0.83998466 - samples/sec: 444.38 - lr: 0.000391\n","2022-02-16 19:13:44,793 epoch 44 - iter 5/19 - loss 0.86901207 - samples/sec: 448.95 - lr: 0.000391\n","2022-02-16 19:13:44,893 epoch 44 - iter 6/19 - loss 0.86076674 - samples/sec: 428.58 - lr: 0.000391\n","2022-02-16 19:13:44,971 epoch 44 - iter 7/19 - loss 0.84399319 - samples/sec: 453.24 - lr: 0.000391\n","2022-02-16 19:13:45,046 epoch 44 - iter 8/19 - loss 0.83339895 - samples/sec: 438.99 - lr: 0.000391\n","2022-02-16 19:13:45,114 epoch 44 - iter 9/19 - loss 0.84154818 - samples/sec: 512.26 - lr: 0.000391\n","2022-02-16 19:13:45,192 epoch 44 - iter 10/19 - loss 0.84898888 - samples/sec: 419.07 - lr: 0.000391\n","2022-02-16 19:13:45,272 epoch 44 - iter 11/19 - loss 0.85450093 - samples/sec: 412.72 - lr: 0.000391\n","2022-02-16 19:13:45,358 epoch 44 - iter 12/19 - loss 0.85533974 - samples/sec: 437.71 - lr: 0.000391\n","2022-02-16 19:13:45,437 epoch 44 - iter 13/19 - loss 0.84912389 - samples/sec: 416.59 - lr: 0.000391\n","2022-02-16 19:13:45,510 epoch 44 - iter 14/19 - loss 0.84840819 - samples/sec: 455.44 - lr: 0.000391\n","2022-02-16 19:13:45,581 epoch 44 - iter 15/19 - loss 0.86317426 - samples/sec: 503.30 - lr: 0.000391\n","2022-02-16 19:13:45,658 epoch 44 - iter 16/19 - loss 0.86667375 - samples/sec: 525.16 - lr: 0.000391\n","2022-02-16 19:13:45,738 epoch 44 - iter 17/19 - loss 0.86512599 - samples/sec: 409.63 - lr: 0.000391\n","2022-02-16 19:13:45,818 epoch 44 - iter 18/19 - loss 0.87208838 - samples/sec: 449.50 - lr: 0.000391\n","2022-02-16 19:13:45,878 epoch 44 - iter 19/19 - loss 0.87262951 - samples/sec: 632.80 - lr: 0.000391\n","2022-02-16 19:13:46,333 ----------------------------------------------------------------------------------------------------\n","2022-02-16 19:13:46,340 EPOCH 44 done: loss 0.8726 - lr 0.0003906\n","2022-02-16 19:13:47,675 DEV : loss 0.9212721586227417 - score 0.5606\n","2022-02-16 19:13:47,753 BAD EPOCHS (no improvement): 2\n","2022-02-16 19:13:47,762 ----------------------------------------------------------------------------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"output_type":"stream","name":"stdout","text":["2022-02-16 19:13:48,744 epoch 45 - iter 1/19 - loss 0.95946974 - samples/sec: 169.25 - lr: 0.000391\n","2022-02-16 19:13:48,833 epoch 45 - iter 2/19 - loss 0.84633166 - samples/sec: 384.26 - lr: 0.000391\n","2022-02-16 19:13:48,925 epoch 45 - iter 3/19 - loss 0.86567577 - samples/sec: 422.20 - lr: 0.000391\n","2022-02-16 19:13:49,054 epoch 45 - iter 4/19 - loss 0.84791005 - samples/sec: 356.47 - lr: 0.000391\n","2022-02-16 19:13:49,141 epoch 45 - iter 5/19 - loss 0.84883416 - samples/sec: 428.67 - lr: 0.000391\n","2022-02-16 19:13:49,233 epoch 45 - iter 6/19 - loss 0.86441330 - samples/sec: 438.31 - lr: 0.000391\n","2022-02-16 19:13:49,317 epoch 45 - iter 7/19 - loss 0.87741442 - samples/sec: 396.75 - lr: 0.000391\n","2022-02-16 19:13:49,392 epoch 45 - iter 8/19 - loss 0.87779822 - samples/sec: 448.74 - lr: 0.000391\n","2022-02-16 19:13:49,467 epoch 45 - iter 9/19 - loss 0.88857126 - samples/sec: 436.46 - lr: 0.000391\n","2022-02-16 19:13:49,548 epoch 45 - iter 10/19 - loss 0.89022788 - samples/sec: 426.93 - lr: 0.000391\n","2022-02-16 19:13:49,631 epoch 45 - iter 11/19 - loss 0.87542984 - samples/sec: 470.33 - lr: 0.000391\n","2022-02-16 19:13:49,711 epoch 45 - iter 12/19 - loss 0.87043241 - samples/sec: 502.98 - lr: 0.000391\n","2022-02-16 19:13:49,787 epoch 45 - iter 13/19 - loss 0.87032404 - samples/sec: 454.18 - lr: 0.000391\n","2022-02-16 19:13:49,855 epoch 45 - iter 14/19 - loss 0.86196282 - samples/sec: 507.85 - lr: 0.000391\n","2022-02-16 19:13:49,925 epoch 45 - iter 15/19 - loss 0.86138961 - samples/sec: 477.34 - lr: 0.000391\n","2022-02-16 19:13:49,996 epoch 45 - iter 16/19 - loss 0.86536365 - samples/sec: 489.58 - lr: 0.000391\n","2022-02-16 19:13:50,077 epoch 45 - iter 17/19 - loss 0.86387406 - samples/sec: 495.42 - lr: 0.000391\n","2022-02-16 19:13:50,151 epoch 45 - iter 18/19 - loss 0.86737864 - samples/sec: 497.54 - lr: 0.000391\n","2022-02-16 19:13:50,210 epoch 45 - iter 19/19 - loss 0.86994075 - samples/sec: 566.93 - lr: 0.000391\n","2022-02-16 19:13:50,621 ----------------------------------------------------------------------------------------------------\n","2022-02-16 19:13:50,624 EPOCH 45 done: loss 0.8699 - lr 0.0003906\n","2022-02-16 19:13:51,968 DEV : loss 0.9212242960929871 - score 0.5606\n","2022-02-16 19:13:52,040 BAD EPOCHS (no improvement): 3\n","2022-02-16 19:13:52,051 ----------------------------------------------------------------------------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"output_type":"stream","name":"stdout","text":["2022-02-16 19:13:53,022 epoch 46 - iter 1/19 - loss 0.87569839 - samples/sec: 173.50 - lr: 0.000391\n","2022-02-16 19:13:53,112 epoch 46 - iter 2/19 - loss 0.85679260 - samples/sec: 428.68 - lr: 0.000391\n","2022-02-16 19:13:53,199 epoch 46 - iter 3/19 - loss 0.83376739 - samples/sec: 439.45 - lr: 0.000391\n","2022-02-16 19:13:53,297 epoch 46 - iter 4/19 - loss 0.83134401 - samples/sec: 362.01 - lr: 0.000391\n","2022-02-16 19:13:53,395 epoch 46 - iter 5/19 - loss 0.84132947 - samples/sec: 431.98 - lr: 0.000391\n","2022-02-16 19:13:53,473 epoch 46 - iter 6/19 - loss 0.85833893 - samples/sec: 482.00 - lr: 0.000391\n","2022-02-16 19:13:53,554 epoch 46 - iter 7/19 - loss 0.86970209 - samples/sec: 456.27 - lr: 0.000391\n","2022-02-16 19:13:53,625 epoch 46 - iter 8/19 - loss 0.88640658 - samples/sec: 489.44 - lr: 0.000391\n","2022-02-16 19:13:53,717 epoch 46 - iter 9/19 - loss 0.87880684 - samples/sec: 415.58 - lr: 0.000391\n","2022-02-16 19:13:53,788 epoch 46 - iter 10/19 - loss 0.88797395 - samples/sec: 514.11 - lr: 0.000391\n","2022-02-16 19:13:53,874 epoch 46 - iter 11/19 - loss 0.88580835 - samples/sec: 501.77 - lr: 0.000391\n","2022-02-16 19:13:53,956 epoch 46 - iter 12/19 - loss 0.88433632 - samples/sec: 437.58 - lr: 0.000391\n","2022-02-16 19:13:54,024 epoch 46 - iter 13/19 - loss 0.88917963 - samples/sec: 490.99 - lr: 0.000391\n","2022-02-16 19:13:54,095 epoch 46 - iter 14/19 - loss 0.88804613 - samples/sec: 469.93 - lr: 0.000391\n","2022-02-16 19:13:54,165 epoch 46 - iter 15/19 - loss 0.88880444 - samples/sec: 508.33 - lr: 0.000391\n","2022-02-16 19:13:54,245 epoch 46 - iter 16/19 - loss 0.88305380 - samples/sec: 465.60 - lr: 0.000391\n","2022-02-16 19:13:54,334 epoch 46 - iter 17/19 - loss 0.87927769 - samples/sec: 423.73 - lr: 0.000391\n","2022-02-16 19:13:54,408 epoch 46 - iter 18/19 - loss 0.87591987 - samples/sec: 489.32 - lr: 0.000391\n","2022-02-16 19:13:54,462 epoch 46 - iter 19/19 - loss 0.88148105 - samples/sec: 633.07 - lr: 0.000391\n","2022-02-16 19:13:54,894 ----------------------------------------------------------------------------------------------------\n","2022-02-16 19:13:54,898 EPOCH 46 done: loss 0.8815 - lr 0.0003906\n","2022-02-16 19:13:56,272 DEV : loss 0.9212913513183594 - score 0.5606\n","Epoch    46: reducing learning rate of group 0 to 1.9531e-04.\n","2022-02-16 19:13:56,348 BAD EPOCHS (no improvement): 4\n","2022-02-16 19:13:56,356 ----------------------------------------------------------------------------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"output_type":"stream","name":"stdout","text":["2022-02-16 19:13:57,332 epoch 47 - iter 1/19 - loss 0.84630889 - samples/sec: 161.80 - lr: 0.000195\n","2022-02-16 19:13:57,426 epoch 47 - iter 2/19 - loss 0.78961492 - samples/sec: 449.03 - lr: 0.000195\n","2022-02-16 19:13:57,509 epoch 47 - iter 3/19 - loss 0.86341218 - samples/sec: 417.34 - lr: 0.000195\n","2022-02-16 19:13:57,606 epoch 47 - iter 4/19 - loss 0.86482909 - samples/sec: 412.17 - lr: 0.000195\n","2022-02-16 19:13:57,696 epoch 47 - iter 5/19 - loss 0.87752542 - samples/sec: 365.73 - lr: 0.000195\n","2022-02-16 19:13:57,773 epoch 47 - iter 6/19 - loss 0.87076814 - samples/sec: 506.92 - lr: 0.000195\n","2022-02-16 19:13:57,856 epoch 47 - iter 7/19 - loss 0.86265875 - samples/sec: 431.91 - lr: 0.000195\n","2022-02-16 19:13:57,942 epoch 47 - iter 8/19 - loss 0.86551040 - samples/sec: 473.32 - lr: 0.000195\n","2022-02-16 19:13:58,034 epoch 47 - iter 9/19 - loss 0.87820455 - samples/sec: 487.36 - lr: 0.000195\n","2022-02-16 19:13:58,107 epoch 47 - iter 10/19 - loss 0.86102570 - samples/sec: 481.02 - lr: 0.000195\n","2022-02-16 19:13:58,175 epoch 47 - iter 11/19 - loss 0.87109445 - samples/sec: 488.18 - lr: 0.000195\n","2022-02-16 19:13:58,246 epoch 47 - iter 12/19 - loss 0.88191268 - samples/sec: 469.30 - lr: 0.000195\n","2022-02-16 19:13:58,320 epoch 47 - iter 13/19 - loss 0.87920400 - samples/sec: 469.45 - lr: 0.000195\n","2022-02-16 19:13:58,395 epoch 47 - iter 14/19 - loss 0.88185426 - samples/sec: 532.47 - lr: 0.000195\n","2022-02-16 19:13:58,478 epoch 47 - iter 15/19 - loss 0.88344241 - samples/sec: 524.08 - lr: 0.000195\n","2022-02-16 19:13:58,562 epoch 47 - iter 16/19 - loss 0.88470234 - samples/sec: 393.19 - lr: 0.000195\n","2022-02-16 19:13:58,634 epoch 47 - iter 17/19 - loss 0.88640430 - samples/sec: 473.45 - lr: 0.000195\n","2022-02-16 19:13:58,712 epoch 47 - iter 18/19 - loss 0.88518099 - samples/sec: 420.28 - lr: 0.000195\n","2022-02-16 19:13:58,768 epoch 47 - iter 19/19 - loss 0.88292757 - samples/sec: 591.59 - lr: 0.000195\n","2022-02-16 19:13:59,210 ----------------------------------------------------------------------------------------------------\n","2022-02-16 19:13:59,215 EPOCH 47 done: loss 0.8829 - lr 0.0001953\n","2022-02-16 19:14:00,562 DEV : loss 0.9212877154350281 - score 0.5606\n","2022-02-16 19:14:00,636 BAD EPOCHS (no improvement): 1\n","2022-02-16 19:14:00,645 ----------------------------------------------------------------------------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"output_type":"stream","name":"stdout","text":["2022-02-16 19:14:01,639 epoch 48 - iter 1/19 - loss 0.89317119 - samples/sec: 148.18 - lr: 0.000195\n","2022-02-16 19:14:01,740 epoch 48 - iter 2/19 - loss 0.94181913 - samples/sec: 381.25 - lr: 0.000195\n","2022-02-16 19:14:01,836 epoch 48 - iter 3/19 - loss 0.89321369 - samples/sec: 412.98 - lr: 0.000195\n","2022-02-16 19:14:01,920 epoch 48 - iter 4/19 - loss 0.90333374 - samples/sec: 400.27 - lr: 0.000195\n","2022-02-16 19:14:02,010 epoch 48 - iter 5/19 - loss 0.90477128 - samples/sec: 420.65 - lr: 0.000195\n","2022-02-16 19:14:02,139 epoch 48 - iter 6/19 - loss 0.86795191 - samples/sec: 375.05 - lr: 0.000195\n","2022-02-16 19:14:02,219 epoch 48 - iter 7/19 - loss 0.86465029 - samples/sec: 413.07 - lr: 0.000195\n","2022-02-16 19:14:02,292 epoch 48 - iter 8/19 - loss 0.87102628 - samples/sec: 474.00 - lr: 0.000195\n","2022-02-16 19:14:02,388 epoch 48 - iter 9/19 - loss 0.86720153 - samples/sec: 452.05 - lr: 0.000195\n","2022-02-16 19:14:02,457 epoch 48 - iter 10/19 - loss 0.87610383 - samples/sec: 482.81 - lr: 0.000195\n","2022-02-16 19:14:02,528 epoch 48 - iter 11/19 - loss 0.88360695 - samples/sec: 474.53 - lr: 0.000195\n","2022-02-16 19:14:02,595 epoch 48 - iter 12/19 - loss 0.88186225 - samples/sec: 488.06 - lr: 0.000195\n","2022-02-16 19:14:02,669 epoch 48 - iter 13/19 - loss 0.88623472 - samples/sec: 443.15 - lr: 0.000195\n","2022-02-16 19:14:02,738 epoch 48 - iter 14/19 - loss 0.87946462 - samples/sec: 481.12 - lr: 0.000195\n","2022-02-16 19:14:02,819 epoch 48 - iter 15/19 - loss 0.86994702 - samples/sec: 494.08 - lr: 0.000195\n","2022-02-16 19:14:02,894 epoch 48 - iter 16/19 - loss 0.87895390 - samples/sec: 447.20 - lr: 0.000195\n","2022-02-16 19:14:02,964 epoch 48 - iter 17/19 - loss 0.87801751 - samples/sec: 474.38 - lr: 0.000195\n","2022-02-16 19:14:03,036 epoch 48 - iter 18/19 - loss 0.88202922 - samples/sec: 459.35 - lr: 0.000195\n","2022-02-16 19:14:03,107 epoch 48 - iter 19/19 - loss 0.87559939 - samples/sec: 461.25 - lr: 0.000195\n","2022-02-16 19:14:03,511 ----------------------------------------------------------------------------------------------------\n","2022-02-16 19:14:03,518 EPOCH 48 done: loss 0.8756 - lr 0.0001953\n","2022-02-16 19:14:04,914 DEV : loss 0.9212695956230164 - score 0.5606\n","2022-02-16 19:14:04,988 BAD EPOCHS (no improvement): 2\n","2022-02-16 19:14:04,996 ----------------------------------------------------------------------------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"output_type":"stream","name":"stdout","text":["2022-02-16 19:14:06,178 epoch 49 - iter 1/19 - loss 0.71967369 - samples/sec: 76.00 - lr: 0.000195\n","2022-02-16 19:14:12,067 epoch 49 - iter 2/19 - loss 0.81442463 - samples/sec: 494.96 - lr: 0.000195\n","2022-02-16 19:14:12,145 epoch 49 - iter 3/19 - loss 0.82264382 - samples/sec: 455.73 - lr: 0.000195\n","2022-02-16 19:14:12,260 epoch 49 - iter 4/19 - loss 0.86125898 - samples/sec: 389.51 - lr: 0.000195\n","2022-02-16 19:14:12,340 epoch 49 - iter 5/19 - loss 0.87439892 - samples/sec: 449.90 - lr: 0.000195\n","2022-02-16 19:14:12,417 epoch 49 - iter 6/19 - loss 0.86550457 - samples/sec: 439.94 - lr: 0.000195\n","2022-02-16 19:14:12,502 epoch 49 - iter 7/19 - loss 0.87802273 - samples/sec: 429.29 - lr: 0.000195\n","2022-02-16 19:14:12,567 epoch 49 - iter 8/19 - loss 0.87626994 - samples/sec: 527.31 - lr: 0.000195\n","2022-02-16 19:14:12,634 epoch 49 - iter 9/19 - loss 0.88767852 - samples/sec: 495.98 - lr: 0.000195\n","2022-02-16 19:14:12,714 epoch 49 - iter 10/19 - loss 0.87548319 - samples/sec: 544.65 - lr: 0.000195\n","2022-02-16 19:14:12,785 epoch 49 - iter 11/19 - loss 0.88891369 - samples/sec: 486.68 - lr: 0.000195\n","2022-02-16 19:14:12,851 epoch 49 - iter 12/19 - loss 0.88603092 - samples/sec: 530.15 - lr: 0.000195\n","2022-02-16 19:14:12,921 epoch 49 - iter 13/19 - loss 0.88991459 - samples/sec: 476.27 - lr: 0.000195\n","2022-02-16 19:14:13,005 epoch 49 - iter 14/19 - loss 0.88315067 - samples/sec: 494.83 - lr: 0.000195\n","2022-02-16 19:14:13,073 epoch 49 - iter 15/19 - loss 0.88495224 - samples/sec: 523.73 - lr: 0.000195\n","2022-02-16 19:14:13,141 epoch 49 - iter 16/19 - loss 0.88524028 - samples/sec: 482.08 - lr: 0.000195\n","2022-02-16 19:14:13,209 epoch 49 - iter 17/19 - loss 0.89242897 - samples/sec: 484.93 - lr: 0.000195\n","2022-02-16 19:14:13,276 epoch 49 - iter 18/19 - loss 0.88745207 - samples/sec: 522.90 - lr: 0.000195\n","2022-02-16 19:14:13,330 epoch 49 - iter 19/19 - loss 0.88475930 - samples/sec: 612.87 - lr: 0.000195\n","2022-02-16 19:14:13,763 ----------------------------------------------------------------------------------------------------\n","2022-02-16 19:14:13,768 EPOCH 49 done: loss 0.8848 - lr 0.0001953\n","2022-02-16 19:14:14,968 DEV : loss 0.921320378780365 - score 0.5606\n","2022-02-16 19:14:15,040 BAD EPOCHS (no improvement): 3\n","2022-02-16 19:14:15,050 ----------------------------------------------------------------------------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"output_type":"stream","name":"stdout","text":["2022-02-16 19:14:15,964 epoch 50 - iter 1/19 - loss 0.95640355 - samples/sec: 208.26 - lr: 0.000195\n","2022-02-16 19:14:16,063 epoch 50 - iter 2/19 - loss 0.92737287 - samples/sec: 407.84 - lr: 0.000195\n","2022-02-16 19:14:16,177 epoch 50 - iter 3/19 - loss 0.93550877 - samples/sec: 411.85 - lr: 0.000195\n","2022-02-16 19:14:16,263 epoch 50 - iter 4/19 - loss 0.93403618 - samples/sec: 385.30 - lr: 0.000195\n","2022-02-16 19:14:16,346 epoch 50 - iter 5/19 - loss 0.93278006 - samples/sec: 411.05 - lr: 0.000195\n","2022-02-16 19:14:16,427 epoch 50 - iter 6/19 - loss 0.92798705 - samples/sec: 419.35 - lr: 0.000195\n","2022-02-16 19:14:16,506 epoch 50 - iter 7/19 - loss 0.90564691 - samples/sec: 426.36 - lr: 0.000195\n","2022-02-16 19:14:16,585 epoch 50 - iter 8/19 - loss 0.89948051 - samples/sec: 421.41 - lr: 0.000195\n","2022-02-16 19:14:16,658 epoch 50 - iter 9/19 - loss 0.90582909 - samples/sec: 475.21 - lr: 0.000195\n","2022-02-16 19:14:16,729 epoch 50 - iter 10/19 - loss 0.89863155 - samples/sec: 462.42 - lr: 0.000195\n","2022-02-16 19:14:16,800 epoch 50 - iter 11/19 - loss 0.89313408 - samples/sec: 470.87 - lr: 0.000195\n","2022-02-16 19:14:16,871 epoch 50 - iter 12/19 - loss 0.89377266 - samples/sec: 471.64 - lr: 0.000195\n","2022-02-16 19:14:16,938 epoch 50 - iter 13/19 - loss 0.88796217 - samples/sec: 515.46 - lr: 0.000195\n","2022-02-16 19:14:17,012 epoch 50 - iter 14/19 - loss 0.88367226 - samples/sec: 535.62 - lr: 0.000195\n","2022-02-16 19:14:17,087 epoch 50 - iter 15/19 - loss 0.88022648 - samples/sec: 485.74 - lr: 0.000195\n","2022-02-16 19:14:17,161 epoch 50 - iter 16/19 - loss 0.88623512 - samples/sec: 509.10 - lr: 0.000195\n","2022-02-16 19:14:17,241 epoch 50 - iter 17/19 - loss 0.87916537 - samples/sec: 456.43 - lr: 0.000195\n","2022-02-16 19:14:17,315 epoch 50 - iter 18/19 - loss 0.87439980 - samples/sec: 470.09 - lr: 0.000195\n","2022-02-16 19:14:17,373 epoch 50 - iter 19/19 - loss 0.87127311 - samples/sec: 635.39 - lr: 0.000195\n","2022-02-16 19:14:17,731 ----------------------------------------------------------------------------------------------------\n","2022-02-16 19:14:17,740 EPOCH 50 done: loss 0.8713 - lr 0.0001953\n","2022-02-16 19:14:18,916 DEV : loss 0.9213801622390747 - score 0.5606\n","Epoch    50: reducing learning rate of group 0 to 9.7656e-05.\n","2022-02-16 19:14:18,990 BAD EPOCHS (no improvement): 4\n","2022-02-16 19:14:34,457 ----------------------------------------------------------------------------------------------------\n","2022-02-16 19:14:34,473 Testing using best model ...\n","2022-02-16 19:14:34,477 loading file ../resources/stance-semeval2016/flair-Feminist Movement/best-model.pt\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"output_type":"stream","name":"stdout","text":["2022-02-16 19:14:50,510 \t0.6491\n","2022-02-16 19:14:50,517 \n","Results:\n","- F-score (micro) 0.6491\n","- F-score (macro) 0.3265\n","- Accuracy 0.6491\n","\n","By class:\n","              precision    recall  f1-score   support\n","\n","       FAVOR     0.5385    0.1207    0.1972        58\n","     AGAINST     0.6544    0.9727    0.7824       183\n","        NONE     0.0000    0.0000    0.0000        44\n","\n","   micro avg     0.6491    0.6491    0.6491       285\n","   macro avg     0.3976    0.3645    0.3265       285\n","weighted avg     0.5298    0.6491    0.5425       285\n"," samples avg     0.6491    0.6491    0.6491       285\n","\n","2022-02-16 19:14:50,528 ----------------------------------------------------------------------------------------------------\n"]},{"output_type":"execute_result","data":{"text/plain":["{'dev_loss_history': [0.8625979423522949,\n","  0.8878387808799744,\n","  0.9137055277824402,\n","  0.9216321706771851,\n","  0.9424606561660767,\n","  0.9258679747581482,\n","  0.9380063414573669,\n","  0.8849154710769653,\n","  0.8967999219894409,\n","  0.8867483139038086,\n","  0.888887345790863,\n","  0.9009777903556824,\n","  0.9561647176742554,\n","  0.876319408416748,\n","  0.908562421798706,\n","  0.9388964176177979,\n","  0.9433361887931824,\n","  0.9197553992271423,\n","  0.9180063009262085,\n","  0.9345412254333496,\n","  0.9248957633972168,\n","  0.9041862487792969,\n","  0.9185274839401245,\n","  0.9254951477050781,\n","  0.9159201979637146,\n","  0.9282150268554688,\n","  0.921781063079834,\n","  0.9181589484214783,\n","  0.919507622718811,\n","  0.9146279096603394,\n","  0.9167970418930054,\n","  0.9186007380485535,\n","  0.9212898015975952,\n","  0.9196454882621765,\n","  0.9206643104553223,\n","  0.9201185703277588,\n","  0.920545220375061,\n","  0.9205406904220581,\n","  0.9204387068748474,\n","  0.9207660555839539,\n","  0.9206703901290894,\n","  0.921105146408081,\n","  0.9215011596679688,\n","  0.9212721586227417,\n","  0.9212242960929871,\n","  0.9212913513183594,\n","  0.9212877154350281,\n","  0.9212695956230164,\n","  0.921320378780365,\n","  0.9213801622390747],\n"," 'dev_score_history': [0.5152,\n","  0.5152,\n","  0.5152,\n","  0.5152,\n","  0.5606,\n","  0.5606,\n","  0.5303,\n","  0.5152,\n","  0.5606,\n","  0.5606,\n","  0.5303,\n","  0.5455,\n","  0.5152,\n","  0.5303,\n","  0.5455,\n","  0.5455,\n","  0.5303,\n","  0.5606,\n","  0.5606,\n","  0.5606,\n","  0.5606,\n","  0.5455,\n","  0.5606,\n","  0.5606,\n","  0.5455,\n","  0.5606,\n","  0.5606,\n","  0.5606,\n","  0.5606,\n","  0.5455,\n","  0.5455,\n","  0.5606,\n","  0.5606,\n","  0.5606,\n","  0.5606,\n","  0.5606,\n","  0.5606,\n","  0.5606,\n","  0.5606,\n","  0.5606,\n","  0.5606,\n","  0.5606,\n","  0.5606,\n","  0.5606,\n","  0.5606,\n","  0.5606,\n","  0.5606,\n","  0.5606,\n","  0.5606,\n","  0.5606],\n"," 'test_score': 0.6491,\n"," 'train_loss_history': [1.008100384160092,\n","  1.0289408062633716,\n","  1.0193662423836558,\n","  1.0088961657724882,\n","  1.0022301705260026,\n","  0.997272977703496,\n","  0.988682066139422,\n","  0.9833715024747347,\n","  0.9830763339996338,\n","  0.9680376146969042,\n","  0.962892864879809,\n","  0.9455763038836027,\n","  0.9424571551774678,\n","  0.944329415497027,\n","  0.9262151812252245,\n","  0.9246946071323595,\n","  0.9145768410281131,\n","  0.9141357886163812,\n","  0.8934768971643949,\n","  0.8944244165169565,\n","  0.8930928613010206,\n","  0.8932988078970658,\n","  0.8889448893697638,\n","  0.9001241577299017,\n","  0.8934020588272497,\n","  0.8951488356841238,\n","  0.8849966808369285,\n","  0.8859601146296451,\n","  0.8741960494141829,\n","  0.8831727191021568,\n","  0.8774998815436112,\n","  0.8817310709702341,\n","  0.8799081350627699,\n","  0.8816208306111788,\n","  0.8716184936071697,\n","  0.8770303788938021,\n","  0.8812923588250813,\n","  0.8734388665149087,\n","  0.8840125297245226,\n","  0.8958543821385032,\n","  0.8670905985330281,\n","  0.8843247859101546,\n","  0.8712447818956877,\n","  0.872629513866023,\n","  0.8699407514772917,\n","  0.8814810514450073,\n","  0.8829275651981956,\n","  0.8755993874449479,\n","  0.8847592974963941,\n","  0.8712731066503023]}"]},"metadata":{},"execution_count":9}]},{"cell_type":"markdown","metadata":{"id":"dfEoE_G0BjAg"},"source":["# ASSIGNMENT 3 (BONUS)\n","\n","+ TODO: Train the TextClassifier for the other 4 targets in the SemEval training data using the data files you have created in ASSIGNMENT 2.\n","+ TODO: Write in a table in this notebook the results obtained for the 5 targets. HINT: check the table in Lab2."]},{"cell_type":"markdown","source":["## Atheism"],"metadata":{"id":"aE1bVKAL3Y5k"}},{"cell_type":"code","source":["# 1. get the corpus\n","target = \"Atheism\"\n","corpus_folder = f\"../resources/{folder}/\"\n","corpus: Corpus = ClassificationCorpus(corpus_folder,\n","                                      train_file=f'train.{target}.txt',\n","                                      #dev_file=f'train.{target}.txt',\n","                                      test_file=f'test.{target}.txt'\n",")\n","\n","# 2. create the label dictionary\n","label_dict = corpus.make_label_dictionary()\n","                                                                                                                                                                                         \n","# 5. create the text classifier\n","classifier = TextClassifier(document_embeddings, label_dictionary=label_dict)\n","\n","# 6. initialize the text classifier trainer\n","trainer = ModelTrainer(classifier, corpus)\n","\n","# 7. start the training\n","trainer.train(f\"../resources/{folder}/flair_{target}\",\n","              train_with_dev=False,\n","              max_epochs=50)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FN7LPFMd3fNN","executionInfo":{"status":"ok","timestamp":1645039396001,"user_tz":-60,"elapsed":506202,"user":{"displayName":"Julen Etxaniz Aragoneses","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GilpYDAmorj7KFdjK26TlsyH_HhFWhLqmESeKoCGsI=s64","userId":"06956422670240182492"}},"outputId":"e2a4eaa2-ef50-42d9-a06a-2a5be22f2e45"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["2022-02-16 19:14:50,644 Reading data from ../resources/stance-semeval2016\n","2022-02-16 19:14:50,648 Train: ../resources/stance-semeval2016/train.Atheism.txt\n","2022-02-16 19:14:50,652 Dev: None\n","2022-02-16 19:14:50,657 Test: ../resources/stance-semeval2016/test.Atheism.txt\n","2022-02-16 19:14:50,704 Computing label dictionary. Progress:\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n","100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 682/682 [00:02<00:00, 332.63it/s]"]},{"output_type":"stream","name":"stdout","text":["2022-02-16 19:14:54,793 [b'AGAINST', b'FAVOR', b'NONE']\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["2022-02-16 19:14:55,027 ----------------------------------------------------------------------------------------------------\n","2022-02-16 19:14:55,036 Model: \"TextClassifier(\n","  (document_embeddings): DocumentRNNEmbeddings(\n","    (embeddings): StackedEmbeddings(\n","      (list_embedding_0): WordEmbeddings('en-crawl')\n","    )\n","    (word_reprojection_map): Linear(in_features=300, out_features=256, bias=True)\n","    (rnn): LSTM(256, 512, batch_first=True)\n","    (dropout): Dropout(p=0.5, inplace=False)\n","  )\n","  (decoder): Linear(in_features=512, out_features=3, bias=True)\n","  (loss_function): CrossEntropyLoss()\n","  (beta): 1.0\n","  (weights): None\n","  (weight_tensor) None\n",")\"\n","2022-02-16 19:14:55,042 ----------------------------------------------------------------------------------------------------\n","2022-02-16 19:14:55,049 Corpus: \"Corpus: 462 train + 51 dev + 220 test sentences\"\n","2022-02-16 19:14:55,052 ----------------------------------------------------------------------------------------------------\n","2022-02-16 19:14:55,056 Parameters:\n","2022-02-16 19:14:55,060  - learning_rate: \"0.1\"\n","2022-02-16 19:14:55,063  - mini_batch_size: \"32\"\n","2022-02-16 19:14:55,066  - patience: \"3\"\n","2022-02-16 19:14:55,070  - anneal_factor: \"0.5\"\n","2022-02-16 19:14:55,073  - max_epochs: \"50\"\n","2022-02-16 19:14:55,081  - shuffle: \"True\"\n","2022-02-16 19:14:55,083  - train_with_dev: \"False\"\n","2022-02-16 19:14:55,088  - batch_growth_annealing: \"False\"\n","2022-02-16 19:14:55,092 ----------------------------------------------------------------------------------------------------\n","2022-02-16 19:14:55,095 Model training base path: \"../resources/stance-semeval2016/flair_Atheism\"\n","2022-02-16 19:14:55,099 ----------------------------------------------------------------------------------------------------\n","2022-02-16 19:14:55,101 Device: cuda:0\n","2022-02-16 19:14:55,105 ----------------------------------------------------------------------------------------------------\n","2022-02-16 19:14:55,109 Embeddings storage mode: cpu\n","2022-02-16 19:14:55,361 ----------------------------------------------------------------------------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"output_type":"stream","name":"stdout","text":["2022-02-16 19:14:56,691 epoch 1 - iter 1/15 - loss 1.12493169 - samples/sec: 129.17 - lr: 0.100000\n","2022-02-16 19:14:56,807 epoch 1 - iter 2/15 - loss 1.10452259 - samples/sec: 322.91 - lr: 0.100000\n","2022-02-16 19:14:56,919 epoch 1 - iter 3/15 - loss 1.08813214 - samples/sec: 321.80 - lr: 0.100000\n","2022-02-16 19:14:57,028 epoch 1 - iter 4/15 - loss 1.06790766 - samples/sec: 352.32 - lr: 0.100000\n","2022-02-16 19:14:57,122 epoch 1 - iter 5/15 - loss 1.06124623 - samples/sec: 350.59 - lr: 0.100000\n","2022-02-16 19:14:57,227 epoch 1 - iter 6/15 - loss 1.05662022 - samples/sec: 396.47 - lr: 0.100000\n","2022-02-16 19:14:57,320 epoch 1 - iter 7/15 - loss 1.08040994 - samples/sec: 363.76 - lr: 0.100000\n","2022-02-16 19:14:57,410 epoch 1 - iter 8/15 - loss 1.08285087 - samples/sec: 378.19 - lr: 0.100000\n","2022-02-16 19:14:57,523 epoch 1 - iter 9/15 - loss 1.07678555 - samples/sec: 325.44 - lr: 0.100000\n","2022-02-16 19:14:57,617 epoch 1 - iter 10/15 - loss 1.07601697 - samples/sec: 397.06 - lr: 0.100000\n","2022-02-16 19:14:57,724 epoch 1 - iter 11/15 - loss 1.07526267 - samples/sec: 385.93 - lr: 0.100000\n","2022-02-16 19:14:57,816 epoch 1 - iter 12/15 - loss 1.05542708 - samples/sec: 360.47 - lr: 0.100000\n","2022-02-16 19:14:57,903 epoch 1 - iter 13/15 - loss 1.02665763 - samples/sec: 394.21 - lr: 0.100000\n","2022-02-16 19:14:57,979 epoch 1 - iter 14/15 - loss 1.00989286 - samples/sec: 432.55 - lr: 0.100000\n","2022-02-16 19:14:58,037 epoch 1 - iter 15/15 - loss 1.00153583 - samples/sec: 573.38 - lr: 0.100000\n","2022-02-16 19:14:58,466 ----------------------------------------------------------------------------------------------------\n","2022-02-16 19:14:58,468 EPOCH 1 done: loss 1.0015 - lr 0.1000000\n","2022-02-16 19:15:00,042 DEV : loss 0.9189904928207397 - score 0.5882\n","2022-02-16 19:15:00,102 BAD EPOCHS (no improvement): 0\n","saving best model\n","2022-02-16 19:15:15,952 ----------------------------------------------------------------------------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"output_type":"stream","name":"stdout","text":["2022-02-16 19:15:17,392 epoch 2 - iter 1/15 - loss 0.93447071 - samples/sec: 144.70 - lr: 0.100000\n","2022-02-16 19:15:17,495 epoch 2 - iter 2/15 - loss 0.95694119 - samples/sec: 372.57 - lr: 0.100000\n","2022-02-16 19:15:17,588 epoch 2 - iter 3/15 - loss 1.00656446 - samples/sec: 424.48 - lr: 0.100000\n","2022-02-16 19:15:17,718 epoch 2 - iter 4/15 - loss 0.99019280 - samples/sec: 433.11 - lr: 0.100000\n","2022-02-16 19:15:17,791 epoch 2 - iter 5/15 - loss 0.99417486 - samples/sec: 466.07 - lr: 0.100000\n","2022-02-16 19:15:17,881 epoch 2 - iter 6/15 - loss 0.97779026 - samples/sec: 368.43 - lr: 0.100000\n","2022-02-16 19:15:17,958 epoch 2 - iter 7/15 - loss 0.95940753 - samples/sec: 430.48 - lr: 0.100000\n","2022-02-16 19:15:18,029 epoch 2 - iter 8/15 - loss 0.95632499 - samples/sec: 462.28 - lr: 0.100000\n","2022-02-16 19:15:18,105 epoch 2 - iter 9/15 - loss 0.95950435 - samples/sec: 431.15 - lr: 0.100000\n","2022-02-16 19:15:18,184 epoch 2 - iter 10/15 - loss 0.94495155 - samples/sec: 478.31 - lr: 0.100000\n","2022-02-16 19:15:18,254 epoch 2 - iter 11/15 - loss 0.93303505 - samples/sec: 473.51 - lr: 0.100000\n","2022-02-16 19:15:18,334 epoch 2 - iter 12/15 - loss 0.92167262 - samples/sec: 507.19 - lr: 0.100000\n","2022-02-16 19:15:18,410 epoch 2 - iter 13/15 - loss 0.93544465 - samples/sec: 433.60 - lr: 0.100000\n","2022-02-16 19:15:18,484 epoch 2 - iter 14/15 - loss 0.94682292 - samples/sec: 442.40 - lr: 0.100000\n","2022-02-16 19:15:18,531 epoch 2 - iter 15/15 - loss 0.95601841 - samples/sec: 753.16 - lr: 0.100000\n","2022-02-16 19:15:19,110 ----------------------------------------------------------------------------------------------------\n","2022-02-16 19:15:19,113 EPOCH 2 done: loss 0.9560 - lr 0.1000000\n","2022-02-16 19:15:20,891 DEV : loss 0.9083842039108276 - score 0.5882\n","2022-02-16 19:15:20,957 BAD EPOCHS (no improvement): 0\n","saving best model\n","2022-02-16 19:15:36,535 ----------------------------------------------------------------------------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"output_type":"stream","name":"stdout","text":["2022-02-16 19:15:37,912 epoch 3 - iter 1/15 - loss 1.03213215 - samples/sec: 218.87 - lr: 0.100000\n","2022-02-16 19:15:37,998 epoch 3 - iter 2/15 - loss 0.94680893 - samples/sec: 389.94 - lr: 0.100000\n","2022-02-16 19:15:38,083 epoch 3 - iter 3/15 - loss 0.95664789 - samples/sec: 437.81 - lr: 0.100000\n","2022-02-16 19:15:38,169 epoch 3 - iter 4/15 - loss 0.94460128 - samples/sec: 444.28 - lr: 0.100000\n","2022-02-16 19:15:38,248 epoch 3 - iter 5/15 - loss 0.95582296 - samples/sec: 472.40 - lr: 0.100000\n","2022-02-16 19:15:38,331 epoch 3 - iter 6/15 - loss 0.95602857 - samples/sec: 457.80 - lr: 0.100000\n","2022-02-16 19:15:38,407 epoch 3 - iter 7/15 - loss 0.95207030 - samples/sec: 493.53 - lr: 0.100000\n","2022-02-16 19:15:38,478 epoch 3 - iter 8/15 - loss 0.95246248 - samples/sec: 532.12 - lr: 0.100000\n","2022-02-16 19:15:38,588 epoch 3 - iter 9/15 - loss 0.96423082 - samples/sec: 325.52 - lr: 0.100000\n","2022-02-16 19:15:38,657 epoch 3 - iter 10/15 - loss 0.95329711 - samples/sec: 515.11 - lr: 0.100000\n","2022-02-16 19:15:38,735 epoch 3 - iter 11/15 - loss 0.94968780 - samples/sec: 495.61 - lr: 0.100000\n","2022-02-16 19:15:38,804 epoch 3 - iter 12/15 - loss 0.94370279 - samples/sec: 545.92 - lr: 0.100000\n","2022-02-16 19:15:38,881 epoch 3 - iter 13/15 - loss 0.94087919 - samples/sec: 477.36 - lr: 0.100000\n","2022-02-16 19:15:38,969 epoch 3 - iter 14/15 - loss 0.93655399 - samples/sec: 419.47 - lr: 0.100000\n","2022-02-16 19:15:39,014 epoch 3 - iter 15/15 - loss 0.94741805 - samples/sec: 831.41 - lr: 0.100000\n","2022-02-16 19:15:39,657 ----------------------------------------------------------------------------------------------------\n","2022-02-16 19:15:39,662 EPOCH 3 done: loss 0.9474 - lr 0.1000000\n","2022-02-16 19:15:41,542 DEV : loss 0.908475399017334 - score 0.5882\n","2022-02-16 19:15:41,602 BAD EPOCHS (no improvement): 1\n","2022-02-16 19:15:41,610 ----------------------------------------------------------------------------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"output_type":"stream","name":"stdout","text":["2022-02-16 19:15:42,911 epoch 4 - iter 1/15 - loss 0.94901556 - samples/sec: 132.88 - lr: 0.100000\n","2022-02-16 19:15:43,005 epoch 4 - iter 2/15 - loss 0.88348350 - samples/sec: 398.38 - lr: 0.100000\n","2022-02-16 19:15:43,131 epoch 4 - iter 3/15 - loss 0.93062772 - samples/sec: 455.19 - lr: 0.100000\n","2022-02-16 19:15:43,209 epoch 4 - iter 4/15 - loss 0.93685542 - samples/sec: 426.33 - lr: 0.100000\n","2022-02-16 19:15:43,275 epoch 4 - iter 5/15 - loss 0.94409169 - samples/sec: 500.52 - lr: 0.100000\n","2022-02-16 19:15:43,359 epoch 4 - iter 6/15 - loss 0.93915706 - samples/sec: 446.59 - lr: 0.100000\n","2022-02-16 19:15:43,438 epoch 4 - iter 7/15 - loss 0.92997764 - samples/sec: 413.38 - lr: 0.100000\n","2022-02-16 19:15:43,516 epoch 4 - iter 8/15 - loss 0.93582496 - samples/sec: 452.65 - lr: 0.100000\n","2022-02-16 19:15:43,590 epoch 4 - iter 9/15 - loss 0.94813708 - samples/sec: 512.28 - lr: 0.100000\n","2022-02-16 19:15:43,658 epoch 4 - iter 10/15 - loss 0.95239490 - samples/sec: 488.14 - lr: 0.100000\n","2022-02-16 19:15:43,735 epoch 4 - iter 11/15 - loss 0.95634619 - samples/sec: 431.51 - lr: 0.100000\n","2022-02-16 19:15:43,811 epoch 4 - iter 12/15 - loss 0.95090792 - samples/sec: 496.77 - lr: 0.100000\n","2022-02-16 19:15:43,887 epoch 4 - iter 13/15 - loss 0.94692371 - samples/sec: 434.49 - lr: 0.100000\n","2022-02-16 19:15:43,962 epoch 4 - iter 14/15 - loss 0.93591841 - samples/sec: 439.77 - lr: 0.100000\n","2022-02-16 19:15:44,008 epoch 4 - iter 15/15 - loss 0.93476118 - samples/sec: 785.19 - lr: 0.100000\n","2022-02-16 19:15:44,549 ----------------------------------------------------------------------------------------------------\n","2022-02-16 19:15:44,555 EPOCH 4 done: loss 0.9348 - lr 0.1000000\n","2022-02-16 19:15:53,978 DEV : loss 0.9007077217102051 - score 0.5882\n","2022-02-16 19:15:54,070 BAD EPOCHS (no improvement): 0\n","saving best model\n","2022-02-16 19:16:09,055 ----------------------------------------------------------------------------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"output_type":"stream","name":"stdout","text":["2022-02-16 19:16:10,313 epoch 5 - iter 1/15 - loss 0.80387735 - samples/sec: 149.44 - lr: 0.100000\n","2022-02-16 19:16:10,417 epoch 5 - iter 2/15 - loss 0.89575240 - samples/sec: 374.49 - lr: 0.100000\n","2022-02-16 19:16:10,500 epoch 5 - iter 3/15 - loss 0.85486088 - samples/sec: 399.45 - lr: 0.100000\n","2022-02-16 19:16:10,593 epoch 5 - iter 4/15 - loss 0.87380338 - samples/sec: 410.73 - lr: 0.100000\n","2022-02-16 19:16:10,694 epoch 5 - iter 5/15 - loss 0.88795755 - samples/sec: 454.56 - lr: 0.100000\n","2022-02-16 19:16:10,769 epoch 5 - iter 6/15 - loss 0.87604366 - samples/sec: 480.26 - lr: 0.100000\n","2022-02-16 19:16:10,846 epoch 5 - iter 7/15 - loss 0.91764593 - samples/sec: 434.13 - lr: 0.100000\n","2022-02-16 19:16:10,920 epoch 5 - iter 8/15 - loss 0.89889114 - samples/sec: 446.69 - lr: 0.100000\n","2022-02-16 19:16:11,012 epoch 5 - iter 9/15 - loss 0.89190906 - samples/sec: 357.79 - lr: 0.100000\n","2022-02-16 19:16:11,085 epoch 5 - iter 10/15 - loss 0.90952716 - samples/sec: 485.19 - lr: 0.100000\n","2022-02-16 19:16:11,171 epoch 5 - iter 11/15 - loss 0.91676623 - samples/sec: 463.66 - lr: 0.100000\n","2022-02-16 19:16:11,247 epoch 5 - iter 12/15 - loss 0.92204816 - samples/sec: 439.18 - lr: 0.100000\n","2022-02-16 19:16:11,320 epoch 5 - iter 13/15 - loss 0.92318036 - samples/sec: 472.87 - lr: 0.100000\n","2022-02-16 19:16:11,389 epoch 5 - iter 14/15 - loss 0.92392117 - samples/sec: 519.58 - lr: 0.100000\n","2022-02-16 19:16:11,433 epoch 5 - iter 15/15 - loss 0.92367707 - samples/sec: 841.37 - lr: 0.100000\n","2022-02-16 19:16:11,919 ----------------------------------------------------------------------------------------------------\n","2022-02-16 19:16:11,921 EPOCH 5 done: loss 0.9237 - lr 0.1000000\n","2022-02-16 19:16:13,518 DEV : loss 0.904578685760498 - score 0.5882\n","2022-02-16 19:16:13,579 BAD EPOCHS (no improvement): 1\n","2022-02-16 19:16:13,589 ----------------------------------------------------------------------------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"output_type":"stream","name":"stdout","text":["2022-02-16 19:16:14,734 epoch 6 - iter 1/15 - loss 0.93877995 - samples/sec: 123.84 - lr: 0.100000\n","2022-02-16 19:16:14,841 epoch 6 - iter 2/15 - loss 0.89808005 - samples/sec: 346.30 - lr: 0.100000\n","2022-02-16 19:16:14,928 epoch 6 - iter 3/15 - loss 0.85292945 - samples/sec: 421.25 - lr: 0.100000\n","2022-02-16 19:16:15,013 epoch 6 - iter 4/15 - loss 0.87026684 - samples/sec: 478.09 - lr: 0.100000\n","2022-02-16 19:16:15,092 epoch 6 - iter 5/15 - loss 0.89010315 - samples/sec: 414.82 - lr: 0.100000\n","2022-02-16 19:16:15,176 epoch 6 - iter 6/15 - loss 0.89549120 - samples/sec: 508.92 - lr: 0.100000\n","2022-02-16 19:16:15,254 epoch 6 - iter 7/15 - loss 0.90243014 - samples/sec: 423.26 - lr: 0.100000\n","2022-02-16 19:16:15,327 epoch 6 - iter 8/15 - loss 0.91981468 - samples/sec: 450.70 - lr: 0.100000\n","2022-02-16 19:16:15,437 epoch 6 - iter 9/15 - loss 0.92498741 - samples/sec: 472.36 - lr: 0.100000\n","2022-02-16 19:16:15,514 epoch 6 - iter 10/15 - loss 0.92546626 - samples/sec: 425.50 - lr: 0.100000\n","2022-02-16 19:16:15,584 epoch 6 - iter 11/15 - loss 0.91602628 - samples/sec: 476.75 - lr: 0.100000\n","2022-02-16 19:16:15,658 epoch 6 - iter 12/15 - loss 0.91490530 - samples/sec: 483.91 - lr: 0.100000\n","2022-02-16 19:16:15,731 epoch 6 - iter 13/15 - loss 0.92238622 - samples/sec: 453.16 - lr: 0.100000\n","2022-02-16 19:16:15,806 epoch 6 - iter 14/15 - loss 0.91505582 - samples/sec: 447.51 - lr: 0.100000\n","2022-02-16 19:16:15,854 epoch 6 - iter 15/15 - loss 0.90644410 - samples/sec: 722.97 - lr: 0.100000\n","2022-02-16 19:16:16,406 ----------------------------------------------------------------------------------------------------\n","2022-02-16 19:16:16,410 EPOCH 6 done: loss 0.9064 - lr 0.1000000\n","2022-02-16 19:16:19,094 DEV : loss 0.8976327180862427 - score 0.5882\n","2022-02-16 19:16:19,264 BAD EPOCHS (no improvement): 0\n","saving best model\n","2022-02-16 19:16:33,904 ----------------------------------------------------------------------------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"output_type":"stream","name":"stdout","text":["2022-02-16 19:16:35,217 epoch 7 - iter 1/15 - loss 0.78362328 - samples/sec: 135.85 - lr: 0.100000\n","2022-02-16 19:16:35,323 epoch 7 - iter 2/15 - loss 0.88723058 - samples/sec: 361.58 - lr: 0.100000\n","2022-02-16 19:16:35,414 epoch 7 - iter 3/15 - loss 0.91305373 - samples/sec: 436.01 - lr: 0.100000\n","2022-02-16 19:16:35,496 epoch 7 - iter 4/15 - loss 0.91542614 - samples/sec: 458.84 - lr: 0.100000\n","2022-02-16 19:16:35,587 epoch 7 - iter 5/15 - loss 0.92975154 - samples/sec: 431.55 - lr: 0.100000\n","2022-02-16 19:16:35,660 epoch 7 - iter 6/15 - loss 0.93345163 - samples/sec: 481.80 - lr: 0.100000\n","2022-02-16 19:16:35,737 epoch 7 - iter 7/15 - loss 0.93178856 - samples/sec: 452.86 - lr: 0.100000\n","2022-02-16 19:16:35,820 epoch 7 - iter 8/15 - loss 0.90148842 - samples/sec: 431.90 - lr: 0.100000\n","2022-02-16 19:16:35,902 epoch 7 - iter 9/15 - loss 0.90702348 - samples/sec: 476.04 - lr: 0.100000\n","2022-02-16 19:16:35,989 epoch 7 - iter 10/15 - loss 0.93029134 - samples/sec: 501.30 - lr: 0.100000\n","2022-02-16 19:16:36,068 epoch 7 - iter 11/15 - loss 0.92688681 - samples/sec: 422.17 - lr: 0.100000\n","2022-02-16 19:16:36,139 epoch 7 - iter 12/15 - loss 0.91896844 - samples/sec: 463.60 - lr: 0.100000\n","2022-02-16 19:16:36,210 epoch 7 - iter 13/15 - loss 0.90359901 - samples/sec: 490.54 - lr: 0.100000\n","2022-02-16 19:16:36,295 epoch 7 - iter 14/15 - loss 0.90109643 - samples/sec: 388.55 - lr: 0.100000\n","2022-02-16 19:16:36,341 epoch 7 - iter 15/15 - loss 0.89613306 - samples/sec: 726.09 - lr: 0.100000\n","2022-02-16 19:16:36,826 ----------------------------------------------------------------------------------------------------\n","2022-02-16 19:16:36,833 EPOCH 7 done: loss 0.8961 - lr 0.1000000\n","2022-02-16 19:16:38,367 DEV : loss 0.8842301368713379 - score 0.5882\n","2022-02-16 19:16:38,435 BAD EPOCHS (no improvement): 0\n","saving best model\n","2022-02-16 19:16:53,438 ----------------------------------------------------------------------------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"output_type":"stream","name":"stdout","text":["2022-02-16 19:16:54,878 epoch 8 - iter 1/15 - loss 1.01711917 - samples/sec: 133.93 - lr: 0.100000\n","2022-02-16 19:16:55,010 epoch 8 - iter 2/15 - loss 0.99830687 - samples/sec: 351.01 - lr: 0.100000\n","2022-02-16 19:16:55,107 epoch 8 - iter 3/15 - loss 0.97199136 - samples/sec: 418.51 - lr: 0.100000\n","2022-02-16 19:16:55,180 epoch 8 - iter 4/15 - loss 0.93966903 - samples/sec: 472.81 - lr: 0.100000\n","2022-02-16 19:16:55,251 epoch 8 - iter 5/15 - loss 0.92578063 - samples/sec: 460.39 - lr: 0.100000\n","2022-02-16 19:16:55,321 epoch 8 - iter 6/15 - loss 0.93030546 - samples/sec: 469.99 - lr: 0.100000\n","2022-02-16 19:16:55,397 epoch 8 - iter 7/15 - loss 0.92640206 - samples/sec: 431.92 - lr: 0.100000\n","2022-02-16 19:16:55,483 epoch 8 - iter 8/15 - loss 0.90888817 - samples/sec: 465.95 - lr: 0.100000\n","2022-02-16 19:16:55,561 epoch 8 - iter 9/15 - loss 0.88739518 - samples/sec: 461.56 - lr: 0.100000\n","2022-02-16 19:16:55,637 epoch 8 - iter 10/15 - loss 0.89706845 - samples/sec: 452.76 - lr: 0.100000\n","2022-02-16 19:16:55,715 epoch 8 - iter 11/15 - loss 0.88680035 - samples/sec: 434.96 - lr: 0.100000\n","2022-02-16 19:16:55,787 epoch 8 - iter 12/15 - loss 0.88055206 - samples/sec: 479.35 - lr: 0.100000\n","2022-02-16 19:16:55,855 epoch 8 - iter 13/15 - loss 0.87819831 - samples/sec: 486.66 - lr: 0.100000\n","2022-02-16 19:16:55,933 epoch 8 - iter 14/15 - loss 0.87436319 - samples/sec: 483.78 - lr: 0.100000\n","2022-02-16 19:16:55,983 epoch 8 - iter 15/15 - loss 0.88585554 - samples/sec: 673.72 - lr: 0.100000\n","2022-02-16 19:16:56,448 ----------------------------------------------------------------------------------------------------\n","2022-02-16 19:16:56,450 EPOCH 8 done: loss 0.8859 - lr 0.1000000\n","2022-02-16 19:16:57,937 DEV : loss 0.881767749786377 - score 0.5882\n","2022-02-16 19:16:58,001 BAD EPOCHS (no improvement): 0\n","saving best model\n","2022-02-16 19:17:12,648 ----------------------------------------------------------------------------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"output_type":"stream","name":"stdout","text":["2022-02-16 19:17:13,972 epoch 9 - iter 1/15 - loss 0.92741507 - samples/sec: 152.21 - lr: 0.100000\n","2022-02-16 19:17:14,065 epoch 9 - iter 2/15 - loss 0.87034813 - samples/sec: 407.10 - lr: 0.100000\n","2022-02-16 19:17:14,155 epoch 9 - iter 3/15 - loss 0.85857717 - samples/sec: 452.26 - lr: 0.100000\n","2022-02-16 19:17:14,237 epoch 9 - iter 4/15 - loss 0.89231427 - samples/sec: 403.06 - lr: 0.100000\n","2022-02-16 19:17:14,325 epoch 9 - iter 5/15 - loss 0.86700972 - samples/sec: 429.34 - lr: 0.100000\n","2022-02-16 19:17:14,408 epoch 9 - iter 6/15 - loss 0.86150353 - samples/sec: 452.30 - lr: 0.100000\n","2022-02-16 19:17:14,480 epoch 9 - iter 7/15 - loss 0.83657988 - samples/sec: 509.56 - lr: 0.100000\n","2022-02-16 19:17:14,561 epoch 9 - iter 8/15 - loss 0.83849770 - samples/sec: 467.73 - lr: 0.100000\n","2022-02-16 19:17:14,653 epoch 9 - iter 9/15 - loss 0.84077825 - samples/sec: 412.01 - lr: 0.100000\n","2022-02-16 19:17:14,726 epoch 9 - iter 10/15 - loss 0.83312742 - samples/sec: 454.71 - lr: 0.100000\n","2022-02-16 19:17:14,809 epoch 9 - iter 11/15 - loss 0.83590195 - samples/sec: 477.99 - lr: 0.100000\n","2022-02-16 19:17:14,878 epoch 9 - iter 12/15 - loss 0.86211735 - samples/sec: 524.05 - lr: 0.100000\n","2022-02-16 19:17:14,951 epoch 9 - iter 13/15 - loss 0.86121024 - samples/sec: 512.57 - lr: 0.100000\n","2022-02-16 19:17:15,032 epoch 9 - iter 14/15 - loss 0.85941676 - samples/sec: 438.30 - lr: 0.100000\n","2022-02-16 19:17:15,078 epoch 9 - iter 15/15 - loss 0.85995149 - samples/sec: 848.17 - lr: 0.100000\n","2022-02-16 19:17:15,560 ----------------------------------------------------------------------------------------------------\n","2022-02-16 19:17:15,566 EPOCH 9 done: loss 0.8600 - lr 0.1000000\n","2022-02-16 19:17:17,101 DEV : loss 0.8722084760665894 - score 0.6078\n","2022-02-16 19:17:17,160 BAD EPOCHS (no improvement): 0\n","saving best model\n","2022-02-16 19:17:31,579 ----------------------------------------------------------------------------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"output_type":"stream","name":"stdout","text":["2022-02-16 19:17:32,880 epoch 10 - iter 1/15 - loss 0.75337338 - samples/sec: 222.94 - lr: 0.100000\n","2022-02-16 19:17:32,982 epoch 10 - iter 2/15 - loss 0.86275649 - samples/sec: 399.48 - lr: 0.100000\n","2022-02-16 19:17:33,061 epoch 10 - iter 3/15 - loss 0.85025684 - samples/sec: 425.85 - lr: 0.100000\n","2022-02-16 19:17:33,147 epoch 10 - iter 4/15 - loss 0.82511421 - samples/sec: 381.91 - lr: 0.100000\n","2022-02-16 19:17:33,225 epoch 10 - iter 5/15 - loss 0.82733090 - samples/sec: 490.92 - lr: 0.100000\n","2022-02-16 19:17:33,332 epoch 10 - iter 6/15 - loss 0.84033946 - samples/sec: 420.33 - lr: 0.100000\n","2022-02-16 19:17:33,401 epoch 10 - iter 7/15 - loss 0.82934690 - samples/sec: 486.24 - lr: 0.100000\n","2022-02-16 19:17:33,487 epoch 10 - iter 8/15 - loss 0.83361906 - samples/sec: 468.75 - lr: 0.100000\n","2022-02-16 19:17:33,570 epoch 10 - iter 9/15 - loss 0.83063237 - samples/sec: 469.04 - lr: 0.100000\n","2022-02-16 19:17:33,649 epoch 10 - iter 10/15 - loss 0.82194344 - samples/sec: 440.20 - lr: 0.100000\n","2022-02-16 19:17:33,726 epoch 10 - iter 11/15 - loss 0.82256319 - samples/sec: 465.73 - lr: 0.100000\n","2022-02-16 19:17:33,810 epoch 10 - iter 12/15 - loss 0.81432567 - samples/sec: 478.80 - lr: 0.100000\n","2022-02-16 19:17:33,879 epoch 10 - iter 13/15 - loss 0.82910286 - samples/sec: 510.86 - lr: 0.100000\n","2022-02-16 19:17:33,954 epoch 10 - iter 14/15 - loss 0.82730358 - samples/sec: 434.64 - lr: 0.100000\n","2022-02-16 19:17:34,004 epoch 10 - iter 15/15 - loss 0.82558586 - samples/sec: 761.46 - lr: 0.100000\n","2022-02-16 19:17:34,528 ----------------------------------------------------------------------------------------------------\n","2022-02-16 19:17:34,535 EPOCH 10 done: loss 0.8256 - lr 0.1000000\n","2022-02-16 19:17:36,122 DEV : loss 0.8539954423904419 - score 0.6078\n","2022-02-16 19:17:36,185 BAD EPOCHS (no improvement): 0\n","saving best model\n","2022-02-16 19:17:51,434 ----------------------------------------------------------------------------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"output_type":"stream","name":"stdout","text":["2022-02-16 19:17:52,771 epoch 11 - iter 1/15 - loss 0.74096775 - samples/sec: 162.38 - lr: 0.100000\n","2022-02-16 19:17:52,867 epoch 11 - iter 2/15 - loss 0.74569362 - samples/sec: 393.85 - lr: 0.100000\n","2022-02-16 19:17:52,958 epoch 11 - iter 3/15 - loss 0.71464499 - samples/sec: 441.05 - lr: 0.100000\n","2022-02-16 19:17:53,037 epoch 11 - iter 4/15 - loss 0.74297425 - samples/sec: 422.57 - lr: 0.100000\n","2022-02-16 19:17:53,127 epoch 11 - iter 5/15 - loss 0.71485641 - samples/sec: 381.98 - lr: 0.100000\n","2022-02-16 19:17:53,211 epoch 11 - iter 6/15 - loss 0.72672314 - samples/sec: 509.24 - lr: 0.100000\n","2022-02-16 19:17:53,305 epoch 11 - iter 7/15 - loss 0.75031767 - samples/sec: 430.59 - lr: 0.100000\n","2022-02-16 19:17:53,383 epoch 11 - iter 8/15 - loss 0.76686041 - samples/sec: 451.10 - lr: 0.100000\n","2022-02-16 19:17:53,458 epoch 11 - iter 9/15 - loss 0.77842906 - samples/sec: 442.57 - lr: 0.100000\n","2022-02-16 19:17:53,531 epoch 11 - iter 10/15 - loss 0.78907992 - samples/sec: 462.74 - lr: 0.100000\n","2022-02-16 19:17:53,622 epoch 11 - iter 11/15 - loss 0.78809072 - samples/sec: 371.10 - lr: 0.100000\n","2022-02-16 19:17:53,700 epoch 11 - iter 12/15 - loss 0.77827305 - samples/sec: 485.35 - lr: 0.100000\n","2022-02-16 19:17:53,779 epoch 11 - iter 13/15 - loss 0.76973276 - samples/sec: 479.43 - lr: 0.100000\n","2022-02-16 19:17:53,856 epoch 11 - iter 14/15 - loss 0.76951043 - samples/sec: 427.18 - lr: 0.100000\n","2022-02-16 19:17:53,907 epoch 11 - iter 15/15 - loss 0.77345837 - samples/sec: 711.82 - lr: 0.100000\n","2022-02-16 19:17:54,418 ----------------------------------------------------------------------------------------------------\n","2022-02-16 19:17:54,420 EPOCH 11 done: loss 0.7735 - lr 0.1000000\n","2022-02-16 19:17:56,005 DEV : loss 0.8295086622238159 - score 0.6078\n","2022-02-16 19:17:56,068 BAD EPOCHS (no improvement): 0\n","saving best model\n","2022-02-16 19:18:10,863 ----------------------------------------------------------------------------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"output_type":"stream","name":"stdout","text":["2022-02-16 19:18:12,224 epoch 12 - iter 1/15 - loss 0.65602869 - samples/sec: 221.58 - lr: 0.100000\n","2022-02-16 19:18:12,323 epoch 12 - iter 2/15 - loss 0.68692160 - samples/sec: 398.00 - lr: 0.100000\n","2022-02-16 19:18:12,418 epoch 12 - iter 3/15 - loss 0.71073689 - samples/sec: 397.55 - lr: 0.100000\n","2022-02-16 19:18:12,497 epoch 12 - iter 4/15 - loss 0.71548212 - samples/sec: 417.29 - lr: 0.100000\n","2022-02-16 19:18:12,568 epoch 12 - iter 5/15 - loss 0.73559352 - samples/sec: 520.95 - lr: 0.100000\n","2022-02-16 19:18:12,658 epoch 12 - iter 6/15 - loss 0.75601082 - samples/sec: 498.29 - lr: 0.100000\n","2022-02-16 19:18:12,741 epoch 12 - iter 7/15 - loss 0.75926965 - samples/sec: 434.28 - lr: 0.100000\n","2022-02-16 19:18:12,821 epoch 12 - iter 8/15 - loss 0.78057025 - samples/sec: 412.95 - lr: 0.100000\n","2022-02-16 19:18:12,908 epoch 12 - iter 9/15 - loss 0.77380056 - samples/sec: 483.50 - lr: 0.100000\n","2022-02-16 19:18:12,975 epoch 12 - iter 10/15 - loss 0.77039639 - samples/sec: 526.79 - lr: 0.100000\n","2022-02-16 19:18:13,055 epoch 12 - iter 11/15 - loss 0.76749273 - samples/sec: 416.12 - lr: 0.100000\n","2022-02-16 19:18:13,124 epoch 12 - iter 12/15 - loss 0.74968302 - samples/sec: 483.53 - lr: 0.100000\n","2022-02-16 19:18:13,201 epoch 12 - iter 13/15 - loss 0.73499591 - samples/sec: 460.02 - lr: 0.100000\n","2022-02-16 19:18:13,277 epoch 12 - iter 14/15 - loss 0.73923789 - samples/sec: 460.96 - lr: 0.100000\n","2022-02-16 19:18:13,323 epoch 12 - iter 15/15 - loss 0.74110499 - samples/sec: 787.23 - lr: 0.100000\n","2022-02-16 19:18:13,864 ----------------------------------------------------------------------------------------------------\n","2022-02-16 19:18:13,874 EPOCH 12 done: loss 0.7411 - lr 0.1000000\n","2022-02-16 19:18:15,514 DEV : loss 0.8224823474884033 - score 0.6078\n","2022-02-16 19:18:15,581 BAD EPOCHS (no improvement): 0\n","saving best model\n","2022-02-16 19:18:30,292 ----------------------------------------------------------------------------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"output_type":"stream","name":"stdout","text":["2022-02-16 19:18:31,709 epoch 13 - iter 1/15 - loss 0.77168167 - samples/sec: 195.85 - lr: 0.100000\n","2022-02-16 19:18:31,813 epoch 13 - iter 2/15 - loss 0.66810489 - samples/sec: 388.64 - lr: 0.100000\n","2022-02-16 19:18:31,893 epoch 13 - iter 3/15 - loss 0.66918880 - samples/sec: 422.67 - lr: 0.100000\n","2022-02-16 19:18:31,974 epoch 13 - iter 4/15 - loss 0.68081063 - samples/sec: 402.97 - lr: 0.100000\n","2022-02-16 19:18:32,049 epoch 13 - iter 5/15 - loss 0.71662091 - samples/sec: 439.77 - lr: 0.100000\n","2022-02-16 19:18:33,722 epoch 13 - iter 6/15 - loss 0.69941076 - samples/sec: 341.28 - lr: 0.100000\n","2022-02-16 19:18:33,799 epoch 13 - iter 7/15 - loss 0.68674852 - samples/sec: 541.73 - lr: 0.100000\n","2022-02-16 19:18:33,866 epoch 13 - iter 8/15 - loss 0.69922468 - samples/sec: 514.73 - lr: 0.100000\n","2022-02-16 19:18:33,939 epoch 13 - iter 9/15 - loss 0.70128418 - samples/sec: 483.74 - lr: 0.100000\n","2022-02-16 19:18:34,018 epoch 13 - iter 10/15 - loss 0.68953091 - samples/sec: 423.79 - lr: 0.100000\n","2022-02-16 19:18:34,088 epoch 13 - iter 11/15 - loss 0.70817857 - samples/sec: 471.13 - lr: 0.100000\n","2022-02-16 19:18:34,164 epoch 13 - iter 12/15 - loss 0.71694823 - samples/sec: 446.29 - lr: 0.100000\n","2022-02-16 19:18:34,232 epoch 13 - iter 13/15 - loss 0.71471769 - samples/sec: 560.27 - lr: 0.100000\n","2022-02-16 19:18:34,316 epoch 13 - iter 14/15 - loss 0.71102026 - samples/sec: 390.38 - lr: 0.100000\n","2022-02-16 19:18:34,361 epoch 13 - iter 15/15 - loss 0.69527529 - samples/sec: 743.44 - lr: 0.100000\n","2022-02-16 19:18:34,893 ----------------------------------------------------------------------------------------------------\n","2022-02-16 19:18:34,895 EPOCH 13 done: loss 0.6953 - lr 0.1000000\n","2022-02-16 19:18:36,462 DEV : loss 0.7886144518852234 - score 0.6275\n","2022-02-16 19:18:36,523 BAD EPOCHS (no improvement): 0\n","saving best model\n","2022-02-16 19:18:51,625 ----------------------------------------------------------------------------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"output_type":"stream","name":"stdout","text":["2022-02-16 19:18:53,002 epoch 14 - iter 1/15 - loss 0.72008187 - samples/sec: 280.78 - lr: 0.100000\n","2022-02-16 19:18:53,100 epoch 14 - iter 2/15 - loss 0.66094428 - samples/sec: 339.46 - lr: 0.100000\n","2022-02-16 19:18:53,183 epoch 14 - iter 3/15 - loss 0.65537387 - samples/sec: 419.72 - lr: 0.100000\n","2022-02-16 19:18:53,269 epoch 14 - iter 4/15 - loss 0.67097798 - samples/sec: 432.32 - lr: 0.100000\n","2022-02-16 19:18:53,340 epoch 14 - iter 5/15 - loss 0.65651653 - samples/sec: 467.61 - lr: 0.100000\n","2022-02-16 19:18:53,460 epoch 14 - iter 6/15 - loss 0.66561173 - samples/sec: 400.61 - lr: 0.100000\n","2022-02-16 19:18:53,553 epoch 14 - iter 7/15 - loss 0.65129596 - samples/sec: 355.39 - lr: 0.100000\n","2022-02-16 19:18:53,628 epoch 14 - iter 8/15 - loss 0.65142407 - samples/sec: 472.28 - lr: 0.100000\n","2022-02-16 19:18:53,718 epoch 14 - iter 9/15 - loss 0.67140597 - samples/sec: 445.76 - lr: 0.100000\n","2022-02-16 19:18:53,791 epoch 14 - iter 10/15 - loss 0.74031450 - samples/sec: 453.99 - lr: 0.100000\n","2022-02-16 19:18:53,868 epoch 14 - iter 11/15 - loss 0.81739381 - samples/sec: 433.46 - lr: 0.100000\n","2022-02-16 19:18:53,950 epoch 14 - iter 12/15 - loss 0.81637480 - samples/sec: 470.47 - lr: 0.100000\n","2022-02-16 19:18:54,031 epoch 14 - iter 13/15 - loss 0.79791979 - samples/sec: 455.12 - lr: 0.100000\n","2022-02-16 19:18:54,110 epoch 14 - iter 14/15 - loss 0.77467399 - samples/sec: 425.04 - lr: 0.100000\n","2022-02-16 19:18:54,156 epoch 14 - iter 15/15 - loss 0.77760295 - samples/sec: 714.00 - lr: 0.100000\n","2022-02-16 19:18:54,677 ----------------------------------------------------------------------------------------------------\n","2022-02-16 19:18:54,680 EPOCH 14 done: loss 0.7776 - lr 0.1000000\n","2022-02-16 19:18:56,287 DEV : loss 0.79549241065979 - score 0.6078\n","2022-02-16 19:18:56,348 BAD EPOCHS (no improvement): 1\n","2022-02-16 19:18:56,357 ----------------------------------------------------------------------------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"output_type":"stream","name":"stdout","text":["2022-02-16 19:18:57,527 epoch 15 - iter 1/15 - loss 0.88921982 - samples/sec: 142.07 - lr: 0.100000\n","2022-02-16 19:18:57,627 epoch 15 - iter 2/15 - loss 0.79974580 - samples/sec: 393.70 - lr: 0.100000\n","2022-02-16 19:18:57,752 epoch 15 - iter 3/15 - loss 0.78877829 - samples/sec: 400.26 - lr: 0.100000\n","2022-02-16 19:18:57,827 epoch 15 - iter 4/15 - loss 0.72881630 - samples/sec: 448.48 - lr: 0.100000\n","2022-02-16 19:18:57,908 epoch 15 - iter 5/15 - loss 0.73197436 - samples/sec: 408.82 - lr: 0.100000\n","2022-02-16 19:18:57,996 epoch 15 - iter 6/15 - loss 0.71665857 - samples/sec: 447.26 - lr: 0.100000\n","2022-02-16 19:18:58,079 epoch 15 - iter 7/15 - loss 0.68549321 - samples/sec: 399.75 - lr: 0.100000\n","2022-02-16 19:18:58,153 epoch 15 - iter 8/15 - loss 0.70515659 - samples/sec: 451.54 - lr: 0.100000\n","2022-02-16 19:18:58,241 epoch 15 - iter 9/15 - loss 0.73387991 - samples/sec: 493.36 - lr: 0.100000\n","2022-02-16 19:18:58,322 epoch 15 - iter 10/15 - loss 0.75815972 - samples/sec: 409.38 - lr: 0.100000\n","2022-02-16 19:18:58,396 epoch 15 - iter 11/15 - loss 0.73804671 - samples/sec: 447.67 - lr: 0.100000\n","2022-02-16 19:18:58,482 epoch 15 - iter 12/15 - loss 0.74452443 - samples/sec: 460.64 - lr: 0.100000\n","2022-02-16 19:18:58,568 epoch 15 - iter 13/15 - loss 0.73407047 - samples/sec: 401.42 - lr: 0.100000\n","2022-02-16 19:18:58,649 epoch 15 - iter 14/15 - loss 0.71664246 - samples/sec: 457.16 - lr: 0.100000\n","2022-02-16 19:18:58,701 epoch 15 - iter 15/15 - loss 0.70304368 - samples/sec: 638.02 - lr: 0.100000\n","2022-02-16 19:18:59,305 ----------------------------------------------------------------------------------------------------\n","2022-02-16 19:18:59,315 EPOCH 15 done: loss 0.7030 - lr 0.1000000\n","2022-02-16 19:19:02,395 DEV : loss 0.7993073463439941 - score 0.6078\n","2022-02-16 19:19:02,567 BAD EPOCHS (no improvement): 2\n","2022-02-16 19:19:02,583 ----------------------------------------------------------------------------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"output_type":"stream","name":"stdout","text":["2022-02-16 19:19:04,500 epoch 16 - iter 1/15 - loss 0.66125679 - samples/sec: 76.94 - lr: 0.100000\n","2022-02-16 19:19:04,746 epoch 16 - iter 2/15 - loss 0.68966582 - samples/sec: 158.37 - lr: 0.100000\n","2022-02-16 19:19:04,908 epoch 16 - iter 3/15 - loss 0.68128771 - samples/sec: 233.45 - lr: 0.100000\n","2022-02-16 19:19:05,147 epoch 16 - iter 4/15 - loss 0.65182950 - samples/sec: 193.02 - lr: 0.100000\n","2022-02-16 19:19:05,318 epoch 16 - iter 5/15 - loss 0.67029939 - samples/sec: 199.53 - lr: 0.100000\n","2022-02-16 19:19:05,478 epoch 16 - iter 6/15 - loss 0.64032030 - samples/sec: 212.19 - lr: 0.100000\n","2022-02-16 19:19:05,634 epoch 16 - iter 7/15 - loss 0.65962089 - samples/sec: 239.29 - lr: 0.100000\n","2022-02-16 19:19:05,748 epoch 16 - iter 8/15 - loss 0.68160756 - samples/sec: 301.98 - lr: 0.100000\n","2022-02-16 19:19:05,868 epoch 16 - iter 9/15 - loss 0.69668167 - samples/sec: 282.69 - lr: 0.100000\n","2022-02-16 19:19:06,004 epoch 16 - iter 10/15 - loss 0.70166377 - samples/sec: 305.96 - lr: 0.100000\n","2022-02-16 19:19:06,128 epoch 16 - iter 11/15 - loss 0.69749510 - samples/sec: 264.81 - lr: 0.100000\n","2022-02-16 19:19:06,249 epoch 16 - iter 12/15 - loss 0.68715702 - samples/sec: 286.21 - lr: 0.100000\n","2022-02-16 19:19:06,388 epoch 16 - iter 13/15 - loss 0.67453987 - samples/sec: 265.72 - lr: 0.100000\n","2022-02-16 19:19:06,520 epoch 16 - iter 14/15 - loss 0.66086803 - samples/sec: 248.09 - lr: 0.100000\n","2022-02-16 19:19:06,600 epoch 16 - iter 15/15 - loss 0.64267649 - samples/sec: 453.30 - lr: 0.100000\n","2022-02-16 19:19:07,313 ----------------------------------------------------------------------------------------------------\n","2022-02-16 19:19:07,316 EPOCH 16 done: loss 0.6427 - lr 0.1000000\n","2022-02-16 19:19:10,094 DEV : loss 0.7935559749603271 - score 0.6078\n","2022-02-16 19:19:10,211 BAD EPOCHS (no improvement): 3\n","2022-02-16 19:19:10,227 ----------------------------------------------------------------------------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"output_type":"stream","name":"stdout","text":["2022-02-16 19:19:11,919 epoch 17 - iter 1/15 - loss 0.58063245 - samples/sec: 109.78 - lr: 0.100000\n","2022-02-16 19:19:12,133 epoch 17 - iter 2/15 - loss 0.62612012 - samples/sec: 181.94 - lr: 0.100000\n","2022-02-16 19:19:12,350 epoch 17 - iter 3/15 - loss 0.67251513 - samples/sec: 154.95 - lr: 0.100000\n","2022-02-16 19:19:12,562 epoch 17 - iter 4/15 - loss 0.66891879 - samples/sec: 302.44 - lr: 0.100000\n","2022-02-16 19:19:12,672 epoch 17 - iter 5/15 - loss 0.64152040 - samples/sec: 306.25 - lr: 0.100000\n","2022-02-16 19:19:12,792 epoch 17 - iter 6/15 - loss 0.67561328 - samples/sec: 275.62 - lr: 0.100000\n","2022-02-16 19:19:12,894 epoch 17 - iter 7/15 - loss 0.67780461 - samples/sec: 325.69 - lr: 0.100000\n","2022-02-16 19:19:12,965 epoch 17 - iter 8/15 - loss 0.66887160 - samples/sec: 495.53 - lr: 0.100000\n","2022-02-16 19:19:13,051 epoch 17 - iter 9/15 - loss 0.65213955 - samples/sec: 387.12 - lr: 0.100000\n","2022-02-16 19:19:13,132 epoch 17 - iter 10/15 - loss 0.64299213 - samples/sec: 469.36 - lr: 0.100000\n","2022-02-16 19:19:13,206 epoch 17 - iter 11/15 - loss 0.63747998 - samples/sec: 443.93 - lr: 0.100000\n","2022-02-16 19:19:13,275 epoch 17 - iter 12/15 - loss 0.64272458 - samples/sec: 474.78 - lr: 0.100000\n","2022-02-16 19:19:13,353 epoch 17 - iter 13/15 - loss 0.63074505 - samples/sec: 418.32 - lr: 0.100000\n","2022-02-16 19:19:13,429 epoch 17 - iter 14/15 - loss 0.62883834 - samples/sec: 447.76 - lr: 0.100000\n","2022-02-16 19:19:13,477 epoch 17 - iter 15/15 - loss 0.63409206 - samples/sec: 700.96 - lr: 0.100000\n","2022-02-16 19:19:13,975 ----------------------------------------------------------------------------------------------------\n","2022-02-16 19:19:13,983 EPOCH 17 done: loss 0.6341 - lr 0.1000000\n","2022-02-16 19:19:15,552 DEV : loss 0.8145319223403931 - score 0.6275\n","Epoch    17: reducing learning rate of group 0 to 5.0000e-02.\n","2022-02-16 19:19:15,617 BAD EPOCHS (no improvement): 4\n","2022-02-16 19:19:15,625 ----------------------------------------------------------------------------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"output_type":"stream","name":"stdout","text":["2022-02-16 19:19:16,764 epoch 18 - iter 1/15 - loss 0.57970297 - samples/sec: 114.36 - lr: 0.050000\n","2022-02-16 19:19:16,881 epoch 18 - iter 2/15 - loss 0.57648924 - samples/sec: 386.45 - lr: 0.050000\n","2022-02-16 19:19:16,962 epoch 18 - iter 3/15 - loss 0.52065777 - samples/sec: 412.89 - lr: 0.050000\n","2022-02-16 19:19:17,033 epoch 18 - iter 4/15 - loss 0.57861843 - samples/sec: 484.69 - lr: 0.050000\n","2022-02-16 19:19:17,105 epoch 18 - iter 5/15 - loss 0.59453793 - samples/sec: 483.75 - lr: 0.050000\n","2022-02-16 19:19:17,193 epoch 18 - iter 6/15 - loss 0.60598354 - samples/sec: 462.20 - lr: 0.050000\n","2022-02-16 19:19:17,268 epoch 18 - iter 7/15 - loss 0.60598544 - samples/sec: 455.58 - lr: 0.050000\n","2022-02-16 19:19:17,350 epoch 18 - iter 8/15 - loss 0.62732652 - samples/sec: 405.45 - lr: 0.050000\n","2022-02-16 19:19:17,437 epoch 18 - iter 9/15 - loss 0.61660798 - samples/sec: 511.15 - lr: 0.050000\n","2022-02-16 19:19:17,508 epoch 18 - iter 10/15 - loss 0.62684038 - samples/sec: 491.56 - lr: 0.050000\n","2022-02-16 19:19:17,585 epoch 18 - iter 11/15 - loss 0.61557909 - samples/sec: 436.15 - lr: 0.050000\n","2022-02-16 19:19:17,672 epoch 18 - iter 12/15 - loss 0.59868535 - samples/sec: 467.75 - lr: 0.050000\n","2022-02-16 19:19:17,744 epoch 18 - iter 13/15 - loss 0.60187991 - samples/sec: 490.73 - lr: 0.050000\n","2022-02-16 19:19:17,816 epoch 18 - iter 14/15 - loss 0.60270448 - samples/sec: 467.64 - lr: 0.050000\n","2022-02-16 19:19:17,860 epoch 18 - iter 15/15 - loss 0.58309995 - samples/sec: 819.59 - lr: 0.050000\n","2022-02-16 19:19:18,414 ----------------------------------------------------------------------------------------------------\n","2022-02-16 19:19:18,416 EPOCH 18 done: loss 0.5831 - lr 0.0500000\n","2022-02-16 19:19:19,918 DEV : loss 0.8191440105438232 - score 0.6275\n","2022-02-16 19:19:20,009 BAD EPOCHS (no improvement): 1\n","2022-02-16 19:19:20,021 ----------------------------------------------------------------------------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"output_type":"stream","name":"stdout","text":["2022-02-16 19:19:21,186 epoch 19 - iter 1/15 - loss 0.82288432 - samples/sec: 138.83 - lr: 0.050000\n","2022-02-16 19:19:21,282 epoch 19 - iter 2/15 - loss 0.70705101 - samples/sec: 421.02 - lr: 0.050000\n","2022-02-16 19:19:21,366 epoch 19 - iter 3/15 - loss 0.67689983 - samples/sec: 439.64 - lr: 0.050000\n","2022-02-16 19:19:21,442 epoch 19 - iter 4/15 - loss 0.68338585 - samples/sec: 457.52 - lr: 0.050000\n","2022-02-16 19:19:21,525 epoch 19 - iter 5/15 - loss 0.67441880 - samples/sec: 481.81 - lr: 0.050000\n","2022-02-16 19:19:21,612 epoch 19 - iter 6/15 - loss 0.66587891 - samples/sec: 445.54 - lr: 0.050000\n","2022-02-16 19:19:21,683 epoch 19 - iter 7/15 - loss 0.63776651 - samples/sec: 466.12 - lr: 0.050000\n","2022-02-16 19:19:21,784 epoch 19 - iter 8/15 - loss 0.61210370 - samples/sec: 473.84 - lr: 0.050000\n","2022-02-16 19:19:21,854 epoch 19 - iter 9/15 - loss 0.61498979 - samples/sec: 472.83 - lr: 0.050000\n","2022-02-16 19:19:21,924 epoch 19 - iter 10/15 - loss 0.59966575 - samples/sec: 472.51 - lr: 0.050000\n","2022-02-16 19:19:22,002 epoch 19 - iter 11/15 - loss 0.60486908 - samples/sec: 418.41 - lr: 0.050000\n","2022-02-16 19:19:22,073 epoch 19 - iter 12/15 - loss 0.60012982 - samples/sec: 472.41 - lr: 0.050000\n","2022-02-16 19:19:22,146 epoch 19 - iter 13/15 - loss 0.58256045 - samples/sec: 445.68 - lr: 0.050000\n","2022-02-16 19:19:22,228 epoch 19 - iter 14/15 - loss 0.58264275 - samples/sec: 456.21 - lr: 0.050000\n","2022-02-16 19:19:22,277 epoch 19 - iter 15/15 - loss 0.57663346 - samples/sec: 779.12 - lr: 0.050000\n","2022-02-16 19:19:22,782 ----------------------------------------------------------------------------------------------------\n","2022-02-16 19:19:22,787 EPOCH 19 done: loss 0.5766 - lr 0.0500000\n","2022-02-16 19:19:24,293 DEV : loss 0.8586483001708984 - score 0.5882\n","2022-02-16 19:19:24,356 BAD EPOCHS (no improvement): 2\n","2022-02-16 19:19:24,368 ----------------------------------------------------------------------------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"output_type":"stream","name":"stdout","text":["2022-02-16 19:19:25,503 epoch 20 - iter 1/15 - loss 0.56735909 - samples/sec: 143.12 - lr: 0.050000\n","2022-02-16 19:19:25,600 epoch 20 - iter 2/15 - loss 0.60169336 - samples/sec: 381.21 - lr: 0.050000\n","2022-02-16 19:19:25,679 epoch 20 - iter 3/15 - loss 0.62953277 - samples/sec: 457.07 - lr: 0.050000\n","2022-02-16 19:19:25,798 epoch 20 - iter 4/15 - loss 0.59342629 - samples/sec: 483.82 - lr: 0.050000\n","2022-02-16 19:19:25,874 epoch 20 - iter 5/15 - loss 0.56259911 - samples/sec: 434.37 - lr: 0.050000\n","2022-02-16 19:19:25,950 epoch 20 - iter 6/15 - loss 0.53143701 - samples/sec: 437.41 - lr: 0.050000\n","2022-02-16 19:19:26,020 epoch 20 - iter 7/15 - loss 0.52225490 - samples/sec: 488.40 - lr: 0.050000\n","2022-02-16 19:19:26,093 epoch 20 - iter 8/15 - loss 0.52504851 - samples/sec: 450.16 - lr: 0.050000\n","2022-02-16 19:19:26,158 epoch 20 - iter 9/15 - loss 0.51106332 - samples/sec: 507.38 - lr: 0.050000\n","2022-02-16 19:19:26,228 epoch 20 - iter 10/15 - loss 0.53432980 - samples/sec: 509.67 - lr: 0.050000\n","2022-02-16 19:19:26,307 epoch 20 - iter 11/15 - loss 0.54206592 - samples/sec: 414.46 - lr: 0.050000\n","2022-02-16 19:19:26,378 epoch 20 - iter 12/15 - loss 0.52951919 - samples/sec: 461.48 - lr: 0.050000\n","2022-02-16 19:19:26,445 epoch 20 - iter 13/15 - loss 0.53254351 - samples/sec: 498.24 - lr: 0.050000\n","2022-02-16 19:19:26,511 epoch 20 - iter 14/15 - loss 0.53455067 - samples/sec: 518.75 - lr: 0.050000\n","2022-02-16 19:19:26,552 epoch 20 - iter 15/15 - loss 0.52942442 - samples/sec: 819.33 - lr: 0.050000\n","2022-02-16 19:19:27,022 ----------------------------------------------------------------------------------------------------\n","2022-02-16 19:19:27,024 EPOCH 20 done: loss 0.5294 - lr 0.0500000\n","2022-02-16 19:19:28,492 DEV : loss 0.8303526639938354 - score 0.6471\n","2022-02-16 19:19:28,565 BAD EPOCHS (no improvement): 0\n","saving best model\n","2022-02-16 19:19:43,060 ----------------------------------------------------------------------------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"output_type":"stream","name":"stdout","text":["2022-02-16 19:19:44,398 epoch 21 - iter 1/15 - loss 0.37602472 - samples/sec: 128.91 - lr: 0.050000\n","2022-02-16 19:19:44,509 epoch 21 - iter 2/15 - loss 0.54376689 - samples/sec: 364.27 - lr: 0.050000\n","2022-02-16 19:19:44,599 epoch 21 - iter 3/15 - loss 0.58512570 - samples/sec: 409.82 - lr: 0.050000\n","2022-02-16 19:19:44,679 epoch 21 - iter 4/15 - loss 0.56553410 - samples/sec: 482.58 - lr: 0.050000\n","2022-02-16 19:19:44,770 epoch 21 - iter 5/15 - loss 0.53390696 - samples/sec: 453.16 - lr: 0.050000\n","2022-02-16 19:19:46,388 epoch 21 - iter 6/15 - loss 0.53495684 - samples/sec: 482.05 - lr: 0.050000\n","2022-02-16 19:19:46,457 epoch 21 - iter 7/15 - loss 0.52463957 - samples/sec: 507.09 - lr: 0.050000\n","2022-02-16 19:19:46,523 epoch 21 - iter 8/15 - loss 0.55175869 - samples/sec: 511.44 - lr: 0.050000\n","2022-02-16 19:19:46,585 epoch 21 - iter 9/15 - loss 0.54143745 - samples/sec: 549.95 - lr: 0.050000\n","2022-02-16 19:19:46,659 epoch 21 - iter 10/15 - loss 0.55558238 - samples/sec: 447.08 - lr: 0.050000\n","2022-02-16 19:19:46,726 epoch 21 - iter 11/15 - loss 0.53928868 - samples/sec: 493.37 - lr: 0.050000\n","2022-02-16 19:19:46,809 epoch 21 - iter 12/15 - loss 0.53977368 - samples/sec: 442.58 - lr: 0.050000\n","2022-02-16 19:19:46,880 epoch 21 - iter 13/15 - loss 0.54425856 - samples/sec: 496.72 - lr: 0.050000\n","2022-02-16 19:19:46,948 epoch 21 - iter 14/15 - loss 0.54091108 - samples/sec: 501.25 - lr: 0.050000\n","2022-02-16 19:19:46,997 epoch 21 - iter 15/15 - loss 0.54252084 - samples/sec: 674.95 - lr: 0.050000\n","2022-02-16 19:19:47,542 ----------------------------------------------------------------------------------------------------\n","2022-02-16 19:19:47,547 EPOCH 21 done: loss 0.5425 - lr 0.0500000\n","2022-02-16 19:19:49,160 DEV : loss 0.9407271146774292 - score 0.5294\n","2022-02-16 19:19:49,222 BAD EPOCHS (no improvement): 1\n","2022-02-16 19:19:49,233 ----------------------------------------------------------------------------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"output_type":"stream","name":"stdout","text":["2022-02-16 19:19:51,205 epoch 22 - iter 1/15 - loss 0.47540790 - samples/sec: 87.09 - lr: 0.050000\n","2022-02-16 19:19:51,386 epoch 22 - iter 2/15 - loss 0.55543503 - samples/sec: 196.09 - lr: 0.050000\n","2022-02-16 19:19:51,611 epoch 22 - iter 3/15 - loss 0.57854166 - samples/sec: 169.09 - lr: 0.050000\n","2022-02-16 19:19:51,817 epoch 22 - iter 4/15 - loss 0.55267888 - samples/sec: 170.46 - lr: 0.050000\n","2022-02-16 19:19:52,004 epoch 22 - iter 5/15 - loss 0.55924705 - samples/sec: 189.71 - lr: 0.050000\n","2022-02-16 19:19:52,204 epoch 22 - iter 6/15 - loss 0.56489686 - samples/sec: 202.74 - lr: 0.050000\n","2022-02-16 19:19:52,387 epoch 22 - iter 7/15 - loss 0.57214289 - samples/sec: 184.58 - lr: 0.050000\n","2022-02-16 19:19:52,551 epoch 22 - iter 8/15 - loss 0.56440083 - samples/sec: 218.46 - lr: 0.050000\n","2022-02-16 19:19:52,812 epoch 22 - iter 9/15 - loss 0.57025768 - samples/sec: 145.20 - lr: 0.050000\n","2022-02-16 19:19:53,034 epoch 22 - iter 10/15 - loss 0.56079668 - samples/sec: 180.20 - lr: 0.050000\n","2022-02-16 19:19:53,211 epoch 22 - iter 11/15 - loss 0.55656359 - samples/sec: 233.42 - lr: 0.050000\n","2022-02-16 19:19:53,407 epoch 22 - iter 12/15 - loss 0.55319554 - samples/sec: 203.69 - lr: 0.050000\n","2022-02-16 19:19:53,569 epoch 22 - iter 13/15 - loss 0.54618065 - samples/sec: 215.50 - lr: 0.050000\n","2022-02-16 19:19:53,769 epoch 22 - iter 14/15 - loss 0.56443754 - samples/sec: 192.08 - lr: 0.050000\n","2022-02-16 19:19:53,882 epoch 22 - iter 15/15 - loss 0.57650089 - samples/sec: 322.52 - lr: 0.050000\n","2022-02-16 19:19:54,717 ----------------------------------------------------------------------------------------------------\n","2022-02-16 19:19:54,728 EPOCH 22 done: loss 0.5765 - lr 0.0500000\n","2022-02-16 19:19:57,509 DEV : loss 0.8102520704269409 - score 0.6471\n","2022-02-16 19:19:57,640 BAD EPOCHS (no improvement): 0\n","saving best model\n","2022-02-16 19:20:12,348 ----------------------------------------------------------------------------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"output_type":"stream","name":"stdout","text":["2022-02-16 19:20:13,662 epoch 23 - iter 1/15 - loss 0.58669013 - samples/sec: 183.95 - lr: 0.050000\n","2022-02-16 19:20:13,761 epoch 23 - iter 2/15 - loss 0.59581894 - samples/sec: 370.06 - lr: 0.050000\n","2022-02-16 19:20:13,867 epoch 23 - iter 3/15 - loss 0.56976994 - samples/sec: 441.43 - lr: 0.050000\n","2022-02-16 19:20:13,948 epoch 23 - iter 4/15 - loss 0.53540613 - samples/sec: 416.65 - lr: 0.050000\n","2022-02-16 19:20:14,024 epoch 23 - iter 5/15 - loss 0.60200819 - samples/sec: 443.55 - lr: 0.050000\n","2022-02-16 19:20:14,117 epoch 23 - iter 6/15 - loss 0.60217042 - samples/sec: 468.14 - lr: 0.050000\n","2022-02-16 19:20:14,196 epoch 23 - iter 7/15 - loss 0.58986453 - samples/sec: 462.52 - lr: 0.050000\n","2022-02-16 19:20:14,292 epoch 23 - iter 8/15 - loss 0.60408870 - samples/sec: 358.00 - lr: 0.050000\n","2022-02-16 19:20:14,377 epoch 23 - iter 9/15 - loss 0.60140266 - samples/sec: 503.59 - lr: 0.050000\n","2022-02-16 19:20:14,454 epoch 23 - iter 10/15 - loss 0.57263669 - samples/sec: 455.65 - lr: 0.050000\n","2022-02-16 19:20:14,534 epoch 23 - iter 11/15 - loss 0.55262121 - samples/sec: 420.72 - lr: 0.050000\n","2022-02-16 19:20:14,619 epoch 23 - iter 12/15 - loss 0.53824920 - samples/sec: 484.39 - lr: 0.050000\n","2022-02-16 19:20:14,698 epoch 23 - iter 13/15 - loss 0.54616233 - samples/sec: 440.99 - lr: 0.050000\n","2022-02-16 19:20:14,777 epoch 23 - iter 14/15 - loss 0.53987006 - samples/sec: 420.58 - lr: 0.050000\n","2022-02-16 19:20:14,839 epoch 23 - iter 15/15 - loss 0.53662461 - samples/sec: 812.21 - lr: 0.050000\n","2022-02-16 19:20:15,394 ----------------------------------------------------------------------------------------------------\n","2022-02-16 19:20:15,396 EPOCH 23 done: loss 0.5366 - lr 0.0500000\n","2022-02-16 19:20:16,986 DEV : loss 0.9107190370559692 - score 0.6078\n","2022-02-16 19:20:17,049 BAD EPOCHS (no improvement): 1\n","2022-02-16 19:20:17,059 ----------------------------------------------------------------------------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"output_type":"stream","name":"stdout","text":["2022-02-16 19:20:18,244 epoch 24 - iter 1/15 - loss 0.91120350 - samples/sec: 162.41 - lr: 0.050000\n","2022-02-16 19:20:18,349 epoch 24 - iter 2/15 - loss 0.80495781 - samples/sec: 373.76 - lr: 0.050000\n","2022-02-16 19:20:18,438 epoch 24 - iter 3/15 - loss 0.69575668 - samples/sec: 422.73 - lr: 0.050000\n","2022-02-16 19:20:18,525 epoch 24 - iter 4/15 - loss 0.68832504 - samples/sec: 444.48 - lr: 0.050000\n","2022-02-16 19:20:18,617 epoch 24 - iter 5/15 - loss 0.64178320 - samples/sec: 395.64 - lr: 0.050000\n","2022-02-16 19:20:18,732 epoch 24 - iter 6/15 - loss 0.63809090 - samples/sec: 469.61 - lr: 0.050000\n","2022-02-16 19:20:18,803 epoch 24 - iter 7/15 - loss 0.64830661 - samples/sec: 469.32 - lr: 0.050000\n","2022-02-16 19:20:18,872 epoch 24 - iter 8/15 - loss 0.65248280 - samples/sec: 501.65 - lr: 0.050000\n","2022-02-16 19:20:18,949 epoch 24 - iter 9/15 - loss 0.63188641 - samples/sec: 422.45 - lr: 0.050000\n","2022-02-16 19:20:19,038 epoch 24 - iter 10/15 - loss 0.63221987 - samples/sec: 370.05 - lr: 0.050000\n","2022-02-16 19:20:19,106 epoch 24 - iter 11/15 - loss 0.61086105 - samples/sec: 519.52 - lr: 0.050000\n","2022-02-16 19:20:19,187 epoch 24 - iter 12/15 - loss 0.60739796 - samples/sec: 440.40 - lr: 0.050000\n","2022-02-16 19:20:19,267 epoch 24 - iter 13/15 - loss 0.58747781 - samples/sec: 415.41 - lr: 0.050000\n","2022-02-16 19:20:19,348 epoch 24 - iter 14/15 - loss 0.58149846 - samples/sec: 430.12 - lr: 0.050000\n","2022-02-16 19:20:19,390 epoch 24 - iter 15/15 - loss 0.55724364 - samples/sec: 821.27 - lr: 0.050000\n","2022-02-16 19:20:19,933 ----------------------------------------------------------------------------------------------------\n","2022-02-16 19:20:19,939 EPOCH 24 done: loss 0.5572 - lr 0.0500000\n","2022-02-16 19:20:22,036 DEV : loss 0.8059751391410828 - score 0.6275\n","2022-02-16 19:20:22,120 BAD EPOCHS (no improvement): 2\n","2022-02-16 19:20:22,137 ----------------------------------------------------------------------------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"output_type":"stream","name":"stdout","text":["2022-02-16 19:20:23,796 epoch 25 - iter 1/15 - loss 0.37592739 - samples/sec: 118.04 - lr: 0.050000\n","2022-02-16 19:20:23,909 epoch 25 - iter 2/15 - loss 0.49355617 - samples/sec: 297.85 - lr: 0.050000\n","2022-02-16 19:20:24,091 epoch 25 - iter 3/15 - loss 0.49609609 - samples/sec: 211.13 - lr: 0.050000\n","2022-02-16 19:20:24,245 epoch 25 - iter 4/15 - loss 0.52597170 - samples/sec: 233.79 - lr: 0.050000\n","2022-02-16 19:20:24,368 epoch 25 - iter 5/15 - loss 0.52822890 - samples/sec: 321.99 - lr: 0.050000\n","2022-02-16 19:20:24,482 epoch 25 - iter 6/15 - loss 0.51986792 - samples/sec: 342.78 - lr: 0.050000\n","2022-02-16 19:20:24,629 epoch 25 - iter 7/15 - loss 0.52791079 - samples/sec: 348.25 - lr: 0.050000\n","2022-02-16 19:20:24,730 epoch 25 - iter 8/15 - loss 0.53093776 - samples/sec: 337.47 - lr: 0.050000\n","2022-02-16 19:20:24,842 epoch 25 - iter 9/15 - loss 0.53240537 - samples/sec: 303.00 - lr: 0.050000\n","2022-02-16 19:20:24,967 epoch 25 - iter 10/15 - loss 0.52603509 - samples/sec: 276.42 - lr: 0.050000\n","2022-02-16 19:20:25,106 epoch 25 - iter 11/15 - loss 0.52359299 - samples/sec: 235.81 - lr: 0.050000\n","2022-02-16 19:20:25,219 epoch 25 - iter 12/15 - loss 0.52122213 - samples/sec: 297.81 - lr: 0.050000\n","2022-02-16 19:20:25,335 epoch 25 - iter 13/15 - loss 0.52329435 - samples/sec: 322.29 - lr: 0.050000\n","2022-02-16 19:20:25,452 epoch 25 - iter 14/15 - loss 0.53697971 - samples/sec: 290.86 - lr: 0.050000\n","2022-02-16 19:20:25,525 epoch 25 - iter 15/15 - loss 0.54043905 - samples/sec: 500.75 - lr: 0.050000\n","2022-02-16 19:20:26,282 ----------------------------------------------------------------------------------------------------\n","2022-02-16 19:20:26,287 EPOCH 25 done: loss 0.5404 - lr 0.0500000\n","2022-02-16 19:20:28,591 DEV : loss 0.7992699146270752 - score 0.6863\n","2022-02-16 19:20:28,703 BAD EPOCHS (no improvement): 0\n","saving best model\n","2022-02-16 19:20:43,945 ----------------------------------------------------------------------------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"output_type":"stream","name":"stdout","text":["2022-02-16 19:20:45,256 epoch 26 - iter 1/15 - loss 0.35579377 - samples/sec: 140.59 - lr: 0.050000\n","2022-02-16 19:20:45,357 epoch 26 - iter 2/15 - loss 0.37273356 - samples/sec: 374.83 - lr: 0.050000\n","2022-02-16 19:20:45,448 epoch 26 - iter 3/15 - loss 0.38407752 - samples/sec: 425.90 - lr: 0.050000\n","2022-02-16 19:20:45,577 epoch 26 - iter 4/15 - loss 0.46571592 - samples/sec: 462.85 - lr: 0.050000\n","2022-02-16 19:20:45,671 epoch 26 - iter 5/15 - loss 0.49245182 - samples/sec: 461.61 - lr: 0.050000\n","2022-02-16 19:20:45,764 epoch 26 - iter 6/15 - loss 0.47892218 - samples/sec: 401.48 - lr: 0.050000\n","2022-02-16 19:20:45,847 epoch 26 - iter 7/15 - loss 0.47291461 - samples/sec: 403.16 - lr: 0.050000\n","2022-02-16 19:20:45,933 epoch 26 - iter 8/15 - loss 0.48345646 - samples/sec: 448.27 - lr: 0.050000\n","2022-02-16 19:20:46,014 epoch 26 - iter 9/15 - loss 0.48710409 - samples/sec: 419.03 - lr: 0.050000\n","2022-02-16 19:20:46,099 epoch 26 - iter 10/15 - loss 0.48064033 - samples/sec: 489.84 - lr: 0.050000\n","2022-02-16 19:20:46,180 epoch 26 - iter 11/15 - loss 0.49114360 - samples/sec: 408.74 - lr: 0.050000\n","2022-02-16 19:20:46,254 epoch 26 - iter 12/15 - loss 0.48350864 - samples/sec: 456.26 - lr: 0.050000\n","2022-02-16 19:20:46,338 epoch 26 - iter 13/15 - loss 0.47664946 - samples/sec: 392.05 - lr: 0.050000\n","2022-02-16 19:20:46,407 epoch 26 - iter 14/15 - loss 0.48660847 - samples/sec: 531.76 - lr: 0.050000\n","2022-02-16 19:20:46,453 epoch 26 - iter 15/15 - loss 0.49513872 - samples/sec: 778.60 - lr: 0.050000\n","2022-02-16 19:20:47,028 ----------------------------------------------------------------------------------------------------\n","2022-02-16 19:20:47,033 EPOCH 26 done: loss 0.4951 - lr 0.0500000\n","2022-02-16 19:20:48,651 DEV : loss 0.8760359287261963 - score 0.5882\n","2022-02-16 19:20:48,723 BAD EPOCHS (no improvement): 1\n","2022-02-16 19:20:48,736 ----------------------------------------------------------------------------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"output_type":"stream","name":"stdout","text":["2022-02-16 19:20:49,970 epoch 27 - iter 1/15 - loss 0.61458570 - samples/sec: 148.31 - lr: 0.050000\n","2022-02-16 19:20:50,070 epoch 27 - iter 2/15 - loss 0.50070871 - samples/sec: 393.23 - lr: 0.050000\n","2022-02-16 19:20:50,177 epoch 27 - iter 3/15 - loss 0.51960471 - samples/sec: 346.95 - lr: 0.050000\n","2022-02-16 19:20:50,263 epoch 27 - iter 4/15 - loss 0.54974227 - samples/sec: 477.84 - lr: 0.050000\n","2022-02-16 19:20:50,346 epoch 27 - iter 5/15 - loss 0.50473713 - samples/sec: 468.16 - lr: 0.050000\n","2022-02-16 19:20:50,437 epoch 27 - iter 6/15 - loss 0.50027914 - samples/sec: 476.40 - lr: 0.050000\n","2022-02-16 19:20:50,537 epoch 27 - iter 7/15 - loss 0.51498495 - samples/sec: 362.62 - lr: 0.050000\n","2022-02-16 19:20:50,609 epoch 27 - iter 8/15 - loss 0.50946185 - samples/sec: 511.96 - lr: 0.050000\n","2022-02-16 19:20:50,693 epoch 27 - iter 9/15 - loss 0.49429580 - samples/sec: 444.45 - lr: 0.050000\n","2022-02-16 19:20:50,938 epoch 27 - iter 10/15 - loss 0.50178410 - samples/sec: 158.78 - lr: 0.050000\n","2022-02-16 19:20:51,022 epoch 27 - iter 11/15 - loss 0.49724334 - samples/sec: 397.30 - lr: 0.050000\n","2022-02-16 19:20:51,125 epoch 27 - iter 12/15 - loss 0.48181024 - samples/sec: 321.88 - lr: 0.050000\n","2022-02-16 19:20:51,277 epoch 27 - iter 13/15 - loss 0.48222749 - samples/sec: 215.65 - lr: 0.050000\n","2022-02-16 19:20:51,372 epoch 27 - iter 14/15 - loss 0.47851731 - samples/sec: 365.47 - lr: 0.050000\n","2022-02-16 19:20:51,466 epoch 27 - iter 15/15 - loss 0.48138756 - samples/sec: 385.02 - lr: 0.050000\n","2022-02-16 19:20:52,397 ----------------------------------------------------------------------------------------------------\n","2022-02-16 19:20:52,404 EPOCH 27 done: loss 0.4814 - lr 0.0500000\n","2022-02-16 19:20:54,679 DEV : loss 0.9433382153511047 - score 0.6667\n","2022-02-16 19:20:54,756 BAD EPOCHS (no improvement): 2\n","2022-02-16 19:20:54,766 ----------------------------------------------------------------------------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"output_type":"stream","name":"stdout","text":["2022-02-16 19:20:56,473 epoch 28 - iter 1/15 - loss 0.58854437 - samples/sec: 163.73 - lr: 0.050000\n","2022-02-16 19:20:56,613 epoch 28 - iter 2/15 - loss 0.53224963 - samples/sec: 333.95 - lr: 0.050000\n","2022-02-16 19:20:56,712 epoch 28 - iter 3/15 - loss 0.49102480 - samples/sec: 334.77 - lr: 0.050000\n","2022-02-16 19:20:56,838 epoch 28 - iter 4/15 - loss 0.45989252 - samples/sec: 350.29 - lr: 0.050000\n","2022-02-16 19:20:56,934 epoch 28 - iter 5/15 - loss 0.48746718 - samples/sec: 354.61 - lr: 0.050000\n","2022-02-16 19:20:57,076 epoch 28 - iter 6/15 - loss 0.52536311 - samples/sec: 236.80 - lr: 0.050000\n","2022-02-16 19:20:57,182 epoch 28 - iter 7/15 - loss 0.50469924 - samples/sec: 352.62 - lr: 0.050000\n","2022-02-16 19:20:57,348 epoch 28 - iter 8/15 - loss 0.48287715 - samples/sec: 244.52 - lr: 0.050000\n","2022-02-16 19:20:57,436 epoch 28 - iter 9/15 - loss 0.46970016 - samples/sec: 398.29 - lr: 0.050000\n","2022-02-16 19:20:57,578 epoch 28 - iter 10/15 - loss 0.45126095 - samples/sec: 232.35 - lr: 0.050000\n","2022-02-16 19:20:57,686 epoch 28 - iter 11/15 - loss 0.45756513 - samples/sec: 310.26 - lr: 0.050000\n","2022-02-16 19:20:57,808 epoch 28 - iter 12/15 - loss 0.46001147 - samples/sec: 283.03 - lr: 0.050000\n","2022-02-16 19:20:57,910 epoch 28 - iter 13/15 - loss 0.46069641 - samples/sec: 389.07 - lr: 0.050000\n","2022-02-16 19:20:58,013 epoch 28 - iter 14/15 - loss 0.48139762 - samples/sec: 338.55 - lr: 0.050000\n","2022-02-16 19:20:58,080 epoch 28 - iter 15/15 - loss 0.46891490 - samples/sec: 539.40 - lr: 0.050000\n","2022-02-16 19:20:58,889 ----------------------------------------------------------------------------------------------------\n","2022-02-16 19:20:58,901 EPOCH 28 done: loss 0.4689 - lr 0.0500000\n","2022-02-16 19:21:01,239 DEV : loss 0.9417362809181213 - score 0.6667\n","2022-02-16 19:21:01,353 BAD EPOCHS (no improvement): 3\n","2022-02-16 19:21:01,371 ----------------------------------------------------------------------------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"output_type":"stream","name":"stdout","text":["2022-02-16 19:21:03,324 epoch 29 - iter 1/15 - loss 0.61637127 - samples/sec: 114.04 - lr: 0.050000\n","2022-02-16 19:21:03,461 epoch 29 - iter 2/15 - loss 0.45246427 - samples/sec: 245.96 - lr: 0.050000\n","2022-02-16 19:21:03,625 epoch 29 - iter 3/15 - loss 0.43279587 - samples/sec: 201.50 - lr: 0.050000\n","2022-02-16 19:21:03,754 epoch 29 - iter 4/15 - loss 0.40059987 - samples/sec: 283.38 - lr: 0.050000\n","2022-02-16 19:21:03,906 epoch 29 - iter 5/15 - loss 0.42672738 - samples/sec: 219.47 - lr: 0.050000\n","2022-02-16 19:21:04,100 epoch 29 - iter 6/15 - loss 0.42044700 - samples/sec: 259.63 - lr: 0.050000\n","2022-02-16 19:21:04,197 epoch 29 - iter 7/15 - loss 0.46334254 - samples/sec: 344.44 - lr: 0.050000\n","2022-02-16 19:21:04,277 epoch 29 - iter 8/15 - loss 0.51039137 - samples/sec: 418.40 - lr: 0.050000\n","2022-02-16 19:21:04,373 epoch 29 - iter 9/15 - loss 0.51199444 - samples/sec: 351.92 - lr: 0.050000\n","2022-02-16 19:21:04,495 epoch 29 - iter 10/15 - loss 0.50936366 - samples/sec: 364.20 - lr: 0.050000\n","2022-02-16 19:21:04,597 epoch 29 - iter 11/15 - loss 0.52315247 - samples/sec: 328.45 - lr: 0.050000\n","2022-02-16 19:21:04,694 epoch 29 - iter 12/15 - loss 0.53358445 - samples/sec: 419.82 - lr: 0.050000\n","2022-02-16 19:21:04,775 epoch 29 - iter 13/15 - loss 0.52461083 - samples/sec: 436.12 - lr: 0.050000\n","2022-02-16 19:21:04,864 epoch 29 - iter 14/15 - loss 0.52191482 - samples/sec: 379.35 - lr: 0.050000\n","2022-02-16 19:21:04,916 epoch 29 - iter 15/15 - loss 0.51145838 - samples/sec: 733.77 - lr: 0.050000\n","2022-02-16 19:21:05,613 ----------------------------------------------------------------------------------------------------\n","2022-02-16 19:21:05,623 EPOCH 29 done: loss 0.5115 - lr 0.0500000\n","2022-02-16 19:21:07,802 DEV : loss 0.908652126789093 - score 0.6667\n","Epoch    29: reducing learning rate of group 0 to 2.5000e-02.\n","2022-02-16 19:21:07,907 BAD EPOCHS (no improvement): 4\n","2022-02-16 19:21:07,916 ----------------------------------------------------------------------------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"output_type":"stream","name":"stdout","text":["2022-02-16 19:21:09,535 epoch 30 - iter 1/15 - loss 0.42793944 - samples/sec: 72.46 - lr: 0.025000\n","2022-02-16 19:21:09,675 epoch 30 - iter 2/15 - loss 0.37022036 - samples/sec: 336.58 - lr: 0.025000\n","2022-02-16 19:21:09,766 epoch 30 - iter 3/15 - loss 0.37693999 - samples/sec: 425.31 - lr: 0.025000\n","2022-02-16 19:21:09,844 epoch 30 - iter 4/15 - loss 0.41363065 - samples/sec: 471.56 - lr: 0.025000\n","2022-02-16 19:21:09,923 epoch 30 - iter 5/15 - loss 0.40595540 - samples/sec: 421.61 - lr: 0.025000\n","2022-02-16 19:21:11,589 epoch 30 - iter 6/15 - loss 0.44788947 - samples/sec: 463.22 - lr: 0.025000\n","2022-02-16 19:21:11,660 epoch 30 - iter 7/15 - loss 0.45212086 - samples/sec: 467.34 - lr: 0.025000\n","2022-02-16 19:21:11,737 epoch 30 - iter 8/15 - loss 0.47681851 - samples/sec: 529.22 - lr: 0.025000\n","2022-02-16 19:21:11,825 epoch 30 - iter 9/15 - loss 0.47858357 - samples/sec: 482.52 - lr: 0.025000\n","2022-02-16 19:21:11,892 epoch 30 - iter 10/15 - loss 0.45961490 - samples/sec: 508.52 - lr: 0.025000\n","2022-02-16 19:21:11,956 epoch 30 - iter 11/15 - loss 0.46996136 - samples/sec: 535.47 - lr: 0.025000\n","2022-02-16 19:21:12,028 epoch 30 - iter 12/15 - loss 0.46001278 - samples/sec: 458.84 - lr: 0.025000\n","2022-02-16 19:21:12,106 epoch 30 - iter 13/15 - loss 0.45469414 - samples/sec: 435.87 - lr: 0.025000\n","2022-02-16 19:21:12,180 epoch 30 - iter 14/15 - loss 0.44868849 - samples/sec: 440.91 - lr: 0.025000\n","2022-02-16 19:21:12,229 epoch 30 - iter 15/15 - loss 0.43561615 - samples/sec: 735.13 - lr: 0.025000\n","2022-02-16 19:21:12,770 ----------------------------------------------------------------------------------------------------\n","2022-02-16 19:21:12,773 EPOCH 30 done: loss 0.4356 - lr 0.0250000\n","2022-02-16 19:21:14,318 DEV : loss 0.8537856340408325 - score 0.6275\n","2022-02-16 19:21:14,386 BAD EPOCHS (no improvement): 1\n","2022-02-16 19:21:14,395 ----------------------------------------------------------------------------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"output_type":"stream","name":"stdout","text":["2022-02-16 19:21:15,575 epoch 31 - iter 1/15 - loss 0.37815925 - samples/sec: 127.91 - lr: 0.025000\n","2022-02-16 19:21:15,689 epoch 31 - iter 2/15 - loss 0.45599563 - samples/sec: 351.48 - lr: 0.025000\n","2022-02-16 19:21:15,792 epoch 31 - iter 3/15 - loss 0.47396295 - samples/sec: 353.75 - lr: 0.025000\n","2022-02-16 19:21:15,880 epoch 31 - iter 4/15 - loss 0.49128497 - samples/sec: 436.52 - lr: 0.025000\n","2022-02-16 19:21:15,972 epoch 31 - iter 5/15 - loss 0.47969930 - samples/sec: 445.54 - lr: 0.025000\n","2022-02-16 19:21:16,064 epoch 31 - iter 6/15 - loss 0.47148173 - samples/sec: 453.48 - lr: 0.025000\n","2022-02-16 19:21:16,143 epoch 31 - iter 7/15 - loss 0.45650896 - samples/sec: 419.56 - lr: 0.025000\n","2022-02-16 19:21:16,238 epoch 31 - iter 8/15 - loss 0.46669856 - samples/sec: 389.73 - lr: 0.025000\n","2022-02-16 19:21:16,322 epoch 31 - iter 9/15 - loss 0.45337955 - samples/sec: 393.92 - lr: 0.025000\n","2022-02-16 19:21:16,396 epoch 31 - iter 10/15 - loss 0.46258661 - samples/sec: 484.90 - lr: 0.025000\n","2022-02-16 19:21:16,483 epoch 31 - iter 11/15 - loss 0.47729504 - samples/sec: 452.09 - lr: 0.025000\n","2022-02-16 19:21:16,560 epoch 31 - iter 12/15 - loss 0.47969616 - samples/sec: 498.21 - lr: 0.025000\n","2022-02-16 19:21:16,633 epoch 31 - iter 13/15 - loss 0.46024268 - samples/sec: 460.52 - lr: 0.025000\n","2022-02-16 19:21:16,730 epoch 31 - iter 14/15 - loss 0.45381858 - samples/sec: 386.50 - lr: 0.025000\n","2022-02-16 19:21:16,779 epoch 31 - iter 15/15 - loss 0.47487194 - samples/sec: 682.24 - lr: 0.025000\n","2022-02-16 19:21:17,241 ----------------------------------------------------------------------------------------------------\n","2022-02-16 19:21:17,247 EPOCH 31 done: loss 0.4749 - lr 0.0250000\n","2022-02-16 19:21:18,860 DEV : loss 0.8678196668624878 - score 0.6471\n","2022-02-16 19:21:18,927 BAD EPOCHS (no improvement): 2\n","2022-02-16 19:21:18,933 ----------------------------------------------------------------------------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"output_type":"stream","name":"stdout","text":["2022-02-16 19:21:20,089 epoch 32 - iter 1/15 - loss 0.51449072 - samples/sec: 111.21 - lr: 0.025000\n","2022-02-16 19:21:20,222 epoch 32 - iter 2/15 - loss 0.51677665 - samples/sec: 379.76 - lr: 0.025000\n","2022-02-16 19:21:20,323 epoch 32 - iter 3/15 - loss 0.46073218 - samples/sec: 342.31 - lr: 0.025000\n","2022-02-16 19:21:20,405 epoch 32 - iter 4/15 - loss 0.43169256 - samples/sec: 404.73 - lr: 0.025000\n","2022-02-16 19:21:20,478 epoch 32 - iter 5/15 - loss 0.42786885 - samples/sec: 461.05 - lr: 0.025000\n","2022-02-16 19:21:20,570 epoch 32 - iter 6/15 - loss 0.45013768 - samples/sec: 426.23 - lr: 0.025000\n","2022-02-16 19:21:20,645 epoch 32 - iter 7/15 - loss 0.45549928 - samples/sec: 444.77 - lr: 0.025000\n","2022-02-16 19:21:20,734 epoch 32 - iter 8/15 - loss 0.46557528 - samples/sec: 503.13 - lr: 0.025000\n","2022-02-16 19:21:20,812 epoch 32 - iter 9/15 - loss 0.44392448 - samples/sec: 451.02 - lr: 0.025000\n","2022-02-16 19:21:20,892 epoch 32 - iter 10/15 - loss 0.44293633 - samples/sec: 408.70 - lr: 0.025000\n","2022-02-16 19:21:20,970 epoch 32 - iter 11/15 - loss 0.43827715 - samples/sec: 422.87 - lr: 0.025000\n","2022-02-16 19:21:21,057 epoch 32 - iter 12/15 - loss 0.43562230 - samples/sec: 486.93 - lr: 0.025000\n","2022-02-16 19:21:21,133 epoch 32 - iter 13/15 - loss 0.42395691 - samples/sec: 457.57 - lr: 0.025000\n","2022-02-16 19:21:21,212 epoch 32 - iter 14/15 - loss 0.42486600 - samples/sec: 440.16 - lr: 0.025000\n","2022-02-16 19:21:21,264 epoch 32 - iter 15/15 - loss 0.41498468 - samples/sec: 667.63 - lr: 0.025000\n","2022-02-16 19:21:21,746 ----------------------------------------------------------------------------------------------------\n","2022-02-16 19:21:21,750 EPOCH 32 done: loss 0.4150 - lr 0.0250000\n","2022-02-16 19:21:23,300 DEV : loss 0.8803818225860596 - score 0.6078\n","2022-02-16 19:21:23,385 BAD EPOCHS (no improvement): 3\n","2022-02-16 19:21:23,413 ----------------------------------------------------------------------------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"output_type":"stream","name":"stdout","text":["2022-02-16 19:21:24,595 epoch 33 - iter 1/15 - loss 0.40270811 - samples/sec: 196.57 - lr: 0.025000\n","2022-02-16 19:21:24,696 epoch 33 - iter 2/15 - loss 0.49558648 - samples/sec: 333.85 - lr: 0.025000\n","2022-02-16 19:21:24,773 epoch 33 - iter 3/15 - loss 0.48713472 - samples/sec: 432.48 - lr: 0.025000\n","2022-02-16 19:21:24,855 epoch 33 - iter 4/15 - loss 0.48088481 - samples/sec: 485.63 - lr: 0.025000\n","2022-02-16 19:21:24,937 epoch 33 - iter 5/15 - loss 0.45567899 - samples/sec: 406.58 - lr: 0.025000\n","2022-02-16 19:21:25,023 epoch 33 - iter 6/15 - loss 0.46459544 - samples/sec: 476.64 - lr: 0.025000\n","2022-02-16 19:21:25,124 epoch 33 - iter 7/15 - loss 0.45387664 - samples/sec: 443.63 - lr: 0.025000\n","2022-02-16 19:21:25,215 epoch 33 - iter 8/15 - loss 0.44565697 - samples/sec: 366.26 - lr: 0.025000\n","2022-02-16 19:21:25,302 epoch 33 - iter 9/15 - loss 0.44354073 - samples/sec: 389.86 - lr: 0.025000\n","2022-02-16 19:21:25,375 epoch 33 - iter 10/15 - loss 0.43556138 - samples/sec: 467.11 - lr: 0.025000\n","2022-02-16 19:21:25,449 epoch 33 - iter 11/15 - loss 0.42409278 - samples/sec: 470.91 - lr: 0.025000\n","2022-02-16 19:21:25,537 epoch 33 - iter 12/15 - loss 0.43068616 - samples/sec: 433.67 - lr: 0.025000\n","2022-02-16 19:21:25,625 epoch 33 - iter 13/15 - loss 0.42385181 - samples/sec: 486.62 - lr: 0.025000\n","2022-02-16 19:21:25,703 epoch 33 - iter 14/15 - loss 0.42492662 - samples/sec: 419.89 - lr: 0.025000\n","2022-02-16 19:21:25,758 epoch 33 - iter 15/15 - loss 0.41156448 - samples/sec: 650.86 - lr: 0.025000\n","2022-02-16 19:21:26,272 ----------------------------------------------------------------------------------------------------\n","2022-02-16 19:21:26,275 EPOCH 33 done: loss 0.4116 - lr 0.0250000\n","2022-02-16 19:21:27,802 DEV : loss 0.8539297580718994 - score 0.6471\n","Epoch    33: reducing learning rate of group 0 to 1.2500e-02.\n","2022-02-16 19:21:27,874 BAD EPOCHS (no improvement): 4\n","2022-02-16 19:21:27,884 ----------------------------------------------------------------------------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"output_type":"stream","name":"stdout","text":["2022-02-16 19:21:29,067 epoch 34 - iter 1/15 - loss 0.51604909 - samples/sec: 121.02 - lr: 0.012500\n","2022-02-16 19:21:29,171 epoch 34 - iter 2/15 - loss 0.40925762 - samples/sec: 362.68 - lr: 0.012500\n","2022-02-16 19:21:29,310 epoch 34 - iter 3/15 - loss 0.41321417 - samples/sec: 388.39 - lr: 0.012500\n","2022-02-16 19:21:29,389 epoch 34 - iter 4/15 - loss 0.39389431 - samples/sec: 437.65 - lr: 0.012500\n","2022-02-16 19:21:29,475 epoch 34 - iter 5/15 - loss 0.37768062 - samples/sec: 382.36 - lr: 0.012500\n","2022-02-16 19:21:29,569 epoch 34 - iter 6/15 - loss 0.38019333 - samples/sec: 363.79 - lr: 0.012500\n","2022-02-16 19:21:29,649 epoch 34 - iter 7/15 - loss 0.37277517 - samples/sec: 414.32 - lr: 0.012500\n","2022-02-16 19:21:29,727 epoch 34 - iter 8/15 - loss 0.38157759 - samples/sec: 424.87 - lr: 0.012500\n","2022-02-16 19:21:29,811 epoch 34 - iter 9/15 - loss 0.38874820 - samples/sec: 420.45 - lr: 0.012500\n","2022-02-16 19:21:29,887 epoch 34 - iter 10/15 - loss 0.41213389 - samples/sec: 440.16 - lr: 0.012500\n","2022-02-16 19:21:29,970 epoch 34 - iter 11/15 - loss 0.40673187 - samples/sec: 395.03 - lr: 0.012500\n","2022-02-16 19:21:30,043 epoch 34 - iter 12/15 - loss 0.39687722 - samples/sec: 464.05 - lr: 0.012500\n","2022-02-16 19:21:30,119 epoch 34 - iter 13/15 - loss 0.40109548 - samples/sec: 435.81 - lr: 0.012500\n","2022-02-16 19:21:30,190 epoch 34 - iter 14/15 - loss 0.43011467 - samples/sec: 487.05 - lr: 0.012500\n","2022-02-16 19:21:30,238 epoch 34 - iter 15/15 - loss 0.41583775 - samples/sec: 730.09 - lr: 0.012500\n","2022-02-16 19:21:30,738 ----------------------------------------------------------------------------------------------------\n","2022-02-16 19:21:30,746 EPOCH 34 done: loss 0.4158 - lr 0.0125000\n","2022-02-16 19:21:32,322 DEV : loss 0.8605692982673645 - score 0.6471\n","2022-02-16 19:21:32,389 BAD EPOCHS (no improvement): 1\n","2022-02-16 19:21:32,398 ----------------------------------------------------------------------------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"output_type":"stream","name":"stdout","text":["2022-02-16 19:21:33,593 epoch 35 - iter 1/15 - loss 0.37818256 - samples/sec: 140.20 - lr: 0.012500\n","2022-02-16 19:21:33,700 epoch 35 - iter 2/15 - loss 0.41256629 - samples/sec: 315.67 - lr: 0.012500\n","2022-02-16 19:21:33,810 epoch 35 - iter 3/15 - loss 0.39901016 - samples/sec: 334.38 - lr: 0.012500\n","2022-02-16 19:21:33,906 epoch 35 - iter 4/15 - loss 0.38814390 - samples/sec: 431.47 - lr: 0.012500\n","2022-02-16 19:21:33,993 epoch 35 - iter 5/15 - loss 0.37542222 - samples/sec: 383.78 - lr: 0.012500\n","2022-02-16 19:21:34,086 epoch 35 - iter 6/15 - loss 0.38787328 - samples/sec: 479.74 - lr: 0.012500\n","2022-02-16 19:21:34,162 epoch 35 - iter 7/15 - loss 0.38111046 - samples/sec: 468.23 - lr: 0.012500\n","2022-02-16 19:21:34,241 epoch 35 - iter 8/15 - loss 0.38155959 - samples/sec: 419.21 - lr: 0.012500\n","2022-02-16 19:21:34,334 epoch 35 - iter 9/15 - loss 0.39037585 - samples/sec: 461.59 - lr: 0.012500\n","2022-02-16 19:21:34,404 epoch 35 - iter 10/15 - loss 0.37103076 - samples/sec: 492.54 - lr: 0.012500\n","2022-02-16 19:21:34,481 epoch 35 - iter 11/15 - loss 0.37028203 - samples/sec: 434.32 - lr: 0.012500\n","2022-02-16 19:21:34,564 epoch 35 - iter 12/15 - loss 0.36154747 - samples/sec: 448.38 - lr: 0.012500\n","2022-02-16 19:21:34,639 epoch 35 - iter 13/15 - loss 0.36180569 - samples/sec: 449.69 - lr: 0.012500\n","2022-02-16 19:21:34,717 epoch 35 - iter 14/15 - loss 0.38189028 - samples/sec: 450.57 - lr: 0.012500\n","2022-02-16 19:21:34,765 epoch 35 - iter 15/15 - loss 0.39920385 - samples/sec: 817.89 - lr: 0.012500\n","2022-02-16 19:21:35,238 ----------------------------------------------------------------------------------------------------\n","2022-02-16 19:21:35,240 EPOCH 35 done: loss 0.3992 - lr 0.0125000\n","2022-02-16 19:21:36,787 DEV : loss 0.8843567371368408 - score 0.6471\n","2022-02-16 19:21:36,850 BAD EPOCHS (no improvement): 2\n","2022-02-16 19:21:36,859 ----------------------------------------------------------------------------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"output_type":"stream","name":"stdout","text":["2022-02-16 19:21:38,025 epoch 36 - iter 1/15 - loss 0.42812458 - samples/sec: 113.38 - lr: 0.012500\n","2022-02-16 19:21:38,130 epoch 36 - iter 2/15 - loss 0.46615310 - samples/sec: 402.30 - lr: 0.012500\n","2022-02-16 19:21:38,230 epoch 36 - iter 3/15 - loss 0.45198455 - samples/sec: 418.01 - lr: 0.012500\n","2022-02-16 19:21:38,309 epoch 36 - iter 4/15 - loss 0.43879031 - samples/sec: 426.82 - lr: 0.012500\n","2022-02-16 19:21:38,385 epoch 36 - iter 5/15 - loss 0.42236207 - samples/sec: 444.99 - lr: 0.012500\n","2022-02-16 19:21:38,476 epoch 36 - iter 6/15 - loss 0.42572619 - samples/sec: 480.66 - lr: 0.012500\n","2022-02-16 19:21:38,559 epoch 36 - iter 7/15 - loss 0.41131543 - samples/sec: 415.74 - lr: 0.012500\n","2022-02-16 19:21:38,634 epoch 36 - iter 8/15 - loss 0.41665742 - samples/sec: 490.95 - lr: 0.012500\n","2022-02-16 19:21:38,718 epoch 36 - iter 9/15 - loss 0.41116729 - samples/sec: 491.71 - lr: 0.012500\n","2022-02-16 19:21:38,805 epoch 36 - iter 10/15 - loss 0.39637526 - samples/sec: 440.65 - lr: 0.012500\n","2022-02-16 19:21:38,877 epoch 36 - iter 11/15 - loss 0.39721375 - samples/sec: 458.52 - lr: 0.012500\n","2022-02-16 19:21:38,948 epoch 36 - iter 12/15 - loss 0.39089731 - samples/sec: 459.59 - lr: 0.012500\n","2022-02-16 19:21:39,033 epoch 36 - iter 13/15 - loss 0.40134834 - samples/sec: 387.31 - lr: 0.012500\n","2022-02-16 19:21:39,106 epoch 36 - iter 14/15 - loss 0.39662842 - samples/sec: 451.99 - lr: 0.012500\n","2022-02-16 19:21:39,157 epoch 36 - iter 15/15 - loss 0.38563047 - samples/sec: 721.64 - lr: 0.012500\n","2022-02-16 19:21:39,634 ----------------------------------------------------------------------------------------------------\n","2022-02-16 19:21:39,636 EPOCH 36 done: loss 0.3856 - lr 0.0125000\n","2022-02-16 19:21:41,238 DEV : loss 0.8678994178771973 - score 0.6471\n","2022-02-16 19:21:41,298 BAD EPOCHS (no improvement): 3\n","2022-02-16 19:21:41,307 ----------------------------------------------------------------------------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"output_type":"stream","name":"stdout","text":["2022-02-16 19:21:42,440 epoch 37 - iter 1/15 - loss 0.34506270 - samples/sec: 154.42 - lr: 0.012500\n","2022-02-16 19:21:42,529 epoch 37 - iter 2/15 - loss 0.42778872 - samples/sec: 430.64 - lr: 0.012500\n","2022-02-16 19:21:42,628 epoch 37 - iter 3/15 - loss 0.42861363 - samples/sec: 441.62 - lr: 0.012500\n","2022-02-16 19:21:42,709 epoch 37 - iter 4/15 - loss 0.44731247 - samples/sec: 411.04 - lr: 0.012500\n","2022-02-16 19:21:42,789 epoch 37 - iter 5/15 - loss 0.41337720 - samples/sec: 484.79 - lr: 0.012500\n","2022-02-16 19:21:42,875 epoch 37 - iter 6/15 - loss 0.38199551 - samples/sec: 493.36 - lr: 0.012500\n","2022-02-16 19:21:42,948 epoch 37 - iter 7/15 - loss 0.38198223 - samples/sec: 454.71 - lr: 0.012500\n","2022-02-16 19:21:43,018 epoch 37 - iter 8/15 - loss 0.38453771 - samples/sec: 486.81 - lr: 0.012500\n","2022-02-16 19:21:43,097 epoch 37 - iter 9/15 - loss 0.38060845 - samples/sec: 496.56 - lr: 0.012500\n","2022-02-16 19:21:43,168 epoch 37 - iter 10/15 - loss 0.39196518 - samples/sec: 471.31 - lr: 0.012500\n","2022-02-16 19:21:43,259 epoch 37 - iter 11/15 - loss 0.39339321 - samples/sec: 390.94 - lr: 0.012500\n","2022-02-16 19:21:43,348 epoch 37 - iter 12/15 - loss 0.38672338 - samples/sec: 452.61 - lr: 0.012500\n","2022-02-16 19:21:43,418 epoch 37 - iter 13/15 - loss 0.39807475 - samples/sec: 487.58 - lr: 0.012500\n","2022-02-16 19:21:43,495 epoch 37 - iter 14/15 - loss 0.39387894 - samples/sec: 462.13 - lr: 0.012500\n","2022-02-16 19:21:43,538 epoch 37 - iter 15/15 - loss 0.38720226 - samples/sec: 865.44 - lr: 0.012500\n","2022-02-16 19:21:44,010 ----------------------------------------------------------------------------------------------------\n","2022-02-16 19:21:44,012 EPOCH 37 done: loss 0.3872 - lr 0.0125000\n","2022-02-16 19:21:45,525 DEV : loss 0.8789794445037842 - score 0.6275\n","Epoch    37: reducing learning rate of group 0 to 6.2500e-03.\n","2022-02-16 19:21:45,592 BAD EPOCHS (no improvement): 4\n","2022-02-16 19:21:45,599 ----------------------------------------------------------------------------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"output_type":"stream","name":"stdout","text":["2022-02-16 19:21:46,728 epoch 38 - iter 1/15 - loss 0.42581108 - samples/sec: 146.61 - lr: 0.006250\n","2022-02-16 19:21:46,837 epoch 38 - iter 2/15 - loss 0.57710053 - samples/sec: 351.45 - lr: 0.006250\n","2022-02-16 19:21:46,923 epoch 38 - iter 3/15 - loss 0.52072508 - samples/sec: 421.79 - lr: 0.006250\n","2022-02-16 19:21:47,024 epoch 38 - iter 4/15 - loss 0.56614608 - samples/sec: 467.06 - lr: 0.006250\n","2022-02-16 19:21:47,103 epoch 38 - iter 5/15 - loss 0.52481933 - samples/sec: 420.40 - lr: 0.006250\n","2022-02-16 19:21:47,190 epoch 38 - iter 6/15 - loss 0.48691401 - samples/sec: 517.17 - lr: 0.006250\n","2022-02-16 19:21:47,263 epoch 38 - iter 7/15 - loss 0.46997283 - samples/sec: 472.71 - lr: 0.006250\n","2022-02-16 19:21:47,341 epoch 38 - iter 8/15 - loss 0.44010752 - samples/sec: 446.88 - lr: 0.006250\n","2022-02-16 19:21:47,415 epoch 38 - iter 9/15 - loss 0.44627863 - samples/sec: 449.60 - lr: 0.006250\n","2022-02-16 19:21:47,497 epoch 38 - iter 10/15 - loss 0.43393003 - samples/sec: 409.58 - lr: 0.006250\n","2022-02-16 19:21:47,567 epoch 38 - iter 11/15 - loss 0.44443699 - samples/sec: 499.49 - lr: 0.006250\n","2022-02-16 19:21:47,641 epoch 38 - iter 12/15 - loss 0.42531219 - samples/sec: 464.48 - lr: 0.006250\n","2022-02-16 19:21:47,717 epoch 38 - iter 13/15 - loss 0.41848998 - samples/sec: 438.56 - lr: 0.006250\n","2022-02-16 19:21:47,796 epoch 38 - iter 14/15 - loss 0.39800448 - samples/sec: 492.05 - lr: 0.006250\n","2022-02-16 19:21:47,839 epoch 38 - iter 15/15 - loss 0.38767373 - samples/sec: 794.21 - lr: 0.006250\n","2022-02-16 19:21:48,305 ----------------------------------------------------------------------------------------------------\n","2022-02-16 19:21:48,312 EPOCH 38 done: loss 0.3877 - lr 0.0062500\n","2022-02-16 19:21:51,412 DEV : loss 0.8594459891319275 - score 0.6471\n","2022-02-16 19:21:51,474 BAD EPOCHS (no improvement): 1\n","2022-02-16 19:21:51,484 ----------------------------------------------------------------------------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"output_type":"stream","name":"stdout","text":["2022-02-16 19:21:52,619 epoch 39 - iter 1/15 - loss 0.51487100 - samples/sec: 114.72 - lr: 0.006250\n","2022-02-16 19:21:52,744 epoch 39 - iter 2/15 - loss 0.53370506 - samples/sec: 352.38 - lr: 0.006250\n","2022-02-16 19:21:52,858 epoch 39 - iter 3/15 - loss 0.48409564 - samples/sec: 404.43 - lr: 0.006250\n","2022-02-16 19:21:52,949 epoch 39 - iter 4/15 - loss 0.50172428 - samples/sec: 455.29 - lr: 0.006250\n","2022-02-16 19:21:53,030 epoch 39 - iter 5/15 - loss 0.52226135 - samples/sec: 411.32 - lr: 0.006250\n","2022-02-16 19:21:53,100 epoch 39 - iter 6/15 - loss 0.49171937 - samples/sec: 489.30 - lr: 0.006250\n","2022-02-16 19:21:53,177 epoch 39 - iter 7/15 - loss 0.47289338 - samples/sec: 459.34 - lr: 0.006250\n","2022-02-16 19:21:53,257 epoch 39 - iter 8/15 - loss 0.45274274 - samples/sec: 417.62 - lr: 0.006250\n","2022-02-16 19:21:53,337 epoch 39 - iter 9/15 - loss 0.42826588 - samples/sec: 435.12 - lr: 0.006250\n","2022-02-16 19:21:53,427 epoch 39 - iter 10/15 - loss 0.41140392 - samples/sec: 437.08 - lr: 0.006250\n","2022-02-16 19:21:53,502 epoch 39 - iter 11/15 - loss 0.40049469 - samples/sec: 446.22 - lr: 0.006250\n","2022-02-16 19:21:53,578 epoch 39 - iter 12/15 - loss 0.41054126 - samples/sec: 477.69 - lr: 0.006250\n","2022-02-16 19:21:53,652 epoch 39 - iter 13/15 - loss 0.40522581 - samples/sec: 463.05 - lr: 0.006250\n","2022-02-16 19:21:53,725 epoch 39 - iter 14/15 - loss 0.40890713 - samples/sec: 455.15 - lr: 0.006250\n","2022-02-16 19:21:53,773 epoch 39 - iter 15/15 - loss 0.40689335 - samples/sec: 724.72 - lr: 0.006250\n","2022-02-16 19:21:54,247 ----------------------------------------------------------------------------------------------------\n","2022-02-16 19:21:54,249 EPOCH 39 done: loss 0.4069 - lr 0.0062500\n","2022-02-16 19:21:55,765 DEV : loss 0.8673889636993408 - score 0.6471\n","2022-02-16 19:21:55,825 BAD EPOCHS (no improvement): 2\n","2022-02-16 19:21:55,834 ----------------------------------------------------------------------------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"output_type":"stream","name":"stdout","text":["2022-02-16 19:21:56,988 epoch 40 - iter 1/15 - loss 0.38951084 - samples/sec: 117.95 - lr: 0.006250\n","2022-02-16 19:21:57,093 epoch 40 - iter 2/15 - loss 0.39238721 - samples/sec: 401.31 - lr: 0.006250\n","2022-02-16 19:21:57,188 epoch 40 - iter 3/15 - loss 0.32785386 - samples/sec: 416.05 - lr: 0.006250\n","2022-02-16 19:21:57,278 epoch 40 - iter 4/15 - loss 0.35104128 - samples/sec: 374.42 - lr: 0.006250\n","2022-02-16 19:21:57,352 epoch 40 - iter 5/15 - loss 0.38931166 - samples/sec: 444.79 - lr: 0.006250\n","2022-02-16 19:21:57,425 epoch 40 - iter 6/15 - loss 0.40172876 - samples/sec: 485.42 - lr: 0.006250\n","2022-02-16 19:21:57,511 epoch 40 - iter 7/15 - loss 0.40678089 - samples/sec: 397.86 - lr: 0.006250\n","2022-02-16 19:21:57,598 epoch 40 - iter 8/15 - loss 0.40017387 - samples/sec: 487.11 - lr: 0.006250\n","2022-02-16 19:21:57,682 epoch 40 - iter 9/15 - loss 0.41474545 - samples/sec: 458.46 - lr: 0.006250\n","2022-02-16 19:21:57,768 epoch 40 - iter 10/15 - loss 0.41935203 - samples/sec: 442.52 - lr: 0.006250\n","2022-02-16 19:21:57,837 epoch 40 - iter 11/15 - loss 0.40346414 - samples/sec: 482.45 - lr: 0.006250\n","2022-02-16 19:21:57,912 epoch 40 - iter 12/15 - loss 0.39051441 - samples/sec: 434.96 - lr: 0.006250\n","2022-02-16 19:21:57,982 epoch 40 - iter 13/15 - loss 0.39431835 - samples/sec: 467.93 - lr: 0.006250\n","2022-02-16 19:21:58,055 epoch 40 - iter 14/15 - loss 0.38856180 - samples/sec: 455.20 - lr: 0.006250\n","2022-02-16 19:21:58,102 epoch 40 - iter 15/15 - loss 0.37660891 - samples/sec: 764.49 - lr: 0.006250\n","2022-02-16 19:21:58,577 ----------------------------------------------------------------------------------------------------\n","2022-02-16 19:21:58,579 EPOCH 40 done: loss 0.3766 - lr 0.0062500\n","2022-02-16 19:22:00,098 DEV : loss 0.8388673067092896 - score 0.6471\n","2022-02-16 19:22:00,158 BAD EPOCHS (no improvement): 3\n","2022-02-16 19:22:00,167 ----------------------------------------------------------------------------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"output_type":"stream","name":"stdout","text":["2022-02-16 19:22:01,346 epoch 41 - iter 1/15 - loss 0.20444553 - samples/sec: 201.88 - lr: 0.006250\n","2022-02-16 19:22:01,441 epoch 41 - iter 2/15 - loss 0.24488077 - samples/sec: 381.63 - lr: 0.006250\n","2022-02-16 19:22:01,536 epoch 41 - iter 3/15 - loss 0.33286711 - samples/sec: 417.90 - lr: 0.006250\n","2022-02-16 19:22:01,615 epoch 41 - iter 4/15 - loss 0.33649018 - samples/sec: 437.19 - lr: 0.006250\n","2022-02-16 19:22:01,697 epoch 41 - iter 5/15 - loss 0.32789758 - samples/sec: 404.54 - lr: 0.006250\n","2022-02-16 19:22:01,797 epoch 41 - iter 6/15 - loss 0.31537053 - samples/sec: 457.50 - lr: 0.006250\n","2022-02-16 19:22:01,876 epoch 41 - iter 7/15 - loss 0.32708880 - samples/sec: 440.36 - lr: 0.006250\n","2022-02-16 19:22:01,961 epoch 41 - iter 8/15 - loss 0.34150905 - samples/sec: 516.73 - lr: 0.006250\n","2022-02-16 19:22:02,033 epoch 41 - iter 9/15 - loss 0.35093921 - samples/sec: 464.52 - lr: 0.006250\n","2022-02-16 19:22:02,106 epoch 41 - iter 10/15 - loss 0.35076129 - samples/sec: 475.58 - lr: 0.006250\n","2022-02-16 19:22:02,178 epoch 41 - iter 11/15 - loss 0.35382343 - samples/sec: 461.35 - lr: 0.006250\n","2022-02-16 19:22:02,258 epoch 41 - iter 12/15 - loss 0.35613523 - samples/sec: 420.79 - lr: 0.006250\n","2022-02-16 19:22:02,333 epoch 41 - iter 13/15 - loss 0.35588595 - samples/sec: 436.25 - lr: 0.006250\n","2022-02-16 19:22:02,413 epoch 41 - iter 14/15 - loss 0.37424198 - samples/sec: 464.45 - lr: 0.006250\n","2022-02-16 19:22:02,469 epoch 41 - iter 15/15 - loss 0.37794160 - samples/sec: 648.03 - lr: 0.006250\n","2022-02-16 19:22:03,051 ----------------------------------------------------------------------------------------------------\n","2022-02-16 19:22:03,056 EPOCH 41 done: loss 0.3779 - lr 0.0062500\n","2022-02-16 19:22:04,616 DEV : loss 0.847277045249939 - score 0.6863\n","Epoch    41: reducing learning rate of group 0 to 3.1250e-03.\n","2022-02-16 19:22:04,686 BAD EPOCHS (no improvement): 4\n","2022-02-16 19:22:04,698 ----------------------------------------------------------------------------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"output_type":"stream","name":"stdout","text":["2022-02-16 19:22:05,896 epoch 42 - iter 1/15 - loss 0.46286729 - samples/sec: 187.30 - lr: 0.003125\n","2022-02-16 19:22:05,983 epoch 42 - iter 2/15 - loss 0.43187107 - samples/sec: 401.81 - lr: 0.003125\n","2022-02-16 19:22:06,068 epoch 42 - iter 3/15 - loss 0.41339385 - samples/sec: 401.36 - lr: 0.003125\n","2022-02-16 19:22:06,157 epoch 42 - iter 4/15 - loss 0.42466261 - samples/sec: 446.20 - lr: 0.003125\n","2022-02-16 19:22:06,229 epoch 42 - iter 5/15 - loss 0.43041041 - samples/sec: 468.28 - lr: 0.003125\n","2022-02-16 19:22:06,328 epoch 42 - iter 6/15 - loss 0.46768712 - samples/sec: 456.32 - lr: 0.003125\n","2022-02-16 19:22:06,410 epoch 42 - iter 7/15 - loss 0.45370070 - samples/sec: 400.54 - lr: 0.003125\n","2022-02-16 19:22:06,494 epoch 42 - iter 8/15 - loss 0.42987067 - samples/sec: 464.51 - lr: 0.003125\n","2022-02-16 19:22:06,573 epoch 42 - iter 9/15 - loss 0.41598789 - samples/sec: 437.39 - lr: 0.003125\n","2022-02-16 19:22:06,664 epoch 42 - iter 10/15 - loss 0.40091602 - samples/sec: 460.43 - lr: 0.003125\n","2022-02-16 19:22:06,741 epoch 42 - iter 11/15 - loss 0.38742160 - samples/sec: 439.95 - lr: 0.003125\n","2022-02-16 19:22:06,818 epoch 42 - iter 12/15 - loss 0.39631605 - samples/sec: 433.06 - lr: 0.003125\n","2022-02-16 19:22:06,922 epoch 42 - iter 13/15 - loss 0.39897743 - samples/sec: 316.08 - lr: 0.003125\n","2022-02-16 19:22:07,028 epoch 42 - iter 14/15 - loss 0.40077519 - samples/sec: 439.93 - lr: 0.003125\n","2022-02-16 19:22:07,079 epoch 42 - iter 15/15 - loss 0.41270409 - samples/sec: 673.89 - lr: 0.003125\n","2022-02-16 19:22:07,554 ----------------------------------------------------------------------------------------------------\n","2022-02-16 19:22:07,556 EPOCH 42 done: loss 0.4127 - lr 0.0031250\n","2022-02-16 19:22:09,055 DEV : loss 0.8482921719551086 - score 0.6471\n","2022-02-16 19:22:09,131 BAD EPOCHS (no improvement): 1\n","2022-02-16 19:22:09,141 ----------------------------------------------------------------------------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"output_type":"stream","name":"stdout","text":["2022-02-16 19:22:10,336 epoch 43 - iter 1/15 - loss 0.24405922 - samples/sec: 134.90 - lr: 0.003125\n","2022-02-16 19:22:10,434 epoch 43 - iter 2/15 - loss 0.24728317 - samples/sec: 400.72 - lr: 0.003125\n","2022-02-16 19:22:10,548 epoch 43 - iter 3/15 - loss 0.32178819 - samples/sec: 368.39 - lr: 0.003125\n","2022-02-16 19:22:10,640 epoch 43 - iter 4/15 - loss 0.33765015 - samples/sec: 373.32 - lr: 0.003125\n","2022-02-16 19:22:10,716 epoch 43 - iter 5/15 - loss 0.34162066 - samples/sec: 439.31 - lr: 0.003125\n","2022-02-16 19:22:10,806 epoch 43 - iter 6/15 - loss 0.34013296 - samples/sec: 462.30 - lr: 0.003125\n","2022-02-16 19:22:10,887 epoch 43 - iter 7/15 - loss 0.35076148 - samples/sec: 408.35 - lr: 0.003125\n","2022-02-16 19:22:10,959 epoch 43 - iter 8/15 - loss 0.35242363 - samples/sec: 470.69 - lr: 0.003125\n","2022-02-16 19:22:11,040 epoch 43 - iter 9/15 - loss 0.37937781 - samples/sec: 535.93 - lr: 0.003125\n","2022-02-16 19:22:11,117 epoch 43 - iter 10/15 - loss 0.36993582 - samples/sec: 426.52 - lr: 0.003125\n","2022-02-16 19:22:11,196 epoch 43 - iter 11/15 - loss 0.34957181 - samples/sec: 417.37 - lr: 0.003125\n","2022-02-16 19:22:11,284 epoch 43 - iter 12/15 - loss 0.35583039 - samples/sec: 493.41 - lr: 0.003125\n","2022-02-16 19:22:11,368 epoch 43 - iter 13/15 - loss 0.35985803 - samples/sec: 389.20 - lr: 0.003125\n","2022-02-16 19:22:11,441 epoch 43 - iter 14/15 - loss 0.36755414 - samples/sec: 455.89 - lr: 0.003125\n","2022-02-16 19:22:11,491 epoch 43 - iter 15/15 - loss 0.37081299 - samples/sec: 704.36 - lr: 0.003125\n","2022-02-16 19:22:11,960 ----------------------------------------------------------------------------------------------------\n","2022-02-16 19:22:11,962 EPOCH 43 done: loss 0.3708 - lr 0.0031250\n","2022-02-16 19:22:13,516 DEV : loss 0.8473740816116333 - score 0.6471\n","2022-02-16 19:22:13,579 BAD EPOCHS (no improvement): 2\n","2022-02-16 19:22:13,589 ----------------------------------------------------------------------------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"output_type":"stream","name":"stdout","text":["2022-02-16 19:22:14,795 epoch 44 - iter 1/15 - loss 0.19185300 - samples/sec: 170.74 - lr: 0.003125\n","2022-02-16 19:22:14,886 epoch 44 - iter 2/15 - loss 0.31082847 - samples/sec: 404.89 - lr: 0.003125\n","2022-02-16 19:22:14,969 epoch 44 - iter 3/15 - loss 0.31465768 - samples/sec: 409.78 - lr: 0.003125\n","2022-02-16 19:22:15,062 epoch 44 - iter 4/15 - loss 0.31147274 - samples/sec: 427.39 - lr: 0.003125\n","2022-02-16 19:22:15,143 epoch 44 - iter 5/15 - loss 0.33796237 - samples/sec: 452.87 - lr: 0.003125\n","2022-02-16 19:22:15,235 epoch 44 - iter 6/15 - loss 0.33828792 - samples/sec: 489.63 - lr: 0.003125\n","2022-02-16 19:22:15,319 epoch 44 - iter 7/15 - loss 0.34141039 - samples/sec: 407.16 - lr: 0.003125\n","2022-02-16 19:22:15,415 epoch 44 - iter 8/15 - loss 0.32690732 - samples/sec: 400.55 - lr: 0.003125\n","2022-02-16 19:22:15,496 epoch 44 - iter 9/15 - loss 0.32903711 - samples/sec: 407.64 - lr: 0.003125\n","2022-02-16 19:22:15,590 epoch 44 - iter 10/15 - loss 0.32966315 - samples/sec: 363.03 - lr: 0.003125\n","2022-02-16 19:22:15,662 epoch 44 - iter 11/15 - loss 0.32513465 - samples/sec: 454.71 - lr: 0.003125\n","2022-02-16 19:22:15,741 epoch 44 - iter 12/15 - loss 0.33114422 - samples/sec: 507.43 - lr: 0.003125\n","2022-02-16 19:22:15,821 epoch 44 - iter 13/15 - loss 0.33279187 - samples/sec: 434.43 - lr: 0.003125\n","2022-02-16 19:22:15,900 epoch 44 - iter 14/15 - loss 0.35059968 - samples/sec: 517.19 - lr: 0.003125\n","2022-02-16 19:22:15,946 epoch 44 - iter 15/15 - loss 0.34966169 - samples/sec: 742.65 - lr: 0.003125\n","2022-02-16 19:22:16,433 ----------------------------------------------------------------------------------------------------\n","2022-02-16 19:22:16,436 EPOCH 44 done: loss 0.3497 - lr 0.0031250\n","2022-02-16 19:22:17,934 DEV : loss 0.8586649894714355 - score 0.6471\n","2022-02-16 19:22:17,999 BAD EPOCHS (no improvement): 3\n","2022-02-16 19:22:18,009 ----------------------------------------------------------------------------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"output_type":"stream","name":"stdout","text":["2022-02-16 19:22:19,193 epoch 45 - iter 1/15 - loss 0.29423437 - samples/sec: 124.37 - lr: 0.003125\n","2022-02-16 19:22:19,329 epoch 45 - iter 2/15 - loss 0.36172929 - samples/sec: 392.25 - lr: 0.003125\n","2022-02-16 19:22:19,424 epoch 45 - iter 3/15 - loss 0.36978698 - samples/sec: 382.12 - lr: 0.003125\n","2022-02-16 19:22:19,507 epoch 45 - iter 4/15 - loss 0.35668334 - samples/sec: 418.64 - lr: 0.003125\n","2022-02-16 19:22:19,586 epoch 45 - iter 5/15 - loss 0.33906587 - samples/sec: 419.94 - lr: 0.003125\n","2022-02-16 19:22:19,660 epoch 45 - iter 6/15 - loss 0.33717548 - samples/sec: 447.51 - lr: 0.003125\n","2022-02-16 19:22:19,746 epoch 45 - iter 7/15 - loss 0.33320925 - samples/sec: 389.47 - lr: 0.003125\n","2022-02-16 19:22:19,840 epoch 45 - iter 8/15 - loss 0.34181400 - samples/sec: 463.58 - lr: 0.003125\n","2022-02-16 19:22:19,920 epoch 45 - iter 9/15 - loss 0.34727410 - samples/sec: 409.09 - lr: 0.003125\n","2022-02-16 19:22:19,995 epoch 45 - iter 10/15 - loss 0.34937390 - samples/sec: 464.84 - lr: 0.003125\n","2022-02-16 19:22:20,068 epoch 45 - iter 11/15 - loss 0.34189186 - samples/sec: 451.60 - lr: 0.003125\n","2022-02-16 19:22:20,147 epoch 45 - iter 12/15 - loss 0.34383759 - samples/sec: 490.68 - lr: 0.003125\n","2022-02-16 19:22:20,220 epoch 45 - iter 13/15 - loss 0.34823555 - samples/sec: 468.55 - lr: 0.003125\n","2022-02-16 19:22:20,313 epoch 45 - iter 14/15 - loss 0.34968684 - samples/sec: 401.06 - lr: 0.003125\n","2022-02-16 19:22:20,364 epoch 45 - iter 15/15 - loss 0.36128097 - samples/sec: 655.55 - lr: 0.003125\n","2022-02-16 19:22:20,855 ----------------------------------------------------------------------------------------------------\n","2022-02-16 19:22:20,865 EPOCH 45 done: loss 0.3613 - lr 0.0031250\n","2022-02-16 19:22:22,409 DEV : loss 0.8447970747947693 - score 0.6471\n","Epoch    45: reducing learning rate of group 0 to 1.5625e-03.\n","2022-02-16 19:22:22,472 BAD EPOCHS (no improvement): 4\n","2022-02-16 19:22:22,480 ----------------------------------------------------------------------------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"output_type":"stream","name":"stdout","text":["2022-02-16 19:22:23,662 epoch 46 - iter 1/15 - loss 0.33045805 - samples/sec: 134.42 - lr: 0.001563\n","2022-02-16 19:22:23,763 epoch 46 - iter 2/15 - loss 0.41488527 - samples/sec: 366.67 - lr: 0.001563\n","2022-02-16 19:22:23,847 epoch 46 - iter 3/15 - loss 0.39801386 - samples/sec: 448.31 - lr: 0.001563\n","2022-02-16 19:22:23,969 epoch 46 - iter 4/15 - loss 0.39422640 - samples/sec: 471.74 - lr: 0.001563\n","2022-02-16 19:22:24,040 epoch 46 - iter 5/15 - loss 0.39272526 - samples/sec: 465.20 - lr: 0.001563\n","2022-02-16 19:22:24,115 epoch 46 - iter 6/15 - loss 0.40743054 - samples/sec: 438.81 - lr: 0.001563\n","2022-02-16 19:22:24,207 epoch 46 - iter 7/15 - loss 0.40697939 - samples/sec: 422.06 - lr: 0.001563\n","2022-02-16 19:22:24,277 epoch 46 - iter 8/15 - loss 0.40198764 - samples/sec: 478.13 - lr: 0.001563\n","2022-02-16 19:22:24,354 epoch 46 - iter 9/15 - loss 0.41151738 - samples/sec: 424.41 - lr: 0.001563\n","2022-02-16 19:22:24,435 epoch 46 - iter 10/15 - loss 0.41188747 - samples/sec: 462.45 - lr: 0.001563\n","2022-02-16 19:22:24,512 epoch 46 - iter 11/15 - loss 0.39768995 - samples/sec: 435.23 - lr: 0.001563\n","2022-02-16 19:22:24,583 epoch 46 - iter 12/15 - loss 0.40514859 - samples/sec: 465.80 - lr: 0.001563\n","2022-02-16 19:22:24,664 epoch 46 - iter 13/15 - loss 0.40538454 - samples/sec: 451.47 - lr: 0.001563\n","2022-02-16 19:22:24,741 epoch 46 - iter 14/15 - loss 0.39741342 - samples/sec: 430.23 - lr: 0.001563\n","2022-02-16 19:22:24,788 epoch 46 - iter 15/15 - loss 0.38690008 - samples/sec: 760.64 - lr: 0.001563\n","2022-02-16 19:22:25,315 ----------------------------------------------------------------------------------------------------\n","2022-02-16 19:22:25,317 EPOCH 46 done: loss 0.3869 - lr 0.0015625\n","2022-02-16 19:22:26,858 DEV : loss 0.8434184789657593 - score 0.6471\n","2022-02-16 19:22:26,924 BAD EPOCHS (no improvement): 1\n","2022-02-16 19:22:26,932 ----------------------------------------------------------------------------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"output_type":"stream","name":"stdout","text":["2022-02-16 19:22:28,117 epoch 47 - iter 1/15 - loss 0.34432945 - samples/sec: 170.65 - lr: 0.001563\n","2022-02-16 19:22:28,229 epoch 47 - iter 2/15 - loss 0.28380121 - samples/sec: 346.89 - lr: 0.001563\n","2022-02-16 19:22:28,315 epoch 47 - iter 3/15 - loss 0.36113819 - samples/sec: 442.56 - lr: 0.001563\n","2022-02-16 19:22:28,408 epoch 47 - iter 4/15 - loss 0.35503184 - samples/sec: 400.16 - lr: 0.001563\n","2022-02-16 19:22:28,481 epoch 47 - iter 5/15 - loss 0.39123086 - samples/sec: 451.22 - lr: 0.001563\n","2022-02-16 19:22:28,580 epoch 47 - iter 6/15 - loss 0.42173079 - samples/sec: 465.86 - lr: 0.001563\n","2022-02-16 19:22:28,654 epoch 47 - iter 7/15 - loss 0.40707601 - samples/sec: 452.28 - lr: 0.001563\n","2022-02-16 19:22:28,730 epoch 47 - iter 8/15 - loss 0.39185464 - samples/sec: 454.09 - lr: 0.001563\n","2022-02-16 19:22:28,806 epoch 47 - iter 9/15 - loss 0.40377025 - samples/sec: 501.89 - lr: 0.001563\n","2022-02-16 19:22:28,887 epoch 47 - iter 10/15 - loss 0.38886229 - samples/sec: 451.45 - lr: 0.001563\n","2022-02-16 19:22:28,967 epoch 47 - iter 11/15 - loss 0.38597846 - samples/sec: 426.11 - lr: 0.001563\n","2022-02-16 19:22:30,584 epoch 47 - iter 12/15 - loss 0.36960483 - samples/sec: 448.76 - lr: 0.001563\n","2022-02-16 19:22:30,655 epoch 47 - iter 13/15 - loss 0.36786222 - samples/sec: 493.53 - lr: 0.001563\n","2022-02-16 19:22:30,728 epoch 47 - iter 14/15 - loss 0.36968752 - samples/sec: 458.71 - lr: 0.001563\n","2022-02-16 19:22:30,776 epoch 47 - iter 15/15 - loss 0.37671930 - samples/sec: 804.74 - lr: 0.001563\n","2022-02-16 19:22:31,292 ----------------------------------------------------------------------------------------------------\n","2022-02-16 19:22:31,294 EPOCH 47 done: loss 0.3767 - lr 0.0015625\n","2022-02-16 19:22:32,874 DEV : loss 0.8451111316680908 - score 0.6667\n","2022-02-16 19:22:32,934 BAD EPOCHS (no improvement): 2\n","2022-02-16 19:22:32,942 ----------------------------------------------------------------------------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"output_type":"stream","name":"stdout","text":["2022-02-16 19:22:34,134 epoch 48 - iter 1/15 - loss 0.31558922 - samples/sec: 130.68 - lr: 0.001563\n","2022-02-16 19:22:34,273 epoch 48 - iter 2/15 - loss 0.30599879 - samples/sec: 340.54 - lr: 0.001563\n","2022-02-16 19:22:34,368 epoch 48 - iter 3/15 - loss 0.31017066 - samples/sec: 350.91 - lr: 0.001563\n","2022-02-16 19:22:34,455 epoch 48 - iter 4/15 - loss 0.33141713 - samples/sec: 379.08 - lr: 0.001563\n","2022-02-16 19:22:34,546 epoch 48 - iter 5/15 - loss 0.31744506 - samples/sec: 358.25 - lr: 0.001563\n","2022-02-16 19:22:34,617 epoch 48 - iter 6/15 - loss 0.31097230 - samples/sec: 471.88 - lr: 0.001563\n","2022-02-16 19:22:34,701 epoch 48 - iter 7/15 - loss 0.30743911 - samples/sec: 389.92 - lr: 0.001563\n","2022-02-16 19:22:34,777 epoch 48 - iter 8/15 - loss 0.31361585 - samples/sec: 459.14 - lr: 0.001563\n","2022-02-16 19:22:34,865 epoch 48 - iter 9/15 - loss 0.30944395 - samples/sec: 468.74 - lr: 0.001563\n","2022-02-16 19:22:34,940 epoch 48 - iter 10/15 - loss 0.32694397 - samples/sec: 439.80 - lr: 0.001563\n","2022-02-16 19:22:35,009 epoch 48 - iter 11/15 - loss 0.34197393 - samples/sec: 485.86 - lr: 0.001563\n","2022-02-16 19:22:35,086 epoch 48 - iter 12/15 - loss 0.33920669 - samples/sec: 428.57 - lr: 0.001563\n","2022-02-16 19:22:35,162 epoch 48 - iter 13/15 - loss 0.35735023 - samples/sec: 431.55 - lr: 0.001563\n","2022-02-16 19:22:35,244 epoch 48 - iter 14/15 - loss 0.36016138 - samples/sec: 465.44 - lr: 0.001563\n","2022-02-16 19:22:35,297 epoch 48 - iter 15/15 - loss 0.37243017 - samples/sec: 688.72 - lr: 0.001563\n","2022-02-16 19:22:35,793 ----------------------------------------------------------------------------------------------------\n","2022-02-16 19:22:35,800 EPOCH 48 done: loss 0.3724 - lr 0.0015625\n","2022-02-16 19:22:37,340 DEV : loss 0.8468157649040222 - score 0.6471\n","2022-02-16 19:22:37,401 BAD EPOCHS (no improvement): 3\n","2022-02-16 19:22:37,407 ----------------------------------------------------------------------------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"output_type":"stream","name":"stdout","text":["2022-02-16 19:22:38,607 epoch 49 - iter 1/15 - loss 0.26766816 - samples/sec: 109.99 - lr: 0.001563\n","2022-02-16 19:22:38,772 epoch 49 - iter 2/15 - loss 0.32969475 - samples/sec: 314.15 - lr: 0.001563\n","2022-02-16 19:22:38,867 epoch 49 - iter 3/15 - loss 0.36929202 - samples/sec: 351.61 - lr: 0.001563\n","2022-02-16 19:22:38,946 epoch 49 - iter 4/15 - loss 0.33245981 - samples/sec: 418.10 - lr: 0.001563\n","2022-02-16 19:22:39,025 epoch 49 - iter 5/15 - loss 0.36858276 - samples/sec: 417.04 - lr: 0.001563\n","2022-02-16 19:22:39,108 epoch 49 - iter 6/15 - loss 0.35158875 - samples/sec: 393.68 - lr: 0.001563\n","2022-02-16 19:22:39,189 epoch 49 - iter 7/15 - loss 0.36613460 - samples/sec: 409.67 - lr: 0.001563\n","2022-02-16 19:22:39,274 epoch 49 - iter 8/15 - loss 0.38784183 - samples/sec: 440.24 - lr: 0.001563\n","2022-02-16 19:22:39,353 epoch 49 - iter 9/15 - loss 0.37579744 - samples/sec: 422.77 - lr: 0.001563\n","2022-02-16 19:22:39,426 epoch 49 - iter 10/15 - loss 0.37223200 - samples/sec: 462.85 - lr: 0.001563\n","2022-02-16 19:22:39,495 epoch 49 - iter 11/15 - loss 0.37369002 - samples/sec: 479.53 - lr: 0.001563\n","2022-02-16 19:22:39,580 epoch 49 - iter 12/15 - loss 0.36213043 - samples/sec: 386.43 - lr: 0.001563\n","2022-02-16 19:22:39,659 epoch 49 - iter 13/15 - loss 0.36402394 - samples/sec: 424.11 - lr: 0.001563\n","2022-02-16 19:22:39,749 epoch 49 - iter 14/15 - loss 0.37291334 - samples/sec: 414.21 - lr: 0.001563\n","2022-02-16 19:22:39,800 epoch 49 - iter 15/15 - loss 0.36509213 - samples/sec: 715.51 - lr: 0.001563\n","2022-02-16 19:22:40,310 ----------------------------------------------------------------------------------------------------\n","2022-02-16 19:22:40,312 EPOCH 49 done: loss 0.3651 - lr 0.0015625\n","2022-02-16 19:22:41,893 DEV : loss 0.8431009650230408 - score 0.6471\n","Epoch    49: reducing learning rate of group 0 to 7.8125e-04.\n","2022-02-16 19:22:41,960 BAD EPOCHS (no improvement): 4\n","2022-02-16 19:22:41,968 ----------------------------------------------------------------------------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"output_type":"stream","name":"stdout","text":["2022-02-16 19:22:43,189 epoch 50 - iter 1/15 - loss 0.22911128 - samples/sec: 206.27 - lr: 0.000781\n","2022-02-16 19:22:43,281 epoch 50 - iter 2/15 - loss 0.35067771 - samples/sec: 366.00 - lr: 0.000781\n","2022-02-16 19:22:43,360 epoch 50 - iter 3/15 - loss 0.30616658 - samples/sec: 425.76 - lr: 0.000781\n","2022-02-16 19:22:43,445 epoch 50 - iter 4/15 - loss 0.34535388 - samples/sec: 387.43 - lr: 0.000781\n","2022-02-16 19:22:43,539 epoch 50 - iter 5/15 - loss 0.33778912 - samples/sec: 377.92 - lr: 0.000781\n","2022-02-16 19:22:43,646 epoch 50 - iter 6/15 - loss 0.35727045 - samples/sec: 446.10 - lr: 0.000781\n","2022-02-16 19:22:43,724 epoch 50 - iter 7/15 - loss 0.36893342 - samples/sec: 448.92 - lr: 0.000781\n","2022-02-16 19:22:43,796 epoch 50 - iter 8/15 - loss 0.37641493 - samples/sec: 458.42 - lr: 0.000781\n","2022-02-16 19:22:43,875 epoch 50 - iter 9/15 - loss 0.36976164 - samples/sec: 426.46 - lr: 0.000781\n","2022-02-16 19:22:43,974 epoch 50 - iter 10/15 - loss 0.36997218 - samples/sec: 405.06 - lr: 0.000781\n","2022-02-16 19:22:44,057 epoch 50 - iter 11/15 - loss 0.36368075 - samples/sec: 404.26 - lr: 0.000781\n","2022-02-16 19:22:44,139 epoch 50 - iter 12/15 - loss 0.38638835 - samples/sec: 452.29 - lr: 0.000781\n","2022-02-16 19:22:44,216 epoch 50 - iter 13/15 - loss 0.37351560 - samples/sec: 432.53 - lr: 0.000781\n","2022-02-16 19:22:44,302 epoch 50 - iter 14/15 - loss 0.37919627 - samples/sec: 380.63 - lr: 0.000781\n","2022-02-16 19:22:44,347 epoch 50 - iter 15/15 - loss 0.40529092 - samples/sec: 748.41 - lr: 0.000781\n","2022-02-16 19:22:44,823 ----------------------------------------------------------------------------------------------------\n","2022-02-16 19:22:44,828 EPOCH 50 done: loss 0.4053 - lr 0.0007813\n","2022-02-16 19:22:46,392 DEV : loss 0.8436516523361206 - score 0.6471\n","2022-02-16 19:22:46,467 BAD EPOCHS (no improvement): 1\n","2022-02-16 19:23:02,081 ----------------------------------------------------------------------------------------------------\n","2022-02-16 19:23:02,084 Testing using best model ...\n","2022-02-16 19:23:02,091 loading file ../resources/stance-semeval2016/flair_Atheism/best-model.pt\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"output_type":"stream","name":"stdout","text":["2022-02-16 19:23:16,431 \t0.7636\n","2022-02-16 19:23:16,436 \n","Results:\n","- F-score (micro) 0.7636\n","- F-score (macro) 0.589\n","- Accuracy 0.7636\n","\n","By class:\n","              precision    recall  f1-score   support\n","\n","     AGAINST     0.8324    0.9000    0.8649       160\n","       FAVOR     0.4348    0.3125    0.3636        32\n","        NONE     0.5833    0.5000    0.5385        28\n","\n","   micro avg     0.7636    0.7636    0.7636       220\n","   macro avg     0.6168    0.5708    0.5890       220\n","weighted avg     0.7428    0.7636    0.7504       220\n"," samples avg     0.7636    0.7636    0.7636       220\n","\n","2022-02-16 19:23:16,444 ----------------------------------------------------------------------------------------------------\n"]},{"output_type":"execute_result","data":{"text/plain":["{'dev_loss_history': [0.9189904928207397,\n","  0.9083842039108276,\n","  0.908475399017334,\n","  0.9007077217102051,\n","  0.904578685760498,\n","  0.8976327180862427,\n","  0.8842301368713379,\n","  0.881767749786377,\n","  0.8722084760665894,\n","  0.8539954423904419,\n","  0.8295086622238159,\n","  0.8224823474884033,\n","  0.7886144518852234,\n","  0.79549241065979,\n","  0.7993073463439941,\n","  0.7935559749603271,\n","  0.8145319223403931,\n","  0.8191440105438232,\n","  0.8586483001708984,\n","  0.8303526639938354,\n","  0.9407271146774292,\n","  0.8102520704269409,\n","  0.9107190370559692,\n","  0.8059751391410828,\n","  0.7992699146270752,\n","  0.8760359287261963,\n","  0.9433382153511047,\n","  0.9417362809181213,\n","  0.908652126789093,\n","  0.8537856340408325,\n","  0.8678196668624878,\n","  0.8803818225860596,\n","  0.8539297580718994,\n","  0.8605692982673645,\n","  0.8843567371368408,\n","  0.8678994178771973,\n","  0.8789794445037842,\n","  0.8594459891319275,\n","  0.8673889636993408,\n","  0.8388673067092896,\n","  0.847277045249939,\n","  0.8482921719551086,\n","  0.8473740816116333,\n","  0.8586649894714355,\n","  0.8447970747947693,\n","  0.8434184789657593,\n","  0.8451111316680908,\n","  0.8468157649040222,\n","  0.8431009650230408,\n","  0.8436516523361206],\n"," 'dev_score_history': [0.5882,\n","  0.5882,\n","  0.5882,\n","  0.5882,\n","  0.5882,\n","  0.5882,\n","  0.5882,\n","  0.5882,\n","  0.6078,\n","  0.6078,\n","  0.6078,\n","  0.6078,\n","  0.6275,\n","  0.6078,\n","  0.6078,\n","  0.6078,\n","  0.6275,\n","  0.6275,\n","  0.5882,\n","  0.6471,\n","  0.5294,\n","  0.6471,\n","  0.6078,\n","  0.6275,\n","  0.6863,\n","  0.5882,\n","  0.6667,\n","  0.6667,\n","  0.6667,\n","  0.6275,\n","  0.6471,\n","  0.6078,\n","  0.6471,\n","  0.6471,\n","  0.6471,\n","  0.6471,\n","  0.6275,\n","  0.6471,\n","  0.6471,\n","  0.6471,\n","  0.6863,\n","  0.6471,\n","  0.6471,\n","  0.6471,\n","  0.6471,\n","  0.6471,\n","  0.6667,\n","  0.6471,\n","  0.6471,\n","  0.6471],\n"," 'test_score': 0.7636,\n"," 'train_loss_history': [1.0015358328819275,\n","  0.9560184081395467,\n","  0.9474180539449056,\n","  0.9347611824671428,\n","  0.9236770749092102,\n","  0.9064441005388896,\n","  0.8961330612500509,\n","  0.8858555356661478,\n","  0.8599514921506246,\n","  0.8255858580271404,\n","  0.7734583655993144,\n","  0.7411049922307332,\n","  0.6952752888202667,\n","  0.7776029507319132,\n","  0.7030436774094899,\n","  0.6426764905452729,\n","  0.6340920627117157,\n","  0.5830999473730724,\n","  0.576633463303248,\n","  0.5294244229793549,\n","  0.5425208369890849,\n","  0.5765008886655172,\n","  0.5366246124108632,\n","  0.5572436402241389,\n","  0.5404390533765157,\n","  0.49513871868451437,\n","  0.48138755559921265,\n","  0.4689149041970571,\n","  0.5114583770434061,\n","  0.4356161534786224,\n","  0.4748719433943431,\n","  0.4149846772352854,\n","  0.4115644782781601,\n","  0.415837753812472,\n","  0.3992038547992706,\n","  0.38563047150770824,\n","  0.38720226287841797,\n","  0.3876737256844838,\n","  0.40689335266749066,\n","  0.3766089071830114,\n","  0.37794159948825834,\n","  0.4127040922641754,\n","  0.37081299324830375,\n","  0.34966169198354086,\n","  0.3612809658050537,\n","  0.3869000832239787,\n","  0.3767192999521891,\n","  0.3724301675955454,\n","  0.365092130502065,\n","  0.4052909215291341]}"]},"metadata":{},"execution_count":10}]},{"cell_type":"markdown","source":["## Climate Change is a Real Concern"],"metadata":{"id":"l9PGY5OL5EjM"}},{"cell_type":"code","source":["# 1. get the corpus\n","target = \"Climate Change is a Real Concern\"\n","corpus_folder = f\"../resources/{folder}/\"\n","corpus: Corpus = ClassificationCorpus(corpus_folder,\n","                                      train_file=f'train.{target}.txt',\n","                                      #dev_file=f'train.{target}.txt',\n","                                      test_file=f'test.{target}.txt'\n",")\n","\n","# 2. create the label dictionary\n","label_dict = corpus.make_label_dictionary()\n","                                                                                                                                                                                         \n","# 5. create the text classifier\n","classifier = TextClassifier(document_embeddings, label_dictionary=label_dict)\n","\n","# 6. initialize the text classifier trainer\n","trainer = ModelTrainer(classifier, corpus)\n","\n","# 7. start the training\n","trainer.train(f\"../resources/{folder}/flair_{target}\",\n","              train_with_dev=False,\n","              max_epochs=50)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mQfMtDP65EjO","executionInfo":{"status":"ok","timestamp":1645039863334,"user_tz":-60,"elapsed":467413,"user":{"displayName":"Julen Etxaniz Aragoneses","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GilpYDAmorj7KFdjK26TlsyH_HhFWhLqmESeKoCGsI=s64","userId":"06956422670240182492"}},"outputId":"98324eee-b8a1-451d-da21-7d6248f980b6"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["2022-02-16 19:23:16,569 Reading data from ../resources/stance-semeval2016\n","2022-02-16 19:23:16,577 Train: ../resources/stance-semeval2016/train.Climate Change is a Real Concern.txt\n","2022-02-16 19:23:16,579 Dev: None\n","2022-02-16 19:23:16,585 Test: ../resources/stance-semeval2016/test.Climate Change is a Real Concern.txt\n","2022-02-16 19:23:16,638 Computing label dictionary. Progress:\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n","100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 524/524 [00:02<00:00, 218.47it/s]"]},{"output_type":"stream","name":"stdout","text":["2022-02-16 19:23:21,851 [b'FAVOR', b'AGAINST', b'NONE']\n","2022-02-16 19:23:21,962 ----------------------------------------------------------------------------------------------------\n","2022-02-16 19:23:21,969 Model: \"TextClassifier(\n","  (document_embeddings): DocumentRNNEmbeddings(\n","    (embeddings): StackedEmbeddings(\n","      (list_embedding_0): WordEmbeddings('en-crawl')\n","    )\n","    (word_reprojection_map): Linear(in_features=300, out_features=256, bias=True)\n","    (rnn): LSTM(256, 512, batch_first=True)\n","    (dropout): Dropout(p=0.5, inplace=False)\n","  )\n","  (decoder): Linear(in_features=512, out_features=3, bias=True)\n","  (loss_function): CrossEntropyLoss()\n","  (beta): 1.0\n","  (weights): None\n","  (weight_tensor) None\n",")\"\n","2022-02-16 19:23:21,974 ----------------------------------------------------------------------------------------------------\n","2022-02-16 19:23:21,979 Corpus: \"Corpus: 355 train + 40 dev + 169 test sentences\"\n","2022-02-16 19:23:21,981 ----------------------------------------------------------------------------------------------------\n","2022-02-16 19:23:21,987 Parameters:\n","2022-02-16 19:23:21,991  - learning_rate: \"0.1\"\n","2022-02-16 19:23:21,997  - mini_batch_size: \"32\"\n","2022-02-16 19:23:22,002  - patience: \"3\"\n","2022-02-16 19:23:22,008  - anneal_factor: \"0.5\"\n","2022-02-16 19:23:22,014  - max_epochs: \"50\"\n","2022-02-16 19:23:22,019  - shuffle: \"True\"\n","2022-02-16 19:23:22,024  - train_with_dev: \"False\"\n","2022-02-16 19:23:22,029  - batch_growth_annealing: \"False\"\n","2022-02-16 19:23:22,034 ----------------------------------------------------------------------------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["2022-02-16 19:23:22,041 Model training base path: \"../resources/stance-semeval2016/flair_Climate Change is a Real Concern\"\n","2022-02-16 19:23:22,049 ----------------------------------------------------------------------------------------------------\n","2022-02-16 19:23:22,058 Device: cuda:0\n","2022-02-16 19:23:22,061 ----------------------------------------------------------------------------------------------------\n","2022-02-16 19:23:22,067 Embeddings storage mode: cpu\n","2022-02-16 19:23:22,097 ----------------------------------------------------------------------------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"output_type":"stream","name":"stdout","text":["2022-02-16 19:23:24,972 epoch 1 - iter 1/12 - loss 1.05846012 - samples/sec: 54.07 - lr: 0.100000\n","2022-02-16 19:23:25,227 epoch 1 - iter 2/12 - loss 1.06585115 - samples/sec: 136.35 - lr: 0.100000\n","2022-02-16 19:23:25,481 epoch 1 - iter 3/12 - loss 1.06375051 - samples/sec: 129.66 - lr: 0.100000\n","2022-02-16 19:23:25,859 epoch 1 - iter 4/12 - loss 1.05401567 - samples/sec: 90.38 - lr: 0.100000\n","2022-02-16 19:23:26,285 epoch 1 - iter 5/12 - loss 1.02787808 - samples/sec: 79.68 - lr: 0.100000\n","2022-02-16 19:23:26,489 epoch 1 - iter 6/12 - loss 1.00223629 - samples/sec: 208.71 - lr: 0.100000\n","2022-02-16 19:23:26,882 epoch 1 - iter 7/12 - loss 0.97426283 - samples/sec: 83.26 - lr: 0.100000\n","2022-02-16 19:23:27,167 epoch 1 - iter 8/12 - loss 0.95152295 - samples/sec: 116.86 - lr: 0.100000\n","2022-02-16 19:23:27,697 epoch 1 - iter 9/12 - loss 0.95432401 - samples/sec: 68.64 - lr: 0.100000\n","2022-02-16 19:23:27,814 epoch 1 - iter 10/12 - loss 0.96831404 - samples/sec: 294.55 - lr: 0.100000\n","2022-02-16 19:23:27,888 epoch 1 - iter 11/12 - loss 0.95503455 - samples/sec: 463.15 - lr: 0.100000\n","2022-02-16 19:23:27,915 epoch 1 - iter 12/12 - loss 0.93980205 - samples/sec: 1436.61 - lr: 0.100000\n","2022-02-16 19:23:28,451 ----------------------------------------------------------------------------------------------------\n","2022-02-16 19:23:28,454 EPOCH 1 done: loss 0.9398 - lr 0.1000000\n","2022-02-16 19:23:30,138 DEV : loss 0.8788999915122986 - score 0.625\n","2022-02-16 19:23:30,184 BAD EPOCHS (no improvement): 0\n","saving best model\n","2022-02-16 19:23:45,619 ----------------------------------------------------------------------------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"output_type":"stream","name":"stdout","text":["2022-02-16 19:23:47,223 epoch 2 - iter 1/12 - loss 0.91481000 - samples/sec: 130.86 - lr: 0.100000\n","2022-02-16 19:23:47,333 epoch 2 - iter 2/12 - loss 0.94662479 - samples/sec: 421.52 - lr: 0.100000\n","2022-02-16 19:23:47,406 epoch 2 - iter 3/12 - loss 0.92755824 - samples/sec: 489.88 - lr: 0.100000\n","2022-02-16 19:23:47,487 epoch 2 - iter 4/12 - loss 0.90524541 - samples/sec: 429.17 - lr: 0.100000\n","2022-02-16 19:23:47,567 epoch 2 - iter 5/12 - loss 0.89255702 - samples/sec: 459.39 - lr: 0.100000\n","2022-02-16 19:23:47,661 epoch 2 - iter 6/12 - loss 0.88220889 - samples/sec: 506.98 - lr: 0.100000\n","2022-02-16 19:23:47,735 epoch 2 - iter 7/12 - loss 0.87300037 - samples/sec: 461.64 - lr: 0.100000\n","2022-02-16 19:23:47,803 epoch 2 - iter 8/12 - loss 0.85990121 - samples/sec: 486.77 - lr: 0.100000\n","2022-02-16 19:23:47,878 epoch 2 - iter 9/12 - loss 0.84242814 - samples/sec: 444.40 - lr: 0.100000\n","2022-02-16 19:23:47,949 epoch 2 - iter 10/12 - loss 0.83273631 - samples/sec: 463.14 - lr: 0.100000\n","2022-02-16 19:23:48,019 epoch 2 - iter 11/12 - loss 0.83468728 - samples/sec: 474.18 - lr: 0.100000\n","2022-02-16 19:23:48,044 epoch 2 - iter 12/12 - loss 0.83356084 - samples/sec: 1459.16 - lr: 0.100000\n","2022-02-16 19:23:48,668 ----------------------------------------------------------------------------------------------------\n","2022-02-16 19:23:48,674 EPOCH 2 done: loss 0.8336 - lr 0.1000000\n","2022-02-16 19:23:50,594 DEV : loss 0.9929863214492798 - score 0.3\n","2022-02-16 19:23:50,641 BAD EPOCHS (no improvement): 1\n","2022-02-16 19:23:50,655 ----------------------------------------------------------------------------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"output_type":"stream","name":"stdout","text":["2022-02-16 19:23:52,484 epoch 3 - iter 1/12 - loss 0.92234439 - samples/sec: 96.44 - lr: 0.100000\n","2022-02-16 19:23:52,677 epoch 3 - iter 2/12 - loss 0.82500362 - samples/sec: 174.76 - lr: 0.100000\n","2022-02-16 19:23:52,974 epoch 3 - iter 3/12 - loss 0.84709450 - samples/sec: 139.57 - lr: 0.100000\n","2022-02-16 19:23:53,278 epoch 3 - iter 4/12 - loss 0.86123399 - samples/sec: 149.37 - lr: 0.100000\n","2022-02-16 19:23:53,410 epoch 3 - iter 5/12 - loss 0.87634579 - samples/sec: 287.72 - lr: 0.100000\n","2022-02-16 19:23:53,631 epoch 3 - iter 6/12 - loss 0.85919780 - samples/sec: 183.74 - lr: 0.100000\n","2022-02-16 19:23:53,820 epoch 3 - iter 7/12 - loss 0.85214599 - samples/sec: 175.69 - lr: 0.100000\n","2022-02-16 19:23:53,982 epoch 3 - iter 8/12 - loss 0.86487004 - samples/sec: 200.58 - lr: 0.100000\n","2022-02-16 19:23:54,135 epoch 3 - iter 9/12 - loss 0.85874663 - samples/sec: 222.30 - lr: 0.100000\n","2022-02-16 19:23:54,322 epoch 3 - iter 10/12 - loss 0.85195261 - samples/sec: 222.40 - lr: 0.100000\n","2022-02-16 19:23:54,491 epoch 3 - iter 11/12 - loss 0.84278524 - samples/sec: 208.75 - lr: 0.100000\n","2022-02-16 19:23:54,549 epoch 3 - iter 12/12 - loss 0.81662307 - samples/sec: 658.36 - lr: 0.100000\n","2022-02-16 19:23:55,387 ----------------------------------------------------------------------------------------------------\n","2022-02-16 19:23:55,389 EPOCH 3 done: loss 0.8166 - lr 0.1000000\n","2022-02-16 19:23:58,606 DEV : loss 0.9621152877807617 - score 0.625\n","2022-02-16 19:23:58,780 BAD EPOCHS (no improvement): 2\n","2022-02-16 19:23:58,796 ----------------------------------------------------------------------------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"output_type":"stream","name":"stdout","text":["2022-02-16 19:24:01,087 epoch 4 - iter 1/12 - loss 1.08524680 - samples/sec: 106.13 - lr: 0.100000\n","2022-02-16 19:24:01,322 epoch 4 - iter 2/12 - loss 0.86959669 - samples/sec: 163.94 - lr: 0.100000\n","2022-02-16 19:24:01,523 epoch 4 - iter 3/12 - loss 0.87392056 - samples/sec: 215.54 - lr: 0.100000\n","2022-02-16 19:24:01,698 epoch 4 - iter 4/12 - loss 0.87364134 - samples/sec: 190.79 - lr: 0.100000\n","2022-02-16 19:24:01,879 epoch 4 - iter 5/12 - loss 0.86692809 - samples/sec: 182.72 - lr: 0.100000\n","2022-02-16 19:24:02,143 epoch 4 - iter 6/12 - loss 0.85939747 - samples/sec: 150.60 - lr: 0.100000\n","2022-02-16 19:24:02,299 epoch 4 - iter 7/12 - loss 0.83573077 - samples/sec: 212.79 - lr: 0.100000\n","2022-02-16 19:24:02,489 epoch 4 - iter 8/12 - loss 0.83941640 - samples/sec: 212.37 - lr: 0.100000\n","2022-02-16 19:24:02,637 epoch 4 - iter 9/12 - loss 0.83825511 - samples/sec: 229.02 - lr: 0.100000\n","2022-02-16 19:24:02,785 epoch 4 - iter 10/12 - loss 0.83799989 - samples/sec: 228.17 - lr: 0.100000\n","2022-02-16 19:24:02,926 epoch 4 - iter 11/12 - loss 0.82446237 - samples/sec: 241.03 - lr: 0.100000\n","2022-02-16 19:24:02,961 epoch 4 - iter 12/12 - loss 0.92291578 - samples/sec: 1232.11 - lr: 0.100000\n","2022-02-16 19:24:03,757 ----------------------------------------------------------------------------------------------------\n","2022-02-16 19:24:03,766 EPOCH 4 done: loss 0.9229 - lr 0.1000000\n","2022-02-16 19:24:06,465 DEV : loss 0.9137294292449951 - score 0.4\n","2022-02-16 19:24:06,510 BAD EPOCHS (no improvement): 3\n","2022-02-16 19:24:06,520 ----------------------------------------------------------------------------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"output_type":"stream","name":"stdout","text":["2022-02-16 19:24:07,878 epoch 5 - iter 1/12 - loss 0.87925005 - samples/sec: 107.70 - lr: 0.100000\n","2022-02-16 19:24:16,082 epoch 5 - iter 2/12 - loss 0.84890714 - samples/sec: 298.37 - lr: 0.100000\n","2022-02-16 19:24:16,164 epoch 5 - iter 3/12 - loss 0.83297046 - samples/sec: 529.70 - lr: 0.100000\n","2022-02-16 19:24:16,234 epoch 5 - iter 4/12 - loss 0.82391366 - samples/sec: 546.20 - lr: 0.100000\n","2022-02-16 19:24:16,310 epoch 5 - iter 5/12 - loss 0.80197535 - samples/sec: 463.54 - lr: 0.100000\n","2022-02-16 19:24:16,386 epoch 5 - iter 6/12 - loss 0.79779472 - samples/sec: 499.83 - lr: 0.100000\n","2022-02-16 19:24:16,471 epoch 5 - iter 7/12 - loss 0.82315726 - samples/sec: 535.41 - lr: 0.100000\n","2022-02-16 19:24:16,535 epoch 5 - iter 8/12 - loss 0.80977053 - samples/sec: 514.36 - lr: 0.100000\n","2022-02-16 19:24:16,603 epoch 5 - iter 9/12 - loss 0.80713346 - samples/sec: 509.33 - lr: 0.100000\n","2022-02-16 19:24:16,666 epoch 5 - iter 10/12 - loss 0.80042238 - samples/sec: 524.26 - lr: 0.100000\n","2022-02-16 19:24:16,738 epoch 5 - iter 11/12 - loss 0.79941758 - samples/sec: 495.36 - lr: 0.100000\n","2022-02-16 19:24:16,761 epoch 5 - iter 12/12 - loss 0.77805486 - samples/sec: 1592.60 - lr: 0.100000\n","2022-02-16 19:24:17,293 ----------------------------------------------------------------------------------------------------\n","2022-02-16 19:24:17,295 EPOCH 5 done: loss 0.7781 - lr 0.1000000\n","2022-02-16 19:24:18,628 DEV : loss 0.9036107063293457 - score 0.625\n","Epoch     5: reducing learning rate of group 0 to 5.0000e-02.\n","2022-02-16 19:24:18,673 BAD EPOCHS (no improvement): 4\n","2022-02-16 19:24:18,685 ----------------------------------------------------------------------------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"output_type":"stream","name":"stdout","text":["2022-02-16 19:24:19,752 epoch 6 - iter 1/12 - loss 0.90013576 - samples/sec: 123.09 - lr: 0.050000\n","2022-02-16 19:24:19,850 epoch 6 - iter 2/12 - loss 0.86801368 - samples/sec: 449.37 - lr: 0.050000\n","2022-02-16 19:24:19,946 epoch 6 - iter 3/12 - loss 0.88879613 - samples/sec: 433.41 - lr: 0.050000\n","2022-02-16 19:24:20,022 epoch 6 - iter 4/12 - loss 0.90484028 - samples/sec: 437.14 - lr: 0.050000\n","2022-02-16 19:24:20,096 epoch 6 - iter 5/12 - loss 0.85139363 - samples/sec: 472.59 - lr: 0.050000\n","2022-02-16 19:24:20,170 epoch 6 - iter 6/12 - loss 0.83037281 - samples/sec: 452.62 - lr: 0.050000\n","2022-02-16 19:24:20,239 epoch 6 - iter 7/12 - loss 0.81928616 - samples/sec: 490.05 - lr: 0.050000\n","2022-02-16 19:24:20,311 epoch 6 - iter 8/12 - loss 0.82399170 - samples/sec: 456.35 - lr: 0.050000\n","2022-02-16 19:24:20,394 epoch 6 - iter 9/12 - loss 0.80575792 - samples/sec: 472.05 - lr: 0.050000\n","2022-02-16 19:24:20,466 epoch 6 - iter 10/12 - loss 0.80001007 - samples/sec: 479.01 - lr: 0.050000\n","2022-02-16 19:24:20,545 epoch 6 - iter 11/12 - loss 0.78128244 - samples/sec: 488.19 - lr: 0.050000\n","2022-02-16 19:24:20,565 epoch 6 - iter 12/12 - loss 0.77533470 - samples/sec: 1890.52 - lr: 0.050000\n","2022-02-16 19:24:20,966 ----------------------------------------------------------------------------------------------------\n","2022-02-16 19:24:20,973 EPOCH 6 done: loss 0.7753 - lr 0.0500000\n","2022-02-16 19:24:22,317 DEV : loss 0.8506278991699219 - score 0.55\n","2022-02-16 19:24:22,369 BAD EPOCHS (no improvement): 1\n","2022-02-16 19:24:22,378 ----------------------------------------------------------------------------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"output_type":"stream","name":"stdout","text":["2022-02-16 19:24:23,432 epoch 7 - iter 1/12 - loss 0.73150015 - samples/sec: 131.21 - lr: 0.050000\n","2022-02-16 19:24:23,523 epoch 7 - iter 2/12 - loss 0.74205017 - samples/sec: 412.20 - lr: 0.050000\n","2022-02-16 19:24:23,600 epoch 7 - iter 3/12 - loss 0.74079398 - samples/sec: 538.79 - lr: 0.050000\n","2022-02-16 19:24:23,694 epoch 7 - iter 4/12 - loss 0.74473660 - samples/sec: 404.08 - lr: 0.050000\n","2022-02-16 19:24:23,785 epoch 7 - iter 5/12 - loss 0.74800024 - samples/sec: 476.32 - lr: 0.050000\n","2022-02-16 19:24:23,869 epoch 7 - iter 6/12 - loss 0.76233006 - samples/sec: 395.87 - lr: 0.050000\n","2022-02-16 19:24:23,944 epoch 7 - iter 7/12 - loss 0.75444141 - samples/sec: 445.80 - lr: 0.050000\n","2022-02-16 19:24:24,014 epoch 7 - iter 8/12 - loss 0.76498467 - samples/sec: 471.12 - lr: 0.050000\n","2022-02-16 19:24:24,085 epoch 7 - iter 9/12 - loss 0.75926370 - samples/sec: 499.28 - lr: 0.050000\n","2022-02-16 19:24:24,164 epoch 7 - iter 10/12 - loss 0.75612123 - samples/sec: 437.20 - lr: 0.050000\n","2022-02-16 19:24:24,247 epoch 7 - iter 11/12 - loss 0.76462762 - samples/sec: 479.64 - lr: 0.050000\n","2022-02-16 19:24:24,270 epoch 7 - iter 12/12 - loss 0.77009008 - samples/sec: 1613.83 - lr: 0.050000\n","2022-02-16 19:24:24,683 ----------------------------------------------------------------------------------------------------\n","2022-02-16 19:24:24,690 EPOCH 7 done: loss 0.7701 - lr 0.0500000\n","2022-02-16 19:24:26,086 DEV : loss 0.8753564953804016 - score 0.55\n","2022-02-16 19:24:26,131 BAD EPOCHS (no improvement): 2\n","2022-02-16 19:24:26,143 ----------------------------------------------------------------------------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"output_type":"stream","name":"stdout","text":["2022-02-16 19:24:27,184 epoch 8 - iter 1/12 - loss 0.66248465 - samples/sec: 139.53 - lr: 0.050000\n","2022-02-16 19:24:27,290 epoch 8 - iter 2/12 - loss 0.75908506 - samples/sec: 453.77 - lr: 0.050000\n","2022-02-16 19:24:27,372 epoch 8 - iter 3/12 - loss 0.75245041 - samples/sec: 468.36 - lr: 0.050000\n","2022-02-16 19:24:27,456 epoch 8 - iter 4/12 - loss 0.73959522 - samples/sec: 446.89 - lr: 0.050000\n","2022-02-16 19:24:27,535 epoch 8 - iter 5/12 - loss 0.74111902 - samples/sec: 480.31 - lr: 0.050000\n","2022-02-16 19:24:27,615 epoch 8 - iter 6/12 - loss 0.73347766 - samples/sec: 496.17 - lr: 0.050000\n","2022-02-16 19:24:27,687 epoch 8 - iter 7/12 - loss 0.73832690 - samples/sec: 489.86 - lr: 0.050000\n","2022-02-16 19:24:27,763 epoch 8 - iter 8/12 - loss 0.74348017 - samples/sec: 444.36 - lr: 0.050000\n","2022-02-16 19:24:27,834 epoch 8 - iter 9/12 - loss 0.76192867 - samples/sec: 515.74 - lr: 0.050000\n","2022-02-16 19:24:27,907 epoch 8 - iter 10/12 - loss 0.75377551 - samples/sec: 516.96 - lr: 0.050000\n","2022-02-16 19:24:27,982 epoch 8 - iter 11/12 - loss 0.75928741 - samples/sec: 483.58 - lr: 0.050000\n","2022-02-16 19:24:28,007 epoch 8 - iter 12/12 - loss 0.73352671 - samples/sec: 1612.09 - lr: 0.050000\n","2022-02-16 19:24:28,419 ----------------------------------------------------------------------------------------------------\n","2022-02-16 19:24:28,421 EPOCH 8 done: loss 0.7335 - lr 0.0500000\n","2022-02-16 19:24:29,707 DEV : loss 0.8229542970657349 - score 0.55\n","2022-02-16 19:24:29,754 BAD EPOCHS (no improvement): 3\n","2022-02-16 19:24:29,761 ----------------------------------------------------------------------------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"output_type":"stream","name":"stdout","text":["2022-02-16 19:24:30,851 epoch 9 - iter 1/12 - loss 0.78233129 - samples/sec: 222.54 - lr: 0.050000\n","2022-02-16 19:24:30,934 epoch 9 - iter 2/12 - loss 0.71138582 - samples/sec: 411.58 - lr: 0.050000\n","2022-02-16 19:24:31,004 epoch 9 - iter 3/12 - loss 0.72693229 - samples/sec: 495.98 - lr: 0.050000\n","2022-02-16 19:24:31,083 epoch 9 - iter 4/12 - loss 0.70030533 - samples/sec: 505.59 - lr: 0.050000\n","2022-02-16 19:24:31,160 epoch 9 - iter 5/12 - loss 0.71310802 - samples/sec: 428.62 - lr: 0.050000\n","2022-02-16 19:24:31,247 epoch 9 - iter 6/12 - loss 0.68685950 - samples/sec: 466.51 - lr: 0.050000\n","2022-02-16 19:24:31,324 epoch 9 - iter 7/12 - loss 0.73602340 - samples/sec: 504.05 - lr: 0.050000\n","2022-02-16 19:24:31,410 epoch 9 - iter 8/12 - loss 0.73847517 - samples/sec: 385.37 - lr: 0.050000\n","2022-02-16 19:24:31,480 epoch 9 - iter 9/12 - loss 0.73861159 - samples/sec: 515.49 - lr: 0.050000\n","2022-02-16 19:24:31,546 epoch 9 - iter 10/12 - loss 0.72827483 - samples/sec: 515.74 - lr: 0.050000\n","2022-02-16 19:24:31,615 epoch 9 - iter 11/12 - loss 0.73262195 - samples/sec: 479.65 - lr: 0.050000\n","2022-02-16 19:24:31,639 epoch 9 - iter 12/12 - loss 0.85504585 - samples/sec: 1787.19 - lr: 0.050000\n","2022-02-16 19:24:32,034 ----------------------------------------------------------------------------------------------------\n","2022-02-16 19:24:32,041 EPOCH 9 done: loss 0.8550 - lr 0.0500000\n","2022-02-16 19:24:33,318 DEV : loss 0.8837971687316895 - score 0.525\n","Epoch     9: reducing learning rate of group 0 to 2.5000e-02.\n","2022-02-16 19:24:33,369 BAD EPOCHS (no improvement): 4\n","2022-02-16 19:24:33,378 ----------------------------------------------------------------------------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"output_type":"stream","name":"stdout","text":["2022-02-16 19:24:34,406 epoch 10 - iter 1/12 - loss 0.97299004 - samples/sec: 135.94 - lr: 0.025000\n","2022-02-16 19:24:34,513 epoch 10 - iter 2/12 - loss 0.88693196 - samples/sec: 392.86 - lr: 0.025000\n","2022-02-16 19:24:34,589 epoch 10 - iter 3/12 - loss 0.81961540 - samples/sec: 438.56 - lr: 0.025000\n","2022-02-16 19:24:34,683 epoch 10 - iter 4/12 - loss 0.79832782 - samples/sec: 473.24 - lr: 0.025000\n","2022-02-16 19:24:34,758 epoch 10 - iter 5/12 - loss 0.77867490 - samples/sec: 440.25 - lr: 0.025000\n","2022-02-16 19:24:34,829 epoch 10 - iter 6/12 - loss 0.76319649 - samples/sec: 466.85 - lr: 0.025000\n","2022-02-16 19:24:34,914 epoch 10 - iter 7/12 - loss 0.75715805 - samples/sec: 386.39 - lr: 0.025000\n","2022-02-16 19:24:34,986 epoch 10 - iter 8/12 - loss 0.76063598 - samples/sec: 471.35 - lr: 0.025000\n","2022-02-16 19:24:35,058 epoch 10 - iter 9/12 - loss 0.75677725 - samples/sec: 518.53 - lr: 0.025000\n","2022-02-16 19:24:35,128 epoch 10 - iter 10/12 - loss 0.75786752 - samples/sec: 522.40 - lr: 0.025000\n","2022-02-16 19:24:35,204 epoch 10 - iter 11/12 - loss 0.75207638 - samples/sec: 435.23 - lr: 0.025000\n","2022-02-16 19:24:35,227 epoch 10 - iter 12/12 - loss 0.81072939 - samples/sec: 1508.01 - lr: 0.025000\n","2022-02-16 19:24:35,643 ----------------------------------------------------------------------------------------------------\n","2022-02-16 19:24:35,650 EPOCH 10 done: loss 0.8107 - lr 0.0250000\n","2022-02-16 19:24:36,984 DEV : loss 0.822258472442627 - score 0.525\n","2022-02-16 19:24:37,029 BAD EPOCHS (no improvement): 1\n","2022-02-16 19:24:37,064 ----------------------------------------------------------------------------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"output_type":"stream","name":"stdout","text":["2022-02-16 19:24:38,122 epoch 11 - iter 1/12 - loss 0.85268009 - samples/sec: 169.57 - lr: 0.025000\n","2022-02-16 19:24:38,208 epoch 11 - iter 2/12 - loss 0.80939651 - samples/sec: 499.85 - lr: 0.025000\n","2022-02-16 19:24:38,284 epoch 11 - iter 3/12 - loss 0.80635442 - samples/sec: 503.53 - lr: 0.025000\n","2022-02-16 19:24:38,353 epoch 11 - iter 4/12 - loss 0.78808561 - samples/sec: 535.57 - lr: 0.025000\n","2022-02-16 19:24:38,434 epoch 11 - iter 5/12 - loss 0.76838089 - samples/sec: 407.34 - lr: 0.025000\n","2022-02-16 19:24:38,505 epoch 11 - iter 6/12 - loss 0.74800792 - samples/sec: 566.41 - lr: 0.025000\n","2022-02-16 19:24:38,580 epoch 11 - iter 7/12 - loss 0.73511555 - samples/sec: 453.88 - lr: 0.025000\n","2022-02-16 19:24:38,651 epoch 11 - iter 8/12 - loss 0.71807566 - samples/sec: 511.35 - lr: 0.025000\n","2022-02-16 19:24:38,734 epoch 11 - iter 9/12 - loss 0.71708566 - samples/sec: 503.21 - lr: 0.025000\n","2022-02-16 19:24:38,804 epoch 11 - iter 10/12 - loss 0.72210106 - samples/sec: 479.74 - lr: 0.025000\n","2022-02-16 19:24:38,885 epoch 11 - iter 11/12 - loss 0.72868477 - samples/sec: 412.63 - lr: 0.025000\n","2022-02-16 19:24:38,911 epoch 11 - iter 12/12 - loss 0.74497595 - samples/sec: 1354.48 - lr: 0.025000\n","2022-02-16 19:24:39,378 ----------------------------------------------------------------------------------------------------\n","2022-02-16 19:24:39,380 EPOCH 11 done: loss 0.7450 - lr 0.0250000\n","2022-02-16 19:24:40,784 DEV : loss 0.8148473501205444 - score 0.6\n","2022-02-16 19:24:40,827 BAD EPOCHS (no improvement): 2\n","2022-02-16 19:24:40,834 ----------------------------------------------------------------------------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"output_type":"stream","name":"stdout","text":["2022-02-16 19:24:41,894 epoch 12 - iter 1/12 - loss 0.78177953 - samples/sec: 348.73 - lr: 0.025000\n","2022-02-16 19:24:41,970 epoch 12 - iter 2/12 - loss 0.71825543 - samples/sec: 459.21 - lr: 0.025000\n","2022-02-16 19:24:42,033 epoch 12 - iter 3/12 - loss 0.70565935 - samples/sec: 535.03 - lr: 0.025000\n","2022-02-16 19:24:42,100 epoch 12 - iter 4/12 - loss 0.70111185 - samples/sec: 531.39 - lr: 0.025000\n","2022-02-16 19:24:42,171 epoch 12 - iter 5/12 - loss 0.71716572 - samples/sec: 459.86 - lr: 0.025000\n","2022-02-16 19:24:42,266 epoch 12 - iter 6/12 - loss 0.74254374 - samples/sec: 501.16 - lr: 0.025000\n","2022-02-16 19:24:42,336 epoch 12 - iter 7/12 - loss 0.71786309 - samples/sec: 498.54 - lr: 0.025000\n","2022-02-16 19:24:42,409 epoch 12 - iter 8/12 - loss 0.71971022 - samples/sec: 484.37 - lr: 0.025000\n","2022-02-16 19:24:42,488 epoch 12 - iter 9/12 - loss 0.73441588 - samples/sec: 413.45 - lr: 0.025000\n","2022-02-16 19:24:42,556 epoch 12 - iter 10/12 - loss 0.72941301 - samples/sec: 496.15 - lr: 0.025000\n","2022-02-16 19:24:42,628 epoch 12 - iter 11/12 - loss 0.72522733 - samples/sec: 463.41 - lr: 0.025000\n","2022-02-16 19:24:42,657 epoch 12 - iter 12/12 - loss 0.73616516 - samples/sec: 1463.98 - lr: 0.025000\n","2022-02-16 19:24:43,037 ----------------------------------------------------------------------------------------------------\n","2022-02-16 19:24:43,043 EPOCH 12 done: loss 0.7362 - lr 0.0250000\n","2022-02-16 19:24:44,350 DEV : loss 0.8464285731315613 - score 0.55\n","2022-02-16 19:24:44,400 BAD EPOCHS (no improvement): 3\n","2022-02-16 19:24:44,410 ----------------------------------------------------------------------------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"output_type":"stream","name":"stdout","text":["2022-02-16 19:24:45,472 epoch 13 - iter 1/12 - loss 0.80506492 - samples/sec: 227.33 - lr: 0.025000\n","2022-02-16 19:24:45,561 epoch 13 - iter 2/12 - loss 0.73927566 - samples/sec: 460.17 - lr: 0.025000\n","2022-02-16 19:24:45,639 epoch 13 - iter 3/12 - loss 0.71094523 - samples/sec: 471.67 - lr: 0.025000\n","2022-02-16 19:24:45,713 epoch 13 - iter 4/12 - loss 0.71725981 - samples/sec: 451.99 - lr: 0.025000\n","2022-02-16 19:24:45,786 epoch 13 - iter 5/12 - loss 0.71872958 - samples/sec: 459.38 - lr: 0.025000\n","2022-02-16 19:24:45,874 epoch 13 - iter 6/12 - loss 0.73398158 - samples/sec: 496.91 - lr: 0.025000\n","2022-02-16 19:24:45,939 epoch 13 - iter 7/12 - loss 0.72517564 - samples/sec: 519.20 - lr: 0.025000\n","2022-02-16 19:24:46,011 epoch 13 - iter 8/12 - loss 0.72505390 - samples/sec: 521.73 - lr: 0.025000\n","2022-02-16 19:24:46,084 epoch 13 - iter 9/12 - loss 0.71688708 - samples/sec: 466.30 - lr: 0.025000\n","2022-02-16 19:24:46,156 epoch 13 - iter 10/12 - loss 0.72092906 - samples/sec: 502.88 - lr: 0.025000\n","2022-02-16 19:24:46,220 epoch 13 - iter 11/12 - loss 0.72117534 - samples/sec: 514.91 - lr: 0.025000\n","2022-02-16 19:24:46,241 epoch 13 - iter 12/12 - loss 0.71146792 - samples/sec: 1714.85 - lr: 0.025000\n","2022-02-16 19:24:46,612 ----------------------------------------------------------------------------------------------------\n","2022-02-16 19:24:46,617 EPOCH 13 done: loss 0.7115 - lr 0.0250000\n","2022-02-16 19:24:47,987 DEV : loss 0.8223634362220764 - score 0.575\n","Epoch    13: reducing learning rate of group 0 to 1.2500e-02.\n","2022-02-16 19:24:48,035 BAD EPOCHS (no improvement): 4\n","2022-02-16 19:24:48,043 ----------------------------------------------------------------------------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"output_type":"stream","name":"stdout","text":["2022-02-16 19:24:49,095 epoch 14 - iter 1/12 - loss 0.74659485 - samples/sec: 269.93 - lr: 0.012500\n","2022-02-16 19:24:49,172 epoch 14 - iter 2/12 - loss 0.72138387 - samples/sec: 442.03 - lr: 0.012500\n","2022-02-16 19:24:49,257 epoch 14 - iter 3/12 - loss 0.75391956 - samples/sec: 512.72 - lr: 0.012500\n","2022-02-16 19:24:49,359 epoch 14 - iter 4/12 - loss 0.74914126 - samples/sec: 322.58 - lr: 0.012500\n","2022-02-16 19:24:49,431 epoch 14 - iter 5/12 - loss 0.74240593 - samples/sec: 461.01 - lr: 0.012500\n","2022-02-16 19:24:49,518 epoch 14 - iter 6/12 - loss 0.71682930 - samples/sec: 506.19 - lr: 0.012500\n","2022-02-16 19:24:49,587 epoch 14 - iter 7/12 - loss 0.71016926 - samples/sec: 503.74 - lr: 0.012500\n","2022-02-16 19:24:49,665 epoch 14 - iter 8/12 - loss 0.70013165 - samples/sec: 495.22 - lr: 0.012500\n","2022-02-16 19:24:49,740 epoch 14 - iter 9/12 - loss 0.70689314 - samples/sec: 441.15 - lr: 0.012500\n","2022-02-16 19:24:49,813 epoch 14 - iter 10/12 - loss 0.69938030 - samples/sec: 452.09 - lr: 0.012500\n","2022-02-16 19:24:49,887 epoch 14 - iter 11/12 - loss 0.70785585 - samples/sec: 450.08 - lr: 0.012500\n","2022-02-16 19:24:49,910 epoch 14 - iter 12/12 - loss 0.68238131 - samples/sec: 1636.22 - lr: 0.012500\n","2022-02-16 19:24:50,347 ----------------------------------------------------------------------------------------------------\n","2022-02-16 19:24:50,353 EPOCH 14 done: loss 0.6824 - lr 0.0125000\n","2022-02-16 19:24:51,764 DEV : loss 0.8077138662338257 - score 0.625\n","2022-02-16 19:24:51,810 BAD EPOCHS (no improvement): 0\n","saving best model\n","2022-02-16 19:25:07,876 ----------------------------------------------------------------------------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"output_type":"stream","name":"stdout","text":["2022-02-16 19:25:09,249 epoch 15 - iter 1/12 - loss 0.62494785 - samples/sec: 171.86 - lr: 0.012500\n","2022-02-16 19:25:09,327 epoch 15 - iter 2/12 - loss 0.73003685 - samples/sec: 502.42 - lr: 0.012500\n","2022-02-16 19:25:09,413 epoch 15 - iter 3/12 - loss 0.74767504 - samples/sec: 528.29 - lr: 0.012500\n","2022-02-16 19:25:09,505 epoch 15 - iter 4/12 - loss 0.72070611 - samples/sec: 457.42 - lr: 0.012500\n","2022-02-16 19:25:09,579 epoch 15 - iter 5/12 - loss 0.70721679 - samples/sec: 498.02 - lr: 0.012500\n","2022-02-16 19:25:09,648 epoch 15 - iter 6/12 - loss 0.70200231 - samples/sec: 477.90 - lr: 0.012500\n","2022-02-16 19:25:09,716 epoch 15 - iter 7/12 - loss 0.70293915 - samples/sec: 485.87 - lr: 0.012500\n","2022-02-16 19:25:09,785 epoch 15 - iter 8/12 - loss 0.69269604 - samples/sec: 481.69 - lr: 0.012500\n","2022-02-16 19:25:09,862 epoch 15 - iter 9/12 - loss 0.69565439 - samples/sec: 539.27 - lr: 0.012500\n","2022-02-16 19:25:09,942 epoch 15 - iter 10/12 - loss 0.69807349 - samples/sec: 453.78 - lr: 0.012500\n","2022-02-16 19:25:10,020 epoch 15 - iter 11/12 - loss 0.71212963 - samples/sec: 434.47 - lr: 0.012500\n","2022-02-16 19:25:10,047 epoch 15 - iter 12/12 - loss 0.70291479 - samples/sec: 1502.04 - lr: 0.012500\n","2022-02-16 19:25:10,612 ----------------------------------------------------------------------------------------------------\n","2022-02-16 19:25:10,614 EPOCH 15 done: loss 0.7029 - lr 0.0125000\n","2022-02-16 19:25:12,322 DEV : loss 0.8070741891860962 - score 0.6\n","2022-02-16 19:25:12,368 BAD EPOCHS (no improvement): 1\n","2022-02-16 19:25:12,378 ----------------------------------------------------------------------------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"output_type":"stream","name":"stdout","text":["2022-02-16 19:25:13,644 epoch 16 - iter 1/12 - loss 0.85196608 - samples/sec: 158.17 - lr: 0.012500\n","2022-02-16 19:25:13,725 epoch 16 - iter 2/12 - loss 0.81303498 - samples/sec: 476.63 - lr: 0.012500\n","2022-02-16 19:25:13,802 epoch 16 - iter 3/12 - loss 0.78414192 - samples/sec: 483.75 - lr: 0.012500\n","2022-02-16 19:25:13,902 epoch 16 - iter 4/12 - loss 0.73555920 - samples/sec: 515.78 - lr: 0.012500\n","2022-02-16 19:25:13,973 epoch 16 - iter 5/12 - loss 0.72218059 - samples/sec: 488.33 - lr: 0.012500\n","2022-02-16 19:25:14,041 epoch 16 - iter 6/12 - loss 0.69836900 - samples/sec: 490.00 - lr: 0.012500\n","2022-02-16 19:25:14,105 epoch 16 - iter 7/12 - loss 0.71551758 - samples/sec: 524.46 - lr: 0.012500\n","2022-02-16 19:25:14,182 epoch 16 - iter 8/12 - loss 0.70497332 - samples/sec: 436.24 - lr: 0.012500\n","2022-02-16 19:25:14,245 epoch 16 - iter 9/12 - loss 0.70856656 - samples/sec: 520.81 - lr: 0.012500\n","2022-02-16 19:25:14,331 epoch 16 - iter 10/12 - loss 0.71379966 - samples/sec: 406.10 - lr: 0.012500\n","2022-02-16 19:25:14,407 epoch 16 - iter 11/12 - loss 0.70209505 - samples/sec: 495.57 - lr: 0.012500\n","2022-02-16 19:25:14,435 epoch 16 - iter 12/12 - loss 0.71345212 - samples/sec: 1521.31 - lr: 0.012500\n","2022-02-16 19:25:14,970 ----------------------------------------------------------------------------------------------------\n","2022-02-16 19:25:14,972 EPOCH 16 done: loss 0.7135 - lr 0.0125000\n","2022-02-16 19:25:16,692 DEV : loss 0.8101582527160645 - score 0.6\n","2022-02-16 19:25:16,741 BAD EPOCHS (no improvement): 2\n","2022-02-16 19:25:16,753 ----------------------------------------------------------------------------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"output_type":"stream","name":"stdout","text":["2022-02-16 19:25:19,213 epoch 17 - iter 1/12 - loss 0.79958797 - samples/sec: 93.40 - lr: 0.012500\n","2022-02-16 19:25:19,370 epoch 17 - iter 2/12 - loss 0.72153485 - samples/sec: 241.53 - lr: 0.012500\n","2022-02-16 19:25:19,515 epoch 17 - iter 3/12 - loss 0.75528576 - samples/sec: 261.95 - lr: 0.012500\n","2022-02-16 19:25:19,640 epoch 17 - iter 4/12 - loss 0.71378264 - samples/sec: 290.45 - lr: 0.012500\n","2022-02-16 19:25:19,854 epoch 17 - iter 5/12 - loss 0.69513242 - samples/sec: 171.87 - lr: 0.012500\n","2022-02-16 19:25:20,066 epoch 17 - iter 6/12 - loss 0.67436723 - samples/sec: 187.69 - lr: 0.012500\n","2022-02-16 19:25:20,202 epoch 17 - iter 7/12 - loss 0.68010132 - samples/sec: 247.29 - lr: 0.012500\n","2022-02-16 19:25:20,344 epoch 17 - iter 8/12 - loss 0.68036143 - samples/sec: 238.43 - lr: 0.012500\n","2022-02-16 19:25:20,511 epoch 17 - iter 9/12 - loss 0.68166557 - samples/sec: 218.51 - lr: 0.012500\n","2022-02-16 19:25:20,704 epoch 17 - iter 10/12 - loss 0.69814795 - samples/sec: 187.47 - lr: 0.012500\n","2022-02-16 19:25:20,869 epoch 17 - iter 11/12 - loss 0.68582322 - samples/sec: 204.52 - lr: 0.012500\n","2022-02-16 19:25:20,929 epoch 17 - iter 12/12 - loss 0.66556047 - samples/sec: 618.30 - lr: 0.012500\n","2022-02-16 19:25:21,725 ----------------------------------------------------------------------------------------------------\n","2022-02-16 19:25:21,738 EPOCH 17 done: loss 0.6656 - lr 0.0125000\n","2022-02-16 19:25:24,983 DEV : loss 0.8102304935455322 - score 0.575\n","2022-02-16 19:25:25,111 BAD EPOCHS (no improvement): 3\n","2022-02-16 19:25:25,128 ----------------------------------------------------------------------------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"output_type":"stream","name":"stdout","text":["2022-02-16 19:25:27,610 epoch 18 - iter 1/12 - loss 0.62428212 - samples/sec: 97.92 - lr: 0.012500\n","2022-02-16 19:25:27,789 epoch 18 - iter 2/12 - loss 0.70672512 - samples/sec: 183.23 - lr: 0.012500\n","2022-02-16 19:25:27,995 epoch 18 - iter 3/12 - loss 0.67929691 - samples/sec: 199.87 - lr: 0.012500\n","2022-02-16 19:25:28,172 epoch 18 - iter 4/12 - loss 0.66979063 - samples/sec: 186.31 - lr: 0.012500\n","2022-02-16 19:25:28,322 epoch 18 - iter 5/12 - loss 0.68928055 - samples/sec: 224.64 - lr: 0.012500\n","2022-02-16 19:25:30,556 epoch 18 - iter 6/12 - loss 0.70624167 - samples/sec: 498.78 - lr: 0.012500\n","2022-02-16 19:25:30,621 epoch 18 - iter 7/12 - loss 0.70980985 - samples/sec: 514.70 - lr: 0.012500\n","2022-02-16 19:25:30,685 epoch 18 - iter 8/12 - loss 0.70462157 - samples/sec: 521.26 - lr: 0.012500\n","2022-02-16 19:25:30,749 epoch 18 - iter 9/12 - loss 0.68934038 - samples/sec: 570.09 - lr: 0.012500\n","2022-02-16 19:25:30,819 epoch 18 - iter 10/12 - loss 0.67742245 - samples/sec: 473.66 - lr: 0.012500\n","2022-02-16 19:25:30,887 epoch 18 - iter 11/12 - loss 0.68922281 - samples/sec: 497.14 - lr: 0.012500\n","2022-02-16 19:25:30,910 epoch 18 - iter 12/12 - loss 0.72904273 - samples/sec: 1611.35 - lr: 0.012500\n","2022-02-16 19:25:31,475 ----------------------------------------------------------------------------------------------------\n","2022-02-16 19:25:31,481 EPOCH 18 done: loss 0.7290 - lr 0.0125000\n","2022-02-16 19:25:33,014 DEV : loss 0.8022955656051636 - score 0.625\n","2022-02-16 19:25:33,063 BAD EPOCHS (no improvement): 0\n","saving best model\n","2022-02-16 19:25:48,350 ----------------------------------------------------------------------------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"output_type":"stream","name":"stdout","text":["2022-02-16 19:25:49,745 epoch 19 - iter 1/12 - loss 0.80010456 - samples/sec: 274.22 - lr: 0.012500\n","2022-02-16 19:25:49,830 epoch 19 - iter 2/12 - loss 0.70403016 - samples/sec: 396.37 - lr: 0.012500\n","2022-02-16 19:25:49,897 epoch 19 - iter 3/12 - loss 0.73572536 - samples/sec: 521.88 - lr: 0.012500\n","2022-02-16 19:25:49,971 epoch 19 - iter 4/12 - loss 0.68668626 - samples/sec: 444.62 - lr: 0.012500\n","2022-02-16 19:25:50,069 epoch 19 - iter 5/12 - loss 0.68296191 - samples/sec: 338.96 - lr: 0.012500\n","2022-02-16 19:25:50,159 epoch 19 - iter 6/12 - loss 0.69937439 - samples/sec: 513.55 - lr: 0.012500\n","2022-02-16 19:25:50,229 epoch 19 - iter 7/12 - loss 0.68752571 - samples/sec: 472.19 - lr: 0.012500\n","2022-02-16 19:25:50,304 epoch 19 - iter 8/12 - loss 0.68498626 - samples/sec: 445.29 - lr: 0.012500\n","2022-02-16 19:25:50,382 epoch 19 - iter 9/12 - loss 0.69384852 - samples/sec: 421.86 - lr: 0.012500\n","2022-02-16 19:25:50,447 epoch 19 - iter 10/12 - loss 0.69619687 - samples/sec: 502.01 - lr: 0.012500\n","2022-02-16 19:25:50,517 epoch 19 - iter 11/12 - loss 0.68985301 - samples/sec: 479.57 - lr: 0.012500\n","2022-02-16 19:25:50,537 epoch 19 - iter 12/12 - loss 0.69268474 - samples/sec: 1850.79 - lr: 0.012500\n","2022-02-16 19:25:51,054 ----------------------------------------------------------------------------------------------------\n","2022-02-16 19:25:51,062 EPOCH 19 done: loss 0.6927 - lr 0.0125000\n","2022-02-16 19:25:52,759 DEV : loss 0.8083817958831787 - score 0.575\n","2022-02-16 19:25:52,803 BAD EPOCHS (no improvement): 1\n","2022-02-16 19:25:52,809 ----------------------------------------------------------------------------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"output_type":"stream","name":"stdout","text":["2022-02-16 19:25:54,079 epoch 20 - iter 1/12 - loss 0.61770785 - samples/sec: 247.49 - lr: 0.012500\n","2022-02-16 19:25:54,159 epoch 20 - iter 2/12 - loss 0.65502968 - samples/sec: 429.41 - lr: 0.012500\n","2022-02-16 19:25:54,234 epoch 20 - iter 3/12 - loss 0.67532967 - samples/sec: 498.21 - lr: 0.012500\n","2022-02-16 19:25:54,320 epoch 20 - iter 4/12 - loss 0.69849667 - samples/sec: 449.37 - lr: 0.012500\n","2022-02-16 19:25:54,388 epoch 20 - iter 5/12 - loss 0.69239244 - samples/sec: 531.81 - lr: 0.012500\n","2022-02-16 19:25:54,491 epoch 20 - iter 6/12 - loss 0.70095695 - samples/sec: 388.02 - lr: 0.012500\n","2022-02-16 19:25:54,575 epoch 20 - iter 7/12 - loss 0.70354375 - samples/sec: 398.09 - lr: 0.012500\n","2022-02-16 19:25:54,648 epoch 20 - iter 8/12 - loss 0.70564053 - samples/sec: 455.78 - lr: 0.012500\n","2022-02-16 19:25:54,719 epoch 20 - iter 9/12 - loss 0.72719088 - samples/sec: 473.20 - lr: 0.012500\n","2022-02-16 19:25:54,793 epoch 20 - iter 10/12 - loss 0.71718334 - samples/sec: 535.99 - lr: 0.012500\n","2022-02-16 19:25:54,870 epoch 20 - iter 11/12 - loss 0.70521491 - samples/sec: 467.37 - lr: 0.012500\n","2022-02-16 19:25:54,894 epoch 20 - iter 12/12 - loss 0.69097443 - samples/sec: 1683.13 - lr: 0.012500\n","2022-02-16 19:25:55,430 ----------------------------------------------------------------------------------------------------\n","2022-02-16 19:25:55,432 EPOCH 20 done: loss 0.6910 - lr 0.0125000\n","2022-02-16 19:25:57,060 DEV : loss 0.7989209890365601 - score 0.625\n","2022-02-16 19:25:57,106 BAD EPOCHS (no improvement): 0\n","saving best model\n","2022-02-16 19:26:11,983 ----------------------------------------------------------------------------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"output_type":"stream","name":"stdout","text":["2022-02-16 19:26:13,316 epoch 21 - iter 1/12 - loss 0.78904325 - samples/sec: 199.87 - lr: 0.012500\n","2022-02-16 19:26:13,390 epoch 21 - iter 2/12 - loss 0.73280984 - samples/sec: 456.24 - lr: 0.012500\n","2022-02-16 19:26:13,473 epoch 21 - iter 3/12 - loss 0.69046350 - samples/sec: 494.83 - lr: 0.012500\n","2022-02-16 19:26:13,557 epoch 21 - iter 4/12 - loss 0.68312338 - samples/sec: 410.72 - lr: 0.012500\n","2022-02-16 19:26:13,637 epoch 21 - iter 5/12 - loss 0.71151522 - samples/sec: 493.93 - lr: 0.012500\n","2022-02-16 19:26:13,722 epoch 21 - iter 6/12 - loss 0.69147229 - samples/sec: 522.24 - lr: 0.012500\n","2022-02-16 19:26:13,799 epoch 21 - iter 7/12 - loss 0.69793659 - samples/sec: 452.74 - lr: 0.012500\n","2022-02-16 19:26:13,866 epoch 21 - iter 8/12 - loss 0.69045503 - samples/sec: 538.26 - lr: 0.012500\n","2022-02-16 19:26:13,944 epoch 21 - iter 9/12 - loss 0.69010472 - samples/sec: 429.32 - lr: 0.012500\n","2022-02-16 19:26:14,009 epoch 21 - iter 10/12 - loss 0.68616837 - samples/sec: 503.14 - lr: 0.012500\n","2022-02-16 19:26:14,093 epoch 21 - iter 11/12 - loss 0.67793423 - samples/sec: 448.98 - lr: 0.012500\n","2022-02-16 19:26:14,116 epoch 21 - iter 12/12 - loss 0.70585309 - samples/sec: 1522.87 - lr: 0.012500\n","2022-02-16 19:26:14,669 ----------------------------------------------------------------------------------------------------\n","2022-02-16 19:26:14,671 EPOCH 21 done: loss 0.7059 - lr 0.0125000\n","2022-02-16 19:26:16,277 DEV : loss 0.8238097429275513 - score 0.575\n","2022-02-16 19:26:16,320 BAD EPOCHS (no improvement): 1\n","2022-02-16 19:26:16,329 ----------------------------------------------------------------------------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"output_type":"stream","name":"stdout","text":["2022-02-16 19:26:17,569 epoch 22 - iter 1/12 - loss 0.86765116 - samples/sec: 172.64 - lr: 0.012500\n","2022-02-16 19:26:17,660 epoch 22 - iter 2/12 - loss 0.66595820 - samples/sec: 367.43 - lr: 0.012500\n","2022-02-16 19:26:17,744 epoch 22 - iter 3/12 - loss 0.62237225 - samples/sec: 446.10 - lr: 0.012500\n","2022-02-16 19:26:17,958 epoch 22 - iter 4/12 - loss 0.62888166 - samples/sec: 168.81 - lr: 0.012500\n","2022-02-16 19:26:18,154 epoch 22 - iter 5/12 - loss 0.61312467 - samples/sec: 212.97 - lr: 0.012500\n","2022-02-16 19:26:18,403 epoch 22 - iter 6/12 - loss 0.64152711 - samples/sec: 152.75 - lr: 0.012500\n","2022-02-16 19:26:18,537 epoch 22 - iter 7/12 - loss 0.65009483 - samples/sec: 266.99 - lr: 0.012500\n","2022-02-16 19:26:18,658 epoch 22 - iter 8/12 - loss 0.65441653 - samples/sec: 277.43 - lr: 0.012500\n","2022-02-16 19:26:18,782 epoch 22 - iter 9/12 - loss 0.66259382 - samples/sec: 266.15 - lr: 0.012500\n","2022-02-16 19:26:18,908 epoch 22 - iter 10/12 - loss 0.67347845 - samples/sec: 290.21 - lr: 0.012500\n","2022-02-16 19:26:19,028 epoch 22 - iter 11/12 - loss 0.67439185 - samples/sec: 318.14 - lr: 0.012500\n","2022-02-16 19:26:19,062 epoch 22 - iter 12/12 - loss 0.72616976 - samples/sec: 1107.60 - lr: 0.012500\n","2022-02-16 19:26:19,863 ----------------------------------------------------------------------------------------------------\n","2022-02-16 19:26:19,872 EPOCH 22 done: loss 0.7262 - lr 0.0125000\n","2022-02-16 19:26:22,483 DEV : loss 0.8081166744232178 - score 0.575\n","2022-02-16 19:26:22,572 BAD EPOCHS (no improvement): 2\n","2022-02-16 19:26:22,593 ----------------------------------------------------------------------------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"output_type":"stream","name":"stdout","text":["2022-02-16 19:26:24,672 epoch 23 - iter 1/12 - loss 0.58853883 - samples/sec: 125.36 - lr: 0.012500\n","2022-02-16 19:26:24,841 epoch 23 - iter 2/12 - loss 0.61207566 - samples/sec: 195.19 - lr: 0.012500\n","2022-02-16 19:26:25,006 epoch 23 - iter 3/12 - loss 0.69020615 - samples/sec: 200.03 - lr: 0.012500\n","2022-02-16 19:26:25,165 epoch 23 - iter 4/12 - loss 0.66928115 - samples/sec: 215.13 - lr: 0.012500\n","2022-02-16 19:26:25,317 epoch 23 - iter 5/12 - loss 0.68321143 - samples/sec: 238.87 - lr: 0.012500\n","2022-02-16 19:26:25,535 epoch 23 - iter 6/12 - loss 0.66603947 - samples/sec: 198.87 - lr: 0.012500\n","2022-02-16 19:26:25,791 epoch 23 - iter 7/12 - loss 0.66226224 - samples/sec: 129.96 - lr: 0.012500\n","2022-02-16 19:26:25,970 epoch 23 - iter 8/12 - loss 0.65984517 - samples/sec: 183.19 - lr: 0.012500\n","2022-02-16 19:26:26,111 epoch 23 - iter 9/12 - loss 0.66415808 - samples/sec: 259.95 - lr: 0.012500\n","2022-02-16 19:26:26,266 epoch 23 - iter 10/12 - loss 0.68615588 - samples/sec: 219.16 - lr: 0.012500\n","2022-02-16 19:26:26,463 epoch 23 - iter 11/12 - loss 0.69068098 - samples/sec: 170.30 - lr: 0.012500\n","2022-02-16 19:26:26,497 epoch 23 - iter 12/12 - loss 0.67651820 - samples/sec: 1202.04 - lr: 0.012500\n","2022-02-16 19:26:27,251 ----------------------------------------------------------------------------------------------------\n","2022-02-16 19:26:27,258 EPOCH 23 done: loss 0.6765 - lr 0.0125000\n","2022-02-16 19:26:30,190 DEV : loss 0.8037258386611938 - score 0.55\n","2022-02-16 19:26:30,305 BAD EPOCHS (no improvement): 3\n","2022-02-16 19:26:30,314 ----------------------------------------------------------------------------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"output_type":"stream","name":"stdout","text":["2022-02-16 19:26:32,349 epoch 24 - iter 1/12 - loss 0.62890393 - samples/sec: 68.82 - lr: 0.012500\n","2022-02-16 19:26:32,451 epoch 24 - iter 2/12 - loss 0.61781225 - samples/sec: 434.53 - lr: 0.012500\n","2022-02-16 19:26:32,534 epoch 24 - iter 3/12 - loss 0.58917179 - samples/sec: 505.60 - lr: 0.012500\n","2022-02-16 19:26:32,633 epoch 24 - iter 4/12 - loss 0.59067492 - samples/sec: 402.20 - lr: 0.012500\n","2022-02-16 19:26:32,704 epoch 24 - iter 5/12 - loss 0.61630422 - samples/sec: 470.80 - lr: 0.012500\n","2022-02-16 19:26:32,777 epoch 24 - iter 6/12 - loss 0.63135598 - samples/sec: 478.23 - lr: 0.012500\n","2022-02-16 19:26:32,849 epoch 24 - iter 7/12 - loss 0.63901280 - samples/sec: 462.56 - lr: 0.012500\n","2022-02-16 19:26:32,919 epoch 24 - iter 8/12 - loss 0.65295950 - samples/sec: 476.55 - lr: 0.012500\n","2022-02-16 19:26:32,991 epoch 24 - iter 9/12 - loss 0.65929959 - samples/sec: 494.95 - lr: 0.012500\n","2022-02-16 19:26:33,064 epoch 24 - iter 10/12 - loss 0.67320370 - samples/sec: 520.56 - lr: 0.012500\n","2022-02-16 19:26:33,138 epoch 24 - iter 11/12 - loss 0.67909659 - samples/sec: 445.50 - lr: 0.012500\n","2022-02-16 19:26:33,161 epoch 24 - iter 12/12 - loss 0.74514574 - samples/sec: 1592.56 - lr: 0.012500\n","2022-02-16 19:26:33,671 ----------------------------------------------------------------------------------------------------\n","2022-02-16 19:26:33,678 EPOCH 24 done: loss 0.7451 - lr 0.0125000\n","2022-02-16 19:26:35,288 DEV : loss 0.7994579076766968 - score 0.55\n","Epoch    24: reducing learning rate of group 0 to 6.2500e-03.\n","2022-02-16 19:26:35,338 BAD EPOCHS (no improvement): 4\n","2022-02-16 19:26:35,346 ----------------------------------------------------------------------------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"output_type":"stream","name":"stdout","text":["2022-02-16 19:26:36,504 epoch 25 - iter 1/12 - loss 0.71886992 - samples/sec: 140.16 - lr: 0.006250\n","2022-02-16 19:26:36,585 epoch 25 - iter 2/12 - loss 0.68113649 - samples/sec: 488.34 - lr: 0.006250\n","2022-02-16 19:26:36,665 epoch 25 - iter 3/12 - loss 0.68883048 - samples/sec: 452.56 - lr: 0.006250\n","2022-02-16 19:26:36,772 epoch 25 - iter 4/12 - loss 0.69726233 - samples/sec: 373.95 - lr: 0.006250\n","2022-02-16 19:26:36,849 epoch 25 - iter 5/12 - loss 0.67897971 - samples/sec: 426.36 - lr: 0.006250\n","2022-02-16 19:26:36,924 epoch 25 - iter 6/12 - loss 0.69446114 - samples/sec: 535.22 - lr: 0.006250\n","2022-02-16 19:26:36,994 epoch 25 - iter 7/12 - loss 0.68565414 - samples/sec: 525.89 - lr: 0.006250\n","2022-02-16 19:26:37,069 epoch 25 - iter 8/12 - loss 0.68903113 - samples/sec: 458.28 - lr: 0.006250\n","2022-02-16 19:26:37,131 epoch 25 - iter 9/12 - loss 0.67131841 - samples/sec: 550.33 - lr: 0.006250\n","2022-02-16 19:26:37,201 epoch 25 - iter 10/12 - loss 0.66667890 - samples/sec: 570.40 - lr: 0.006250\n","2022-02-16 19:26:37,273 epoch 25 - iter 11/12 - loss 0.66905774 - samples/sec: 486.86 - lr: 0.006250\n","2022-02-16 19:26:37,294 epoch 25 - iter 12/12 - loss 0.64159339 - samples/sec: 1736.57 - lr: 0.006250\n","2022-02-16 19:26:37,824 ----------------------------------------------------------------------------------------------------\n","2022-02-16 19:26:37,830 EPOCH 25 done: loss 0.6416 - lr 0.0062500\n","2022-02-16 19:26:39,515 DEV : loss 0.7910913228988647 - score 0.65\n","2022-02-16 19:26:39,563 BAD EPOCHS (no improvement): 0\n","saving best model\n","2022-02-16 19:26:54,869 ----------------------------------------------------------------------------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"output_type":"stream","name":"stdout","text":["2022-02-16 19:26:56,384 epoch 26 - iter 1/12 - loss 0.62827432 - samples/sec: 303.74 - lr: 0.006250\n","2022-02-16 19:26:56,461 epoch 26 - iter 2/12 - loss 0.63923317 - samples/sec: 440.49 - lr: 0.006250\n","2022-02-16 19:26:56,531 epoch 26 - iter 3/12 - loss 0.64030691 - samples/sec: 484.80 - lr: 0.006250\n","2022-02-16 19:26:56,622 epoch 26 - iter 4/12 - loss 0.65208456 - samples/sec: 422.16 - lr: 0.006250\n","2022-02-16 19:26:56,695 epoch 26 - iter 5/12 - loss 0.61663935 - samples/sec: 508.42 - lr: 0.006250\n","2022-02-16 19:26:56,779 epoch 26 - iter 6/12 - loss 0.61437783 - samples/sec: 554.03 - lr: 0.006250\n","2022-02-16 19:26:56,856 epoch 26 - iter 7/12 - loss 0.63222268 - samples/sec: 434.37 - lr: 0.006250\n","2022-02-16 19:26:56,924 epoch 26 - iter 8/12 - loss 0.63465535 - samples/sec: 512.38 - lr: 0.006250\n","2022-02-16 19:26:56,995 epoch 26 - iter 9/12 - loss 0.65724179 - samples/sec: 460.84 - lr: 0.006250\n","2022-02-16 19:26:57,058 epoch 26 - iter 10/12 - loss 0.67224973 - samples/sec: 526.96 - lr: 0.006250\n","2022-02-16 19:26:57,131 epoch 26 - iter 11/12 - loss 0.67160052 - samples/sec: 518.52 - lr: 0.006250\n","2022-02-16 19:26:57,153 epoch 26 - iter 12/12 - loss 0.67746326 - samples/sec: 1664.41 - lr: 0.006250\n","2022-02-16 19:26:57,733 ----------------------------------------------------------------------------------------------------\n","2022-02-16 19:26:57,735 EPOCH 26 done: loss 0.6775 - lr 0.0062500\n","2022-02-16 19:26:59,377 DEV : loss 0.7921041250228882 - score 0.65\n","2022-02-16 19:26:59,421 BAD EPOCHS (no improvement): 1\n","2022-02-16 19:26:59,428 ----------------------------------------------------------------------------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"output_type":"stream","name":"stdout","text":["2022-02-16 19:27:00,625 epoch 27 - iter 1/12 - loss 0.68077534 - samples/sec: 150.48 - lr: 0.006250\n","2022-02-16 19:27:00,711 epoch 27 - iter 2/12 - loss 0.61331132 - samples/sec: 485.79 - lr: 0.006250\n","2022-02-16 19:27:00,797 epoch 27 - iter 3/12 - loss 0.61589791 - samples/sec: 504.36 - lr: 0.006250\n","2022-02-16 19:27:00,875 epoch 27 - iter 4/12 - loss 0.63902782 - samples/sec: 468.23 - lr: 0.006250\n","2022-02-16 19:27:00,943 epoch 27 - iter 5/12 - loss 0.65143764 - samples/sec: 488.15 - lr: 0.006250\n","2022-02-16 19:27:01,030 epoch 27 - iter 6/12 - loss 0.65383773 - samples/sec: 481.94 - lr: 0.006250\n","2022-02-16 19:27:01,097 epoch 27 - iter 7/12 - loss 0.68204352 - samples/sec: 490.74 - lr: 0.006250\n","2022-02-16 19:27:01,169 epoch 27 - iter 8/12 - loss 0.68696697 - samples/sec: 517.98 - lr: 0.006250\n","2022-02-16 19:27:01,238 epoch 27 - iter 9/12 - loss 0.67114499 - samples/sec: 480.72 - lr: 0.006250\n","2022-02-16 19:27:01,307 epoch 27 - iter 10/12 - loss 0.67735133 - samples/sec: 572.72 - lr: 0.006250\n","2022-02-16 19:27:01,376 epoch 27 - iter 11/12 - loss 0.66702671 - samples/sec: 520.21 - lr: 0.006250\n","2022-02-16 19:27:01,405 epoch 27 - iter 12/12 - loss 0.65934034 - samples/sec: 1374.65 - lr: 0.006250\n","2022-02-16 19:27:01,874 ----------------------------------------------------------------------------------------------------\n","2022-02-16 19:27:01,881 EPOCH 27 done: loss 0.6593 - lr 0.0062500\n","2022-02-16 19:27:03,590 DEV : loss 0.7925406098365784 - score 0.6\n","2022-02-16 19:27:03,720 BAD EPOCHS (no improvement): 2\n","2022-02-16 19:27:03,738 ----------------------------------------------------------------------------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"output_type":"stream","name":"stdout","text":["2022-02-16 19:27:05,839 epoch 28 - iter 1/12 - loss 0.58013666 - samples/sec: 109.83 - lr: 0.006250\n","2022-02-16 19:27:06,064 epoch 28 - iter 2/12 - loss 0.59559077 - samples/sec: 182.73 - lr: 0.006250\n","2022-02-16 19:27:06,388 epoch 28 - iter 3/12 - loss 0.62822813 - samples/sec: 112.45 - lr: 0.006250\n","2022-02-16 19:27:06,609 epoch 28 - iter 4/12 - loss 0.61966024 - samples/sec: 149.81 - lr: 0.006250\n","2022-02-16 19:27:06,798 epoch 28 - iter 5/12 - loss 0.67596383 - samples/sec: 182.79 - lr: 0.006250\n","2022-02-16 19:27:06,944 epoch 28 - iter 6/12 - loss 0.64880137 - samples/sec: 344.37 - lr: 0.006250\n","2022-02-16 19:27:07,078 epoch 28 - iter 7/12 - loss 0.65382899 - samples/sec: 252.32 - lr: 0.006250\n","2022-02-16 19:27:07,221 epoch 28 - iter 8/12 - loss 0.64457494 - samples/sec: 236.43 - lr: 0.006250\n","2022-02-16 19:27:07,404 epoch 28 - iter 9/12 - loss 0.64701217 - samples/sec: 252.65 - lr: 0.006250\n","2022-02-16 19:27:07,556 epoch 28 - iter 10/12 - loss 0.65966753 - samples/sec: 226.54 - lr: 0.006250\n","2022-02-16 19:27:07,677 epoch 28 - iter 11/12 - loss 0.66739540 - samples/sec: 276.21 - lr: 0.006250\n","2022-02-16 19:27:07,714 epoch 28 - iter 12/12 - loss 0.67220726 - samples/sec: 1025.21 - lr: 0.006250\n","2022-02-16 19:27:08,434 ----------------------------------------------------------------------------------------------------\n","2022-02-16 19:27:08,444 EPOCH 28 done: loss 0.6722 - lr 0.0062500\n","2022-02-16 19:27:11,243 DEV : loss 0.7943075895309448 - score 0.625\n","2022-02-16 19:27:11,353 BAD EPOCHS (no improvement): 3\n","2022-02-16 19:27:11,367 ----------------------------------------------------------------------------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"output_type":"stream","name":"stdout","text":["2022-02-16 19:27:13,304 epoch 29 - iter 1/12 - loss 0.58886868 - samples/sec: 119.37 - lr: 0.006250\n","2022-02-16 19:27:13,453 epoch 29 - iter 2/12 - loss 0.62711346 - samples/sec: 231.35 - lr: 0.006250\n","2022-02-16 19:27:13,586 epoch 29 - iter 3/12 - loss 0.66349137 - samples/sec: 259.87 - lr: 0.006250\n","2022-02-16 19:27:13,738 epoch 29 - iter 4/12 - loss 0.64973861 - samples/sec: 243.80 - lr: 0.006250\n","2022-02-16 19:27:13,923 epoch 29 - iter 5/12 - loss 0.68042629 - samples/sec: 234.65 - lr: 0.006250\n","2022-02-16 19:27:14,074 epoch 29 - iter 6/12 - loss 0.67206190 - samples/sec: 257.98 - lr: 0.006250\n","2022-02-16 19:27:14,210 epoch 29 - iter 7/12 - loss 0.64634396 - samples/sec: 255.89 - lr: 0.006250\n","2022-02-16 19:27:14,343 epoch 29 - iter 8/12 - loss 0.63997585 - samples/sec: 263.85 - lr: 0.006250\n","2022-02-16 19:27:14,530 epoch 29 - iter 9/12 - loss 0.64378738 - samples/sec: 175.13 - lr: 0.006250\n","2022-02-16 19:27:14,761 epoch 29 - iter 10/12 - loss 0.65722928 - samples/sec: 140.81 - lr: 0.006250\n","2022-02-16 19:27:14,967 epoch 29 - iter 11/12 - loss 0.65477702 - samples/sec: 176.48 - lr: 0.006250\n","2022-02-16 19:27:15,005 epoch 29 - iter 12/12 - loss 0.64089079 - samples/sec: 1097.43 - lr: 0.006250\n","2022-02-16 19:27:15,649 ----------------------------------------------------------------------------------------------------\n","2022-02-16 19:27:15,657 EPOCH 29 done: loss 0.6409 - lr 0.0062500\n","2022-02-16 19:27:17,667 DEV : loss 0.7995345592498779 - score 0.6\n","Epoch    29: reducing learning rate of group 0 to 3.1250e-03.\n","2022-02-16 19:27:17,713 BAD EPOCHS (no improvement): 4\n","2022-02-16 19:27:17,722 ----------------------------------------------------------------------------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"output_type":"stream","name":"stdout","text":["2022-02-16 19:27:18,858 epoch 30 - iter 1/12 - loss 0.67756057 - samples/sec: 141.55 - lr: 0.003125\n","2022-02-16 19:27:18,949 epoch 30 - iter 2/12 - loss 0.68392155 - samples/sec: 506.15 - lr: 0.003125\n","2022-02-16 19:27:19,020 epoch 30 - iter 3/12 - loss 0.68852774 - samples/sec: 518.80 - lr: 0.003125\n","2022-02-16 19:27:19,123 epoch 30 - iter 4/12 - loss 0.66330139 - samples/sec: 426.71 - lr: 0.003125\n","2022-02-16 19:27:19,195 epoch 30 - iter 5/12 - loss 0.66003458 - samples/sec: 461.94 - lr: 0.003125\n","2022-02-16 19:27:19,268 epoch 30 - iter 6/12 - loss 0.65761613 - samples/sec: 450.52 - lr: 0.003125\n","2022-02-16 19:27:19,341 epoch 30 - iter 7/12 - loss 0.69361028 - samples/sec: 465.25 - lr: 0.003125\n","2022-02-16 19:27:19,415 epoch 30 - iter 8/12 - loss 0.69092193 - samples/sec: 441.11 - lr: 0.003125\n","2022-02-16 19:27:19,485 epoch 30 - iter 9/12 - loss 0.69517035 - samples/sec: 471.79 - lr: 0.003125\n","2022-02-16 19:27:19,558 epoch 30 - iter 10/12 - loss 0.68346159 - samples/sec: 478.57 - lr: 0.003125\n","2022-02-16 19:27:19,624 epoch 30 - iter 11/12 - loss 0.66999013 - samples/sec: 502.40 - lr: 0.003125\n","2022-02-16 19:27:19,648 epoch 30 - iter 12/12 - loss 0.64007413 - samples/sec: 1630.72 - lr: 0.003125\n","2022-02-16 19:27:20,066 ----------------------------------------------------------------------------------------------------\n","2022-02-16 19:27:20,074 EPOCH 30 done: loss 0.6401 - lr 0.0031250\n","2022-02-16 19:27:21,508 DEV : loss 0.7920525074005127 - score 0.625\n","2022-02-16 19:27:21,554 BAD EPOCHS (no improvement): 1\n","2022-02-16 19:27:21,566 ----------------------------------------------------------------------------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"output_type":"stream","name":"stdout","text":["2022-02-16 19:27:22,718 epoch 31 - iter 1/12 - loss 0.72767931 - samples/sec: 406.67 - lr: 0.003125\n","2022-02-16 19:27:22,791 epoch 31 - iter 2/12 - loss 0.62798923 - samples/sec: 470.59 - lr: 0.003125\n","2022-02-16 19:27:22,870 epoch 31 - iter 3/12 - loss 0.66965950 - samples/sec: 423.31 - lr: 0.003125\n","2022-02-16 19:27:22,935 epoch 31 - iter 4/12 - loss 0.64930727 - samples/sec: 544.92 - lr: 0.003125\n","2022-02-16 19:27:23,009 epoch 31 - iter 5/12 - loss 0.62983561 - samples/sec: 452.10 - lr: 0.003125\n","2022-02-16 19:27:23,072 epoch 31 - iter 6/12 - loss 0.63234033 - samples/sec: 572.03 - lr: 0.003125\n","2022-02-16 19:27:24,733 epoch 31 - iter 7/12 - loss 0.62419597 - samples/sec: 483.81 - lr: 0.003125\n","2022-02-16 19:27:24,794 epoch 31 - iter 8/12 - loss 0.61090928 - samples/sec: 543.93 - lr: 0.003125\n","2022-02-16 19:27:24,859 epoch 31 - iter 9/12 - loss 0.62203810 - samples/sec: 508.10 - lr: 0.003125\n","2022-02-16 19:27:24,928 epoch 31 - iter 10/12 - loss 0.63143423 - samples/sec: 478.97 - lr: 0.003125\n","2022-02-16 19:27:24,992 epoch 31 - iter 11/12 - loss 0.65740488 - samples/sec: 525.12 - lr: 0.003125\n","2022-02-16 19:27:25,015 epoch 31 - iter 12/12 - loss 0.63002754 - samples/sec: 1604.92 - lr: 0.003125\n","2022-02-16 19:27:25,488 ----------------------------------------------------------------------------------------------------\n","2022-02-16 19:27:25,490 EPOCH 31 done: loss 0.6300 - lr 0.0031250\n","2022-02-16 19:27:26,933 DEV : loss 0.7920268774032593 - score 0.625\n","2022-02-16 19:27:26,974 BAD EPOCHS (no improvement): 2\n","2022-02-16 19:27:26,983 ----------------------------------------------------------------------------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"output_type":"stream","name":"stdout","text":["2022-02-16 19:27:28,097 epoch 32 - iter 1/12 - loss 0.70658737 - samples/sec: 168.43 - lr: 0.003125\n","2022-02-16 19:27:28,183 epoch 32 - iter 2/12 - loss 0.68820938 - samples/sec: 435.91 - lr: 0.003125\n","2022-02-16 19:27:28,265 epoch 32 - iter 3/12 - loss 0.70036815 - samples/sec: 536.13 - lr: 0.003125\n","2022-02-16 19:27:28,342 epoch 32 - iter 4/12 - loss 0.65382819 - samples/sec: 481.63 - lr: 0.003125\n","2022-02-16 19:27:28,441 epoch 32 - iter 5/12 - loss 0.65535951 - samples/sec: 391.37 - lr: 0.003125\n","2022-02-16 19:27:28,513 epoch 32 - iter 6/12 - loss 0.67752255 - samples/sec: 502.74 - lr: 0.003125\n","2022-02-16 19:27:28,583 epoch 32 - iter 7/12 - loss 0.67421345 - samples/sec: 474.71 - lr: 0.003125\n","2022-02-16 19:27:28,662 epoch 32 - iter 8/12 - loss 0.66288871 - samples/sec: 482.08 - lr: 0.003125\n","2022-02-16 19:27:28,737 epoch 32 - iter 9/12 - loss 0.69528741 - samples/sec: 501.57 - lr: 0.003125\n","2022-02-16 19:27:28,813 epoch 32 - iter 10/12 - loss 0.69473564 - samples/sec: 433.66 - lr: 0.003125\n","2022-02-16 19:27:28,884 epoch 32 - iter 11/12 - loss 0.67208126 - samples/sec: 470.63 - lr: 0.003125\n","2022-02-16 19:27:28,910 epoch 32 - iter 12/12 - loss 0.65719674 - samples/sec: 1496.86 - lr: 0.003125\n","2022-02-16 19:27:29,338 ----------------------------------------------------------------------------------------------------\n","2022-02-16 19:27:29,343 EPOCH 32 done: loss 0.6572 - lr 0.0031250\n","2022-02-16 19:27:30,733 DEV : loss 0.7935653924942017 - score 0.625\n","2022-02-16 19:27:30,777 BAD EPOCHS (no improvement): 3\n","2022-02-16 19:27:30,787 ----------------------------------------------------------------------------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"output_type":"stream","name":"stdout","text":["2022-02-16 19:27:31,900 epoch 33 - iter 1/12 - loss 0.79651284 - samples/sec: 137.55 - lr: 0.003125\n","2022-02-16 19:27:31,979 epoch 33 - iter 2/12 - loss 0.70637697 - samples/sec: 486.19 - lr: 0.003125\n","2022-02-16 19:27:32,086 epoch 33 - iter 3/12 - loss 0.65719434 - samples/sec: 430.68 - lr: 0.003125\n","2022-02-16 19:27:32,154 epoch 33 - iter 4/12 - loss 0.62356839 - samples/sec: 489.48 - lr: 0.003125\n","2022-02-16 19:27:32,229 epoch 33 - iter 5/12 - loss 0.64564769 - samples/sec: 473.60 - lr: 0.003125\n","2022-02-16 19:27:32,297 epoch 33 - iter 6/12 - loss 0.62131937 - samples/sec: 483.54 - lr: 0.003125\n","2022-02-16 19:27:32,377 epoch 33 - iter 7/12 - loss 0.63096301 - samples/sec: 413.42 - lr: 0.003125\n","2022-02-16 19:27:32,449 epoch 33 - iter 8/12 - loss 0.65363869 - samples/sec: 452.88 - lr: 0.003125\n","2022-02-16 19:27:32,521 epoch 33 - iter 9/12 - loss 0.66934404 - samples/sec: 534.84 - lr: 0.003125\n","2022-02-16 19:27:32,586 epoch 33 - iter 10/12 - loss 0.65527411 - samples/sec: 507.91 - lr: 0.003125\n","2022-02-16 19:27:32,664 epoch 33 - iter 11/12 - loss 0.65525340 - samples/sec: 462.98 - lr: 0.003125\n","2022-02-16 19:27:32,692 epoch 33 - iter 12/12 - loss 0.70919100 - samples/sec: 1351.95 - lr: 0.003125\n","2022-02-16 19:27:33,116 ----------------------------------------------------------------------------------------------------\n","2022-02-16 19:27:33,125 EPOCH 33 done: loss 0.7092 - lr 0.0031250\n","2022-02-16 19:27:34,547 DEV : loss 0.786449134349823 - score 0.65\n","2022-02-16 19:27:34,597 BAD EPOCHS (no improvement): 0\n","saving best model\n","2022-02-16 19:27:50,127 ----------------------------------------------------------------------------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"output_type":"stream","name":"stdout","text":["2022-02-16 19:27:51,470 epoch 34 - iter 1/12 - loss 0.57670480 - samples/sec: 147.82 - lr: 0.003125\n","2022-02-16 19:27:51,559 epoch 34 - iter 2/12 - loss 0.68110406 - samples/sec: 463.61 - lr: 0.003125\n","2022-02-16 19:27:51,650 epoch 34 - iter 3/12 - loss 0.65632365 - samples/sec: 453.18 - lr: 0.003125\n","2022-02-16 19:27:51,733 epoch 34 - iter 4/12 - loss 0.66259657 - samples/sec: 404.84 - lr: 0.003125\n","2022-02-16 19:27:51,821 epoch 34 - iter 5/12 - loss 0.66926696 - samples/sec: 370.27 - lr: 0.003125\n","2022-02-16 19:27:51,889 epoch 34 - iter 6/12 - loss 0.67309070 - samples/sec: 590.66 - lr: 0.003125\n","2022-02-16 19:27:51,963 epoch 34 - iter 7/12 - loss 0.66085486 - samples/sec: 448.55 - lr: 0.003125\n","2022-02-16 19:27:52,046 epoch 34 - iter 8/12 - loss 0.67224143 - samples/sec: 504.27 - lr: 0.003125\n","2022-02-16 19:27:52,113 epoch 34 - iter 9/12 - loss 0.66670186 - samples/sec: 511.49 - lr: 0.003125\n","2022-02-16 19:27:52,191 epoch 34 - iter 10/12 - loss 0.66035561 - samples/sec: 418.50 - lr: 0.003125\n","2022-02-16 19:27:52,266 epoch 34 - iter 11/12 - loss 0.66216019 - samples/sec: 463.93 - lr: 0.003125\n","2022-02-16 19:27:52,289 epoch 34 - iter 12/12 - loss 0.68092006 - samples/sec: 1508.86 - lr: 0.003125\n","2022-02-16 19:27:52,787 ----------------------------------------------------------------------------------------------------\n","2022-02-16 19:27:52,790 EPOCH 34 done: loss 0.6809 - lr 0.0031250\n","2022-02-16 19:27:54,517 DEV : loss 0.788538932800293 - score 0.65\n","2022-02-16 19:27:54,561 BAD EPOCHS (no improvement): 1\n","2022-02-16 19:27:54,574 ----------------------------------------------------------------------------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"output_type":"stream","name":"stdout","text":["2022-02-16 19:27:55,847 epoch 35 - iter 1/12 - loss 0.78897065 - samples/sec: 169.30 - lr: 0.003125\n","2022-02-16 19:27:55,942 epoch 35 - iter 2/12 - loss 0.70406064 - samples/sec: 407.16 - lr: 0.003125\n","2022-02-16 19:27:56,028 epoch 35 - iter 3/12 - loss 0.70863012 - samples/sec: 431.18 - lr: 0.003125\n","2022-02-16 19:27:56,121 epoch 35 - iter 4/12 - loss 0.71796565 - samples/sec: 450.48 - lr: 0.003125\n","2022-02-16 19:27:56,202 epoch 35 - iter 5/12 - loss 0.72379922 - samples/sec: 436.21 - lr: 0.003125\n","2022-02-16 19:27:56,296 epoch 35 - iter 6/12 - loss 0.70282418 - samples/sec: 451.13 - lr: 0.003125\n","2022-02-16 19:27:56,368 epoch 35 - iter 7/12 - loss 0.67253577 - samples/sec: 458.85 - lr: 0.003125\n","2022-02-16 19:27:56,436 epoch 35 - iter 8/12 - loss 0.65998336 - samples/sec: 494.41 - lr: 0.003125\n","2022-02-16 19:27:56,521 epoch 35 - iter 9/12 - loss 0.66306881 - samples/sec: 394.77 - lr: 0.003125\n","2022-02-16 19:27:56,594 epoch 35 - iter 10/12 - loss 0.66503218 - samples/sec: 458.45 - lr: 0.003125\n","2022-02-16 19:27:56,667 epoch 35 - iter 11/12 - loss 0.66970502 - samples/sec: 460.77 - lr: 0.003125\n","2022-02-16 19:27:56,692 epoch 35 - iter 12/12 - loss 0.69058432 - samples/sec: 1668.94 - lr: 0.003125\n","2022-02-16 19:27:57,180 ----------------------------------------------------------------------------------------------------\n","2022-02-16 19:27:57,184 EPOCH 35 done: loss 0.6906 - lr 0.0031250\n","2022-02-16 19:27:58,761 DEV : loss 0.7872284650802612 - score 0.65\n","2022-02-16 19:27:58,803 BAD EPOCHS (no improvement): 2\n","2022-02-16 19:27:58,812 ----------------------------------------------------------------------------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"output_type":"stream","name":"stdout","text":["2022-02-16 19:28:01,314 epoch 36 - iter 1/12 - loss 0.62126791 - samples/sec: 83.63 - lr: 0.003125\n","2022-02-16 19:28:01,563 epoch 36 - iter 2/12 - loss 0.62199217 - samples/sec: 138.23 - lr: 0.003125\n","2022-02-16 19:28:01,755 epoch 36 - iter 3/12 - loss 0.64426951 - samples/sec: 173.62 - lr: 0.003125\n","2022-02-16 19:28:01,986 epoch 36 - iter 4/12 - loss 0.61632051 - samples/sec: 159.90 - lr: 0.003125\n","2022-02-16 19:28:02,220 epoch 36 - iter 5/12 - loss 0.61880575 - samples/sec: 153.18 - lr: 0.003125\n","2022-02-16 19:28:02,457 epoch 36 - iter 6/12 - loss 0.65369463 - samples/sec: 197.50 - lr: 0.003125\n","2022-02-16 19:28:02,623 epoch 36 - iter 7/12 - loss 0.64425620 - samples/sec: 203.52 - lr: 0.003125\n","2022-02-16 19:28:02,770 epoch 36 - iter 8/12 - loss 0.66295412 - samples/sec: 224.62 - lr: 0.003125\n","2022-02-16 19:28:02,947 epoch 36 - iter 9/12 - loss 0.65941006 - samples/sec: 183.43 - lr: 0.003125\n","2022-02-16 19:28:03,097 epoch 36 - iter 10/12 - loss 0.65855642 - samples/sec: 218.62 - lr: 0.003125\n","2022-02-16 19:28:03,251 epoch 36 - iter 11/12 - loss 0.65779574 - samples/sec: 227.53 - lr: 0.003125\n","2022-02-16 19:28:03,291 epoch 36 - iter 12/12 - loss 0.66002056 - samples/sec: 1124.90 - lr: 0.003125\n","2022-02-16 19:28:04,086 ----------------------------------------------------------------------------------------------------\n","2022-02-16 19:28:04,095 EPOCH 36 done: loss 0.6600 - lr 0.0031250\n","2022-02-16 19:28:07,504 DEV : loss 0.789122462272644 - score 0.65\n","2022-02-16 19:28:07,661 BAD EPOCHS (no improvement): 3\n","2022-02-16 19:28:07,672 ----------------------------------------------------------------------------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"output_type":"stream","name":"stdout","text":["2022-02-16 19:28:10,131 epoch 37 - iter 1/12 - loss 0.53518331 - samples/sec: 93.83 - lr: 0.003125\n","2022-02-16 19:28:10,346 epoch 37 - iter 2/12 - loss 0.66204715 - samples/sec: 178.10 - lr: 0.003125\n","2022-02-16 19:28:10,595 epoch 37 - iter 3/12 - loss 0.63047105 - samples/sec: 131.61 - lr: 0.003125\n","2022-02-16 19:28:10,827 epoch 37 - iter 4/12 - loss 0.62559801 - samples/sec: 148.75 - lr: 0.003125\n","2022-02-16 19:28:11,059 epoch 37 - iter 5/12 - loss 0.64239676 - samples/sec: 162.55 - lr: 0.003125\n","2022-02-16 19:28:11,264 epoch 37 - iter 6/12 - loss 0.63389499 - samples/sec: 223.14 - lr: 0.003125\n","2022-02-16 19:28:11,452 epoch 37 - iter 7/12 - loss 0.63829749 - samples/sec: 178.40 - lr: 0.003125\n","2022-02-16 19:28:11,641 epoch 37 - iter 8/12 - loss 0.62706730 - samples/sec: 212.64 - lr: 0.003125\n","2022-02-16 19:28:11,859 epoch 37 - iter 9/12 - loss 0.63826050 - samples/sec: 156.69 - lr: 0.003125\n","2022-02-16 19:28:11,942 epoch 37 - iter 10/12 - loss 0.65410647 - samples/sec: 418.47 - lr: 0.003125\n","2022-02-16 19:28:12,014 epoch 37 - iter 11/12 - loss 0.65488758 - samples/sec: 464.69 - lr: 0.003125\n","2022-02-16 19:28:12,039 epoch 37 - iter 12/12 - loss 0.66040231 - samples/sec: 1578.18 - lr: 0.003125\n","2022-02-16 19:28:12,498 ----------------------------------------------------------------------------------------------------\n","2022-02-16 19:28:12,507 EPOCH 37 done: loss 0.6604 - lr 0.0031250\n","2022-02-16 19:28:14,080 DEV : loss 0.7864469885826111 - score 0.65\n","2022-02-16 19:28:14,124 BAD EPOCHS (no improvement): 0\n","saving best model\n","2022-02-16 19:28:29,719 ----------------------------------------------------------------------------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"output_type":"stream","name":"stdout","text":["2022-02-16 19:28:31,106 epoch 38 - iter 1/12 - loss 0.63574147 - samples/sec: 312.73 - lr: 0.003125\n","2022-02-16 19:28:31,181 epoch 38 - iter 2/12 - loss 0.69828457 - samples/sec: 450.83 - lr: 0.003125\n","2022-02-16 19:28:31,276 epoch 38 - iter 3/12 - loss 0.71229055 - samples/sec: 423.04 - lr: 0.003125\n","2022-02-16 19:28:31,344 epoch 38 - iter 4/12 - loss 0.66304033 - samples/sec: 496.37 - lr: 0.003125\n","2022-02-16 19:28:31,430 epoch 38 - iter 5/12 - loss 0.65850201 - samples/sec: 382.07 - lr: 0.003125\n","2022-02-16 19:28:31,515 epoch 38 - iter 6/12 - loss 0.70545228 - samples/sec: 560.99 - lr: 0.003125\n","2022-02-16 19:28:31,582 epoch 38 - iter 7/12 - loss 0.69661929 - samples/sec: 519.07 - lr: 0.003125\n","2022-02-16 19:28:31,656 epoch 38 - iter 8/12 - loss 0.67584525 - samples/sec: 443.57 - lr: 0.003125\n","2022-02-16 19:28:31,726 epoch 38 - iter 9/12 - loss 0.67383532 - samples/sec: 517.51 - lr: 0.003125\n","2022-02-16 19:28:31,795 epoch 38 - iter 10/12 - loss 0.66239229 - samples/sec: 481.14 - lr: 0.003125\n","2022-02-16 19:28:31,875 epoch 38 - iter 11/12 - loss 0.65365843 - samples/sec: 418.55 - lr: 0.003125\n","2022-02-16 19:28:31,899 epoch 38 - iter 12/12 - loss 0.68637302 - samples/sec: 1464.35 - lr: 0.003125\n","2022-02-16 19:28:32,427 ----------------------------------------------------------------------------------------------------\n","2022-02-16 19:28:32,431 EPOCH 38 done: loss 0.6864 - lr 0.0031250\n","2022-02-16 19:28:34,213 DEV : loss 0.7873278856277466 - score 0.6\n","2022-02-16 19:28:34,263 BAD EPOCHS (no improvement): 1\n","2022-02-16 19:28:34,271 ----------------------------------------------------------------------------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"output_type":"stream","name":"stdout","text":["2022-02-16 19:28:35,593 epoch 39 - iter 1/12 - loss 0.51316750 - samples/sec: 154.82 - lr: 0.003125\n","2022-02-16 19:28:35,677 epoch 39 - iter 2/12 - loss 0.60646921 - samples/sec: 479.69 - lr: 0.003125\n","2022-02-16 19:28:35,770 epoch 39 - iter 3/12 - loss 0.61088391 - samples/sec: 428.67 - lr: 0.003125\n","2022-02-16 19:28:35,859 epoch 39 - iter 4/12 - loss 0.66302763 - samples/sec: 464.18 - lr: 0.003125\n","2022-02-16 19:28:35,936 epoch 39 - iter 5/12 - loss 0.69099841 - samples/sec: 447.76 - lr: 0.003125\n","2022-02-16 19:28:36,019 epoch 39 - iter 6/12 - loss 0.66200943 - samples/sec: 503.09 - lr: 0.003125\n","2022-02-16 19:28:36,088 epoch 39 - iter 7/12 - loss 0.68779405 - samples/sec: 494.93 - lr: 0.003125\n","2022-02-16 19:28:36,161 epoch 39 - iter 8/12 - loss 0.68098629 - samples/sec: 471.87 - lr: 0.003125\n","2022-02-16 19:28:36,236 epoch 39 - iter 9/12 - loss 0.66256781 - samples/sec: 521.21 - lr: 0.003125\n","2022-02-16 19:28:36,310 epoch 39 - iter 10/12 - loss 0.64954669 - samples/sec: 504.43 - lr: 0.003125\n","2022-02-16 19:28:36,381 epoch 39 - iter 11/12 - loss 0.65070116 - samples/sec: 490.91 - lr: 0.003125\n","2022-02-16 19:28:36,401 epoch 39 - iter 12/12 - loss 0.69246225 - samples/sec: 1896.91 - lr: 0.003125\n","2022-02-16 19:28:36,922 ----------------------------------------------------------------------------------------------------\n","2022-02-16 19:28:36,929 EPOCH 39 done: loss 0.6925 - lr 0.0031250\n","2022-02-16 19:28:38,592 DEV : loss 0.7876337170600891 - score 0.575\n","2022-02-16 19:28:38,634 BAD EPOCHS (no improvement): 2\n","2022-02-16 19:28:38,643 ----------------------------------------------------------------------------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"output_type":"stream","name":"stdout","text":["2022-02-16 19:28:40,658 epoch 40 - iter 1/12 - loss 0.50407958 - samples/sec: 71.21 - lr: 0.003125\n","2022-02-16 19:28:40,869 epoch 40 - iter 2/12 - loss 0.65112722 - samples/sec: 208.93 - lr: 0.003125\n","2022-02-16 19:28:41,114 epoch 40 - iter 3/12 - loss 0.63308428 - samples/sec: 144.87 - lr: 0.003125\n","2022-02-16 19:28:41,259 epoch 40 - iter 4/12 - loss 0.63672450 - samples/sec: 239.08 - lr: 0.003125\n","2022-02-16 19:28:41,438 epoch 40 - iter 5/12 - loss 0.64691122 - samples/sec: 259.78 - lr: 0.003125\n","2022-02-16 19:28:41,564 epoch 40 - iter 6/12 - loss 0.64481750 - samples/sec: 286.72 - lr: 0.003125\n","2022-02-16 19:28:41,721 epoch 40 - iter 7/12 - loss 0.64202476 - samples/sec: 220.74 - lr: 0.003125\n","2022-02-16 19:28:41,898 epoch 40 - iter 8/12 - loss 0.65112711 - samples/sec: 184.45 - lr: 0.003125\n","2022-02-16 19:28:42,092 epoch 40 - iter 9/12 - loss 0.64612685 - samples/sec: 194.97 - lr: 0.003125\n","2022-02-16 19:28:42,270 epoch 40 - iter 10/12 - loss 0.65763086 - samples/sec: 221.37 - lr: 0.003125\n","2022-02-16 19:28:42,438 epoch 40 - iter 11/12 - loss 0.65184354 - samples/sec: 195.57 - lr: 0.003125\n","2022-02-16 19:28:42,470 epoch 40 - iter 12/12 - loss 0.70534345 - samples/sec: 1215.01 - lr: 0.003125\n","2022-02-16 19:28:43,166 ----------------------------------------------------------------------------------------------------\n","2022-02-16 19:28:43,176 EPOCH 40 done: loss 0.7053 - lr 0.0031250\n","2022-02-16 19:28:45,875 DEV : loss 0.7852253317832947 - score 0.6\n","2022-02-16 19:28:45,985 BAD EPOCHS (no improvement): 3\n","2022-02-16 19:28:45,994 ----------------------------------------------------------------------------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"output_type":"stream","name":"stdout","text":["2022-02-16 19:28:47,929 epoch 41 - iter 1/12 - loss 0.57245672 - samples/sec: 80.38 - lr: 0.003125\n","2022-02-16 19:28:48,189 epoch 41 - iter 2/12 - loss 0.63074878 - samples/sec: 154.72 - lr: 0.003125\n","2022-02-16 19:28:48,341 epoch 41 - iter 3/12 - loss 0.66445210 - samples/sec: 218.36 - lr: 0.003125\n","2022-02-16 19:28:48,514 epoch 41 - iter 4/12 - loss 0.65679406 - samples/sec: 191.90 - lr: 0.003125\n","2022-02-16 19:28:48,707 epoch 41 - iter 5/12 - loss 0.63565170 - samples/sec: 186.02 - lr: 0.003125\n","2022-02-16 19:28:48,905 epoch 41 - iter 6/12 - loss 0.63828327 - samples/sec: 206.13 - lr: 0.003125\n","2022-02-16 19:28:49,067 epoch 41 - iter 7/12 - loss 0.65136855 - samples/sec: 209.12 - lr: 0.003125\n","2022-02-16 19:28:49,240 epoch 41 - iter 8/12 - loss 0.65133759 - samples/sec: 219.44 - lr: 0.003125\n","2022-02-16 19:28:49,439 epoch 41 - iter 9/12 - loss 0.65895429 - samples/sec: 172.24 - lr: 0.003125\n","2022-02-16 19:28:49,634 epoch 41 - iter 10/12 - loss 0.66229923 - samples/sec: 171.22 - lr: 0.003125\n","2022-02-16 19:28:49,816 epoch 41 - iter 11/12 - loss 0.65489712 - samples/sec: 185.39 - lr: 0.003125\n","2022-02-16 19:28:49,853 epoch 41 - iter 12/12 - loss 0.62541463 - samples/sec: 1222.78 - lr: 0.003125\n","2022-02-16 19:28:50,520 ----------------------------------------------------------------------------------------------------\n","2022-02-16 19:28:50,529 EPOCH 41 done: loss 0.6254 - lr 0.0031250\n","2022-02-16 19:28:53,037 DEV : loss 0.7841647863388062 - score 0.6\n","Epoch    41: reducing learning rate of group 0 to 1.5625e-03.\n","2022-02-16 19:28:53,125 BAD EPOCHS (no improvement): 4\n","2022-02-16 19:28:53,142 ----------------------------------------------------------------------------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"output_type":"stream","name":"stdout","text":["2022-02-16 19:28:54,988 epoch 42 - iter 1/12 - loss 0.57050443 - samples/sec: 115.63 - lr: 0.001563\n","2022-02-16 19:28:55,160 epoch 42 - iter 2/12 - loss 0.63724920 - samples/sec: 195.50 - lr: 0.001563\n","2022-02-16 19:28:55,227 epoch 42 - iter 3/12 - loss 0.65706335 - samples/sec: 495.11 - lr: 0.001563\n","2022-02-16 19:28:55,304 epoch 42 - iter 4/12 - loss 0.62291740 - samples/sec: 422.78 - lr: 0.001563\n","2022-02-16 19:28:55,391 epoch 42 - iter 5/12 - loss 0.66385109 - samples/sec: 480.81 - lr: 0.001563\n","2022-02-16 19:28:55,460 epoch 42 - iter 6/12 - loss 0.66252560 - samples/sec: 528.81 - lr: 0.001563\n","2022-02-16 19:28:55,533 epoch 42 - iter 7/12 - loss 0.66858026 - samples/sec: 460.17 - lr: 0.001563\n","2022-02-16 19:28:55,597 epoch 42 - iter 8/12 - loss 0.66069458 - samples/sec: 534.37 - lr: 0.001563\n","2022-02-16 19:28:55,666 epoch 42 - iter 9/12 - loss 0.65184287 - samples/sec: 473.76 - lr: 0.001563\n","2022-02-16 19:28:55,732 epoch 42 - iter 10/12 - loss 0.65187407 - samples/sec: 504.78 - lr: 0.001563\n","2022-02-16 19:28:55,803 epoch 42 - iter 11/12 - loss 0.66977058 - samples/sec: 533.36 - lr: 0.001563\n","2022-02-16 19:28:55,829 epoch 42 - iter 12/12 - loss 0.65369850 - samples/sec: 1416.28 - lr: 0.001563\n","2022-02-16 19:28:56,241 ----------------------------------------------------------------------------------------------------\n","2022-02-16 19:28:56,246 EPOCH 42 done: loss 0.6537 - lr 0.0015625\n","2022-02-16 19:28:57,636 DEV : loss 0.7841473817825317 - score 0.625\n","2022-02-16 19:28:57,678 BAD EPOCHS (no improvement): 1\n","2022-02-16 19:28:57,686 ----------------------------------------------------------------------------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"output_type":"stream","name":"stdout","text":["2022-02-16 19:28:58,767 epoch 43 - iter 1/12 - loss 0.57717013 - samples/sec: 163.96 - lr: 0.001563\n","2022-02-16 19:28:58,854 epoch 43 - iter 2/12 - loss 0.68261951 - samples/sec: 486.15 - lr: 0.001563\n","2022-02-16 19:28:58,933 epoch 43 - iter 3/12 - loss 0.69873687 - samples/sec: 470.86 - lr: 0.001563\n","2022-02-16 19:28:59,008 epoch 43 - iter 4/12 - loss 0.65811181 - samples/sec: 437.32 - lr: 0.001563\n","2022-02-16 19:28:59,082 epoch 43 - iter 5/12 - loss 0.63109425 - samples/sec: 504.43 - lr: 0.001563\n","2022-02-16 19:28:59,183 epoch 43 - iter 6/12 - loss 0.63367477 - samples/sec: 392.35 - lr: 0.001563\n","2022-02-16 19:28:59,265 epoch 43 - iter 7/12 - loss 0.63987126 - samples/sec: 418.96 - lr: 0.001563\n","2022-02-16 19:28:59,341 epoch 43 - iter 8/12 - loss 0.64256928 - samples/sec: 558.47 - lr: 0.001563\n","2022-02-16 19:28:59,408 epoch 43 - iter 9/12 - loss 0.64089200 - samples/sec: 498.24 - lr: 0.001563\n","2022-02-16 19:28:59,479 epoch 43 - iter 10/12 - loss 0.63851797 - samples/sec: 486.89 - lr: 0.001563\n","2022-02-16 19:28:59,551 epoch 43 - iter 11/12 - loss 0.64563488 - samples/sec: 485.96 - lr: 0.001563\n","2022-02-16 19:28:59,574 epoch 43 - iter 12/12 - loss 0.63692788 - samples/sec: 1558.26 - lr: 0.001563\n","2022-02-16 19:28:59,955 ----------------------------------------------------------------------------------------------------\n","2022-02-16 19:28:59,959 EPOCH 43 done: loss 0.6369 - lr 0.0015625\n","2022-02-16 19:29:01,312 DEV : loss 0.7841664552688599 - score 0.625\n","2022-02-16 19:29:01,371 BAD EPOCHS (no improvement): 2\n","2022-02-16 19:29:01,380 ----------------------------------------------------------------------------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"output_type":"stream","name":"stdout","text":["2022-02-16 19:29:02,442 epoch 44 - iter 1/12 - loss 0.61836994 - samples/sec: 154.58 - lr: 0.001563\n","2022-02-16 19:29:02,555 epoch 44 - iter 2/12 - loss 0.76353303 - samples/sec: 476.49 - lr: 0.001563\n","2022-02-16 19:29:02,635 epoch 44 - iter 3/12 - loss 0.74065087 - samples/sec: 456.54 - lr: 0.001563\n","2022-02-16 19:29:02,710 epoch 44 - iter 4/12 - loss 0.70707440 - samples/sec: 435.90 - lr: 0.001563\n","2022-02-16 19:29:02,791 epoch 44 - iter 5/12 - loss 0.67171196 - samples/sec: 528.70 - lr: 0.001563\n","2022-02-16 19:29:02,869 epoch 44 - iter 6/12 - loss 0.67092132 - samples/sec: 469.70 - lr: 0.001563\n","2022-02-16 19:29:02,943 epoch 44 - iter 7/12 - loss 0.67471907 - samples/sec: 448.22 - lr: 0.001563\n","2022-02-16 19:29:03,012 epoch 44 - iter 8/12 - loss 0.68110494 - samples/sec: 472.54 - lr: 0.001563\n","2022-02-16 19:29:03,083 epoch 44 - iter 9/12 - loss 0.68626901 - samples/sec: 470.02 - lr: 0.001563\n","2022-02-16 19:29:03,148 epoch 44 - iter 10/12 - loss 0.67274399 - samples/sec: 510.02 - lr: 0.001563\n","2022-02-16 19:29:03,230 epoch 44 - iter 11/12 - loss 0.65999649 - samples/sec: 447.86 - lr: 0.001563\n","2022-02-16 19:29:03,253 epoch 44 - iter 12/12 - loss 0.63477425 - samples/sec: 1533.13 - lr: 0.001563\n","2022-02-16 19:29:03,640 ----------------------------------------------------------------------------------------------------\n","2022-02-16 19:29:03,648 EPOCH 44 done: loss 0.6348 - lr 0.0015625\n","2022-02-16 19:29:04,988 DEV : loss 0.7841310501098633 - score 0.65\n","2022-02-16 19:29:05,035 BAD EPOCHS (no improvement): 0\n","saving best model\n","2022-02-16 19:29:20,812 ----------------------------------------------------------------------------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"output_type":"stream","name":"stdout","text":["2022-02-16 19:29:22,205 epoch 45 - iter 1/12 - loss 0.64979714 - samples/sec: 138.51 - lr: 0.001563\n","2022-02-16 19:29:23,923 epoch 45 - iter 2/12 - loss 0.65746713 - samples/sec: 453.84 - lr: 0.001563\n","2022-02-16 19:29:23,988 epoch 45 - iter 3/12 - loss 0.67826388 - samples/sec: 544.64 - lr: 0.001563\n","2022-02-16 19:29:24,054 epoch 45 - iter 4/12 - loss 0.65767793 - samples/sec: 504.98 - lr: 0.001563\n","2022-02-16 19:29:24,150 epoch 45 - iter 5/12 - loss 0.65228791 - samples/sec: 414.97 - lr: 0.001563\n","2022-02-16 19:29:24,226 epoch 45 - iter 6/12 - loss 0.67029431 - samples/sec: 513.27 - lr: 0.001563\n","2022-02-16 19:29:24,297 epoch 45 - iter 7/12 - loss 0.65107400 - samples/sec: 477.39 - lr: 0.001563\n","2022-02-16 19:29:24,370 epoch 45 - iter 8/12 - loss 0.64962870 - samples/sec: 515.68 - lr: 0.001563\n","2022-02-16 19:29:24,435 epoch 45 - iter 9/12 - loss 0.63193140 - samples/sec: 533.60 - lr: 0.001563\n","2022-02-16 19:29:24,525 epoch 45 - iter 10/12 - loss 0.63769882 - samples/sec: 370.42 - lr: 0.001563\n","2022-02-16 19:29:24,592 epoch 45 - iter 11/12 - loss 0.64186028 - samples/sec: 545.98 - lr: 0.001563\n","2022-02-16 19:29:24,614 epoch 45 - iter 12/12 - loss 0.62491826 - samples/sec: 1800.06 - lr: 0.001563\n","2022-02-16 19:29:25,160 ----------------------------------------------------------------------------------------------------\n","2022-02-16 19:29:25,163 EPOCH 45 done: loss 0.6249 - lr 0.0015625\n","2022-02-16 19:29:27,028 DEV : loss 0.7842047214508057 - score 0.65\n","2022-02-16 19:29:27,082 BAD EPOCHS (no improvement): 1\n","2022-02-16 19:29:27,095 ----------------------------------------------------------------------------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"output_type":"stream","name":"stdout","text":["2022-02-16 19:29:28,407 epoch 46 - iter 1/12 - loss 0.58647263 - samples/sec: 109.12 - lr: 0.001563\n","2022-02-16 19:29:28,508 epoch 46 - iter 2/12 - loss 0.66772604 - samples/sec: 421.17 - lr: 0.001563\n","2022-02-16 19:29:28,601 epoch 46 - iter 3/12 - loss 0.67761552 - samples/sec: 445.64 - lr: 0.001563\n","2022-02-16 19:29:28,693 epoch 46 - iter 4/12 - loss 0.70260775 - samples/sec: 355.65 - lr: 0.001563\n","2022-02-16 19:29:28,766 epoch 46 - iter 5/12 - loss 0.69616016 - samples/sec: 457.22 - lr: 0.001563\n","2022-02-16 19:29:28,851 epoch 46 - iter 6/12 - loss 0.70094529 - samples/sec: 541.51 - lr: 0.001563\n","2022-02-16 19:29:28,927 epoch 46 - iter 7/12 - loss 0.68420963 - samples/sec: 443.37 - lr: 0.001563\n","2022-02-16 19:29:29,008 epoch 46 - iter 8/12 - loss 0.66417156 - samples/sec: 403.70 - lr: 0.001563\n","2022-02-16 19:29:29,080 epoch 46 - iter 9/12 - loss 0.64456066 - samples/sec: 468.95 - lr: 0.001563\n","2022-02-16 19:29:29,156 epoch 46 - iter 10/12 - loss 0.65526645 - samples/sec: 432.45 - lr: 0.001563\n","2022-02-16 19:29:29,231 epoch 46 - iter 11/12 - loss 0.64861041 - samples/sec: 442.49 - lr: 0.001563\n","2022-02-16 19:29:29,264 epoch 46 - iter 12/12 - loss 0.62759170 - samples/sec: 1775.44 - lr: 0.001563\n","2022-02-16 19:29:29,987 ----------------------------------------------------------------------------------------------------\n","2022-02-16 19:29:29,992 EPOCH 46 done: loss 0.6276 - lr 0.0015625\n","2022-02-16 19:29:33,144 DEV : loss 0.7834396362304688 - score 0.625\n","2022-02-16 19:29:33,244 BAD EPOCHS (no improvement): 2\n","2022-02-16 19:29:33,258 ----------------------------------------------------------------------------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"output_type":"stream","name":"stdout","text":["2022-02-16 19:29:35,766 epoch 47 - iter 1/12 - loss 0.72899365 - samples/sec: 135.79 - lr: 0.001563\n","2022-02-16 19:29:35,962 epoch 47 - iter 2/12 - loss 0.79914522 - samples/sec: 235.26 - lr: 0.001563\n","2022-02-16 19:29:36,114 epoch 47 - iter 3/12 - loss 0.69762802 - samples/sec: 227.21 - lr: 0.001563\n","2022-02-16 19:29:36,256 epoch 47 - iter 4/12 - loss 0.67744252 - samples/sec: 245.59 - lr: 0.001563\n","2022-02-16 19:29:36,400 epoch 47 - iter 5/12 - loss 0.69594036 - samples/sec: 243.11 - lr: 0.001563\n","2022-02-16 19:29:36,543 epoch 47 - iter 6/12 - loss 0.68317574 - samples/sec: 236.12 - lr: 0.001563\n","2022-02-16 19:29:36,664 epoch 47 - iter 7/12 - loss 0.67303263 - samples/sec: 289.70 - lr: 0.001563\n","2022-02-16 19:29:36,782 epoch 47 - iter 8/12 - loss 0.68041812 - samples/sec: 322.99 - lr: 0.001563\n","2022-02-16 19:29:36,901 epoch 47 - iter 9/12 - loss 0.67586466 - samples/sec: 279.02 - lr: 0.001563\n","2022-02-16 19:29:36,993 epoch 47 - iter 10/12 - loss 0.65823547 - samples/sec: 398.26 - lr: 0.001563\n","2022-02-16 19:29:37,093 epoch 47 - iter 11/12 - loss 0.64798683 - samples/sec: 364.65 - lr: 0.001563\n","2022-02-16 19:29:37,138 epoch 47 - iter 12/12 - loss 0.63268074 - samples/sec: 849.11 - lr: 0.001563\n","2022-02-16 19:29:37,850 ----------------------------------------------------------------------------------------------------\n","2022-02-16 19:29:37,854 EPOCH 47 done: loss 0.6327 - lr 0.0015625\n","2022-02-16 19:29:40,242 DEV : loss 0.7833383083343506 - score 0.65\n","2022-02-16 19:29:40,382 BAD EPOCHS (no improvement): 0\n","saving best model\n","2022-02-16 19:29:55,832 ----------------------------------------------------------------------------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"output_type":"stream","name":"stdout","text":["2022-02-16 19:29:57,273 epoch 48 - iter 1/12 - loss 0.58602291 - samples/sec: 250.48 - lr: 0.001563\n","2022-02-16 19:29:57,352 epoch 48 - iter 2/12 - loss 0.76155117 - samples/sec: 425.51 - lr: 0.001563\n","2022-02-16 19:29:57,429 epoch 48 - iter 3/12 - loss 0.73583800 - samples/sec: 500.51 - lr: 0.001563\n","2022-02-16 19:29:57,511 epoch 48 - iter 4/12 - loss 0.72614092 - samples/sec: 402.10 - lr: 0.001563\n","2022-02-16 19:29:57,604 epoch 48 - iter 5/12 - loss 0.70399178 - samples/sec: 493.54 - lr: 0.001563\n","2022-02-16 19:29:57,685 epoch 48 - iter 6/12 - loss 0.68487064 - samples/sec: 556.57 - lr: 0.001563\n","2022-02-16 19:29:57,756 epoch 48 - iter 7/12 - loss 0.66944184 - samples/sec: 490.76 - lr: 0.001563\n","2022-02-16 19:29:57,829 epoch 48 - iter 8/12 - loss 0.66530371 - samples/sec: 466.84 - lr: 0.001563\n","2022-02-16 19:29:57,903 epoch 48 - iter 9/12 - loss 0.66009551 - samples/sec: 494.03 - lr: 0.001563\n","2022-02-16 19:29:57,984 epoch 48 - iter 10/12 - loss 0.65593615 - samples/sec: 423.56 - lr: 0.001563\n","2022-02-16 19:29:58,054 epoch 48 - iter 11/12 - loss 0.65020879 - samples/sec: 516.14 - lr: 0.001563\n","2022-02-16 19:29:58,077 epoch 48 - iter 12/12 - loss 0.62380129 - samples/sec: 1558.95 - lr: 0.001563\n","2022-02-16 19:29:58,604 ----------------------------------------------------------------------------------------------------\n","2022-02-16 19:29:58,612 EPOCH 48 done: loss 0.6238 - lr 0.0015625\n","2022-02-16 19:30:00,366 DEV : loss 0.7832005620002747 - score 0.65\n","2022-02-16 19:30:00,413 BAD EPOCHS (no improvement): 0\n","saving best model\n","2022-02-16 19:30:15,407 ----------------------------------------------------------------------------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"output_type":"stream","name":"stdout","text":["2022-02-16 19:30:16,901 epoch 49 - iter 1/12 - loss 0.66056013 - samples/sec: 160.51 - lr: 0.001563\n","2022-02-16 19:30:16,976 epoch 49 - iter 2/12 - loss 0.66025534 - samples/sec: 452.24 - lr: 0.001563\n","2022-02-16 19:30:17,049 epoch 49 - iter 3/12 - loss 0.62603269 - samples/sec: 530.65 - lr: 0.001563\n","2022-02-16 19:30:17,122 epoch 49 - iter 4/12 - loss 0.61016989 - samples/sec: 550.88 - lr: 0.001563\n","2022-02-16 19:30:17,209 epoch 49 - iter 5/12 - loss 0.60461686 - samples/sec: 529.29 - lr: 0.001563\n","2022-02-16 19:30:17,292 epoch 49 - iter 6/12 - loss 0.60436325 - samples/sec: 488.32 - lr: 0.001563\n","2022-02-16 19:30:17,364 epoch 49 - iter 7/12 - loss 0.59338788 - samples/sec: 468.64 - lr: 0.001563\n","2022-02-16 19:30:17,432 epoch 49 - iter 8/12 - loss 0.60778074 - samples/sec: 500.54 - lr: 0.001563\n","2022-02-16 19:30:17,512 epoch 49 - iter 9/12 - loss 0.62274469 - samples/sec: 449.29 - lr: 0.001563\n","2022-02-16 19:30:17,588 epoch 49 - iter 10/12 - loss 0.63120918 - samples/sec: 519.85 - lr: 0.001563\n","2022-02-16 19:30:17,663 epoch 49 - iter 11/12 - loss 0.64724483 - samples/sec: 495.28 - lr: 0.001563\n","2022-02-16 19:30:17,693 epoch 49 - iter 12/12 - loss 0.64519892 - samples/sec: 1543.12 - lr: 0.001563\n","2022-02-16 19:30:18,225 ----------------------------------------------------------------------------------------------------\n","2022-02-16 19:30:18,232 EPOCH 49 done: loss 0.6452 - lr 0.0015625\n","2022-02-16 19:30:20,016 DEV : loss 0.7843894958496094 - score 0.65\n","2022-02-16 19:30:20,075 BAD EPOCHS (no improvement): 1\n","2022-02-16 19:30:20,101 ----------------------------------------------------------------------------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"output_type":"stream","name":"stdout","text":["2022-02-16 19:30:21,424 epoch 50 - iter 1/12 - loss 0.73726487 - samples/sec: 165.99 - lr: 0.001563\n","2022-02-16 19:30:21,504 epoch 50 - iter 2/12 - loss 0.71991807 - samples/sec: 503.41 - lr: 0.001563\n","2022-02-16 19:30:21,581 epoch 50 - iter 3/12 - loss 0.66320151 - samples/sec: 496.96 - lr: 0.001563\n","2022-02-16 19:30:21,668 epoch 50 - iter 4/12 - loss 0.68870984 - samples/sec: 449.02 - lr: 0.001563\n","2022-02-16 19:30:21,745 epoch 50 - iter 5/12 - loss 0.68585126 - samples/sec: 453.93 - lr: 0.001563\n","2022-02-16 19:30:21,822 epoch 50 - iter 6/12 - loss 0.67218346 - samples/sec: 561.23 - lr: 0.001563\n","2022-02-16 19:30:21,909 epoch 50 - iter 7/12 - loss 0.67189263 - samples/sec: 441.44 - lr: 0.001563\n","2022-02-16 19:30:21,974 epoch 50 - iter 8/12 - loss 0.66900028 - samples/sec: 508.12 - lr: 0.001563\n","2022-02-16 19:30:22,041 epoch 50 - iter 9/12 - loss 0.67300404 - samples/sec: 491.53 - lr: 0.001563\n","2022-02-16 19:30:22,126 epoch 50 - iter 10/12 - loss 0.66181682 - samples/sec: 393.30 - lr: 0.001563\n","2022-02-16 19:30:22,204 epoch 50 - iter 11/12 - loss 0.65488940 - samples/sec: 558.80 - lr: 0.001563\n","2022-02-16 19:30:22,228 epoch 50 - iter 12/12 - loss 0.62127227 - samples/sec: 1666.29 - lr: 0.001563\n","2022-02-16 19:30:22,698 ----------------------------------------------------------------------------------------------------\n","2022-02-16 19:30:22,707 EPOCH 50 done: loss 0.6213 - lr 0.0015625\n","2022-02-16 19:30:24,302 DEV : loss 0.7844857573509216 - score 0.65\n","2022-02-16 19:30:24,354 BAD EPOCHS (no improvement): 2\n","2022-02-16 19:30:46,347 ----------------------------------------------------------------------------------------------------\n","2022-02-16 19:30:46,447 Testing using best model ...\n","2022-02-16 19:30:46,450 loading file ../resources/stance-semeval2016/flair_Climate Change is a Real Concern/best-model.pt\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"output_type":"stream","name":"stdout","text":["2022-02-16 19:31:03,969 \t0.716\n","2022-02-16 19:31:03,982 \n","Results:\n","- F-score (micro) 0.716\n","- F-score (macro) 0.3989\n","- Accuracy 0.716\n","\n","By class:\n","              precision    recall  f1-score   support\n","\n","       FAVOR     0.7956    0.8862    0.8385       123\n","     AGAINST     0.0000    0.0000    0.0000        11\n","        NONE     0.3750    0.3429    0.3582        35\n","\n","   micro avg     0.7160    0.7160    0.7160       169\n","   macro avg     0.3902    0.4097    0.3989       169\n","weighted avg     0.6567    0.7160    0.6844       169\n"," samples avg     0.7160    0.7160    0.7160       169\n","\n","2022-02-16 19:31:03,993 ----------------------------------------------------------------------------------------------------\n"]},{"output_type":"execute_result","data":{"text/plain":["{'dev_loss_history': [0.8788999915122986,\n","  0.9929863214492798,\n","  0.9621152877807617,\n","  0.9137294292449951,\n","  0.9036107063293457,\n","  0.8506278991699219,\n","  0.8753564953804016,\n","  0.8229542970657349,\n","  0.8837971687316895,\n","  0.822258472442627,\n","  0.8148473501205444,\n","  0.8464285731315613,\n","  0.8223634362220764,\n","  0.8077138662338257,\n","  0.8070741891860962,\n","  0.8101582527160645,\n","  0.8102304935455322,\n","  0.8022955656051636,\n","  0.8083817958831787,\n","  0.7989209890365601,\n","  0.8238097429275513,\n","  0.8081166744232178,\n","  0.8037258386611938,\n","  0.7994579076766968,\n","  0.7910913228988647,\n","  0.7921041250228882,\n","  0.7925406098365784,\n","  0.7943075895309448,\n","  0.7995345592498779,\n","  0.7920525074005127,\n","  0.7920268774032593,\n","  0.7935653924942017,\n","  0.786449134349823,\n","  0.788538932800293,\n","  0.7872284650802612,\n","  0.789122462272644,\n","  0.7864469885826111,\n","  0.7873278856277466,\n","  0.7876337170600891,\n","  0.7852253317832947,\n","  0.7841647863388062,\n","  0.7841473817825317,\n","  0.7841664552688599,\n","  0.7841310501098633,\n","  0.7842047214508057,\n","  0.7834396362304688,\n","  0.7833383083343506,\n","  0.7832005620002747,\n","  0.7843894958496094,\n","  0.7844857573509216],\n"," 'dev_score_history': [0.625,\n","  0.3,\n","  0.625,\n","  0.4,\n","  0.625,\n","  0.55,\n","  0.55,\n","  0.55,\n","  0.525,\n","  0.525,\n","  0.6,\n","  0.55,\n","  0.575,\n","  0.625,\n","  0.6,\n","  0.6,\n","  0.575,\n","  0.625,\n","  0.575,\n","  0.625,\n","  0.575,\n","  0.575,\n","  0.55,\n","  0.55,\n","  0.65,\n","  0.65,\n","  0.6,\n","  0.625,\n","  0.6,\n","  0.625,\n","  0.625,\n","  0.625,\n","  0.65,\n","  0.65,\n","  0.65,\n","  0.65,\n","  0.65,\n","  0.6,\n","  0.575,\n","  0.6,\n","  0.6,\n","  0.625,\n","  0.625,\n","  0.65,\n","  0.65,\n","  0.625,\n","  0.65,\n","  0.65,\n","  0.65,\n","  0.65],\n"," 'test_score': 0.716,\n"," 'train_loss_history': [0.9398020456234614,\n","  0.8335608392953873,\n","  0.8166230668624243,\n","  0.9229157765706381,\n","  0.7780548632144928,\n","  0.7753347009420395,\n","  0.7700900783141454,\n","  0.7335267116626104,\n","  0.8550458500782648,\n","  0.810729389389356,\n","  0.7449759542942047,\n","  0.7361651559670767,\n","  0.7114679167668024,\n","  0.6823813070853552,\n","  0.7029147893190384,\n","  0.7134521206219991,\n","  0.6655604665478071,\n","  0.7290427337090174,\n","  0.6926847398281097,\n","  0.6909744292497635,\n","  0.7058530946572622,\n","  0.7261697550614675,\n","  0.6765182018280029,\n","  0.7451457381248474,\n","  0.6415933941801389,\n","  0.6774632607897123,\n","  0.6593403369188309,\n","  0.672207256158193,\n","  0.6408907944957415,\n","  0.640074131389459,\n","  0.6300275400280952,\n","  0.6571967403093973,\n","  0.7091910019516945,\n","  0.6809200594822565,\n","  0.6905843193332354,\n","  0.6600205600261688,\n","  0.660402312874794,\n","  0.6863730202118555,\n","  0.6924622505903244,\n","  0.7053434451421102,\n","  0.6254146322607994,\n","  0.6536984965205193,\n","  0.6369278828303019,\n","  0.6347742453217506,\n","  0.6249182571967443,\n","  0.6275916993618011,\n","  0.6326807414491972,\n","  0.6238012885053953,\n","  0.645198921362559,\n","  0.6212722733616829]}"]},"metadata":{},"execution_count":11}]},{"cell_type":"markdown","source":["## Hillary Clinton"],"metadata":{"id":"CVjhEwTF5E4X"}},{"cell_type":"code","source":["# 1. get the corpus\n","target = \"Hillary Clinton\"\n","corpus_folder = f\"../resources/{folder}/\"\n","corpus: Corpus = ClassificationCorpus(corpus_folder,\n","                                      train_file=f'train.{target}.txt',\n","                                      #dev_file=f'train.{target}.txt',\n","                                      test_file=f'test.{target}.txt'\n",")\n","\n","# 2. create the label dictionary\n","label_dict = corpus.make_label_dictionary()\n","                                                                                                                                                                                         \n","# 5. create the text classifier\n","classifier = TextClassifier(document_embeddings, label_dictionary=label_dict)\n","\n","# 6. initialize the text classifier trainer\n","trainer = ModelTrainer(classifier, corpus)\n","\n","# 7. start the training\n","trainer.train(f\"../resources/{folder}/flair_{target}\",\n","              train_with_dev=False,\n","              max_epochs=50)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VGeDUj005E4Y","executionInfo":{"status":"ok","timestamp":1645040441370,"user_tz":-60,"elapsed":578064,"user":{"displayName":"Julen Etxaniz Aragoneses","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GilpYDAmorj7KFdjK26TlsyH_HhFWhLqmESeKoCGsI=s64","userId":"06956422670240182492"}},"outputId":"a900936b-dd69-4ab6-bfa4-344d3050988b"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["2022-02-16 19:31:04,221 Reading data from ../resources/stance-semeval2016\n","2022-02-16 19:31:04,224 Train: ../resources/stance-semeval2016/train.Hillary Clinton.txt\n","2022-02-16 19:31:04,235 Dev: None\n","2022-02-16 19:31:04,239 Test: ../resources/stance-semeval2016/test.Hillary Clinton.txt\n","2022-02-16 19:31:04,338 Computing label dictionary. Progress:\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n","100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 915/915 [00:02<00:00, 321.61it/s]"]},{"output_type":"stream","name":"stdout","text":["2022-02-16 19:31:09,248 [b'AGAINST', b'NONE', b'FAVOR']\n","2022-02-16 19:31:09,297 ----------------------------------------------------------------------------------------------------\n","2022-02-16 19:31:09,303 Model: \"TextClassifier(\n","  (document_embeddings): DocumentRNNEmbeddings(\n","    (embeddings): StackedEmbeddings(\n","      (list_embedding_0): WordEmbeddings('en-crawl')\n","    )\n","    (word_reprojection_map): Linear(in_features=300, out_features=256, bias=True)\n","    (rnn): LSTM(256, 512, batch_first=True)\n","    (dropout): Dropout(p=0.5, inplace=False)\n","  )\n","  (decoder): Linear(in_features=512, out_features=3, bias=True)\n","  (loss_function): CrossEntropyLoss()\n","  (beta): 1.0\n","  (weights): None\n","  (weight_tensor) None\n",")\"\n","2022-02-16 19:31:09,308 ----------------------------------------------------------------------------------------------------\n","2022-02-16 19:31:09,313 Corpus: \"Corpus: 620 train + 69 dev + 295 test sentences\"\n","2022-02-16 19:31:09,319 ----------------------------------------------------------------------------------------------------\n","2022-02-16 19:31:09,325 Parameters:\n","2022-02-16 19:31:09,334  - learning_rate: \"0.1\"\n","2022-02-16 19:31:09,339  - mini_batch_size: \"32\"\n","2022-02-16 19:31:09,350  - patience: \"3\"\n","2022-02-16 19:31:09,356  - anneal_factor: \"0.5\"\n","2022-02-16 19:31:09,364  - max_epochs: \"50\"\n","2022-02-16 19:31:09,369  - shuffle: \"True\"\n","2022-02-16 19:31:09,376  - train_with_dev: \"False\"\n","2022-02-16 19:31:09,384  - batch_growth_annealing: \"False\"\n","2022-02-16 19:31:09,391 ----------------------------------------------------------------------------------------------------\n","2022-02-16 19:31:09,398 Model training base path: \"../resources/stance-semeval2016/flair_Hillary Clinton\"\n","2022-02-16 19:31:09,407 ----------------------------------------------------------------------------------------------------\n","2022-02-16 19:31:09,428 Device: cuda:0\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["2022-02-16 19:31:09,454 ----------------------------------------------------------------------------------------------------\n","2022-02-16 19:31:09,463 Embeddings storage mode: cpu\n","2022-02-16 19:31:09,486 ----------------------------------------------------------------------------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"output_type":"stream","name":"stdout","text":["2022-02-16 19:31:12,095 epoch 1 - iter 2/20 - loss 1.10768378 - samples/sec: 109.77 - lr: 0.100000\n","2022-02-16 19:31:12,404 epoch 1 - iter 4/20 - loss 1.09808919 - samples/sec: 209.62 - lr: 0.100000\n","2022-02-16 19:31:12,746 epoch 1 - iter 6/20 - loss 1.08961499 - samples/sec: 229.32 - lr: 0.100000\n","2022-02-16 19:31:12,981 epoch 1 - iter 8/20 - loss 1.08849350 - samples/sec: 282.69 - lr: 0.100000\n","2022-02-16 19:31:13,179 epoch 1 - iter 10/20 - loss 1.08878633 - samples/sec: 378.33 - lr: 0.100000\n","2022-02-16 19:31:13,358 epoch 1 - iter 12/20 - loss 1.07960336 - samples/sec: 419.48 - lr: 0.100000\n","2022-02-16 19:31:13,525 epoch 1 - iter 14/20 - loss 1.07435431 - samples/sec: 392.50 - lr: 0.100000\n","2022-02-16 19:31:13,684 epoch 1 - iter 16/20 - loss 1.00205488 - samples/sec: 411.46 - lr: 0.100000\n","2022-02-16 19:31:13,837 epoch 1 - iter 18/20 - loss 0.99983402 - samples/sec: 429.24 - lr: 0.100000\n","2022-02-16 19:31:13,967 epoch 1 - iter 20/20 - loss 0.93711917 - samples/sec: 515.28 - lr: 0.100000\n","2022-02-16 19:31:14,382 ----------------------------------------------------------------------------------------------------\n","2022-02-16 19:31:14,385 EPOCH 1 done: loss 0.9371 - lr 0.1000000\n","2022-02-16 19:31:15,979 DEV : loss 1.074609637260437 - score 0.5362\n","2022-02-16 19:31:16,050 BAD EPOCHS (no improvement): 0\n","saving best model\n","2022-02-16 19:31:31,551 ----------------------------------------------------------------------------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"output_type":"stream","name":"stdout","text":["2022-02-16 19:31:33,411 epoch 2 - iter 2/20 - loss 1.18906236 - samples/sec: 213.56 - lr: 0.100000\n","2022-02-16 19:31:33,635 epoch 2 - iter 4/20 - loss 1.09347312 - samples/sec: 375.78 - lr: 0.100000\n","2022-02-16 19:31:33,803 epoch 2 - iter 6/20 - loss 1.05621004 - samples/sec: 398.17 - lr: 0.100000\n","2022-02-16 19:31:33,960 epoch 2 - iter 8/20 - loss 1.01691815 - samples/sec: 413.90 - lr: 0.100000\n","2022-02-16 19:31:34,109 epoch 2 - iter 10/20 - loss 1.00777193 - samples/sec: 482.92 - lr: 0.100000\n","2022-02-16 19:31:34,277 epoch 2 - iter 12/20 - loss 0.99109321 - samples/sec: 432.01 - lr: 0.100000\n","2022-02-16 19:31:34,419 epoch 2 - iter 14/20 - loss 0.98862035 - samples/sec: 461.90 - lr: 0.100000\n","2022-02-16 19:31:34,564 epoch 2 - iter 16/20 - loss 0.97797428 - samples/sec: 503.07 - lr: 0.100000\n","2022-02-16 19:31:34,712 epoch 2 - iter 18/20 - loss 0.98110861 - samples/sec: 519.64 - lr: 0.100000\n","2022-02-16 19:31:34,821 epoch 2 - iter 20/20 - loss 0.97920690 - samples/sec: 610.10 - lr: 0.100000\n","2022-02-16 19:31:35,365 ----------------------------------------------------------------------------------------------------\n","2022-02-16 19:31:35,372 EPOCH 2 done: loss 0.9792 - lr 0.1000000\n","2022-02-16 19:31:37,410 DEV : loss 0.9209212064743042 - score 0.5362\n","2022-02-16 19:31:37,517 BAD EPOCHS (no improvement): 0\n","saving best model\n","2022-02-16 19:31:52,339 ----------------------------------------------------------------------------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"output_type":"stream","name":"stdout","text":["2022-02-16 19:32:09,354 epoch 3 - iter 2/20 - loss 1.05257857 - samples/sec: 187.35 - lr: 0.100000\n","2022-02-16 19:32:09,823 epoch 3 - iter 4/20 - loss 1.03493455 - samples/sec: 140.80 - lr: 0.100000\n","2022-02-16 19:32:10,297 epoch 3 - iter 6/20 - loss 0.99468275 - samples/sec: 151.62 - lr: 0.100000\n","2022-02-16 19:32:10,664 epoch 3 - iter 8/20 - loss 0.97869337 - samples/sec: 199.08 - lr: 0.100000\n","2022-02-16 19:32:10,986 epoch 3 - iter 10/20 - loss 0.93172584 - samples/sec: 218.93 - lr: 0.100000\n","2022-02-16 19:32:11,269 epoch 3 - iter 12/20 - loss 0.92381871 - samples/sec: 250.56 - lr: 0.100000\n","2022-02-16 19:32:11,604 epoch 3 - iter 14/20 - loss 0.90927188 - samples/sec: 202.85 - lr: 0.100000\n","2022-02-16 19:32:11,977 epoch 3 - iter 16/20 - loss 0.94651543 - samples/sec: 174.53 - lr: 0.100000\n","2022-02-16 19:32:12,342 epoch 3 - iter 18/20 - loss 0.96096117 - samples/sec: 183.47 - lr: 0.100000\n","2022-02-16 19:32:12,595 epoch 3 - iter 20/20 - loss 0.95582353 - samples/sec: 270.52 - lr: 0.100000\n","2022-02-16 19:32:13,381 ----------------------------------------------------------------------------------------------------\n","2022-02-16 19:32:13,388 EPOCH 3 done: loss 0.9558 - lr 0.1000000\n","2022-02-16 19:32:16,340 DEV : loss 0.9103115797042847 - score 0.5362\n","2022-02-16 19:32:16,571 BAD EPOCHS (no improvement): 0\n","saving best model\n","2022-02-16 19:32:32,216 ----------------------------------------------------------------------------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"output_type":"stream","name":"stdout","text":["2022-02-16 19:32:33,785 epoch 4 - iter 2/20 - loss 0.81857756 - samples/sec: 261.15 - lr: 0.100000\n","2022-02-16 19:32:33,951 epoch 4 - iter 4/20 - loss 0.87328897 - samples/sec: 396.85 - lr: 0.100000\n","2022-02-16 19:32:34,135 epoch 4 - iter 6/20 - loss 0.88550529 - samples/sec: 421.64 - lr: 0.100000\n","2022-02-16 19:32:34,298 epoch 4 - iter 8/20 - loss 0.90638641 - samples/sec: 454.45 - lr: 0.100000\n","2022-02-16 19:32:34,434 epoch 4 - iter 10/20 - loss 0.91420954 - samples/sec: 481.86 - lr: 0.100000\n","2022-02-16 19:32:34,580 epoch 4 - iter 12/20 - loss 0.90243382 - samples/sec: 449.78 - lr: 0.100000\n","2022-02-16 19:32:34,736 epoch 4 - iter 14/20 - loss 0.93033739 - samples/sec: 471.68 - lr: 0.100000\n","2022-02-16 19:32:34,878 epoch 4 - iter 16/20 - loss 0.93438750 - samples/sec: 474.18 - lr: 0.100000\n","2022-02-16 19:32:35,012 epoch 4 - iter 18/20 - loss 0.94296757 - samples/sec: 483.63 - lr: 0.100000\n","2022-02-16 19:32:35,127 epoch 4 - iter 20/20 - loss 0.94221342 - samples/sec: 637.96 - lr: 0.100000\n","2022-02-16 19:32:35,642 ----------------------------------------------------------------------------------------------------\n","2022-02-16 19:32:35,648 EPOCH 4 done: loss 0.9422 - lr 0.1000000\n","2022-02-16 19:32:37,498 DEV : loss 0.908013105392456 - score 0.5362\n","2022-02-16 19:32:37,570 BAD EPOCHS (no improvement): 0\n","saving best model\n","2022-02-16 19:32:52,920 ----------------------------------------------------------------------------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"output_type":"stream","name":"stdout","text":["2022-02-16 19:32:54,480 epoch 5 - iter 2/20 - loss 1.04917774 - samples/sec: 224.93 - lr: 0.100000\n","2022-02-16 19:32:54,679 epoch 5 - iter 4/20 - loss 0.95327686 - samples/sec: 403.09 - lr: 0.100000\n","2022-02-16 19:32:54,842 epoch 5 - iter 6/20 - loss 0.94187421 - samples/sec: 397.61 - lr: 0.100000\n","2022-02-16 19:32:54,992 epoch 5 - iter 8/20 - loss 0.95902774 - samples/sec: 432.99 - lr: 0.100000\n","2022-02-16 19:32:55,124 epoch 5 - iter 10/20 - loss 0.94663385 - samples/sec: 551.76 - lr: 0.100000\n","2022-02-16 19:32:55,279 epoch 5 - iter 12/20 - loss 0.94469407 - samples/sec: 516.13 - lr: 0.100000\n","2022-02-16 19:32:55,412 epoch 5 - iter 14/20 - loss 0.95118340 - samples/sec: 493.59 - lr: 0.100000\n","2022-02-16 19:32:55,538 epoch 5 - iter 16/20 - loss 0.93344922 - samples/sec: 520.64 - lr: 0.100000\n","2022-02-16 19:32:55,678 epoch 5 - iter 18/20 - loss 0.92317648 - samples/sec: 482.13 - lr: 0.100000\n","2022-02-16 19:32:55,784 epoch 5 - iter 20/20 - loss 0.93218916 - samples/sec: 619.69 - lr: 0.100000\n","2022-02-16 19:32:56,340 ----------------------------------------------------------------------------------------------------\n","2022-02-16 19:32:56,345 EPOCH 5 done: loss 0.9322 - lr 0.1000000\n","2022-02-16 19:32:58,037 DEV : loss 0.9318515658378601 - score 0.5652\n","2022-02-16 19:32:58,109 BAD EPOCHS (no improvement): 0\n","saving best model\n","2022-02-16 19:33:13,333 ----------------------------------------------------------------------------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"output_type":"stream","name":"stdout","text":["2022-02-16 19:33:15,025 epoch 6 - iter 2/20 - loss 0.92222279 - samples/sec: 219.63 - lr: 0.100000\n","2022-02-16 19:33:15,201 epoch 6 - iter 4/20 - loss 0.93274033 - samples/sec: 455.21 - lr: 0.100000\n","2022-02-16 19:33:15,388 epoch 6 - iter 6/20 - loss 0.96608758 - samples/sec: 402.74 - lr: 0.100000\n","2022-02-16 19:33:15,573 epoch 6 - iter 8/20 - loss 0.94911713 - samples/sec: 400.80 - lr: 0.100000\n","2022-02-16 19:33:15,714 epoch 6 - iter 10/20 - loss 0.94506475 - samples/sec: 473.82 - lr: 0.100000\n","2022-02-16 19:33:15,853 epoch 6 - iter 12/20 - loss 0.91981503 - samples/sec: 473.41 - lr: 0.100000\n","2022-02-16 19:33:16,006 epoch 6 - iter 14/20 - loss 0.92800823 - samples/sec: 515.29 - lr: 0.100000\n","2022-02-16 19:33:16,141 epoch 6 - iter 16/20 - loss 0.92847851 - samples/sec: 483.48 - lr: 0.100000\n","2022-02-16 19:33:16,282 epoch 6 - iter 18/20 - loss 0.92089015 - samples/sec: 479.39 - lr: 0.100000\n","2022-02-16 19:33:16,413 epoch 6 - iter 20/20 - loss 0.92134661 - samples/sec: 549.37 - lr: 0.100000\n","2022-02-16 19:33:17,154 ----------------------------------------------------------------------------------------------------\n","2022-02-16 19:33:17,156 EPOCH 6 done: loss 0.9213 - lr 0.1000000\n","2022-02-16 19:33:19,065 DEV : loss 0.8997544646263123 - score 0.5362\n","2022-02-16 19:33:19,142 BAD EPOCHS (no improvement): 1\n","2022-02-16 19:33:19,151 ----------------------------------------------------------------------------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"output_type":"stream","name":"stdout","text":["2022-02-16 19:33:20,560 epoch 7 - iter 2/20 - loss 0.94054964 - samples/sec: 218.85 - lr: 0.100000\n","2022-02-16 19:33:20,761 epoch 7 - iter 4/20 - loss 0.88250983 - samples/sec: 365.52 - lr: 0.100000\n","2022-02-16 19:33:20,945 epoch 7 - iter 6/20 - loss 0.91329374 - samples/sec: 403.71 - lr: 0.100000\n","2022-02-16 19:33:21,131 epoch 7 - iter 8/20 - loss 0.93680092 - samples/sec: 453.15 - lr: 0.100000\n","2022-02-16 19:33:21,258 epoch 7 - iter 10/20 - loss 0.92262783 - samples/sec: 516.56 - lr: 0.100000\n","2022-02-16 19:33:21,396 epoch 7 - iter 12/20 - loss 0.91683069 - samples/sec: 475.53 - lr: 0.100000\n","2022-02-16 19:33:21,529 epoch 7 - iter 14/20 - loss 0.90282413 - samples/sec: 522.47 - lr: 0.100000\n","2022-02-16 19:33:21,671 epoch 7 - iter 16/20 - loss 0.89852808 - samples/sec: 457.45 - lr: 0.100000\n","2022-02-16 19:33:21,801 epoch 7 - iter 18/20 - loss 0.90055876 - samples/sec: 505.45 - lr: 0.100000\n","2022-02-16 19:33:21,916 epoch 7 - iter 20/20 - loss 0.90784931 - samples/sec: 655.75 - lr: 0.100000\n","2022-02-16 19:33:22,711 ----------------------------------------------------------------------------------------------------\n","2022-02-16 19:33:22,722 EPOCH 7 done: loss 0.9078 - lr 0.1000000\n","2022-02-16 19:33:26,320 DEV : loss 1.0334051847457886 - score 0.4783\n","2022-02-16 19:33:26,466 BAD EPOCHS (no improvement): 2\n","2022-02-16 19:33:26,479 ----------------------------------------------------------------------------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"output_type":"stream","name":"stdout","text":["2022-02-16 19:33:28,673 epoch 8 - iter 2/20 - loss 0.98864761 - samples/sec: 132.12 - lr: 0.100000\n","2022-02-16 19:33:28,983 epoch 8 - iter 4/20 - loss 0.94341849 - samples/sec: 215.83 - lr: 0.100000\n","2022-02-16 19:33:29,596 epoch 8 - iter 6/20 - loss 0.95894254 - samples/sec: 124.48 - lr: 0.100000\n","2022-02-16 19:33:29,988 epoch 8 - iter 8/20 - loss 0.91640140 - samples/sec: 177.25 - lr: 0.100000\n","2022-02-16 19:33:30,308 epoch 8 - iter 10/20 - loss 0.95619339 - samples/sec: 202.16 - lr: 0.100000\n","2022-02-16 19:33:30,615 epoch 8 - iter 12/20 - loss 0.95135599 - samples/sec: 262.36 - lr: 0.100000\n","2022-02-16 19:33:30,874 epoch 8 - iter 14/20 - loss 0.92372670 - samples/sec: 252.60 - lr: 0.100000\n","2022-02-16 19:33:31,085 epoch 8 - iter 16/20 - loss 0.91956664 - samples/sec: 310.88 - lr: 0.100000\n","2022-02-16 19:33:31,351 epoch 8 - iter 18/20 - loss 0.91528184 - samples/sec: 286.88 - lr: 0.100000\n","2022-02-16 19:33:31,577 epoch 8 - iter 20/20 - loss 0.90204650 - samples/sec: 300.22 - lr: 0.100000\n","2022-02-16 19:33:32,266 ----------------------------------------------------------------------------------------------------\n","2022-02-16 19:33:32,271 EPOCH 8 done: loss 0.9020 - lr 0.1000000\n","2022-02-16 19:33:35,100 DEV : loss 0.8716272711753845 - score 0.5797\n","2022-02-16 19:33:35,293 BAD EPOCHS (no improvement): 0\n","saving best model\n","2022-02-16 19:33:51,124 ----------------------------------------------------------------------------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"output_type":"stream","name":"stdout","text":["2022-02-16 19:33:52,709 epoch 9 - iter 2/20 - loss 0.79499817 - samples/sec: 217.10 - lr: 0.100000\n","2022-02-16 19:33:52,902 epoch 9 - iter 4/20 - loss 0.89348063 - samples/sec: 413.29 - lr: 0.100000\n","2022-02-16 19:33:53,066 epoch 9 - iter 6/20 - loss 0.85233441 - samples/sec: 437.72 - lr: 0.100000\n","2022-02-16 19:33:53,223 epoch 9 - iter 8/20 - loss 0.83135070 - samples/sec: 438.80 - lr: 0.100000\n","2022-02-16 19:33:53,375 epoch 9 - iter 10/20 - loss 0.84532937 - samples/sec: 477.55 - lr: 0.100000\n","2022-02-16 19:33:53,546 epoch 9 - iter 12/20 - loss 0.86216695 - samples/sec: 491.55 - lr: 0.100000\n","2022-02-16 19:33:53,675 epoch 9 - iter 14/20 - loss 0.88012196 - samples/sec: 521.30 - lr: 0.100000\n","2022-02-16 19:33:53,816 epoch 9 - iter 16/20 - loss 0.86923479 - samples/sec: 468.57 - lr: 0.100000\n","2022-02-16 19:33:53,947 epoch 9 - iter 18/20 - loss 0.88268653 - samples/sec: 538.45 - lr: 0.100000\n","2022-02-16 19:33:54,056 epoch 9 - iter 20/20 - loss 0.88081413 - samples/sec: 630.90 - lr: 0.100000\n","2022-02-16 19:33:54,591 ----------------------------------------------------------------------------------------------------\n","2022-02-16 19:33:54,597 EPOCH 9 done: loss 0.8808 - lr 0.1000000\n","2022-02-16 19:33:59,309 DEV : loss 0.8413482904434204 - score 0.5507\n","2022-02-16 19:33:59,481 BAD EPOCHS (no improvement): 1\n","2022-02-16 19:33:59,497 ----------------------------------------------------------------------------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"output_type":"stream","name":"stdout","text":["2022-02-16 19:34:02,386 epoch 10 - iter 2/20 - loss 0.81983075 - samples/sec: 86.06 - lr: 0.100000\n","2022-02-16 19:34:02,904 epoch 10 - iter 4/20 - loss 0.81523411 - samples/sec: 143.84 - lr: 0.100000\n","2022-02-16 19:34:03,315 epoch 10 - iter 6/20 - loss 0.82546351 - samples/sec: 172.13 - lr: 0.100000\n","2022-02-16 19:34:03,801 epoch 10 - iter 8/20 - loss 0.85027424 - samples/sec: 135.46 - lr: 0.100000\n","2022-02-16 19:34:04,268 epoch 10 - iter 10/20 - loss 0.86223436 - samples/sec: 182.11 - lr: 0.100000\n","2022-02-16 19:34:04,553 epoch 10 - iter 12/20 - loss 0.85530050 - samples/sec: 245.84 - lr: 0.100000\n","2022-02-16 19:34:04,906 epoch 10 - iter 14/20 - loss 0.87056495 - samples/sec: 186.49 - lr: 0.100000\n","2022-02-16 19:34:05,369 epoch 10 - iter 16/20 - loss 0.86233228 - samples/sec: 144.66 - lr: 0.100000\n","2022-02-16 19:34:05,615 epoch 10 - iter 18/20 - loss 0.86158636 - samples/sec: 277.55 - lr: 0.100000\n","2022-02-16 19:34:05,852 epoch 10 - iter 20/20 - loss 0.87362309 - samples/sec: 278.71 - lr: 0.100000\n","2022-02-16 19:34:06,510 ----------------------------------------------------------------------------------------------------\n","2022-02-16 19:34:06,518 EPOCH 10 done: loss 0.8736 - lr 0.1000000\n","2022-02-16 19:34:09,535 DEV : loss 0.9461197853088379 - score 0.4638\n","2022-02-16 19:34:09,681 BAD EPOCHS (no improvement): 2\n","2022-02-16 19:34:09,698 ----------------------------------------------------------------------------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"output_type":"stream","name":"stdout","text":["2022-02-16 19:34:11,863 epoch 11 - iter 2/20 - loss 0.92038864 - samples/sec: 130.12 - lr: 0.100000\n","2022-02-16 19:34:12,365 epoch 11 - iter 4/20 - loss 0.81264453 - samples/sec: 163.32 - lr: 0.100000\n","2022-02-16 19:34:12,795 epoch 11 - iter 6/20 - loss 0.82557011 - samples/sec: 186.67 - lr: 0.100000\n","2022-02-16 19:34:13,092 epoch 11 - iter 8/20 - loss 0.82225146 - samples/sec: 229.36 - lr: 0.100000\n","2022-02-16 19:34:13,228 epoch 11 - iter 10/20 - loss 0.84366471 - samples/sec: 482.25 - lr: 0.100000\n","2022-02-16 19:34:13,375 epoch 11 - iter 12/20 - loss 0.84448996 - samples/sec: 469.49 - lr: 0.100000\n","2022-02-16 19:34:13,509 epoch 11 - iter 14/20 - loss 0.83536732 - samples/sec: 492.99 - lr: 0.100000\n","2022-02-16 19:34:13,659 epoch 11 - iter 16/20 - loss 0.81704002 - samples/sec: 441.95 - lr: 0.100000\n","2022-02-16 19:34:13,800 epoch 11 - iter 18/20 - loss 0.84119954 - samples/sec: 481.71 - lr: 0.100000\n","2022-02-16 19:34:13,906 epoch 11 - iter 20/20 - loss 0.86160915 - samples/sec: 662.44 - lr: 0.100000\n","2022-02-16 19:34:14,308 ----------------------------------------------------------------------------------------------------\n","2022-02-16 19:34:14,310 EPOCH 11 done: loss 0.8616 - lr 0.1000000\n","2022-02-16 19:34:15,824 DEV : loss 0.856968104839325 - score 0.5072\n","2022-02-16 19:34:15,900 BAD EPOCHS (no improvement): 3\n","2022-02-16 19:34:15,912 ----------------------------------------------------------------------------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"output_type":"stream","name":"stdout","text":["2022-02-16 19:34:17,186 epoch 12 - iter 2/20 - loss 0.68466479 - samples/sec: 175.22 - lr: 0.100000\n","2022-02-16 19:34:17,385 epoch 12 - iter 4/20 - loss 0.83851154 - samples/sec: 400.95 - lr: 0.100000\n","2022-02-16 19:34:17,554 epoch 12 - iter 6/20 - loss 0.81956059 - samples/sec: 411.40 - lr: 0.100000\n","2022-02-16 19:34:17,712 epoch 12 - iter 8/20 - loss 0.83469347 - samples/sec: 431.13 - lr: 0.100000\n","2022-02-16 19:34:17,901 epoch 12 - iter 10/20 - loss 0.81815472 - samples/sec: 489.62 - lr: 0.100000\n","2022-02-16 19:34:18,037 epoch 12 - iter 12/20 - loss 0.82882398 - samples/sec: 492.92 - lr: 0.100000\n","2022-02-16 19:34:18,172 epoch 12 - iter 14/20 - loss 0.81530702 - samples/sec: 489.55 - lr: 0.100000\n","2022-02-16 19:34:18,311 epoch 12 - iter 16/20 - loss 0.82973792 - samples/sec: 490.57 - lr: 0.100000\n","2022-02-16 19:34:18,455 epoch 12 - iter 18/20 - loss 0.81785958 - samples/sec: 464.85 - lr: 0.100000\n","2022-02-16 19:34:18,565 epoch 12 - iter 20/20 - loss 0.83371151 - samples/sec: 602.66 - lr: 0.100000\n","2022-02-16 19:34:18,940 ----------------------------------------------------------------------------------------------------\n","2022-02-16 19:34:18,947 EPOCH 12 done: loss 0.8337 - lr 0.1000000\n","2022-02-16 19:34:20,353 DEV : loss 0.8473937511444092 - score 0.5797\n","2022-02-16 19:34:20,427 BAD EPOCHS (no improvement): 0\n","saving best model\n","2022-02-16 19:34:36,342 ----------------------------------------------------------------------------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"output_type":"stream","name":"stdout","text":["2022-02-16 19:34:37,880 epoch 13 - iter 2/20 - loss 0.83142048 - samples/sec: 206.89 - lr: 0.100000\n","2022-02-16 19:34:38,061 epoch 13 - iter 4/20 - loss 0.86484054 - samples/sec: 426.34 - lr: 0.100000\n","2022-02-16 19:34:38,230 epoch 13 - iter 6/20 - loss 0.82754322 - samples/sec: 428.75 - lr: 0.100000\n","2022-02-16 19:34:38,428 epoch 13 - iter 8/20 - loss 0.86033887 - samples/sec: 393.09 - lr: 0.100000\n","2022-02-16 19:34:38,556 epoch 13 - iter 10/20 - loss 0.85004689 - samples/sec: 514.00 - lr: 0.100000\n","2022-02-16 19:34:38,695 epoch 13 - iter 12/20 - loss 0.84511957 - samples/sec: 469.35 - lr: 0.100000\n","2022-02-16 19:34:38,832 epoch 13 - iter 14/20 - loss 0.83551430 - samples/sec: 486.24 - lr: 0.100000\n","2022-02-16 19:34:38,972 epoch 13 - iter 16/20 - loss 0.83908698 - samples/sec: 466.20 - lr: 0.100000\n","2022-02-16 19:34:39,109 epoch 13 - iter 18/20 - loss 0.84092171 - samples/sec: 489.95 - lr: 0.100000\n","2022-02-16 19:34:39,246 epoch 13 - iter 20/20 - loss 0.82813581 - samples/sec: 554.18 - lr: 0.100000\n","2022-02-16 19:34:39,800 ----------------------------------------------------------------------------------------------------\n","2022-02-16 19:34:39,806 EPOCH 13 done: loss 0.8281 - lr 0.1000000\n","2022-02-16 19:34:41,650 DEV : loss 0.8460134267807007 - score 0.5797\n","2022-02-16 19:34:41,733 BAD EPOCHS (no improvement): 0\n","saving best model\n","2022-02-16 19:34:56,738 ----------------------------------------------------------------------------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"output_type":"stream","name":"stdout","text":["2022-02-16 19:34:58,456 epoch 14 - iter 2/20 - loss 0.67735153 - samples/sec: 281.99 - lr: 0.100000\n","2022-02-16 19:34:58,623 epoch 14 - iter 4/20 - loss 0.73355015 - samples/sec: 394.12 - lr: 0.100000\n","2022-02-16 19:34:58,823 epoch 14 - iter 6/20 - loss 0.71464973 - samples/sec: 445.72 - lr: 0.100000\n","2022-02-16 19:34:58,970 epoch 14 - iter 8/20 - loss 0.68825995 - samples/sec: 451.96 - lr: 0.100000\n","2022-02-16 19:34:59,101 epoch 14 - iter 10/20 - loss 0.74415141 - samples/sec: 514.08 - lr: 0.100000\n","2022-02-16 19:34:59,234 epoch 14 - iter 12/20 - loss 0.76294965 - samples/sec: 507.12 - lr: 0.100000\n","2022-02-16 19:34:59,381 epoch 14 - iter 14/20 - loss 0.77646447 - samples/sec: 469.00 - lr: 0.100000\n","2022-02-16 19:34:59,524 epoch 14 - iter 16/20 - loss 0.77992244 - samples/sec: 459.06 - lr: 0.100000\n","2022-02-16 19:34:59,653 epoch 14 - iter 18/20 - loss 0.78408312 - samples/sec: 539.35 - lr: 0.100000\n","2022-02-16 19:34:59,761 epoch 14 - iter 20/20 - loss 0.78846522 - samples/sec: 666.89 - lr: 0.100000\n","2022-02-16 19:35:00,261 ----------------------------------------------------------------------------------------------------\n","2022-02-16 19:35:00,263 EPOCH 14 done: loss 0.7885 - lr 0.1000000\n","2022-02-16 19:35:02,183 DEV : loss 0.8564955592155457 - score 0.5217\n","2022-02-16 19:35:02,261 BAD EPOCHS (no improvement): 1\n","2022-02-16 19:35:02,271 ----------------------------------------------------------------------------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"output_type":"stream","name":"stdout","text":["2022-02-16 19:35:05,020 epoch 15 - iter 2/20 - loss 0.88940504 - samples/sec: 113.53 - lr: 0.100000\n","2022-02-16 19:35:05,608 epoch 15 - iter 4/20 - loss 0.85495868 - samples/sec: 118.24 - lr: 0.100000\n","2022-02-16 19:35:06,037 epoch 15 - iter 6/20 - loss 0.82163824 - samples/sec: 181.23 - lr: 0.100000\n","2022-02-16 19:35:06,395 epoch 15 - iter 8/20 - loss 0.80913916 - samples/sec: 193.20 - lr: 0.100000\n","2022-02-16 19:35:06,872 epoch 15 - iter 10/20 - loss 0.78640382 - samples/sec: 138.02 - lr: 0.100000\n","2022-02-16 19:35:07,443 epoch 15 - iter 12/20 - loss 0.75433699 - samples/sec: 151.35 - lr: 0.100000\n","2022-02-16 19:35:08,024 epoch 15 - iter 14/20 - loss 0.75998801 - samples/sec: 113.03 - lr: 0.100000\n","2022-02-16 19:35:08,329 epoch 15 - iter 16/20 - loss 0.75092001 - samples/sec: 219.30 - lr: 0.100000\n","2022-02-16 19:35:08,662 epoch 15 - iter 18/20 - loss 0.76672081 - samples/sec: 199.72 - lr: 0.100000\n","2022-02-16 19:35:08,936 epoch 15 - iter 20/20 - loss 0.77766628 - samples/sec: 241.24 - lr: 0.100000\n","2022-02-16 19:35:09,835 ----------------------------------------------------------------------------------------------------\n","2022-02-16 19:35:09,847 EPOCH 15 done: loss 0.7777 - lr 0.1000000\n","2022-02-16 19:35:13,319 DEV : loss 1.2571353912353516 - score 0.3913\n","2022-02-16 19:35:13,542 BAD EPOCHS (no improvement): 2\n","2022-02-16 19:35:13,560 ----------------------------------------------------------------------------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"output_type":"stream","name":"stdout","text":["2022-02-16 19:35:16,516 epoch 16 - iter 2/20 - loss 0.94562298 - samples/sec: 94.10 - lr: 0.100000\n","2022-02-16 19:35:16,682 epoch 16 - iter 4/20 - loss 0.85393643 - samples/sec: 428.98 - lr: 0.100000\n","2022-02-16 19:35:16,889 epoch 16 - iter 6/20 - loss 0.81823614 - samples/sec: 427.73 - lr: 0.100000\n","2022-02-16 19:35:17,046 epoch 16 - iter 8/20 - loss 0.80218202 - samples/sec: 415.70 - lr: 0.100000\n","2022-02-16 19:35:17,180 epoch 16 - iter 10/20 - loss 0.80160732 - samples/sec: 489.39 - lr: 0.100000\n","2022-02-16 19:35:17,323 epoch 16 - iter 12/20 - loss 0.80250856 - samples/sec: 489.17 - lr: 0.100000\n","2022-02-16 19:35:17,477 epoch 16 - iter 14/20 - loss 0.78346520 - samples/sec: 423.63 - lr: 0.100000\n","2022-02-16 19:35:17,628 epoch 16 - iter 16/20 - loss 0.77624687 - samples/sec: 446.16 - lr: 0.100000\n","2022-02-16 19:35:17,775 epoch 16 - iter 18/20 - loss 0.77475339 - samples/sec: 493.67 - lr: 0.100000\n","2022-02-16 19:35:17,894 epoch 16 - iter 20/20 - loss 0.75921625 - samples/sec: 629.63 - lr: 0.100000\n","2022-02-16 19:35:18,302 ----------------------------------------------------------------------------------------------------\n","2022-02-16 19:35:18,309 EPOCH 16 done: loss 0.7592 - lr 0.1000000\n","2022-02-16 19:35:19,846 DEV : loss 0.7676151990890503 - score 0.6087\n","2022-02-16 19:35:19,923 BAD EPOCHS (no improvement): 0\n","saving best model\n","2022-02-16 19:35:35,903 ----------------------------------------------------------------------------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"output_type":"stream","name":"stdout","text":["2022-02-16 19:35:37,503 epoch 17 - iter 2/20 - loss 0.70542401 - samples/sec: 218.31 - lr: 0.100000\n","2022-02-16 19:35:37,693 epoch 17 - iter 4/20 - loss 0.81027243 - samples/sec: 408.70 - lr: 0.100000\n","2022-02-16 19:35:39,916 epoch 17 - iter 6/20 - loss 0.77024255 - samples/sec: 401.91 - lr: 0.100000\n","2022-02-16 19:35:40,053 epoch 17 - iter 8/20 - loss 0.76414867 - samples/sec: 499.58 - lr: 0.100000\n","2022-02-16 19:35:40,184 epoch 17 - iter 10/20 - loss 0.76793488 - samples/sec: 513.09 - lr: 0.100000\n","2022-02-16 19:35:40,344 epoch 17 - iter 12/20 - loss 0.76781653 - samples/sec: 459.56 - lr: 0.100000\n","2022-02-16 19:35:40,482 epoch 17 - iter 14/20 - loss 0.74905544 - samples/sec: 524.58 - lr: 0.100000\n","2022-02-16 19:35:40,611 epoch 17 - iter 16/20 - loss 0.74961948 - samples/sec: 523.24 - lr: 0.100000\n","2022-02-16 19:35:40,744 epoch 17 - iter 18/20 - loss 0.75599335 - samples/sec: 486.90 - lr: 0.100000\n","2022-02-16 19:35:40,848 epoch 17 - iter 20/20 - loss 0.76060354 - samples/sec: 706.27 - lr: 0.100000\n","2022-02-16 19:35:41,404 ----------------------------------------------------------------------------------------------------\n","2022-02-16 19:35:41,410 EPOCH 17 done: loss 0.7606 - lr 0.1000000\n","2022-02-16 19:35:43,725 DEV : loss 0.8399022817611694 - score 0.5507\n","2022-02-16 19:35:43,901 BAD EPOCHS (no improvement): 1\n","2022-02-16 19:35:43,918 ----------------------------------------------------------------------------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"output_type":"stream","name":"stdout","text":["2022-02-16 19:35:47,015 epoch 18 - iter 2/20 - loss 0.70793337 - samples/sec: 116.63 - lr: 0.100000\n","2022-02-16 19:35:47,478 epoch 18 - iter 4/20 - loss 0.69411023 - samples/sec: 151.64 - lr: 0.100000\n","2022-02-16 19:35:47,796 epoch 18 - iter 6/20 - loss 0.68125192 - samples/sec: 248.17 - lr: 0.100000\n","2022-02-16 19:35:48,159 epoch 18 - iter 8/20 - loss 0.72264050 - samples/sec: 181.63 - lr: 0.100000\n","2022-02-16 19:35:48,456 epoch 18 - iter 10/20 - loss 0.74369009 - samples/sec: 223.81 - lr: 0.100000\n","2022-02-16 19:35:48,894 epoch 18 - iter 12/20 - loss 0.74219364 - samples/sec: 172.57 - lr: 0.100000\n","2022-02-16 19:35:49,294 epoch 18 - iter 14/20 - loss 0.73904308 - samples/sec: 164.25 - lr: 0.100000\n","2022-02-16 19:35:49,607 epoch 18 - iter 16/20 - loss 0.73644933 - samples/sec: 207.61 - lr: 0.100000\n","2022-02-16 19:35:49,962 epoch 18 - iter 18/20 - loss 0.73441383 - samples/sec: 206.78 - lr: 0.100000\n","2022-02-16 19:35:50,217 epoch 18 - iter 20/20 - loss 0.72410956 - samples/sec: 265.38 - lr: 0.100000\n","2022-02-16 19:35:50,876 ----------------------------------------------------------------------------------------------------\n","2022-02-16 19:35:50,879 EPOCH 18 done: loss 0.7241 - lr 0.1000000\n","2022-02-16 19:35:54,397 DEV : loss 0.9951761960983276 - score 0.5797\n","2022-02-16 19:35:54,678 BAD EPOCHS (no improvement): 2\n","2022-02-16 19:35:54,705 ----------------------------------------------------------------------------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"output_type":"stream","name":"stdout","text":["2022-02-16 19:35:58,019 epoch 19 - iter 2/20 - loss 0.71776173 - samples/sec: 80.34 - lr: 0.100000\n","2022-02-16 19:35:58,234 epoch 19 - iter 4/20 - loss 0.70292485 - samples/sec: 359.39 - lr: 0.100000\n","2022-02-16 19:35:58,413 epoch 19 - iter 6/20 - loss 0.75389547 - samples/sec: 401.06 - lr: 0.100000\n","2022-02-16 19:35:58,574 epoch 19 - iter 8/20 - loss 0.71864709 - samples/sec: 417.45 - lr: 0.100000\n","2022-02-16 19:35:58,721 epoch 19 - iter 10/20 - loss 0.75257628 - samples/sec: 498.69 - lr: 0.100000\n","2022-02-16 19:35:58,879 epoch 19 - iter 12/20 - loss 0.73237332 - samples/sec: 485.94 - lr: 0.100000\n","2022-02-16 19:35:59,014 epoch 19 - iter 14/20 - loss 0.71799231 - samples/sec: 491.42 - lr: 0.100000\n","2022-02-16 19:35:59,178 epoch 19 - iter 16/20 - loss 0.72398884 - samples/sec: 407.42 - lr: 0.100000\n","2022-02-16 19:35:59,319 epoch 19 - iter 18/20 - loss 0.72478678 - samples/sec: 499.68 - lr: 0.100000\n","2022-02-16 19:35:59,424 epoch 19 - iter 20/20 - loss 0.73801990 - samples/sec: 633.69 - lr: 0.100000\n","2022-02-16 19:35:59,824 ----------------------------------------------------------------------------------------------------\n","2022-02-16 19:35:59,829 EPOCH 19 done: loss 0.7380 - lr 0.1000000\n","2022-02-16 19:36:01,356 DEV : loss 0.9829202890396118 - score 0.5362\n","2022-02-16 19:36:01,440 BAD EPOCHS (no improvement): 3\n","2022-02-16 19:36:01,447 ----------------------------------------------------------------------------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"output_type":"stream","name":"stdout","text":["2022-02-16 19:36:02,718 epoch 20 - iter 2/20 - loss 0.72242367 - samples/sec: 178.92 - lr: 0.100000\n","2022-02-16 19:36:02,893 epoch 20 - iter 4/20 - loss 0.77666037 - samples/sec: 425.13 - lr: 0.100000\n","2022-02-16 19:36:03,077 epoch 20 - iter 6/20 - loss 0.76356638 - samples/sec: 423.53 - lr: 0.100000\n","2022-02-16 19:36:03,234 epoch 20 - iter 8/20 - loss 0.72886866 - samples/sec: 424.24 - lr: 0.100000\n","2022-02-16 19:36:03,426 epoch 20 - iter 10/20 - loss 0.72261356 - samples/sec: 439.99 - lr: 0.100000\n","2022-02-16 19:36:03,568 epoch 20 - iter 12/20 - loss 0.70745780 - samples/sec: 460.61 - lr: 0.100000\n","2022-02-16 19:36:03,711 epoch 20 - iter 14/20 - loss 0.68911916 - samples/sec: 466.44 - lr: 0.100000\n","2022-02-16 19:36:03,860 epoch 20 - iter 16/20 - loss 0.69704013 - samples/sec: 482.58 - lr: 0.100000\n","2022-02-16 19:36:03,993 epoch 20 - iter 18/20 - loss 0.70029220 - samples/sec: 506.87 - lr: 0.100000\n","2022-02-16 19:36:04,113 epoch 20 - iter 20/20 - loss 0.70284516 - samples/sec: 543.11 - lr: 0.100000\n","2022-02-16 19:36:04,500 ----------------------------------------------------------------------------------------------------\n","2022-02-16 19:36:04,503 EPOCH 20 done: loss 0.7028 - lr 0.1000000\n","2022-02-16 19:36:05,974 DEV : loss 0.9762847423553467 - score 0.4493\n","Epoch    20: reducing learning rate of group 0 to 5.0000e-02.\n","2022-02-16 19:36:06,054 BAD EPOCHS (no improvement): 4\n","2022-02-16 19:36:06,064 ----------------------------------------------------------------------------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"output_type":"stream","name":"stdout","text":["2022-02-16 19:36:07,329 epoch 21 - iter 2/20 - loss 0.84260362 - samples/sec: 294.41 - lr: 0.050000\n","2022-02-16 19:36:07,505 epoch 21 - iter 4/20 - loss 0.80937068 - samples/sec: 410.14 - lr: 0.050000\n","2022-02-16 19:36:07,706 epoch 21 - iter 6/20 - loss 0.76542682 - samples/sec: 378.76 - lr: 0.050000\n","2022-02-16 19:36:07,867 epoch 21 - iter 8/20 - loss 0.69898181 - samples/sec: 414.61 - lr: 0.050000\n","2022-02-16 19:36:08,009 epoch 21 - iter 10/20 - loss 0.69529081 - samples/sec: 501.32 - lr: 0.050000\n","2022-02-16 19:36:08,182 epoch 21 - iter 12/20 - loss 0.68915576 - samples/sec: 471.82 - lr: 0.050000\n","2022-02-16 19:36:08,325 epoch 21 - iter 14/20 - loss 0.68919471 - samples/sec: 468.07 - lr: 0.050000\n","2022-02-16 19:36:08,470 epoch 21 - iter 16/20 - loss 0.69620060 - samples/sec: 447.98 - lr: 0.050000\n","2022-02-16 19:36:08,628 epoch 21 - iter 18/20 - loss 0.68132672 - samples/sec: 423.54 - lr: 0.050000\n","2022-02-16 19:36:08,739 epoch 21 - iter 20/20 - loss 0.67840314 - samples/sec: 596.77 - lr: 0.050000\n","2022-02-16 19:36:09,085 ----------------------------------------------------------------------------------------------------\n","2022-02-16 19:36:09,087 EPOCH 21 done: loss 0.6784 - lr 0.0500000\n","2022-02-16 19:36:10,535 DEV : loss 0.8251398801803589 - score 0.5942\n","2022-02-16 19:36:10,608 BAD EPOCHS (no improvement): 1\n","2022-02-16 19:36:10,618 ----------------------------------------------------------------------------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"output_type":"stream","name":"stdout","text":["2022-02-16 19:36:11,848 epoch 22 - iter 2/20 - loss 0.54296105 - samples/sec: 202.58 - lr: 0.050000\n","2022-02-16 19:36:12,031 epoch 22 - iter 4/20 - loss 0.64828654 - samples/sec: 388.49 - lr: 0.050000\n","2022-02-16 19:36:12,227 epoch 22 - iter 6/20 - loss 0.63082961 - samples/sec: 426.56 - lr: 0.050000\n","2022-02-16 19:36:12,374 epoch 22 - iter 8/20 - loss 0.66156169 - samples/sec: 443.29 - lr: 0.050000\n","2022-02-16 19:36:12,511 epoch 22 - iter 10/20 - loss 0.66816486 - samples/sec: 476.73 - lr: 0.050000\n","2022-02-16 19:36:12,653 epoch 22 - iter 12/20 - loss 0.64185285 - samples/sec: 487.47 - lr: 0.050000\n","2022-02-16 19:36:12,781 epoch 22 - iter 14/20 - loss 0.64284215 - samples/sec: 510.30 - lr: 0.050000\n","2022-02-16 19:36:12,912 epoch 22 - iter 16/20 - loss 0.64753427 - samples/sec: 530.82 - lr: 0.050000\n","2022-02-16 19:36:13,064 epoch 22 - iter 18/20 - loss 0.64770686 - samples/sec: 468.14 - lr: 0.050000\n","2022-02-16 19:36:13,173 epoch 22 - iter 20/20 - loss 0.66215284 - samples/sec: 647.95 - lr: 0.050000\n","2022-02-16 19:36:13,507 ----------------------------------------------------------------------------------------------------\n","2022-02-16 19:36:13,510 EPOCH 22 done: loss 0.6622 - lr 0.0500000\n","2022-02-16 19:36:14,925 DEV : loss 0.9528338313102722 - score 0.5942\n","2022-02-16 19:36:15,002 BAD EPOCHS (no improvement): 2\n","2022-02-16 19:36:15,012 ----------------------------------------------------------------------------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"output_type":"stream","name":"stdout","text":["2022-02-16 19:36:16,264 epoch 23 - iter 2/20 - loss 0.65821895 - samples/sec: 203.40 - lr: 0.050000\n","2022-02-16 19:36:16,438 epoch 23 - iter 4/20 - loss 0.66412063 - samples/sec: 403.49 - lr: 0.050000\n","2022-02-16 19:36:16,628 epoch 23 - iter 6/20 - loss 0.62785184 - samples/sec: 411.15 - lr: 0.050000\n","2022-02-16 19:36:16,788 epoch 23 - iter 8/20 - loss 0.61334809 - samples/sec: 418.14 - lr: 0.050000\n","2022-02-16 19:36:16,951 epoch 23 - iter 10/20 - loss 0.62143175 - samples/sec: 471.83 - lr: 0.050000\n","2022-02-16 19:36:17,082 epoch 23 - iter 12/20 - loss 0.61863871 - samples/sec: 496.49 - lr: 0.050000\n","2022-02-16 19:36:17,234 epoch 23 - iter 14/20 - loss 0.63493204 - samples/sec: 475.90 - lr: 0.050000\n","2022-02-16 19:36:17,386 epoch 23 - iter 16/20 - loss 0.63179029 - samples/sec: 447.10 - lr: 0.050000\n","2022-02-16 19:36:17,519 epoch 23 - iter 18/20 - loss 0.62621974 - samples/sec: 488.45 - lr: 0.050000\n","2022-02-16 19:36:17,632 epoch 23 - iter 20/20 - loss 0.64380634 - samples/sec: 632.24 - lr: 0.050000\n","2022-02-16 19:36:17,959 ----------------------------------------------------------------------------------------------------\n","2022-02-16 19:36:17,966 EPOCH 23 done: loss 0.6438 - lr 0.0500000\n","2022-02-16 19:36:19,315 DEV : loss 0.6871880888938904 - score 0.5797\n","2022-02-16 19:36:19,397 BAD EPOCHS (no improvement): 3\n","2022-02-16 19:36:19,412 ----------------------------------------------------------------------------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"output_type":"stream","name":"stdout","text":["2022-02-16 19:36:20,619 epoch 24 - iter 2/20 - loss 0.59164155 - samples/sec: 228.85 - lr: 0.050000\n","2022-02-16 19:36:20,779 epoch 24 - iter 4/20 - loss 0.60402948 - samples/sec: 416.10 - lr: 0.050000\n","2022-02-16 19:36:20,964 epoch 24 - iter 6/20 - loss 0.61206413 - samples/sec: 425.64 - lr: 0.050000\n","2022-02-16 19:36:21,125 epoch 24 - iter 8/20 - loss 0.60006279 - samples/sec: 442.05 - lr: 0.050000\n","2022-02-16 19:36:21,253 epoch 24 - iter 10/20 - loss 0.59173635 - samples/sec: 509.49 - lr: 0.050000\n","2022-02-16 19:36:23,046 epoch 24 - iter 12/20 - loss 0.58831551 - samples/sec: 523.84 - lr: 0.050000\n","2022-02-16 19:36:23,187 epoch 24 - iter 14/20 - loss 0.58781952 - samples/sec: 479.22 - lr: 0.050000\n","2022-02-16 19:36:23,311 epoch 24 - iter 16/20 - loss 0.59353235 - samples/sec: 531.14 - lr: 0.050000\n","2022-02-16 19:36:23,442 epoch 24 - iter 18/20 - loss 0.61530490 - samples/sec: 554.08 - lr: 0.050000\n","2022-02-16 19:36:23,558 epoch 24 - iter 20/20 - loss 0.61380319 - samples/sec: 580.51 - lr: 0.050000\n","2022-02-16 19:36:23,902 ----------------------------------------------------------------------------------------------------\n","2022-02-16 19:36:23,909 EPOCH 24 done: loss 0.6138 - lr 0.0500000\n","2022-02-16 19:36:25,383 DEV : loss 0.6898099780082703 - score 0.6522\n","2022-02-16 19:36:25,462 BAD EPOCHS (no improvement): 0\n","saving best model\n","2022-02-16 19:36:41,593 ----------------------------------------------------------------------------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"output_type":"stream","name":"stdout","text":["2022-02-16 19:36:43,175 epoch 25 - iter 2/20 - loss 0.59129706 - samples/sec: 201.56 - lr: 0.050000\n","2022-02-16 19:36:43,352 epoch 25 - iter 4/20 - loss 0.61066762 - samples/sec: 393.03 - lr: 0.050000\n","2022-02-16 19:36:43,558 epoch 25 - iter 6/20 - loss 0.58585968 - samples/sec: 385.86 - lr: 0.050000\n","2022-02-16 19:36:43,716 epoch 25 - iter 8/20 - loss 0.63944020 - samples/sec: 426.22 - lr: 0.050000\n","2022-02-16 19:36:43,865 epoch 25 - iter 10/20 - loss 0.62727332 - samples/sec: 476.83 - lr: 0.050000\n","2022-02-16 19:36:44,017 epoch 25 - iter 12/20 - loss 0.62371630 - samples/sec: 512.62 - lr: 0.050000\n","2022-02-16 19:36:44,149 epoch 25 - iter 14/20 - loss 0.61728930 - samples/sec: 496.73 - lr: 0.050000\n","2022-02-16 19:36:44,283 epoch 25 - iter 16/20 - loss 0.63239911 - samples/sec: 499.69 - lr: 0.050000\n","2022-02-16 19:36:44,427 epoch 25 - iter 18/20 - loss 0.63396287 - samples/sec: 503.11 - lr: 0.050000\n","2022-02-16 19:36:44,558 epoch 25 - iter 20/20 - loss 0.62790418 - samples/sec: 500.48 - lr: 0.050000\n","2022-02-16 19:36:45,069 ----------------------------------------------------------------------------------------------------\n","2022-02-16 19:36:45,072 EPOCH 25 done: loss 0.6279 - lr 0.0500000\n","2022-02-16 19:36:46,898 DEV : loss 0.6848871111869812 - score 0.6232\n","2022-02-16 19:36:46,972 BAD EPOCHS (no improvement): 1\n","2022-02-16 19:36:46,984 ----------------------------------------------------------------------------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"output_type":"stream","name":"stdout","text":["2022-02-16 19:36:48,718 epoch 26 - iter 2/20 - loss 0.77853504 - samples/sec: 115.04 - lr: 0.050000\n","2022-02-16 19:36:49,278 epoch 26 - iter 4/20 - loss 0.70604727 - samples/sec: 139.58 - lr: 0.050000\n","2022-02-16 19:36:49,614 epoch 26 - iter 6/20 - loss 0.66693901 - samples/sec: 217.98 - lr: 0.050000\n","2022-02-16 19:36:49,939 epoch 26 - iter 8/20 - loss 0.68941619 - samples/sec: 230.37 - lr: 0.050000\n","2022-02-16 19:36:50,478 epoch 26 - iter 10/20 - loss 0.67627452 - samples/sec: 121.33 - lr: 0.050000\n","2022-02-16 19:36:50,953 epoch 26 - iter 12/20 - loss 0.66356630 - samples/sec: 145.38 - lr: 0.050000\n","2022-02-16 19:36:51,311 epoch 26 - iter 14/20 - loss 0.65759152 - samples/sec: 204.32 - lr: 0.050000\n","2022-02-16 19:36:51,598 epoch 26 - iter 16/20 - loss 0.65250189 - samples/sec: 233.31 - lr: 0.050000\n","2022-02-16 19:36:51,859 epoch 26 - iter 18/20 - loss 0.64123570 - samples/sec: 289.92 - lr: 0.050000\n","2022-02-16 19:36:52,031 epoch 26 - iter 20/20 - loss 0.63926242 - samples/sec: 384.15 - lr: 0.050000\n","2022-02-16 19:36:52,727 ----------------------------------------------------------------------------------------------------\n","2022-02-16 19:36:52,743 EPOCH 26 done: loss 0.6393 - lr 0.0500000\n","2022-02-16 19:36:55,650 DEV : loss 0.6900558471679688 - score 0.6232\n","2022-02-16 19:36:55,906 BAD EPOCHS (no improvement): 2\n","2022-02-16 19:36:55,922 ----------------------------------------------------------------------------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"output_type":"stream","name":"stdout","text":["2022-02-16 19:36:58,041 epoch 27 - iter 2/20 - loss 0.65272611 - samples/sec: 93.40 - lr: 0.050000\n","2022-02-16 19:36:58,466 epoch 27 - iter 4/20 - loss 0.63085018 - samples/sec: 168.35 - lr: 0.050000\n","2022-02-16 19:36:58,873 epoch 27 - iter 6/20 - loss 0.65875776 - samples/sec: 194.31 - lr: 0.050000\n","2022-02-16 19:36:59,242 epoch 27 - iter 8/20 - loss 0.64953616 - samples/sec: 179.71 - lr: 0.050000\n","2022-02-16 19:36:59,535 epoch 27 - iter 10/20 - loss 0.65346010 - samples/sec: 260.65 - lr: 0.050000\n","2022-02-16 19:36:59,853 epoch 27 - iter 12/20 - loss 0.64943606 - samples/sec: 243.14 - lr: 0.050000\n","2022-02-16 19:37:00,112 epoch 27 - iter 14/20 - loss 0.66788944 - samples/sec: 279.96 - lr: 0.050000\n","2022-02-16 19:37:00,431 epoch 27 - iter 16/20 - loss 0.66687189 - samples/sec: 207.00 - lr: 0.050000\n","2022-02-16 19:37:00,655 epoch 27 - iter 18/20 - loss 0.64828990 - samples/sec: 295.57 - lr: 0.050000\n","2022-02-16 19:37:00,846 epoch 27 - iter 20/20 - loss 0.64869162 - samples/sec: 364.50 - lr: 0.050000\n","2022-02-16 19:37:01,399 ----------------------------------------------------------------------------------------------------\n","2022-02-16 19:37:01,404 EPOCH 27 done: loss 0.6487 - lr 0.0500000\n","2022-02-16 19:37:03,926 DEV : loss 0.7247755527496338 - score 0.6232\n","2022-02-16 19:37:04,047 BAD EPOCHS (no improvement): 3\n","2022-02-16 19:37:04,068 ----------------------------------------------------------------------------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"output_type":"stream","name":"stdout","text":["2022-02-16 19:37:05,627 epoch 28 - iter 2/20 - loss 0.70245999 - samples/sec: 213.72 - lr: 0.050000\n","2022-02-16 19:37:05,805 epoch 28 - iter 4/20 - loss 0.66868725 - samples/sec: 423.45 - lr: 0.050000\n","2022-02-16 19:37:06,001 epoch 28 - iter 6/20 - loss 0.64695689 - samples/sec: 432.79 - lr: 0.050000\n","2022-02-16 19:37:06,153 epoch 28 - iter 8/20 - loss 0.61838904 - samples/sec: 443.04 - lr: 0.050000\n","2022-02-16 19:37:06,296 epoch 28 - iter 10/20 - loss 0.62965752 - samples/sec: 467.39 - lr: 0.050000\n","2022-02-16 19:37:06,432 epoch 28 - iter 12/20 - loss 0.63575632 - samples/sec: 521.98 - lr: 0.050000\n","2022-02-16 19:37:06,561 epoch 28 - iter 14/20 - loss 0.65193964 - samples/sec: 523.66 - lr: 0.050000\n","2022-02-16 19:37:06,699 epoch 28 - iter 16/20 - loss 0.65877854 - samples/sec: 488.16 - lr: 0.050000\n","2022-02-16 19:37:06,833 epoch 28 - iter 18/20 - loss 0.65319801 - samples/sec: 497.26 - lr: 0.050000\n","2022-02-16 19:37:06,941 epoch 28 - iter 20/20 - loss 0.63962851 - samples/sec: 682.62 - lr: 0.050000\n","2022-02-16 19:37:07,320 ----------------------------------------------------------------------------------------------------\n","2022-02-16 19:37:07,322 EPOCH 28 done: loss 0.6396 - lr 0.0500000\n","2022-02-16 19:37:08,860 DEV : loss 0.5865464210510254 - score 0.6812\n","2022-02-16 19:37:08,938 BAD EPOCHS (no improvement): 0\n","saving best model\n","2022-02-16 19:37:24,826 ----------------------------------------------------------------------------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"output_type":"stream","name":"stdout","text":["2022-02-16 19:37:26,473 epoch 29 - iter 2/20 - loss 0.50573708 - samples/sec: 256.15 - lr: 0.050000\n","2022-02-16 19:37:26,636 epoch 29 - iter 4/20 - loss 0.61285897 - samples/sec: 405.55 - lr: 0.050000\n","2022-02-16 19:37:26,829 epoch 29 - iter 6/20 - loss 0.61556219 - samples/sec: 427.56 - lr: 0.050000\n","2022-02-16 19:37:26,995 epoch 29 - iter 8/20 - loss 0.60514634 - samples/sec: 395.96 - lr: 0.050000\n","2022-02-16 19:37:27,160 epoch 29 - iter 10/20 - loss 0.60669799 - samples/sec: 435.46 - lr: 0.050000\n","2022-02-16 19:37:27,326 epoch 29 - iter 12/20 - loss 0.59116068 - samples/sec: 478.32 - lr: 0.050000\n","2022-02-16 19:37:27,460 epoch 29 - iter 14/20 - loss 0.60115516 - samples/sec: 504.57 - lr: 0.050000\n","2022-02-16 19:37:27,603 epoch 29 - iter 16/20 - loss 0.62420270 - samples/sec: 460.68 - lr: 0.050000\n","2022-02-16 19:37:27,738 epoch 29 - iter 18/20 - loss 0.63557287 - samples/sec: 513.60 - lr: 0.050000\n","2022-02-16 19:37:27,841 epoch 29 - iter 20/20 - loss 0.61799870 - samples/sec: 652.05 - lr: 0.050000\n","2022-02-16 19:37:28,368 ----------------------------------------------------------------------------------------------------\n","2022-02-16 19:37:28,371 EPOCH 29 done: loss 0.6180 - lr 0.0500000\n","2022-02-16 19:37:30,265 DEV : loss 0.6232314109802246 - score 0.6232\n","2022-02-16 19:37:30,342 BAD EPOCHS (no improvement): 1\n","2022-02-16 19:37:30,350 ----------------------------------------------------------------------------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"output_type":"stream","name":"stdout","text":["2022-02-16 19:37:31,804 epoch 30 - iter 2/20 - loss 0.62833554 - samples/sec: 179.62 - lr: 0.050000\n","2022-02-16 19:37:31,981 epoch 30 - iter 4/20 - loss 0.66134498 - samples/sec: 428.80 - lr: 0.050000\n","2022-02-16 19:37:32,157 epoch 30 - iter 6/20 - loss 0.59430264 - samples/sec: 415.50 - lr: 0.050000\n","2022-02-16 19:37:32,343 epoch 30 - iter 8/20 - loss 0.60341699 - samples/sec: 397.96 - lr: 0.050000\n","2022-02-16 19:37:32,493 epoch 30 - iter 10/20 - loss 0.58038003 - samples/sec: 512.30 - lr: 0.050000\n","2022-02-16 19:37:32,633 epoch 30 - iter 12/20 - loss 0.59389811 - samples/sec: 480.56 - lr: 0.050000\n","2022-02-16 19:37:32,767 epoch 30 - iter 14/20 - loss 0.59732964 - samples/sec: 492.99 - lr: 0.050000\n","2022-02-16 19:37:32,911 epoch 30 - iter 16/20 - loss 0.59277365 - samples/sec: 531.93 - lr: 0.050000\n","2022-02-16 19:37:33,035 epoch 30 - iter 18/20 - loss 0.59378695 - samples/sec: 529.11 - lr: 0.050000\n","2022-02-16 19:37:33,141 epoch 30 - iter 20/20 - loss 0.60322626 - samples/sec: 618.22 - lr: 0.050000\n","2022-02-16 19:37:33,794 ----------------------------------------------------------------------------------------------------\n","2022-02-16 19:37:33,799 EPOCH 30 done: loss 0.6032 - lr 0.0500000\n","2022-02-16 19:37:37,719 DEV : loss 0.6254600286483765 - score 0.6957\n","2022-02-16 19:37:37,904 BAD EPOCHS (no improvement): 0\n","saving best model\n","2022-02-16 19:37:53,531 ----------------------------------------------------------------------------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"output_type":"stream","name":"stdout","text":["2022-02-16 19:37:55,204 epoch 31 - iter 2/20 - loss 0.56907935 - samples/sec: 251.42 - lr: 0.050000\n","2022-02-16 19:37:55,392 epoch 31 - iter 4/20 - loss 0.51780127 - samples/sec: 405.91 - lr: 0.050000\n","2022-02-16 19:37:55,561 epoch 31 - iter 6/20 - loss 0.55607739 - samples/sec: 427.12 - lr: 0.050000\n","2022-02-16 19:37:55,725 epoch 31 - iter 8/20 - loss 0.57725893 - samples/sec: 399.11 - lr: 0.050000\n","2022-02-16 19:37:55,879 epoch 31 - iter 10/20 - loss 0.58073723 - samples/sec: 505.39 - lr: 0.050000\n","2022-02-16 19:37:56,019 epoch 31 - iter 12/20 - loss 0.58325453 - samples/sec: 476.91 - lr: 0.050000\n","2022-02-16 19:37:56,154 epoch 31 - iter 14/20 - loss 0.58787014 - samples/sec: 482.83 - lr: 0.050000\n","2022-02-16 19:37:56,307 epoch 31 - iter 16/20 - loss 0.59439097 - samples/sec: 503.31 - lr: 0.050000\n","2022-02-16 19:37:56,438 epoch 31 - iter 18/20 - loss 0.60382268 - samples/sec: 496.99 - lr: 0.050000\n","2022-02-16 19:37:56,548 epoch 31 - iter 20/20 - loss 0.59083091 - samples/sec: 672.16 - lr: 0.050000\n","2022-02-16 19:37:57,061 ----------------------------------------------------------------------------------------------------\n","2022-02-16 19:37:57,071 EPOCH 31 done: loss 0.5908 - lr 0.0500000\n","2022-02-16 19:37:59,142 DEV : loss 0.7395541071891785 - score 0.6377\n","2022-02-16 19:37:59,313 BAD EPOCHS (no improvement): 1\n","2022-02-16 19:37:59,332 ----------------------------------------------------------------------------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"output_type":"stream","name":"stdout","text":["2022-02-16 19:38:14,822 epoch 32 - iter 2/20 - loss 0.70180774 - samples/sec: 249.84 - lr: 0.050000\n","2022-02-16 19:38:15,185 epoch 32 - iter 4/20 - loss 0.64169858 - samples/sec: 183.58 - lr: 0.050000\n","2022-02-16 19:38:15,513 epoch 32 - iter 6/20 - loss 0.59189113 - samples/sec: 215.19 - lr: 0.050000\n","2022-02-16 19:38:15,870 epoch 32 - iter 8/20 - loss 0.61111300 - samples/sec: 182.42 - lr: 0.050000\n","2022-02-16 19:38:16,169 epoch 32 - iter 10/20 - loss 0.58909333 - samples/sec: 264.75 - lr: 0.050000\n","2022-02-16 19:38:16,367 epoch 32 - iter 12/20 - loss 0.57912133 - samples/sec: 339.74 - lr: 0.050000\n","2022-02-16 19:38:16,496 epoch 32 - iter 14/20 - loss 0.56735370 - samples/sec: 520.89 - lr: 0.050000\n","2022-02-16 19:38:16,650 epoch 32 - iter 16/20 - loss 0.56591590 - samples/sec: 459.70 - lr: 0.050000\n","2022-02-16 19:38:16,769 epoch 32 - iter 18/20 - loss 0.56612744 - samples/sec: 561.60 - lr: 0.050000\n","2022-02-16 19:38:16,869 epoch 32 - iter 20/20 - loss 0.58803817 - samples/sec: 650.68 - lr: 0.050000\n","2022-02-16 19:38:17,335 ----------------------------------------------------------------------------------------------------\n","2022-02-16 19:38:17,340 EPOCH 32 done: loss 0.5880 - lr 0.0500000\n","2022-02-16 19:38:18,854 DEV : loss 0.5898076295852661 - score 0.6667\n","2022-02-16 19:38:18,932 BAD EPOCHS (no improvement): 2\n","2022-02-16 19:38:18,942 ----------------------------------------------------------------------------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"output_type":"stream","name":"stdout","text":["2022-02-16 19:38:20,235 epoch 33 - iter 2/20 - loss 0.52364063 - samples/sec: 208.92 - lr: 0.050000\n","2022-02-16 19:38:20,432 epoch 33 - iter 4/20 - loss 0.57829860 - samples/sec: 390.45 - lr: 0.050000\n","2022-02-16 19:38:20,610 epoch 33 - iter 6/20 - loss 0.56602143 - samples/sec: 410.00 - lr: 0.050000\n","2022-02-16 19:38:20,787 epoch 33 - iter 8/20 - loss 0.55224504 - samples/sec: 410.27 - lr: 0.050000\n","2022-02-16 19:38:20,960 epoch 33 - iter 10/20 - loss 0.54771792 - samples/sec: 491.24 - lr: 0.050000\n","2022-02-16 19:38:21,089 epoch 33 - iter 12/20 - loss 0.54008801 - samples/sec: 522.85 - lr: 0.050000\n","2022-02-16 19:38:21,224 epoch 33 - iter 14/20 - loss 0.55052545 - samples/sec: 481.53 - lr: 0.050000\n","2022-02-16 19:38:21,378 epoch 33 - iter 16/20 - loss 0.56339177 - samples/sec: 519.42 - lr: 0.050000\n","2022-02-16 19:38:21,514 epoch 33 - iter 18/20 - loss 0.57089698 - samples/sec: 480.73 - lr: 0.050000\n","2022-02-16 19:38:21,619 epoch 33 - iter 20/20 - loss 0.58585398 - samples/sec: 623.78 - lr: 0.050000\n","2022-02-16 19:38:21,964 ----------------------------------------------------------------------------------------------------\n","2022-02-16 19:38:21,970 EPOCH 33 done: loss 0.5859 - lr 0.0500000\n","2022-02-16 19:38:23,466 DEV : loss 0.6878511309623718 - score 0.5942\n","2022-02-16 19:38:23,538 BAD EPOCHS (no improvement): 3\n","2022-02-16 19:38:23,546 ----------------------------------------------------------------------------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"output_type":"stream","name":"stdout","text":["2022-02-16 19:38:24,810 epoch 34 - iter 2/20 - loss 0.61479852 - samples/sec: 232.24 - lr: 0.050000\n","2022-02-16 19:38:24,973 epoch 34 - iter 4/20 - loss 0.57198283 - samples/sec: 428.50 - lr: 0.050000\n","2022-02-16 19:38:25,167 epoch 34 - iter 6/20 - loss 0.56941011 - samples/sec: 399.82 - lr: 0.050000\n","2022-02-16 19:38:25,310 epoch 34 - iter 8/20 - loss 0.61129952 - samples/sec: 478.46 - lr: 0.050000\n","2022-02-16 19:38:25,461 epoch 34 - iter 10/20 - loss 0.61657636 - samples/sec: 464.54 - lr: 0.050000\n","2022-02-16 19:38:25,605 epoch 34 - iter 12/20 - loss 0.62749747 - samples/sec: 512.58 - lr: 0.050000\n","2022-02-16 19:38:25,741 epoch 34 - iter 14/20 - loss 0.61077303 - samples/sec: 479.74 - lr: 0.050000\n","2022-02-16 19:38:25,886 epoch 34 - iter 16/20 - loss 0.60433623 - samples/sec: 503.41 - lr: 0.050000\n","2022-02-16 19:38:26,038 epoch 34 - iter 18/20 - loss 0.60757327 - samples/sec: 471.28 - lr: 0.050000\n","2022-02-16 19:38:26,157 epoch 34 - iter 20/20 - loss 0.58968779 - samples/sec: 553.48 - lr: 0.050000\n","2022-02-16 19:38:26,512 ----------------------------------------------------------------------------------------------------\n","2022-02-16 19:38:26,519 EPOCH 34 done: loss 0.5897 - lr 0.0500000\n","2022-02-16 19:38:27,989 DEV : loss 0.6920633316040039 - score 0.6812\n","Epoch    34: reducing learning rate of group 0 to 2.5000e-02.\n","2022-02-16 19:38:28,069 BAD EPOCHS (no improvement): 4\n","2022-02-16 19:38:28,078 ----------------------------------------------------------------------------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"output_type":"stream","name":"stdout","text":["2022-02-16 19:38:29,303 epoch 35 - iter 2/20 - loss 0.58624208 - samples/sec: 228.86 - lr: 0.025000\n","2022-02-16 19:38:29,509 epoch 35 - iter 4/20 - loss 0.54012217 - samples/sec: 369.58 - lr: 0.025000\n","2022-02-16 19:38:29,685 epoch 35 - iter 6/20 - loss 0.56056905 - samples/sec: 433.30 - lr: 0.025000\n","2022-02-16 19:38:29,847 epoch 35 - iter 8/20 - loss 0.53490176 - samples/sec: 411.67 - lr: 0.025000\n","2022-02-16 19:38:30,022 epoch 35 - iter 10/20 - loss 0.53014890 - samples/sec: 480.83 - lr: 0.025000\n","2022-02-16 19:38:30,155 epoch 35 - iter 12/20 - loss 0.56356160 - samples/sec: 503.32 - lr: 0.025000\n","2022-02-16 19:38:30,292 epoch 35 - iter 14/20 - loss 0.56332872 - samples/sec: 516.79 - lr: 0.025000\n","2022-02-16 19:38:30,422 epoch 35 - iter 16/20 - loss 0.57479113 - samples/sec: 512.33 - lr: 0.025000\n","2022-02-16 19:38:30,576 epoch 35 - iter 18/20 - loss 0.56568559 - samples/sec: 439.62 - lr: 0.025000\n","2022-02-16 19:38:30,681 epoch 35 - iter 20/20 - loss 0.56040726 - samples/sec: 640.42 - lr: 0.025000\n","2022-02-16 19:38:31,049 ----------------------------------------------------------------------------------------------------\n","2022-02-16 19:38:31,056 EPOCH 35 done: loss 0.5604 - lr 0.0250000\n","2022-02-16 19:38:32,568 DEV : loss 0.706295371055603 - score 0.6377\n","2022-02-16 19:38:32,659 BAD EPOCHS (no improvement): 1\n","2022-02-16 19:38:32,669 ----------------------------------------------------------------------------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"output_type":"stream","name":"stdout","text":["2022-02-16 19:38:33,964 epoch 36 - iter 2/20 - loss 0.55857837 - samples/sec: 226.93 - lr: 0.025000\n","2022-02-16 19:38:34,133 epoch 36 - iter 4/20 - loss 0.56955162 - samples/sec: 442.20 - lr: 0.025000\n","2022-02-16 19:38:34,335 epoch 36 - iter 6/20 - loss 0.55378061 - samples/sec: 387.23 - lr: 0.025000\n","2022-02-16 19:38:34,505 epoch 36 - iter 8/20 - loss 0.54436048 - samples/sec: 428.05 - lr: 0.025000\n","2022-02-16 19:38:34,647 epoch 36 - iter 10/20 - loss 0.53827753 - samples/sec: 471.83 - lr: 0.025000\n","2022-02-16 19:38:34,794 epoch 36 - iter 12/20 - loss 0.53672756 - samples/sec: 493.20 - lr: 0.025000\n","2022-02-16 19:38:34,937 epoch 36 - iter 14/20 - loss 0.54497149 - samples/sec: 521.38 - lr: 0.025000\n","2022-02-16 19:38:35,076 epoch 36 - iter 16/20 - loss 0.54775921 - samples/sec: 470.84 - lr: 0.025000\n","2022-02-16 19:38:35,217 epoch 36 - iter 18/20 - loss 0.54513224 - samples/sec: 512.06 - lr: 0.025000\n","2022-02-16 19:38:35,331 epoch 36 - iter 20/20 - loss 0.55396921 - samples/sec: 625.87 - lr: 0.025000\n","2022-02-16 19:38:35,714 ----------------------------------------------------------------------------------------------------\n","2022-02-16 19:38:35,720 EPOCH 36 done: loss 0.5540 - lr 0.0250000\n","2022-02-16 19:38:37,197 DEV : loss 0.5918476581573486 - score 0.6522\n","2022-02-16 19:38:37,277 BAD EPOCHS (no improvement): 2\n","2022-02-16 19:38:37,288 ----------------------------------------------------------------------------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"output_type":"stream","name":"stdout","text":["2022-02-16 19:38:38,557 epoch 37 - iter 2/20 - loss 0.54351225 - samples/sec: 218.80 - lr: 0.025000\n","2022-02-16 19:38:38,739 epoch 37 - iter 4/20 - loss 0.61411278 - samples/sec: 394.44 - lr: 0.025000\n","2022-02-16 19:38:38,929 epoch 37 - iter 6/20 - loss 0.57943812 - samples/sec: 405.27 - lr: 0.025000\n","2022-02-16 19:38:39,093 epoch 37 - iter 8/20 - loss 0.62946368 - samples/sec: 447.68 - lr: 0.025000\n","2022-02-16 19:38:39,248 epoch 37 - iter 10/20 - loss 0.61925553 - samples/sec: 424.06 - lr: 0.025000\n","2022-02-16 19:38:39,415 epoch 37 - iter 12/20 - loss 0.60332161 - samples/sec: 425.80 - lr: 0.025000\n","2022-02-16 19:38:39,563 epoch 37 - iter 14/20 - loss 0.60007641 - samples/sec: 495.59 - lr: 0.025000\n","2022-02-16 19:38:39,710 epoch 37 - iter 16/20 - loss 0.58661518 - samples/sec: 484.93 - lr: 0.025000\n","2022-02-16 19:38:39,856 epoch 37 - iter 18/20 - loss 0.57974828 - samples/sec: 444.78 - lr: 0.025000\n","2022-02-16 19:38:39,967 epoch 37 - iter 20/20 - loss 0.58106267 - samples/sec: 663.80 - lr: 0.025000\n","2022-02-16 19:38:40,300 ----------------------------------------------------------------------------------------------------\n","2022-02-16 19:38:40,305 EPOCH 37 done: loss 0.5811 - lr 0.0250000\n","2022-02-16 19:38:41,754 DEV : loss 0.6250482201576233 - score 0.6087\n","2022-02-16 19:38:41,831 BAD EPOCHS (no improvement): 3\n","2022-02-16 19:38:41,841 ----------------------------------------------------------------------------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"output_type":"stream","name":"stdout","text":["2022-02-16 19:38:43,384 epoch 38 - iter 2/20 - loss 0.56256010 - samples/sec: 221.83 - lr: 0.025000\n","2022-02-16 19:38:43,556 epoch 38 - iter 4/20 - loss 0.53463975 - samples/sec: 411.32 - lr: 0.025000\n","2022-02-16 19:38:43,749 epoch 38 - iter 6/20 - loss 0.52195805 - samples/sec: 405.56 - lr: 0.025000\n","2022-02-16 19:38:43,921 epoch 38 - iter 8/20 - loss 0.51691277 - samples/sec: 412.65 - lr: 0.025000\n","2022-02-16 19:38:44,057 epoch 38 - iter 10/20 - loss 0.54296013 - samples/sec: 483.56 - lr: 0.025000\n","2022-02-16 19:38:44,204 epoch 38 - iter 12/20 - loss 0.54216501 - samples/sec: 494.66 - lr: 0.025000\n","2022-02-16 19:38:44,360 epoch 38 - iter 14/20 - loss 0.55582796 - samples/sec: 477.27 - lr: 0.025000\n","2022-02-16 19:38:44,501 epoch 38 - iter 16/20 - loss 0.55183928 - samples/sec: 478.63 - lr: 0.025000\n","2022-02-16 19:38:44,637 epoch 38 - iter 18/20 - loss 0.55194550 - samples/sec: 496.29 - lr: 0.025000\n","2022-02-16 19:38:44,747 epoch 38 - iter 20/20 - loss 0.57998081 - samples/sec: 667.31 - lr: 0.025000\n","2022-02-16 19:38:45,091 ----------------------------------------------------------------------------------------------------\n","2022-02-16 19:38:45,093 EPOCH 38 done: loss 0.5800 - lr 0.0250000\n","2022-02-16 19:38:46,521 DEV : loss 0.6980378031730652 - score 0.6377\n","Epoch    38: reducing learning rate of group 0 to 1.2500e-02.\n","2022-02-16 19:38:46,596 BAD EPOCHS (no improvement): 4\n","2022-02-16 19:38:46,605 ----------------------------------------------------------------------------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"output_type":"stream","name":"stdout","text":["2022-02-16 19:38:47,853 epoch 39 - iter 2/20 - loss 0.53934751 - samples/sec: 251.07 - lr: 0.012500\n","2022-02-16 19:38:48,019 epoch 39 - iter 4/20 - loss 0.53128509 - samples/sec: 413.97 - lr: 0.012500\n","2022-02-16 19:38:48,208 epoch 39 - iter 6/20 - loss 0.54444583 - samples/sec: 419.83 - lr: 0.012500\n","2022-02-16 19:38:48,361 epoch 39 - iter 8/20 - loss 0.52073127 - samples/sec: 432.67 - lr: 0.012500\n","2022-02-16 19:38:48,521 epoch 39 - iter 10/20 - loss 0.52177370 - samples/sec: 480.08 - lr: 0.012500\n","2022-02-16 19:38:50,351 epoch 39 - iter 12/20 - loss 0.53765611 - samples/sec: 35.27 - lr: 0.012500\n","2022-02-16 19:38:50,489 epoch 39 - iter 14/20 - loss 0.53831980 - samples/sec: 478.84 - lr: 0.012500\n","2022-02-16 19:38:50,627 epoch 39 - iter 16/20 - loss 0.53233431 - samples/sec: 525.96 - lr: 0.012500\n","2022-02-16 19:38:50,763 epoch 39 - iter 18/20 - loss 0.53232962 - samples/sec: 503.54 - lr: 0.012500\n","2022-02-16 19:38:50,864 epoch 39 - iter 20/20 - loss 0.54142374 - samples/sec: 654.74 - lr: 0.012500\n","2022-02-16 19:38:51,258 ----------------------------------------------------------------------------------------------------\n","2022-02-16 19:38:51,265 EPOCH 39 done: loss 0.5414 - lr 0.0125000\n","2022-02-16 19:38:52,791 DEV : loss 0.6035435199737549 - score 0.6812\n","2022-02-16 19:38:52,871 BAD EPOCHS (no improvement): 1\n","2022-02-16 19:38:52,877 ----------------------------------------------------------------------------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"output_type":"stream","name":"stdout","text":["2022-02-16 19:38:54,158 epoch 40 - iter 2/20 - loss 0.54286368 - samples/sec: 249.26 - lr: 0.012500\n","2022-02-16 19:38:54,332 epoch 40 - iter 4/20 - loss 0.52556819 - samples/sec: 408.61 - lr: 0.012500\n","2022-02-16 19:38:54,564 epoch 40 - iter 6/20 - loss 0.52855128 - samples/sec: 360.74 - lr: 0.012500\n","2022-02-16 19:38:54,745 epoch 40 - iter 8/20 - loss 0.53970158 - samples/sec: 367.44 - lr: 0.012500\n","2022-02-16 19:38:54,893 epoch 40 - iter 10/20 - loss 0.55621908 - samples/sec: 441.93 - lr: 0.012500\n","2022-02-16 19:38:55,039 epoch 40 - iter 12/20 - loss 0.55934332 - samples/sec: 459.28 - lr: 0.012500\n","2022-02-16 19:38:55,176 epoch 40 - iter 14/20 - loss 0.56007105 - samples/sec: 485.86 - lr: 0.012500\n","2022-02-16 19:38:55,313 epoch 40 - iter 16/20 - loss 0.56972626 - samples/sec: 483.62 - lr: 0.012500\n","2022-02-16 19:38:55,456 epoch 40 - iter 18/20 - loss 0.55983684 - samples/sec: 473.32 - lr: 0.012500\n","2022-02-16 19:38:55,569 epoch 40 - iter 20/20 - loss 0.57028055 - samples/sec: 643.73 - lr: 0.012500\n","2022-02-16 19:38:55,943 ----------------------------------------------------------------------------------------------------\n","2022-02-16 19:38:55,945 EPOCH 40 done: loss 0.5703 - lr 0.0125000\n","2022-02-16 19:38:57,407 DEV : loss 0.5708533525466919 - score 0.6522\n","2022-02-16 19:38:57,484 BAD EPOCHS (no improvement): 2\n","2022-02-16 19:38:57,493 ----------------------------------------------------------------------------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"output_type":"stream","name":"stdout","text":["2022-02-16 19:38:58,770 epoch 41 - iter 2/20 - loss 0.49891041 - samples/sec: 160.65 - lr: 0.012500\n","2022-02-16 19:38:58,967 epoch 41 - iter 4/20 - loss 0.53134955 - samples/sec: 369.39 - lr: 0.012500\n","2022-02-16 19:38:59,155 epoch 41 - iter 6/20 - loss 0.55002872 - samples/sec: 400.50 - lr: 0.012500\n","2022-02-16 19:38:59,351 epoch 41 - iter 8/20 - loss 0.52640189 - samples/sec: 410.47 - lr: 0.012500\n","2022-02-16 19:38:59,490 epoch 41 - iter 10/20 - loss 0.50260829 - samples/sec: 486.83 - lr: 0.012500\n","2022-02-16 19:38:59,630 epoch 41 - iter 12/20 - loss 0.50837410 - samples/sec: 517.49 - lr: 0.012500\n","2022-02-16 19:38:59,764 epoch 41 - iter 14/20 - loss 0.51683268 - samples/sec: 495.42 - lr: 0.012500\n","2022-02-16 19:38:59,916 epoch 41 - iter 16/20 - loss 0.52031893 - samples/sec: 429.70 - lr: 0.012500\n","2022-02-16 19:39:00,067 epoch 41 - iter 18/20 - loss 0.52146767 - samples/sec: 449.95 - lr: 0.012500\n","2022-02-16 19:39:00,175 epoch 41 - iter 20/20 - loss 0.52760678 - samples/sec: 611.45 - lr: 0.012500\n","2022-02-16 19:39:00,518 ----------------------------------------------------------------------------------------------------\n","2022-02-16 19:39:00,526 EPOCH 41 done: loss 0.5276 - lr 0.0125000\n","2022-02-16 19:39:02,032 DEV : loss 0.6150220036506653 - score 0.6522\n","2022-02-16 19:39:02,112 BAD EPOCHS (no improvement): 3\n","2022-02-16 19:39:02,121 ----------------------------------------------------------------------------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"output_type":"stream","name":"stdout","text":["2022-02-16 19:39:03,356 epoch 42 - iter 2/20 - loss 0.53564577 - samples/sec: 226.09 - lr: 0.012500\n","2022-02-16 19:39:03,526 epoch 42 - iter 4/20 - loss 0.59180144 - samples/sec: 444.10 - lr: 0.012500\n","2022-02-16 19:39:03,713 epoch 42 - iter 6/20 - loss 0.55415560 - samples/sec: 416.16 - lr: 0.012500\n","2022-02-16 19:39:03,871 epoch 42 - iter 8/20 - loss 0.53569426 - samples/sec: 421.63 - lr: 0.012500\n","2022-02-16 19:39:04,012 epoch 42 - iter 10/20 - loss 0.51966597 - samples/sec: 520.13 - lr: 0.012500\n","2022-02-16 19:39:04,174 epoch 42 - iter 12/20 - loss 0.52883051 - samples/sec: 488.28 - lr: 0.012500\n","2022-02-16 19:39:04,333 epoch 42 - iter 14/20 - loss 0.52982236 - samples/sec: 452.46 - lr: 0.012500\n","2022-02-16 19:39:04,470 epoch 42 - iter 16/20 - loss 0.54615445 - samples/sec: 476.55 - lr: 0.012500\n","2022-02-16 19:39:04,613 epoch 42 - iter 18/20 - loss 0.54576611 - samples/sec: 485.13 - lr: 0.012500\n","2022-02-16 19:39:04,721 epoch 42 - iter 20/20 - loss 0.54564659 - samples/sec: 611.52 - lr: 0.012500\n","2022-02-16 19:39:05,080 ----------------------------------------------------------------------------------------------------\n","2022-02-16 19:39:05,081 EPOCH 42 done: loss 0.5456 - lr 0.0125000\n","2022-02-16 19:39:06,612 DEV : loss 0.6124423742294312 - score 0.6812\n","Epoch    42: reducing learning rate of group 0 to 6.2500e-03.\n","2022-02-16 19:39:06,689 BAD EPOCHS (no improvement): 4\n","2022-02-16 19:39:06,701 ----------------------------------------------------------------------------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"output_type":"stream","name":"stdout","text":["2022-02-16 19:39:07,938 epoch 43 - iter 2/20 - loss 0.52385029 - samples/sec: 197.36 - lr: 0.006250\n","2022-02-16 19:39:08,111 epoch 43 - iter 4/20 - loss 0.54588664 - samples/sec: 439.53 - lr: 0.006250\n","2022-02-16 19:39:08,280 epoch 43 - iter 6/20 - loss 0.51237782 - samples/sec: 439.22 - lr: 0.006250\n","2022-02-16 19:39:08,457 epoch 43 - iter 8/20 - loss 0.49558285 - samples/sec: 383.10 - lr: 0.006250\n","2022-02-16 19:39:08,598 epoch 43 - iter 10/20 - loss 0.50553446 - samples/sec: 539.78 - lr: 0.006250\n","2022-02-16 19:39:08,757 epoch 43 - iter 12/20 - loss 0.50572834 - samples/sec: 496.02 - lr: 0.006250\n","2022-02-16 19:39:08,891 epoch 43 - iter 14/20 - loss 0.50513996 - samples/sec: 543.99 - lr: 0.006250\n","2022-02-16 19:39:09,026 epoch 43 - iter 16/20 - loss 0.50515655 - samples/sec: 486.20 - lr: 0.006250\n","2022-02-16 19:39:09,155 epoch 43 - iter 18/20 - loss 0.51222945 - samples/sec: 544.87 - lr: 0.006250\n","2022-02-16 19:39:09,266 epoch 43 - iter 20/20 - loss 0.51513214 - samples/sec: 596.41 - lr: 0.006250\n","2022-02-16 19:39:09,609 ----------------------------------------------------------------------------------------------------\n","2022-02-16 19:39:09,615 EPOCH 43 done: loss 0.5151 - lr 0.0062500\n","2022-02-16 19:39:11,050 DEV : loss 0.6323484778404236 - score 0.6812\n","2022-02-16 19:39:11,127 BAD EPOCHS (no improvement): 1\n","2022-02-16 19:39:11,136 ----------------------------------------------------------------------------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"output_type":"stream","name":"stdout","text":["2022-02-16 19:39:12,381 epoch 44 - iter 2/20 - loss 0.57809810 - samples/sec: 235.93 - lr: 0.006250\n","2022-02-16 19:39:12,566 epoch 44 - iter 4/20 - loss 0.52237730 - samples/sec: 393.53 - lr: 0.006250\n","2022-02-16 19:39:12,756 epoch 44 - iter 6/20 - loss 0.48634178 - samples/sec: 404.73 - lr: 0.006250\n","2022-02-16 19:39:12,939 epoch 44 - iter 8/20 - loss 0.47774296 - samples/sec: 406.07 - lr: 0.006250\n","2022-02-16 19:39:13,071 epoch 44 - iter 10/20 - loss 0.50837596 - samples/sec: 503.97 - lr: 0.006250\n","2022-02-16 19:39:13,233 epoch 44 - iter 12/20 - loss 0.50440564 - samples/sec: 458.81 - lr: 0.006250\n","2022-02-16 19:39:13,372 epoch 44 - iter 14/20 - loss 0.51894854 - samples/sec: 475.65 - lr: 0.006250\n","2022-02-16 19:39:13,517 epoch 44 - iter 16/20 - loss 0.52737884 - samples/sec: 452.00 - lr: 0.006250\n","2022-02-16 19:39:13,677 epoch 44 - iter 18/20 - loss 0.51888483 - samples/sec: 433.11 - lr: 0.006250\n","2022-02-16 19:39:13,788 epoch 44 - iter 20/20 - loss 0.53150811 - samples/sec: 658.17 - lr: 0.006250\n","2022-02-16 19:39:14,146 ----------------------------------------------------------------------------------------------------\n","2022-02-16 19:39:14,152 EPOCH 44 done: loss 0.5315 - lr 0.0062500\n","2022-02-16 19:39:15,619 DEV : loss 0.6334648132324219 - score 0.6087\n","2022-02-16 19:39:15,715 BAD EPOCHS (no improvement): 2\n","2022-02-16 19:39:15,726 ----------------------------------------------------------------------------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"output_type":"stream","name":"stdout","text":["2022-02-16 19:39:17,013 epoch 45 - iter 2/20 - loss 0.50138994 - samples/sec: 213.94 - lr: 0.006250\n","2022-02-16 19:39:17,180 epoch 45 - iter 4/20 - loss 0.48862428 - samples/sec: 447.59 - lr: 0.006250\n","2022-02-16 19:39:17,377 epoch 45 - iter 6/20 - loss 0.51486833 - samples/sec: 394.88 - lr: 0.006250\n","2022-02-16 19:39:17,562 epoch 45 - iter 8/20 - loss 0.52434279 - samples/sec: 439.93 - lr: 0.006250\n","2022-02-16 19:39:17,710 epoch 45 - iter 10/20 - loss 0.52460260 - samples/sec: 442.91 - lr: 0.006250\n","2022-02-16 19:39:17,840 epoch 45 - iter 12/20 - loss 0.51721908 - samples/sec: 500.12 - lr: 0.006250\n","2022-02-16 19:39:17,981 epoch 45 - iter 14/20 - loss 0.51761906 - samples/sec: 487.44 - lr: 0.006250\n","2022-02-16 19:39:18,116 epoch 45 - iter 16/20 - loss 0.52613903 - samples/sec: 482.57 - lr: 0.006250\n","2022-02-16 19:39:18,250 epoch 45 - iter 18/20 - loss 0.51863271 - samples/sec: 495.92 - lr: 0.006250\n","2022-02-16 19:39:18,365 epoch 45 - iter 20/20 - loss 0.54229696 - samples/sec: 625.96 - lr: 0.006250\n","2022-02-16 19:39:18,754 ----------------------------------------------------------------------------------------------------\n","2022-02-16 19:39:18,759 EPOCH 45 done: loss 0.5423 - lr 0.0062500\n","2022-02-16 19:39:20,207 DEV : loss 0.6097650527954102 - score 0.6667\n","2022-02-16 19:39:20,293 BAD EPOCHS (no improvement): 3\n","2022-02-16 19:39:20,306 ----------------------------------------------------------------------------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"output_type":"stream","name":"stdout","text":["2022-02-16 19:39:21,573 epoch 46 - iter 2/20 - loss 0.38535936 - samples/sec: 252.00 - lr: 0.006250\n","2022-02-16 19:39:21,737 epoch 46 - iter 4/20 - loss 0.41958306 - samples/sec: 402.63 - lr: 0.006250\n","2022-02-16 19:39:21,933 epoch 46 - iter 6/20 - loss 0.49744711 - samples/sec: 422.24 - lr: 0.006250\n","2022-02-16 19:39:22,100 epoch 46 - iter 8/20 - loss 0.49321141 - samples/sec: 441.82 - lr: 0.006250\n","2022-02-16 19:39:22,237 epoch 46 - iter 10/20 - loss 0.49817335 - samples/sec: 474.79 - lr: 0.006250\n","2022-02-16 19:39:22,378 epoch 46 - iter 12/20 - loss 0.49757360 - samples/sec: 480.77 - lr: 0.006250\n","2022-02-16 19:39:22,508 epoch 46 - iter 14/20 - loss 0.50102387 - samples/sec: 515.36 - lr: 0.006250\n","2022-02-16 19:39:22,634 epoch 46 - iter 16/20 - loss 0.50140762 - samples/sec: 537.03 - lr: 0.006250\n","2022-02-16 19:39:22,780 epoch 46 - iter 18/20 - loss 0.51163175 - samples/sec: 511.12 - lr: 0.006250\n","2022-02-16 19:39:22,890 epoch 46 - iter 20/20 - loss 0.52904148 - samples/sec: 611.48 - lr: 0.006250\n","2022-02-16 19:39:23,266 ----------------------------------------------------------------------------------------------------\n","2022-02-16 19:39:23,272 EPOCH 46 done: loss 0.5290 - lr 0.0062500\n","2022-02-16 19:39:24,732 DEV : loss 0.5910553336143494 - score 0.6377\n","Epoch    46: reducing learning rate of group 0 to 3.1250e-03.\n","2022-02-16 19:39:24,810 BAD EPOCHS (no improvement): 4\n","2022-02-16 19:39:24,818 ----------------------------------------------------------------------------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"output_type":"stream","name":"stdout","text":["2022-02-16 19:39:26,078 epoch 47 - iter 2/20 - loss 0.45075183 - samples/sec: 237.86 - lr: 0.003125\n","2022-02-16 19:39:26,279 epoch 47 - iter 4/20 - loss 0.51687499 - samples/sec: 354.02 - lr: 0.003125\n","2022-02-16 19:39:28,130 epoch 47 - iter 6/20 - loss 0.49805958 - samples/sec: 390.96 - lr: 0.003125\n","2022-02-16 19:39:28,273 epoch 47 - iter 8/20 - loss 0.50988802 - samples/sec: 477.25 - lr: 0.003125\n","2022-02-16 19:39:28,407 epoch 47 - iter 10/20 - loss 0.53531044 - samples/sec: 492.44 - lr: 0.003125\n","2022-02-16 19:39:28,548 epoch 47 - iter 12/20 - loss 0.53486897 - samples/sec: 520.68 - lr: 0.003125\n","2022-02-16 19:39:28,696 epoch 47 - iter 14/20 - loss 0.55074012 - samples/sec: 442.41 - lr: 0.003125\n","2022-02-16 19:39:28,826 epoch 47 - iter 16/20 - loss 0.55642004 - samples/sec: 502.50 - lr: 0.003125\n","2022-02-16 19:39:28,966 epoch 47 - iter 18/20 - loss 0.55257215 - samples/sec: 528.33 - lr: 0.003125\n","2022-02-16 19:39:29,070 epoch 47 - iter 20/20 - loss 0.54717314 - samples/sec: 638.05 - lr: 0.003125\n","2022-02-16 19:39:29,434 ----------------------------------------------------------------------------------------------------\n","2022-02-16 19:39:29,440 EPOCH 47 done: loss 0.5472 - lr 0.0031250\n","2022-02-16 19:39:30,931 DEV : loss 0.6014435887336731 - score 0.6812\n","2022-02-16 19:39:31,009 BAD EPOCHS (no improvement): 1\n","2022-02-16 19:39:31,018 ----------------------------------------------------------------------------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"output_type":"stream","name":"stdout","text":["2022-02-16 19:39:32,300 epoch 48 - iter 2/20 - loss 0.51977001 - samples/sec: 239.30 - lr: 0.003125\n","2022-02-16 19:39:32,481 epoch 48 - iter 4/20 - loss 0.46347780 - samples/sec: 373.12 - lr: 0.003125\n","2022-02-16 19:39:32,712 epoch 48 - iter 6/20 - loss 0.46018175 - samples/sec: 360.97 - lr: 0.003125\n","2022-02-16 19:39:32,874 epoch 48 - iter 8/20 - loss 0.47478573 - samples/sec: 401.25 - lr: 0.003125\n","2022-02-16 19:39:33,017 epoch 48 - iter 10/20 - loss 0.49650336 - samples/sec: 459.14 - lr: 0.003125\n","2022-02-16 19:39:33,160 epoch 48 - iter 12/20 - loss 0.51001025 - samples/sec: 463.42 - lr: 0.003125\n","2022-02-16 19:39:33,298 epoch 48 - iter 14/20 - loss 0.51689956 - samples/sec: 475.10 - lr: 0.003125\n","2022-02-16 19:39:33,439 epoch 48 - iter 16/20 - loss 0.54786151 - samples/sec: 458.06 - lr: 0.003125\n","2022-02-16 19:39:33,593 epoch 48 - iter 18/20 - loss 0.54190369 - samples/sec: 455.72 - lr: 0.003125\n","2022-02-16 19:39:33,714 epoch 48 - iter 20/20 - loss 0.54039489 - samples/sec: 585.91 - lr: 0.003125\n","2022-02-16 19:39:34,104 ----------------------------------------------------------------------------------------------------\n","2022-02-16 19:39:34,111 EPOCH 48 done: loss 0.5404 - lr 0.0031250\n","2022-02-16 19:39:35,603 DEV : loss 0.5935913920402527 - score 0.6957\n","2022-02-16 19:39:35,720 BAD EPOCHS (no improvement): 0\n","saving best model\n","2022-02-16 19:39:51,839 ----------------------------------------------------------------------------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"output_type":"stream","name":"stdout","text":["2022-02-16 19:39:53,479 epoch 49 - iter 2/20 - loss 0.42243229 - samples/sec: 208.23 - lr: 0.003125\n","2022-02-16 19:39:53,666 epoch 49 - iter 4/20 - loss 0.48122989 - samples/sec: 384.06 - lr: 0.003125\n","2022-02-16 19:39:53,844 epoch 49 - iter 6/20 - loss 0.47793998 - samples/sec: 381.14 - lr: 0.003125\n","2022-02-16 19:39:54,018 epoch 49 - iter 8/20 - loss 0.44919466 - samples/sec: 437.94 - lr: 0.003125\n","2022-02-16 19:39:54,160 epoch 49 - iter 10/20 - loss 0.47298207 - samples/sec: 473.63 - lr: 0.003125\n","2022-02-16 19:39:54,320 epoch 49 - iter 12/20 - loss 0.51309945 - samples/sec: 420.73 - lr: 0.003125\n","2022-02-16 19:39:54,477 epoch 49 - iter 14/20 - loss 0.54297229 - samples/sec: 466.08 - lr: 0.003125\n","2022-02-16 19:39:54,609 epoch 49 - iter 16/20 - loss 0.54106572 - samples/sec: 498.15 - lr: 0.003125\n","2022-02-16 19:39:54,739 epoch 49 - iter 18/20 - loss 0.53232389 - samples/sec: 505.64 - lr: 0.003125\n","2022-02-16 19:39:54,855 epoch 49 - iter 20/20 - loss 0.51981447 - samples/sec: 570.77 - lr: 0.003125\n","2022-02-16 19:39:55,379 ----------------------------------------------------------------------------------------------------\n","2022-02-16 19:39:55,382 EPOCH 49 done: loss 0.5198 - lr 0.0031250\n","2022-02-16 19:39:57,246 DEV : loss 0.5986711978912354 - score 0.6667\n","2022-02-16 19:39:57,330 BAD EPOCHS (no improvement): 1\n","2022-02-16 19:39:57,350 ----------------------------------------------------------------------------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"output_type":"stream","name":"stdout","text":["2022-02-16 19:39:58,848 epoch 50 - iter 2/20 - loss 0.48713994 - samples/sec: 238.93 - lr: 0.003125\n","2022-02-16 19:39:59,101 epoch 50 - iter 4/20 - loss 0.50597622 - samples/sec: 263.85 - lr: 0.003125\n","2022-02-16 19:39:59,684 epoch 50 - iter 6/20 - loss 0.50546064 - samples/sec: 123.90 - lr: 0.003125\n","2022-02-16 19:39:59,992 epoch 50 - iter 8/20 - loss 0.49729188 - samples/sec: 249.93 - lr: 0.003125\n","2022-02-16 19:40:00,267 epoch 50 - iter 10/20 - loss 0.50012220 - samples/sec: 240.81 - lr: 0.003125\n","2022-02-16 19:40:00,605 epoch 50 - iter 12/20 - loss 0.51742396 - samples/sec: 212.05 - lr: 0.003125\n","2022-02-16 19:40:00,880 epoch 50 - iter 14/20 - loss 0.53425642 - samples/sec: 264.68 - lr: 0.003125\n","2022-02-16 19:40:01,153 epoch 50 - iter 16/20 - loss 0.54420203 - samples/sec: 246.41 - lr: 0.003125\n","2022-02-16 19:40:01,452 epoch 50 - iter 18/20 - loss 0.52894544 - samples/sec: 224.77 - lr: 0.003125\n","2022-02-16 19:40:01,725 epoch 50 - iter 20/20 - loss 0.52858020 - samples/sec: 255.32 - lr: 0.003125\n","2022-02-16 19:40:02,501 ----------------------------------------------------------------------------------------------------\n","2022-02-16 19:40:02,511 EPOCH 50 done: loss 0.5286 - lr 0.0031250\n","2022-02-16 19:40:05,422 DEV : loss 0.6008057594299316 - score 0.6812\n","2022-02-16 19:40:05,562 BAD EPOCHS (no improvement): 2\n","2022-02-16 19:40:24,415 ----------------------------------------------------------------------------------------------------\n","2022-02-16 19:40:24,418 Testing using best model ...\n","2022-02-16 19:40:24,478 loading file ../resources/stance-semeval2016/flair_Hillary Clinton/best-model.pt\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"output_type":"stream","name":"stdout","text":["2022-02-16 19:40:41,975 \t0.7322\n","2022-02-16 19:40:41,983 \n","Results:\n","- F-score (micro) 0.7322\n","- F-score (macro) 0.6602\n","- Accuracy 0.7322\n","\n","By class:\n","              precision    recall  f1-score   support\n","\n","     AGAINST     0.7321    0.8895    0.8031       172\n","        NONE     0.7544    0.5513    0.6370        78\n","       FAVOR     0.6897    0.4444    0.5405        45\n","\n","   micro avg     0.7322    0.7322    0.7322       295\n","   macro avg     0.7254    0.6284    0.6602       295\n","weighted avg     0.7315    0.7322    0.7192       295\n"," samples avg     0.7322    0.7322    0.7322       295\n","\n","2022-02-16 19:40:41,990 ----------------------------------------------------------------------------------------------------\n"]},{"output_type":"execute_result","data":{"text/plain":["{'dev_loss_history': [1.074609637260437,\n","  0.9209212064743042,\n","  0.9103115797042847,\n","  0.908013105392456,\n","  0.9318515658378601,\n","  0.8997544646263123,\n","  1.0334051847457886,\n","  0.8716272711753845,\n","  0.8413482904434204,\n","  0.9461197853088379,\n","  0.856968104839325,\n","  0.8473937511444092,\n","  0.8460134267807007,\n","  0.8564955592155457,\n","  1.2571353912353516,\n","  0.7676151990890503,\n","  0.8399022817611694,\n","  0.9951761960983276,\n","  0.9829202890396118,\n","  0.9762847423553467,\n","  0.8251398801803589,\n","  0.9528338313102722,\n","  0.6871880888938904,\n","  0.6898099780082703,\n","  0.6848871111869812,\n","  0.6900558471679688,\n","  0.7247755527496338,\n","  0.5865464210510254,\n","  0.6232314109802246,\n","  0.6254600286483765,\n","  0.7395541071891785,\n","  0.5898076295852661,\n","  0.6878511309623718,\n","  0.6920633316040039,\n","  0.706295371055603,\n","  0.5918476581573486,\n","  0.6250482201576233,\n","  0.6980378031730652,\n","  0.6035435199737549,\n","  0.5708533525466919,\n","  0.6150220036506653,\n","  0.6124423742294312,\n","  0.6323484778404236,\n","  0.6334648132324219,\n","  0.6097650527954102,\n","  0.5910553336143494,\n","  0.6014435887336731,\n","  0.5935913920402527,\n","  0.5986711978912354,\n","  0.6008057594299316],\n"," 'dev_score_history': [0.5362,\n","  0.5362,\n","  0.5362,\n","  0.5362,\n","  0.5652,\n","  0.5362,\n","  0.4783,\n","  0.5797,\n","  0.5507,\n","  0.4638,\n","  0.5072,\n","  0.5797,\n","  0.5797,\n","  0.5217,\n","  0.3913,\n","  0.6087,\n","  0.5507,\n","  0.5797,\n","  0.5362,\n","  0.4493,\n","  0.5942,\n","  0.5942,\n","  0.5797,\n","  0.6522,\n","  0.6232,\n","  0.6232,\n","  0.6232,\n","  0.6812,\n","  0.6232,\n","  0.6957,\n","  0.6377,\n","  0.6667,\n","  0.5942,\n","  0.6812,\n","  0.6377,\n","  0.6522,\n","  0.6087,\n","  0.6377,\n","  0.6812,\n","  0.6522,\n","  0.6522,\n","  0.6812,\n","  0.6812,\n","  0.6087,\n","  0.6667,\n","  0.6377,\n","  0.6812,\n","  0.6957,\n","  0.6667,\n","  0.6812],\n"," 'test_score': 0.7322,\n"," 'train_loss_history': [0.9371191650629044,\n","  0.9792068988084793,\n","  0.9558235347270966,\n","  0.9422134160995483,\n","  0.9321891635656356,\n","  0.9213466137647629,\n","  0.907849308848381,\n","  0.9020464956760407,\n","  0.8808141261339187,\n","  0.8736230909824372,\n","  0.8616091489791871,\n","  0.833711513876915,\n","  0.82813580930233,\n","  0.788465216755867,\n","  0.7776662796735764,\n","  0.7592162519693375,\n","  0.7606035381555557,\n","  0.7241095632314682,\n","  0.7380198955535888,\n","  0.702845162153244,\n","  0.6784031435847282,\n","  0.662152835726738,\n","  0.6438063398003578,\n","  0.6138031899929046,\n","  0.6279041811823844,\n","  0.6392624244093895,\n","  0.6486916214227676,\n","  0.6396285146474838,\n","  0.6179987013339996,\n","  0.6032262593507767,\n","  0.5908309072256088,\n","  0.5880381718277932,\n","  0.5858539834618568,\n","  0.5896877855062485,\n","  0.5604072570800781,\n","  0.5539692059159279,\n","  0.5810626685619354,\n","  0.5799808144569397,\n","  0.5414237409830094,\n","  0.5702805548906327,\n","  0.5276067793369293,\n","  0.5456465855240822,\n","  0.515132138133049,\n","  0.5315081089735031,\n","  0.5422969579696655,\n","  0.5290414750576019,\n","  0.5471731439232826,\n","  0.5403948858380317,\n","  0.5198144689202309,\n","  0.5285801976919174]}"]},"metadata":{},"execution_count":12}]},{"cell_type":"markdown","source":["## Legalization of Abortion"],"metadata":{"id":"ZRezp6cx5FRA"}},{"cell_type":"code","source":["# 1. get the corpus\n","target = \"Legalization of Abortion\"\n","corpus_folder = f\"../resources/{folder}/\"\n","corpus: Corpus = ClassificationCorpus(corpus_folder,\n","                                      train_file=f'train.{target}.txt',\n","                                      #dev_file=f'train.{target}.txt',\n","                                      test_file=f'test.{target}.txt'\n",")\n","\n","# 2. create the label dictionary\n","label_dict = corpus.make_label_dictionary()\n","                                                                                                                                                                                         \n","# 5. create the text classifier\n","classifier = TextClassifier(document_embeddings, label_dictionary=label_dict)\n","\n","# 6. initialize the text classifier trainer\n","trainer = ModelTrainer(classifier, corpus)\n","\n","# 7. start the training\n","trainer.train(f\"../resources/{folder}/flair_{target}\",\n","              train_with_dev=False,\n","              max_epochs=50)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nOsY9RTU5FRB","executionInfo":{"status":"ok","timestamp":1645040932710,"user_tz":-60,"elapsed":491395,"user":{"displayName":"Julen Etxaniz Aragoneses","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GilpYDAmorj7KFdjK26TlsyH_HhFWhLqmESeKoCGsI=s64","userId":"06956422670240182492"}},"outputId":"ccdb52a2-02f4-4577-8b8d-4751508bb6c0"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["2022-02-16 19:40:42,135 Reading data from ../resources/stance-semeval2016\n","2022-02-16 19:40:42,140 Train: ../resources/stance-semeval2016/train.Legalization of Abortion.txt\n","2022-02-16 19:40:42,142 Dev: None\n","2022-02-16 19:40:42,144 Test: ../resources/stance-semeval2016/test.Legalization of Abortion.txt\n","2022-02-16 19:40:42,609 Computing label dictionary. Progress:\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n","100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 868/868 [00:02<00:00, 308.82it/s]"]},{"output_type":"stream","name":"stdout","text":["2022-02-16 19:40:47,992 [b'AGAINST', b'FAVOR', b'NONE']\n","2022-02-16 19:40:48,054 ----------------------------------------------------------------------------------------------------\n","2022-02-16 19:40:48,059 Model: \"TextClassifier(\n","  (document_embeddings): DocumentRNNEmbeddings(\n","    (embeddings): StackedEmbeddings(\n","      (list_embedding_0): WordEmbeddings('en-crawl')\n","    )\n","    (word_reprojection_map): Linear(in_features=300, out_features=256, bias=True)\n","    (rnn): LSTM(256, 512, batch_first=True)\n","    (dropout): Dropout(p=0.5, inplace=False)\n","  )\n","  (decoder): Linear(in_features=512, out_features=3, bias=True)\n","  (loss_function): CrossEntropyLoss()\n","  (beta): 1.0\n","  (weights): None\n","  (weight_tensor) None\n",")\"\n","2022-02-16 19:40:48,064 ----------------------------------------------------------------------------------------------------\n","2022-02-16 19:40:48,072 Corpus: \"Corpus: 588 train + 65 dev + 280 test sentences\"\n","2022-02-16 19:40:48,076 ----------------------------------------------------------------------------------------------------\n","2022-02-16 19:40:48,082 Parameters:\n","2022-02-16 19:40:48,088  - learning_rate: \"0.1\"\n","2022-02-16 19:40:48,094  - mini_batch_size: \"32\"\n","2022-02-16 19:40:48,103  - patience: \"3\"\n","2022-02-16 19:40:48,115  - anneal_factor: \"0.5\"\n","2022-02-16 19:40:48,119  - max_epochs: \"50\"\n","2022-02-16 19:40:48,130  - shuffle: \"True\"\n","2022-02-16 19:40:48,134  - train_with_dev: \"False\"\n","2022-02-16 19:40:48,146  - batch_growth_annealing: \"False\"\n","2022-02-16 19:40:48,148 ----------------------------------------------------------------------------------------------------\n","2022-02-16 19:40:48,156 Model training base path: \"../resources/stance-semeval2016/flair_Legalization of Abortion\"\n","2022-02-16 19:40:48,167 ----------------------------------------------------------------------------------------------------\n","2022-02-16 19:40:48,176 Device: cuda:0\n","2022-02-16 19:40:48,179 ----------------------------------------------------------------------------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["2022-02-16 19:40:48,193 Embeddings storage mode: cpu\n","2022-02-16 19:40:48,221 ----------------------------------------------------------------------------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"output_type":"stream","name":"stdout","text":["2022-02-16 19:40:50,670 epoch 1 - iter 1/19 - loss 1.08767939 - samples/sec: 77.05 - lr: 0.100000\n","2022-02-16 19:40:51,005 epoch 1 - iter 2/19 - loss 1.07142186 - samples/sec: 153.18 - lr: 0.100000\n","2022-02-16 19:40:51,218 epoch 1 - iter 3/19 - loss 1.09224939 - samples/sec: 158.68 - lr: 0.100000\n","2022-02-16 19:40:51,524 epoch 1 - iter 4/19 - loss 1.08811331 - samples/sec: 108.88 - lr: 0.100000\n","2022-02-16 19:40:51,652 epoch 1 - iter 5/19 - loss 1.09910018 - samples/sec: 272.49 - lr: 0.100000\n","2022-02-16 19:40:51,760 epoch 1 - iter 6/19 - loss 1.10120465 - samples/sec: 306.71 - lr: 0.100000\n","2022-02-16 19:40:51,861 epoch 1 - iter 7/19 - loss 1.09747180 - samples/sec: 378.73 - lr: 0.100000\n","2022-02-16 19:40:51,952 epoch 1 - iter 8/19 - loss 1.08029240 - samples/sec: 436.34 - lr: 0.100000\n","2022-02-16 19:40:52,048 epoch 1 - iter 9/19 - loss 1.06031246 - samples/sec: 354.95 - lr: 0.100000\n","2022-02-16 19:40:52,138 epoch 1 - iter 10/19 - loss 1.04707129 - samples/sec: 366.98 - lr: 0.100000\n","2022-02-16 19:40:52,220 epoch 1 - iter 11/19 - loss 1.04555635 - samples/sec: 402.59 - lr: 0.100000\n","2022-02-16 19:40:52,296 epoch 1 - iter 12/19 - loss 1.04765680 - samples/sec: 432.10 - lr: 0.100000\n","2022-02-16 19:40:52,390 epoch 1 - iter 13/19 - loss 1.04800213 - samples/sec: 403.72 - lr: 0.100000\n","2022-02-16 19:40:52,496 epoch 1 - iter 14/19 - loss 1.04186259 - samples/sec: 413.63 - lr: 0.100000\n","2022-02-16 19:40:52,603 epoch 1 - iter 15/19 - loss 1.03174567 - samples/sec: 305.31 - lr: 0.100000\n","2022-02-16 19:40:52,685 epoch 1 - iter 16/19 - loss 1.04824432 - samples/sec: 412.92 - lr: 0.100000\n","2022-02-16 19:40:52,767 epoch 1 - iter 17/19 - loss 1.03747199 - samples/sec: 400.59 - lr: 0.100000\n","2022-02-16 19:40:52,856 epoch 1 - iter 18/19 - loss 1.01500074 - samples/sec: 377.89 - lr: 0.100000\n","2022-02-16 19:40:52,911 epoch 1 - iter 19/19 - loss 0.97957076 - samples/sec: 661.49 - lr: 0.100000\n","2022-02-16 19:40:53,321 ----------------------------------------------------------------------------------------------------\n","2022-02-16 19:40:53,323 EPOCH 1 done: loss 0.9796 - lr 0.1000000\n","2022-02-16 19:40:54,965 DEV : loss 0.9600419998168945 - score 0.4769\n","2022-02-16 19:40:55,044 BAD EPOCHS (no improvement): 0\n","saving best model\n","2022-02-16 19:41:11,331 ----------------------------------------------------------------------------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"output_type":"stream","name":"stdout","text":["2022-02-16 19:41:13,087 epoch 2 - iter 1/19 - loss 1.11790884 - samples/sec: 210.20 - lr: 0.100000\n","2022-02-16 19:41:13,204 epoch 2 - iter 2/19 - loss 1.06907350 - samples/sec: 310.95 - lr: 0.100000\n","2022-02-16 19:41:13,303 epoch 2 - iter 3/19 - loss 1.03851781 - samples/sec: 336.58 - lr: 0.100000\n","2022-02-16 19:41:13,394 epoch 2 - iter 4/19 - loss 0.98829737 - samples/sec: 366.60 - lr: 0.100000\n","2022-02-16 19:41:15,991 epoch 2 - iter 5/19 - loss 0.97789272 - samples/sec: 419.53 - lr: 0.100000\n","2022-02-16 19:41:16,083 epoch 2 - iter 6/19 - loss 0.97785956 - samples/sec: 422.07 - lr: 0.100000\n","2022-02-16 19:41:16,154 epoch 2 - iter 7/19 - loss 0.95922520 - samples/sec: 486.38 - lr: 0.100000\n","2022-02-16 19:41:16,221 epoch 2 - iter 8/19 - loss 0.94719224 - samples/sec: 491.85 - lr: 0.100000\n","2022-02-16 19:41:16,291 epoch 2 - iter 9/19 - loss 0.99427012 - samples/sec: 483.70 - lr: 0.100000\n","2022-02-16 19:41:16,361 epoch 2 - iter 10/19 - loss 0.98223154 - samples/sec: 486.63 - lr: 0.100000\n","2022-02-16 19:41:16,446 epoch 2 - iter 11/19 - loss 0.98055956 - samples/sec: 506.98 - lr: 0.100000\n","2022-02-16 19:41:16,538 epoch 2 - iter 12/19 - loss 0.98694601 - samples/sec: 436.57 - lr: 0.100000\n","2022-02-16 19:41:16,608 epoch 2 - iter 13/19 - loss 0.98010191 - samples/sec: 476.39 - lr: 0.100000\n","2022-02-16 19:41:16,675 epoch 2 - iter 14/19 - loss 0.98061691 - samples/sec: 496.93 - lr: 0.100000\n","2022-02-16 19:41:16,749 epoch 2 - iter 15/19 - loss 0.97987124 - samples/sec: 451.53 - lr: 0.100000\n","2022-02-16 19:41:16,813 epoch 2 - iter 16/19 - loss 0.98524259 - samples/sec: 542.64 - lr: 0.100000\n","2022-02-16 19:41:16,899 epoch 2 - iter 17/19 - loss 0.98428858 - samples/sec: 386.24 - lr: 0.100000\n","2022-02-16 19:41:16,971 epoch 2 - iter 18/19 - loss 0.98527480 - samples/sec: 531.17 - lr: 0.100000\n","2022-02-16 19:41:17,016 epoch 2 - iter 19/19 - loss 0.98357591 - samples/sec: 746.81 - lr: 0.100000\n","2022-02-16 19:41:17,622 ----------------------------------------------------------------------------------------------------\n","2022-02-16 19:41:17,627 EPOCH 2 done: loss 0.9836 - lr 0.1000000\n","2022-02-16 19:41:19,738 DEV : loss 0.9189927577972412 - score 0.4615\n","2022-02-16 19:41:19,815 BAD EPOCHS (no improvement): 1\n","2022-02-16 19:41:19,828 ----------------------------------------------------------------------------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"output_type":"stream","name":"stdout","text":["2022-02-16 19:41:23,061 epoch 3 - iter 1/19 - loss 0.87082368 - samples/sec: 52.47 - lr: 0.100000\n","2022-02-16 19:41:23,351 epoch 3 - iter 2/19 - loss 0.87487474 - samples/sec: 134.77 - lr: 0.100000\n","2022-02-16 19:41:23,568 epoch 3 - iter 3/19 - loss 0.91511800 - samples/sec: 155.31 - lr: 0.100000\n","2022-02-16 19:41:23,758 epoch 3 - iter 4/19 - loss 0.90527700 - samples/sec: 176.78 - lr: 0.100000\n","2022-02-16 19:41:23,972 epoch 3 - iter 5/19 - loss 0.91656467 - samples/sec: 178.89 - lr: 0.100000\n","2022-02-16 19:41:24,233 epoch 3 - iter 6/19 - loss 0.93219438 - samples/sec: 155.23 - lr: 0.100000\n","2022-02-16 19:41:24,395 epoch 3 - iter 7/19 - loss 0.94804615 - samples/sec: 209.82 - lr: 0.100000\n","2022-02-16 19:41:24,628 epoch 3 - iter 8/19 - loss 0.95836831 - samples/sec: 180.15 - lr: 0.100000\n","2022-02-16 19:41:24,829 epoch 3 - iter 9/19 - loss 0.96358801 - samples/sec: 167.70 - lr: 0.100000\n","2022-02-16 19:41:24,969 epoch 3 - iter 10/19 - loss 0.95541113 - samples/sec: 232.40 - lr: 0.100000\n","2022-02-16 19:41:25,089 epoch 3 - iter 11/19 - loss 0.95229096 - samples/sec: 281.51 - lr: 0.100000\n","2022-02-16 19:41:25,215 epoch 3 - iter 12/19 - loss 0.95549418 - samples/sec: 275.50 - lr: 0.100000\n","2022-02-16 19:41:25,338 epoch 3 - iter 13/19 - loss 0.96915340 - samples/sec: 335.80 - lr: 0.100000\n","2022-02-16 19:41:25,487 epoch 3 - iter 14/19 - loss 0.97059823 - samples/sec: 251.96 - lr: 0.100000\n","2022-02-16 19:41:25,624 epoch 3 - iter 15/19 - loss 0.95723594 - samples/sec: 252.73 - lr: 0.100000\n","2022-02-16 19:41:25,746 epoch 3 - iter 16/19 - loss 0.96128864 - samples/sec: 272.82 - lr: 0.100000\n","2022-02-16 19:41:25,882 epoch 3 - iter 17/19 - loss 0.96068702 - samples/sec: 246.05 - lr: 0.100000\n","2022-02-16 19:41:25,996 epoch 3 - iter 18/19 - loss 0.95956625 - samples/sec: 301.97 - lr: 0.100000\n","2022-02-16 19:41:26,063 epoch 3 - iter 19/19 - loss 0.95209997 - samples/sec: 538.29 - lr: 0.100000\n","2022-02-16 19:41:26,772 ----------------------------------------------------------------------------------------------------\n","2022-02-16 19:41:26,784 EPOCH 3 done: loss 0.9521 - lr 0.1000000\n","2022-02-16 19:41:29,812 DEV : loss 0.8694517612457275 - score 0.4923\n","2022-02-16 19:41:29,942 BAD EPOCHS (no improvement): 0\n","saving best model\n","2022-02-16 19:41:45,662 ----------------------------------------------------------------------------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"output_type":"stream","name":"stdout","text":["2022-02-16 19:41:47,294 epoch 4 - iter 1/19 - loss 0.97171378 - samples/sec: 164.06 - lr: 0.100000\n","2022-02-16 19:41:47,417 epoch 4 - iter 2/19 - loss 0.90524426 - samples/sec: 294.63 - lr: 0.100000\n","2022-02-16 19:41:47,518 epoch 4 - iter 3/19 - loss 0.92780141 - samples/sec: 449.52 - lr: 0.100000\n","2022-02-16 19:41:47,604 epoch 4 - iter 4/19 - loss 0.90942091 - samples/sec: 408.14 - lr: 0.100000\n","2022-02-16 19:41:47,692 epoch 4 - iter 5/19 - loss 0.93070996 - samples/sec: 387.33 - lr: 0.100000\n","2022-02-16 19:41:47,793 epoch 4 - iter 6/19 - loss 0.93292412 - samples/sec: 390.86 - lr: 0.100000\n","2022-02-16 19:41:47,873 epoch 4 - iter 7/19 - loss 0.93166020 - samples/sec: 419.38 - lr: 0.100000\n","2022-02-16 19:41:47,946 epoch 4 - iter 8/19 - loss 0.91661174 - samples/sec: 454.13 - lr: 0.100000\n","2022-02-16 19:41:48,022 epoch 4 - iter 9/19 - loss 0.92427317 - samples/sec: 543.52 - lr: 0.100000\n","2022-02-16 19:41:48,098 epoch 4 - iter 10/19 - loss 0.91490132 - samples/sec: 429.70 - lr: 0.100000\n","2022-02-16 19:41:48,168 epoch 4 - iter 11/19 - loss 0.91110554 - samples/sec: 491.49 - lr: 0.100000\n","2022-02-16 19:41:48,252 epoch 4 - iter 12/19 - loss 0.91163216 - samples/sec: 536.66 - lr: 0.100000\n","2022-02-16 19:41:48,327 epoch 4 - iter 13/19 - loss 0.91365909 - samples/sec: 434.61 - lr: 0.100000\n","2022-02-16 19:41:48,407 epoch 4 - iter 14/19 - loss 0.91336930 - samples/sec: 416.03 - lr: 0.100000\n","2022-02-16 19:41:48,491 epoch 4 - iter 15/19 - loss 0.92685118 - samples/sec: 459.70 - lr: 0.100000\n","2022-02-16 19:41:48,570 epoch 4 - iter 16/19 - loss 0.91950444 - samples/sec: 497.36 - lr: 0.100000\n","2022-02-16 19:41:48,638 epoch 4 - iter 17/19 - loss 0.92769882 - samples/sec: 519.02 - lr: 0.100000\n","2022-02-16 19:41:48,714 epoch 4 - iter 18/19 - loss 0.92417517 - samples/sec: 446.52 - lr: 0.100000\n","2022-02-16 19:41:48,754 epoch 4 - iter 19/19 - loss 0.92668399 - samples/sec: 933.27 - lr: 0.100000\n","2022-02-16 19:41:49,276 ----------------------------------------------------------------------------------------------------\n","2022-02-16 19:41:49,281 EPOCH 4 done: loss 0.9267 - lr 0.1000000\n","2022-02-16 19:41:51,209 DEV : loss 1.098806381225586 - score 0.3846\n","2022-02-16 19:41:51,291 BAD EPOCHS (no improvement): 1\n","2022-02-16 19:41:51,298 ----------------------------------------------------------------------------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"output_type":"stream","name":"stdout","text":["2022-02-16 19:41:52,831 epoch 5 - iter 1/19 - loss 0.93008977 - samples/sec: 151.04 - lr: 0.100000\n","2022-02-16 19:41:52,952 epoch 5 - iter 2/19 - loss 0.92017242 - samples/sec: 343.12 - lr: 0.100000\n","2022-02-16 19:41:53,042 epoch 5 - iter 3/19 - loss 0.96556757 - samples/sec: 382.58 - lr: 0.100000\n","2022-02-16 19:41:53,135 epoch 5 - iter 4/19 - loss 0.93637623 - samples/sec: 424.83 - lr: 0.100000\n","2022-02-16 19:41:53,230 epoch 5 - iter 5/19 - loss 0.91432196 - samples/sec: 399.22 - lr: 0.100000\n","2022-02-16 19:41:53,344 epoch 5 - iter 6/19 - loss 0.91463469 - samples/sec: 361.48 - lr: 0.100000\n","2022-02-16 19:41:53,425 epoch 5 - iter 7/19 - loss 0.92708280 - samples/sec: 432.27 - lr: 0.100000\n","2022-02-16 19:41:53,497 epoch 5 - iter 8/19 - loss 0.94577020 - samples/sec: 462.29 - lr: 0.100000\n","2022-02-16 19:41:53,574 epoch 5 - iter 9/19 - loss 0.93451784 - samples/sec: 475.73 - lr: 0.100000\n","2022-02-16 19:41:53,644 epoch 5 - iter 10/19 - loss 0.93727039 - samples/sec: 484.65 - lr: 0.100000\n","2022-02-16 19:41:53,730 epoch 5 - iter 11/19 - loss 0.93767501 - samples/sec: 462.12 - lr: 0.100000\n","2022-02-16 19:41:53,811 epoch 5 - iter 12/19 - loss 0.94274425 - samples/sec: 527.34 - lr: 0.100000\n","2022-02-16 19:41:53,881 epoch 5 - iter 13/19 - loss 0.94167289 - samples/sec: 466.39 - lr: 0.100000\n","2022-02-16 19:41:53,949 epoch 5 - iter 14/19 - loss 0.94133114 - samples/sec: 501.66 - lr: 0.100000\n","2022-02-16 19:41:54,016 epoch 5 - iter 15/19 - loss 0.93394800 - samples/sec: 491.19 - lr: 0.100000\n","2022-02-16 19:41:54,084 epoch 5 - iter 16/19 - loss 0.94129656 - samples/sec: 548.87 - lr: 0.100000\n","2022-02-16 19:41:54,156 epoch 5 - iter 17/19 - loss 0.93924546 - samples/sec: 453.01 - lr: 0.100000\n","2022-02-16 19:41:54,237 epoch 5 - iter 18/19 - loss 0.93451197 - samples/sec: 447.33 - lr: 0.100000\n","2022-02-16 19:41:54,281 epoch 5 - iter 19/19 - loss 0.92518875 - samples/sec: 793.26 - lr: 0.100000\n","2022-02-16 19:41:54,859 ----------------------------------------------------------------------------------------------------\n","2022-02-16 19:41:54,860 EPOCH 5 done: loss 0.9252 - lr 0.1000000\n","2022-02-16 19:41:58,779 DEV : loss 0.8332707285881042 - score 0.4769\n","2022-02-16 19:41:58,954 BAD EPOCHS (no improvement): 2\n","2022-02-16 19:41:58,970 ----------------------------------------------------------------------------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"output_type":"stream","name":"stdout","text":["2022-02-16 19:42:02,059 epoch 6 - iter 1/19 - loss 0.82840776 - samples/sec: 62.02 - lr: 0.100000\n","2022-02-16 19:42:02,370 epoch 6 - iter 2/19 - loss 0.92813939 - samples/sec: 115.62 - lr: 0.100000\n","2022-02-16 19:42:02,792 epoch 6 - iter 3/19 - loss 0.92491353 - samples/sec: 104.78 - lr: 0.100000\n","2022-02-16 19:42:03,012 epoch 6 - iter 4/19 - loss 0.94830772 - samples/sec: 158.70 - lr: 0.100000\n","2022-02-16 19:42:03,297 epoch 6 - iter 5/19 - loss 0.91906077 - samples/sec: 134.12 - lr: 0.100000\n","2022-02-16 19:42:03,530 epoch 6 - iter 6/19 - loss 0.89951799 - samples/sec: 161.40 - lr: 0.100000\n","2022-02-16 19:42:03,862 epoch 6 - iter 7/19 - loss 0.88858747 - samples/sec: 102.16 - lr: 0.100000\n","2022-02-16 19:42:04,120 epoch 6 - iter 8/19 - loss 0.89699038 - samples/sec: 158.92 - lr: 0.100000\n","2022-02-16 19:42:04,352 epoch 6 - iter 9/19 - loss 0.88694249 - samples/sec: 189.79 - lr: 0.100000\n","2022-02-16 19:42:04,594 epoch 6 - iter 10/19 - loss 0.88148156 - samples/sec: 134.65 - lr: 0.100000\n","2022-02-16 19:42:04,800 epoch 6 - iter 11/19 - loss 0.86294620 - samples/sec: 161.99 - lr: 0.100000\n","2022-02-16 19:42:04,979 epoch 6 - iter 12/19 - loss 0.84569938 - samples/sec: 192.90 - lr: 0.100000\n","2022-02-16 19:42:05,217 epoch 6 - iter 13/19 - loss 0.84388211 - samples/sec: 141.81 - lr: 0.100000\n","2022-02-16 19:42:05,481 epoch 6 - iter 14/19 - loss 0.85100673 - samples/sec: 149.05 - lr: 0.100000\n","2022-02-16 19:42:05,753 epoch 6 - iter 15/19 - loss 0.86009392 - samples/sec: 139.73 - lr: 0.100000\n","2022-02-16 19:42:05,943 epoch 6 - iter 16/19 - loss 0.86139738 - samples/sec: 174.82 - lr: 0.100000\n","2022-02-16 19:42:06,108 epoch 6 - iter 17/19 - loss 0.85299313 - samples/sec: 210.57 - lr: 0.100000\n","2022-02-16 19:42:06,298 epoch 6 - iter 18/19 - loss 0.86930006 - samples/sec: 176.25 - lr: 0.100000\n","2022-02-16 19:42:06,371 epoch 6 - iter 19/19 - loss 0.86755427 - samples/sec: 477.99 - lr: 0.100000\n","2022-02-16 19:42:07,012 ----------------------------------------------------------------------------------------------------\n","2022-02-16 19:42:07,021 EPOCH 6 done: loss 0.8676 - lr 0.1000000\n","2022-02-16 19:42:10,001 DEV : loss 0.9058871269226074 - score 0.4462\n","2022-02-16 19:42:10,086 BAD EPOCHS (no improvement): 3\n","2022-02-16 19:42:10,093 ----------------------------------------------------------------------------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"output_type":"stream","name":"stdout","text":["2022-02-16 19:42:11,361 epoch 7 - iter 1/19 - loss 0.84038818 - samples/sec: 181.97 - lr: 0.100000\n","2022-02-16 19:42:11,469 epoch 7 - iter 2/19 - loss 0.85552534 - samples/sec: 327.69 - lr: 0.100000\n","2022-02-16 19:42:11,555 epoch 7 - iter 3/19 - loss 0.86901748 - samples/sec: 428.64 - lr: 0.100000\n","2022-02-16 19:42:11,643 epoch 7 - iter 4/19 - loss 0.85664508 - samples/sec: 435.03 - lr: 0.100000\n","2022-02-16 19:42:11,718 epoch 7 - iter 5/19 - loss 0.84608479 - samples/sec: 443.54 - lr: 0.100000\n","2022-02-16 19:42:11,821 epoch 7 - iter 6/19 - loss 0.86987785 - samples/sec: 431.30 - lr: 0.100000\n","2022-02-16 19:42:11,899 epoch 7 - iter 7/19 - loss 0.86439504 - samples/sec: 426.12 - lr: 0.100000\n","2022-02-16 19:42:11,971 epoch 7 - iter 8/19 - loss 0.85168964 - samples/sec: 477.48 - lr: 0.100000\n","2022-02-16 19:42:12,064 epoch 7 - iter 9/19 - loss 0.86699767 - samples/sec: 496.52 - lr: 0.100000\n","2022-02-16 19:42:12,153 epoch 7 - iter 10/19 - loss 0.86676406 - samples/sec: 453.17 - lr: 0.100000\n","2022-02-16 19:42:12,231 epoch 7 - iter 11/19 - loss 0.85669679 - samples/sec: 450.46 - lr: 0.100000\n","2022-02-16 19:42:12,300 epoch 7 - iter 12/19 - loss 0.85356822 - samples/sec: 505.17 - lr: 0.100000\n","2022-02-16 19:42:12,383 epoch 7 - iter 13/19 - loss 0.87665533 - samples/sec: 407.31 - lr: 0.100000\n","2022-02-16 19:42:12,461 epoch 7 - iter 14/19 - loss 0.87431536 - samples/sec: 427.39 - lr: 0.100000\n","2022-02-16 19:42:12,532 epoch 7 - iter 15/19 - loss 0.87180441 - samples/sec: 476.55 - lr: 0.100000\n","2022-02-16 19:42:12,612 epoch 7 - iter 16/19 - loss 0.86389364 - samples/sec: 455.45 - lr: 0.100000\n","2022-02-16 19:42:12,681 epoch 7 - iter 17/19 - loss 0.85540251 - samples/sec: 486.73 - lr: 0.100000\n","2022-02-16 19:42:12,756 epoch 7 - iter 18/19 - loss 0.85780453 - samples/sec: 451.82 - lr: 0.100000\n","2022-02-16 19:42:12,799 epoch 7 - iter 19/19 - loss 0.84511296 - samples/sec: 840.37 - lr: 0.100000\n","2022-02-16 19:42:13,195 ----------------------------------------------------------------------------------------------------\n","2022-02-16 19:42:13,199 EPOCH 7 done: loss 0.8451 - lr 0.1000000\n","2022-02-16 19:42:14,807 DEV : loss 0.7443398237228394 - score 0.4923\n","2022-02-16 19:42:14,912 BAD EPOCHS (no improvement): 0\n","saving best model\n","2022-02-16 19:42:31,023 ----------------------------------------------------------------------------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"output_type":"stream","name":"stdout","text":["2022-02-16 19:42:32,611 epoch 8 - iter 1/19 - loss 0.71170092 - samples/sec: 154.56 - lr: 0.100000\n","2022-02-16 19:42:32,707 epoch 8 - iter 2/19 - loss 0.83359277 - samples/sec: 350.08 - lr: 0.100000\n","2022-02-16 19:42:32,806 epoch 8 - iter 3/19 - loss 0.80954315 - samples/sec: 402.30 - lr: 0.100000\n","2022-02-16 19:42:32,903 epoch 8 - iter 4/19 - loss 0.82666275 - samples/sec: 396.49 - lr: 0.100000\n","2022-02-16 19:42:32,986 epoch 8 - iter 5/19 - loss 0.80428307 - samples/sec: 435.89 - lr: 0.100000\n","2022-02-16 19:42:33,084 epoch 8 - iter 6/19 - loss 0.81283531 - samples/sec: 435.89 - lr: 0.100000\n","2022-02-16 19:42:33,167 epoch 8 - iter 7/19 - loss 0.81447647 - samples/sec: 398.49 - lr: 0.100000\n","2022-02-16 19:42:33,238 epoch 8 - iter 8/19 - loss 0.81924041 - samples/sec: 466.96 - lr: 0.100000\n","2022-02-16 19:42:33,316 epoch 8 - iter 9/19 - loss 0.83342375 - samples/sec: 452.25 - lr: 0.100000\n","2022-02-16 19:42:33,396 epoch 8 - iter 10/19 - loss 0.83521829 - samples/sec: 517.12 - lr: 0.100000\n","2022-02-16 19:42:33,472 epoch 8 - iter 11/19 - loss 0.82970607 - samples/sec: 488.28 - lr: 0.100000\n","2022-02-16 19:42:33,556 epoch 8 - iter 12/19 - loss 0.82263718 - samples/sec: 504.00 - lr: 0.100000\n","2022-02-16 19:42:33,629 epoch 8 - iter 13/19 - loss 0.84060179 - samples/sec: 475.87 - lr: 0.100000\n","2022-02-16 19:42:33,706 epoch 8 - iter 14/19 - loss 0.84500103 - samples/sec: 444.10 - lr: 0.100000\n","2022-02-16 19:42:33,777 epoch 8 - iter 15/19 - loss 0.83913189 - samples/sec: 495.97 - lr: 0.100000\n","2022-02-16 19:42:33,849 epoch 8 - iter 16/19 - loss 0.84672344 - samples/sec: 535.94 - lr: 0.100000\n","2022-02-16 19:42:33,921 epoch 8 - iter 17/19 - loss 0.83864499 - samples/sec: 507.14 - lr: 0.100000\n","2022-02-16 19:42:33,997 epoch 8 - iter 18/19 - loss 0.84167620 - samples/sec: 492.03 - lr: 0.100000\n","2022-02-16 19:42:34,041 epoch 8 - iter 19/19 - loss 0.83952401 - samples/sec: 797.67 - lr: 0.100000\n","2022-02-16 19:42:34,627 ----------------------------------------------------------------------------------------------------\n","2022-02-16 19:42:34,630 EPOCH 8 done: loss 0.8395 - lr 0.1000000\n","2022-02-16 19:42:36,697 DEV : loss 0.7582077383995056 - score 0.4615\n","2022-02-16 19:42:36,773 BAD EPOCHS (no improvement): 1\n","2022-02-16 19:42:36,782 ----------------------------------------------------------------------------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"output_type":"stream","name":"stdout","text":["2022-02-16 19:42:38,250 epoch 9 - iter 1/19 - loss 0.92149425 - samples/sec: 127.21 - lr: 0.100000\n","2022-02-16 19:42:38,384 epoch 9 - iter 2/19 - loss 0.90213627 - samples/sec: 322.05 - lr: 0.100000\n","2022-02-16 19:42:40,197 epoch 9 - iter 3/19 - loss 0.80824018 - samples/sec: 410.51 - lr: 0.100000\n","2022-02-16 19:42:40,360 epoch 9 - iter 4/19 - loss 0.80714226 - samples/sec: 201.51 - lr: 0.100000\n","2022-02-16 19:42:40,732 epoch 9 - iter 5/19 - loss 0.80760460 - samples/sec: 90.44 - lr: 0.100000\n","2022-02-16 19:42:40,974 epoch 9 - iter 6/19 - loss 0.82630257 - samples/sec: 203.80 - lr: 0.100000\n","2022-02-16 19:42:41,325 epoch 9 - iter 7/19 - loss 0.80468399 - samples/sec: 94.19 - lr: 0.100000\n","2022-02-16 19:42:41,651 epoch 9 - iter 8/19 - loss 0.80538551 - samples/sec: 101.47 - lr: 0.100000\n","2022-02-16 19:42:41,901 epoch 9 - iter 9/19 - loss 0.81898323 - samples/sec: 132.14 - lr: 0.100000\n","2022-02-16 19:42:42,129 epoch 9 - iter 10/19 - loss 0.81757954 - samples/sec: 145.30 - lr: 0.100000\n","2022-02-16 19:42:42,379 epoch 9 - iter 11/19 - loss 0.81791068 - samples/sec: 136.03 - lr: 0.100000\n","2022-02-16 19:42:42,693 epoch 9 - iter 12/19 - loss 0.81097457 - samples/sec: 116.04 - lr: 0.100000\n","2022-02-16 19:42:42,855 epoch 9 - iter 13/19 - loss 0.79565484 - samples/sec: 203.73 - lr: 0.100000\n","2022-02-16 19:42:43,129 epoch 9 - iter 14/19 - loss 0.79938150 - samples/sec: 121.82 - lr: 0.100000\n","2022-02-16 19:42:43,289 epoch 9 - iter 15/19 - loss 0.80932910 - samples/sec: 209.31 - lr: 0.100000\n","2022-02-16 19:42:43,527 epoch 9 - iter 16/19 - loss 0.80598810 - samples/sec: 140.67 - lr: 0.100000\n","2022-02-16 19:42:43,711 epoch 9 - iter 17/19 - loss 0.80190509 - samples/sec: 183.09 - lr: 0.100000\n","2022-02-16 19:42:43,883 epoch 9 - iter 18/19 - loss 0.79877438 - samples/sec: 211.08 - lr: 0.100000\n","2022-02-16 19:42:43,973 epoch 9 - iter 19/19 - loss 0.79461315 - samples/sec: 382.25 - lr: 0.100000\n","2022-02-16 19:42:44,874 ----------------------------------------------------------------------------------------------------\n","2022-02-16 19:42:44,887 EPOCH 9 done: loss 0.7946 - lr 0.1000000\n","2022-02-16 19:42:48,480 DEV : loss 0.7327412366867065 - score 0.5538\n","2022-02-16 19:42:48,712 BAD EPOCHS (no improvement): 0\n","saving best model\n","2022-02-16 19:43:04,580 ----------------------------------------------------------------------------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"output_type":"stream","name":"stdout","text":["2022-02-16 19:43:06,146 epoch 10 - iter 1/19 - loss 0.71529585 - samples/sec: 123.43 - lr: 0.100000\n","2022-02-16 19:43:06,263 epoch 10 - iter 2/19 - loss 0.84617376 - samples/sec: 331.02 - lr: 0.100000\n","2022-02-16 19:43:06,369 epoch 10 - iter 3/19 - loss 0.86372073 - samples/sec: 372.11 - lr: 0.100000\n","2022-02-16 19:43:06,467 epoch 10 - iter 4/19 - loss 0.82043371 - samples/sec: 347.04 - lr: 0.100000\n","2022-02-16 19:43:06,588 epoch 10 - iter 5/19 - loss 0.80472342 - samples/sec: 336.93 - lr: 0.100000\n","2022-02-16 19:43:06,696 epoch 10 - iter 6/19 - loss 0.82217960 - samples/sec: 349.34 - lr: 0.100000\n","2022-02-16 19:43:06,778 epoch 10 - iter 7/19 - loss 0.78590782 - samples/sec: 434.38 - lr: 0.100000\n","2022-02-16 19:43:06,856 epoch 10 - iter 8/19 - loss 0.77450684 - samples/sec: 431.42 - lr: 0.100000\n","2022-02-16 19:43:06,945 epoch 10 - iter 9/19 - loss 0.78559874 - samples/sec: 409.84 - lr: 0.100000\n","2022-02-16 19:43:07,019 epoch 10 - iter 10/19 - loss 0.79453292 - samples/sec: 477.29 - lr: 0.100000\n","2022-02-16 19:43:07,110 epoch 10 - iter 11/19 - loss 0.79165161 - samples/sec: 457.64 - lr: 0.100000\n","2022-02-16 19:43:07,199 epoch 10 - iter 12/19 - loss 0.79970251 - samples/sec: 441.30 - lr: 0.100000\n","2022-02-16 19:43:07,281 epoch 10 - iter 13/19 - loss 0.79229448 - samples/sec: 424.80 - lr: 0.100000\n","2022-02-16 19:43:07,354 epoch 10 - iter 14/19 - loss 0.79579079 - samples/sec: 459.65 - lr: 0.100000\n","2022-02-16 19:43:07,436 epoch 10 - iter 15/19 - loss 0.79226885 - samples/sec: 460.27 - lr: 0.100000\n","2022-02-16 19:43:07,506 epoch 10 - iter 16/19 - loss 0.78043004 - samples/sec: 505.20 - lr: 0.100000\n","2022-02-16 19:43:07,590 epoch 10 - iter 17/19 - loss 0.77865766 - samples/sec: 439.28 - lr: 0.100000\n","2022-02-16 19:43:07,677 epoch 10 - iter 18/19 - loss 0.78259377 - samples/sec: 430.28 - lr: 0.100000\n","2022-02-16 19:43:07,717 epoch 10 - iter 19/19 - loss 0.78914824 - samples/sec: 845.08 - lr: 0.100000\n","2022-02-16 19:43:08,287 ----------------------------------------------------------------------------------------------------\n","2022-02-16 19:43:08,290 EPOCH 10 done: loss 0.7891 - lr 0.1000000\n","2022-02-16 19:43:10,331 DEV : loss 0.7486989498138428 - score 0.5231\n","2022-02-16 19:43:10,412 BAD EPOCHS (no improvement): 1\n","2022-02-16 19:43:10,422 ----------------------------------------------------------------------------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"output_type":"stream","name":"stdout","text":["2022-02-16 19:43:13,246 epoch 11 - iter 1/19 - loss 0.71919054 - samples/sec: 73.32 - lr: 0.100000\n","2022-02-16 19:43:13,410 epoch 11 - iter 2/19 - loss 0.78632239 - samples/sec: 203.01 - lr: 0.100000\n","2022-02-16 19:43:13,668 epoch 11 - iter 3/19 - loss 0.83286792 - samples/sec: 126.79 - lr: 0.100000\n","2022-02-16 19:43:13,869 epoch 11 - iter 4/19 - loss 0.86018175 - samples/sec: 169.79 - lr: 0.100000\n","2022-02-16 19:43:14,084 epoch 11 - iter 5/19 - loss 0.83664753 - samples/sec: 168.55 - lr: 0.100000\n","2022-02-16 19:43:14,323 epoch 11 - iter 6/19 - loss 0.81255000 - samples/sec: 175.44 - lr: 0.100000\n","2022-02-16 19:43:14,528 epoch 11 - iter 7/19 - loss 0.80312084 - samples/sec: 161.91 - lr: 0.100000\n","2022-02-16 19:43:14,715 epoch 11 - iter 8/19 - loss 0.80082130 - samples/sec: 211.77 - lr: 0.100000\n","2022-02-16 19:43:14,892 epoch 11 - iter 9/19 - loss 0.79221824 - samples/sec: 193.82 - lr: 0.100000\n","2022-02-16 19:43:15,123 epoch 11 - iter 10/19 - loss 0.78983946 - samples/sec: 148.70 - lr: 0.100000\n","2022-02-16 19:43:15,311 epoch 11 - iter 11/19 - loss 0.78847031 - samples/sec: 182.49 - lr: 0.100000\n","2022-02-16 19:43:15,568 epoch 11 - iter 12/19 - loss 0.80099412 - samples/sec: 173.66 - lr: 0.100000\n","2022-02-16 19:43:15,786 epoch 11 - iter 13/19 - loss 0.78805517 - samples/sec: 152.67 - lr: 0.100000\n","2022-02-16 19:43:16,015 epoch 11 - iter 14/19 - loss 0.79667863 - samples/sec: 157.06 - lr: 0.100000\n","2022-02-16 19:43:16,160 epoch 11 - iter 15/19 - loss 0.79909122 - samples/sec: 226.43 - lr: 0.100000\n","2022-02-16 19:43:16,324 epoch 11 - iter 16/19 - loss 0.81291472 - samples/sec: 206.30 - lr: 0.100000\n","2022-02-16 19:43:16,510 epoch 11 - iter 17/19 - loss 0.80984061 - samples/sec: 177.79 - lr: 0.100000\n","2022-02-16 19:43:16,714 epoch 11 - iter 18/19 - loss 0.80149465 - samples/sec: 171.20 - lr: 0.100000\n","2022-02-16 19:43:16,816 epoch 11 - iter 19/19 - loss 0.79272559 - samples/sec: 343.94 - lr: 0.100000\n","2022-02-16 19:43:17,622 ----------------------------------------------------------------------------------------------------\n","2022-02-16 19:43:17,625 EPOCH 11 done: loss 0.7927 - lr 0.1000000\n","2022-02-16 19:43:21,336 DEV : loss 0.6811479926109314 - score 0.5692\n","2022-02-16 19:43:21,506 BAD EPOCHS (no improvement): 0\n","saving best model\n","2022-02-16 19:43:37,385 ----------------------------------------------------------------------------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"output_type":"stream","name":"stdout","text":["2022-02-16 19:43:38,871 epoch 12 - iter 1/19 - loss 0.52910411 - samples/sec: 110.65 - lr: 0.100000\n","2022-02-16 19:43:38,982 epoch 12 - iter 2/19 - loss 0.70104885 - samples/sec: 356.52 - lr: 0.100000\n","2022-02-16 19:43:39,087 epoch 12 - iter 3/19 - loss 0.71161999 - samples/sec: 414.57 - lr: 0.100000\n","2022-02-16 19:43:39,204 epoch 12 - iter 4/19 - loss 0.72786283 - samples/sec: 281.52 - lr: 0.100000\n","2022-02-16 19:43:39,329 epoch 12 - iter 5/19 - loss 0.74640774 - samples/sec: 279.12 - lr: 0.100000\n","2022-02-16 19:43:39,430 epoch 12 - iter 6/19 - loss 0.73135149 - samples/sec: 396.39 - lr: 0.100000\n","2022-02-16 19:43:39,519 epoch 12 - iter 7/19 - loss 0.73487811 - samples/sec: 396.24 - lr: 0.100000\n","2022-02-16 19:43:39,605 epoch 12 - iter 8/19 - loss 0.73382135 - samples/sec: 520.48 - lr: 0.100000\n","2022-02-16 19:43:39,680 epoch 12 - iter 9/19 - loss 0.72764719 - samples/sec: 446.28 - lr: 0.100000\n","2022-02-16 19:43:39,762 epoch 12 - iter 10/19 - loss 0.70947646 - samples/sec: 479.51 - lr: 0.100000\n","2022-02-16 19:43:39,835 epoch 12 - iter 11/19 - loss 0.73187760 - samples/sec: 485.05 - lr: 0.100000\n","2022-02-16 19:43:39,909 epoch 12 - iter 12/19 - loss 0.72749732 - samples/sec: 471.45 - lr: 0.100000\n","2022-02-16 19:43:39,986 epoch 12 - iter 13/19 - loss 0.72967566 - samples/sec: 441.76 - lr: 0.100000\n","2022-02-16 19:43:40,065 epoch 12 - iter 14/19 - loss 0.73476956 - samples/sec: 542.91 - lr: 0.100000\n","2022-02-16 19:43:40,145 epoch 12 - iter 15/19 - loss 0.74244104 - samples/sec: 410.56 - lr: 0.100000\n","2022-02-16 19:43:40,217 epoch 12 - iter 16/19 - loss 0.75063631 - samples/sec: 509.88 - lr: 0.100000\n","2022-02-16 19:43:40,297 epoch 12 - iter 17/19 - loss 0.73600087 - samples/sec: 460.79 - lr: 0.100000\n","2022-02-16 19:43:40,369 epoch 12 - iter 18/19 - loss 0.73351822 - samples/sec: 473.91 - lr: 0.100000\n","2022-02-16 19:43:40,414 epoch 12 - iter 19/19 - loss 0.72724353 - samples/sec: 860.44 - lr: 0.100000\n","2022-02-16 19:43:40,979 ----------------------------------------------------------------------------------------------------\n","2022-02-16 19:43:40,987 EPOCH 12 done: loss 0.7272 - lr 0.1000000\n","2022-02-16 19:43:43,036 DEV : loss 0.6298842430114746 - score 0.6\n","2022-02-16 19:43:43,114 BAD EPOCHS (no improvement): 0\n","saving best model\n","2022-02-16 19:43:58,098 ----------------------------------------------------------------------------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"output_type":"stream","name":"stdout","text":["2022-02-16 19:43:59,771 epoch 13 - iter 1/19 - loss 0.83830434 - samples/sec: 121.50 - lr: 0.100000\n","2022-02-16 19:43:59,920 epoch 13 - iter 2/19 - loss 0.86202931 - samples/sec: 386.62 - lr: 0.100000\n","2022-02-16 19:44:00,004 epoch 13 - iter 3/19 - loss 0.88067085 - samples/sec: 400.26 - lr: 0.100000\n","2022-02-16 19:44:00,090 epoch 13 - iter 4/19 - loss 0.86349422 - samples/sec: 385.38 - lr: 0.100000\n","2022-02-16 19:44:00,170 epoch 13 - iter 5/19 - loss 0.82455466 - samples/sec: 421.24 - lr: 0.100000\n","2022-02-16 19:44:00,262 epoch 13 - iter 6/19 - loss 0.79030831 - samples/sec: 386.93 - lr: 0.100000\n","2022-02-16 19:44:00,341 epoch 13 - iter 7/19 - loss 0.77250711 - samples/sec: 419.09 - lr: 0.100000\n","2022-02-16 19:44:00,441 epoch 13 - iter 8/19 - loss 0.78466680 - samples/sec: 445.02 - lr: 0.100000\n","2022-02-16 19:44:00,511 epoch 13 - iter 9/19 - loss 0.75278964 - samples/sec: 483.14 - lr: 0.100000\n","2022-02-16 19:44:00,582 epoch 13 - iter 10/19 - loss 0.73782226 - samples/sec: 478.02 - lr: 0.100000\n","2022-02-16 19:44:00,654 epoch 13 - iter 11/19 - loss 0.74993477 - samples/sec: 461.07 - lr: 0.100000\n","2022-02-16 19:44:00,734 epoch 13 - iter 12/19 - loss 0.74051926 - samples/sec: 408.40 - lr: 0.100000\n","2022-02-16 19:44:00,804 epoch 13 - iter 13/19 - loss 0.73227776 - samples/sec: 483.79 - lr: 0.100000\n","2022-02-16 19:44:00,900 epoch 13 - iter 14/19 - loss 0.75084674 - samples/sec: 465.43 - lr: 0.100000\n","2022-02-16 19:44:00,977 epoch 13 - iter 15/19 - loss 0.75282623 - samples/sec: 427.68 - lr: 0.100000\n","2022-02-16 19:44:01,049 epoch 13 - iter 16/19 - loss 0.74143959 - samples/sec: 467.21 - lr: 0.100000\n","2022-02-16 19:44:01,127 epoch 13 - iter 17/19 - loss 0.73765977 - samples/sec: 429.32 - lr: 0.100000\n","2022-02-16 19:44:01,202 epoch 13 - iter 18/19 - loss 0.73837051 - samples/sec: 469.59 - lr: 0.100000\n","2022-02-16 19:44:01,243 epoch 13 - iter 19/19 - loss 0.73628547 - samples/sec: 901.29 - lr: 0.100000\n","2022-02-16 19:44:01,757 ----------------------------------------------------------------------------------------------------\n","2022-02-16 19:44:01,765 EPOCH 13 done: loss 0.7363 - lr 0.1000000\n","2022-02-16 19:44:03,684 DEV : loss 0.6540738344192505 - score 0.6615\n","2022-02-16 19:44:03,767 BAD EPOCHS (no improvement): 0\n","saving best model\n","2022-02-16 19:44:19,307 ----------------------------------------------------------------------------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"output_type":"stream","name":"stdout","text":["2022-02-16 19:44:20,956 epoch 14 - iter 1/19 - loss 0.73220414 - samples/sec: 134.70 - lr: 0.100000\n","2022-02-16 19:44:21,042 epoch 14 - iter 2/19 - loss 0.77524266 - samples/sec: 402.95 - lr: 0.100000\n","2022-02-16 19:44:21,128 epoch 14 - iter 3/19 - loss 0.72565279 - samples/sec: 454.13 - lr: 0.100000\n","2022-02-16 19:44:21,214 epoch 14 - iter 4/19 - loss 0.70185575 - samples/sec: 433.19 - lr: 0.100000\n","2022-02-16 19:44:21,309 epoch 14 - iter 5/19 - loss 0.71805931 - samples/sec: 394.11 - lr: 0.100000\n","2022-02-16 19:44:21,425 epoch 14 - iter 6/19 - loss 0.69603715 - samples/sec: 388.30 - lr: 0.100000\n","2022-02-16 19:44:21,536 epoch 14 - iter 7/19 - loss 0.69613239 - samples/sec: 355.60 - lr: 0.100000\n","2022-02-16 19:44:21,621 epoch 14 - iter 8/19 - loss 0.71032213 - samples/sec: 392.54 - lr: 0.100000\n","2022-02-16 19:44:21,698 epoch 14 - iter 9/19 - loss 0.71369014 - samples/sec: 430.43 - lr: 0.100000\n","2022-02-16 19:44:21,776 epoch 14 - iter 10/19 - loss 0.70034956 - samples/sec: 430.04 - lr: 0.100000\n","2022-02-16 19:44:21,843 epoch 14 - iter 11/19 - loss 0.71613637 - samples/sec: 526.01 - lr: 0.100000\n","2022-02-16 19:44:21,929 epoch 14 - iter 12/19 - loss 0.71957525 - samples/sec: 472.00 - lr: 0.100000\n","2022-02-16 19:44:21,998 epoch 14 - iter 13/19 - loss 0.71688866 - samples/sec: 488.73 - lr: 0.100000\n","2022-02-16 19:44:22,061 epoch 14 - iter 14/19 - loss 0.72366375 - samples/sec: 531.88 - lr: 0.100000\n","2022-02-16 19:44:22,148 epoch 14 - iter 15/19 - loss 0.71204110 - samples/sec: 482.68 - lr: 0.100000\n","2022-02-16 19:44:22,218 epoch 14 - iter 16/19 - loss 0.70863029 - samples/sec: 471.54 - lr: 0.100000\n","2022-02-16 19:44:22,289 epoch 14 - iter 17/19 - loss 0.71633477 - samples/sec: 460.96 - lr: 0.100000\n","2022-02-16 19:44:22,362 epoch 14 - iter 18/19 - loss 0.71880937 - samples/sec: 547.89 - lr: 0.100000\n","2022-02-16 19:44:22,410 epoch 14 - iter 19/19 - loss 0.71423107 - samples/sec: 698.48 - lr: 0.100000\n","2022-02-16 19:44:22,947 ----------------------------------------------------------------------------------------------------\n","2022-02-16 19:44:22,954 EPOCH 14 done: loss 0.7142 - lr 0.1000000\n","2022-02-16 19:44:24,910 DEV : loss 0.5862265825271606 - score 0.5846\n","2022-02-16 19:44:25,024 BAD EPOCHS (no improvement): 1\n","2022-02-16 19:44:25,034 ----------------------------------------------------------------------------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"output_type":"stream","name":"stdout","text":["2022-02-16 19:44:26,489 epoch 15 - iter 1/19 - loss 0.83362103 - samples/sec: 191.35 - lr: 0.100000\n","2022-02-16 19:44:26,619 epoch 15 - iter 2/19 - loss 0.66702995 - samples/sec: 315.47 - lr: 0.100000\n","2022-02-16 19:44:26,723 epoch 15 - iter 3/19 - loss 0.75021118 - samples/sec: 381.24 - lr: 0.100000\n","2022-02-16 19:44:26,808 epoch 15 - iter 4/19 - loss 0.74638619 - samples/sec: 391.21 - lr: 0.100000\n","2022-02-16 19:44:26,894 epoch 15 - iter 5/19 - loss 0.72433672 - samples/sec: 388.57 - lr: 0.100000\n","2022-02-16 19:44:27,007 epoch 15 - iter 6/19 - loss 0.69065542 - samples/sec: 389.40 - lr: 0.100000\n","2022-02-16 19:44:27,104 epoch 15 - iter 7/19 - loss 0.69338908 - samples/sec: 351.70 - lr: 0.100000\n","2022-02-16 19:44:27,273 epoch 15 - iter 8/19 - loss 0.72407386 - samples/sec: 199.53 - lr: 0.100000\n","2022-02-16 19:44:27,560 epoch 15 - iter 9/19 - loss 0.70792390 - samples/sec: 160.91 - lr: 0.100000\n","2022-02-16 19:44:27,743 epoch 15 - iter 10/19 - loss 0.70071036 - samples/sec: 183.75 - lr: 0.100000\n","2022-02-16 19:44:27,938 epoch 15 - iter 11/19 - loss 0.69370668 - samples/sec: 169.80 - lr: 0.100000\n","2022-02-16 19:44:28,231 epoch 15 - iter 12/19 - loss 0.67639063 - samples/sec: 110.30 - lr: 0.100000\n","2022-02-16 19:44:28,523 epoch 15 - iter 13/19 - loss 0.68335373 - samples/sec: 123.24 - lr: 0.100000\n","2022-02-16 19:44:28,732 epoch 15 - iter 14/19 - loss 0.67166166 - samples/sec: 164.85 - lr: 0.100000\n","2022-02-16 19:44:28,939 epoch 15 - iter 15/19 - loss 0.66806675 - samples/sec: 198.77 - lr: 0.100000\n","2022-02-16 19:44:29,085 epoch 15 - iter 16/19 - loss 0.67756186 - samples/sec: 235.22 - lr: 0.100000\n","2022-02-16 19:44:29,264 epoch 15 - iter 17/19 - loss 0.68057557 - samples/sec: 183.63 - lr: 0.100000\n","2022-02-16 19:44:29,420 epoch 15 - iter 18/19 - loss 0.69036948 - samples/sec: 210.80 - lr: 0.100000\n","2022-02-16 19:44:29,510 epoch 15 - iter 19/19 - loss 0.68201439 - samples/sec: 403.28 - lr: 0.100000\n","2022-02-16 19:44:30,294 ----------------------------------------------------------------------------------------------------\n","2022-02-16 19:44:30,304 EPOCH 15 done: loss 0.6820 - lr 0.1000000\n","2022-02-16 19:44:34,001 DEV : loss 0.5597807765007019 - score 0.6154\n","2022-02-16 19:44:34,277 BAD EPOCHS (no improvement): 2\n","2022-02-16 19:44:34,297 ----------------------------------------------------------------------------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"output_type":"stream","name":"stdout","text":["2022-02-16 19:44:37,004 epoch 16 - iter 1/19 - loss 0.46254694 - samples/sec: 72.04 - lr: 0.100000\n","2022-02-16 19:44:37,204 epoch 16 - iter 2/19 - loss 0.57943371 - samples/sec: 194.60 - lr: 0.100000\n","2022-02-16 19:44:37,435 epoch 16 - iter 3/19 - loss 0.61986240 - samples/sec: 175.51 - lr: 0.100000\n","2022-02-16 19:44:37,796 epoch 16 - iter 4/19 - loss 0.68055354 - samples/sec: 91.62 - lr: 0.100000\n","2022-02-16 19:44:38,002 epoch 16 - iter 5/19 - loss 0.65876255 - samples/sec: 166.64 - lr: 0.100000\n","2022-02-16 19:44:38,284 epoch 16 - iter 6/19 - loss 0.67067870 - samples/sec: 143.31 - lr: 0.100000\n","2022-02-16 19:44:38,492 epoch 16 - iter 7/19 - loss 0.64717788 - samples/sec: 168.31 - lr: 0.100000\n","2022-02-16 19:44:38,729 epoch 16 - iter 8/19 - loss 0.64386648 - samples/sec: 140.14 - lr: 0.100000\n","2022-02-16 19:44:41,741 epoch 16 - iter 9/19 - loss 0.63367389 - samples/sec: 450.78 - lr: 0.100000\n","2022-02-16 19:44:41,806 epoch 16 - iter 10/19 - loss 0.62306665 - samples/sec: 517.27 - lr: 0.100000\n","2022-02-16 19:44:41,873 epoch 16 - iter 11/19 - loss 0.62921023 - samples/sec: 514.75 - lr: 0.100000\n","2022-02-16 19:44:41,960 epoch 16 - iter 12/19 - loss 0.62960738 - samples/sec: 386.38 - lr: 0.100000\n","2022-02-16 19:44:42,027 epoch 16 - iter 13/19 - loss 0.63530423 - samples/sec: 509.99 - lr: 0.100000\n","2022-02-16 19:44:42,108 epoch 16 - iter 14/19 - loss 0.64806362 - samples/sec: 491.26 - lr: 0.100000\n","2022-02-16 19:44:42,180 epoch 16 - iter 15/19 - loss 0.65831205 - samples/sec: 516.21 - lr: 0.100000\n","2022-02-16 19:44:42,255 epoch 16 - iter 16/19 - loss 0.65994547 - samples/sec: 459.09 - lr: 0.100000\n","2022-02-16 19:44:42,328 epoch 16 - iter 17/19 - loss 0.65193475 - samples/sec: 452.97 - lr: 0.100000\n","2022-02-16 19:44:42,405 epoch 16 - iter 18/19 - loss 0.67346533 - samples/sec: 427.16 - lr: 0.100000\n","2022-02-16 19:44:42,446 epoch 16 - iter 19/19 - loss 0.68883602 - samples/sec: 922.83 - lr: 0.100000\n","2022-02-16 19:44:42,911 ----------------------------------------------------------------------------------------------------\n","2022-02-16 19:44:42,917 EPOCH 16 done: loss 0.6888 - lr 0.1000000\n","2022-02-16 19:44:44,682 DEV : loss 0.549913227558136 - score 0.5538\n","2022-02-16 19:44:44,760 BAD EPOCHS (no improvement): 3\n","2022-02-16 19:44:44,770 ----------------------------------------------------------------------------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"output_type":"stream","name":"stdout","text":["2022-02-16 19:44:46,103 epoch 17 - iter 1/19 - loss 0.74234521 - samples/sec: 169.93 - lr: 0.100000\n","2022-02-16 19:44:46,217 epoch 17 - iter 2/19 - loss 0.65529376 - samples/sec: 346.06 - lr: 0.100000\n","2022-02-16 19:44:46,313 epoch 17 - iter 3/19 - loss 0.59645639 - samples/sec: 357.77 - lr: 0.100000\n","2022-02-16 19:44:46,423 epoch 17 - iter 4/19 - loss 0.56621395 - samples/sec: 302.60 - lr: 0.100000\n","2022-02-16 19:44:46,519 epoch 17 - iter 5/19 - loss 0.59192418 - samples/sec: 368.48 - lr: 0.100000\n","2022-02-16 19:44:46,652 epoch 17 - iter 6/19 - loss 0.60775004 - samples/sec: 373.84 - lr: 0.100000\n","2022-02-16 19:44:46,760 epoch 17 - iter 7/19 - loss 0.60918694 - samples/sec: 352.52 - lr: 0.100000\n","2022-02-16 19:44:46,844 epoch 17 - iter 8/19 - loss 0.60554566 - samples/sec: 391.16 - lr: 0.100000\n","2022-02-16 19:44:46,922 epoch 17 - iter 9/19 - loss 0.57719962 - samples/sec: 425.47 - lr: 0.100000\n","2022-02-16 19:44:47,019 epoch 17 - iter 10/19 - loss 0.59443145 - samples/sec: 357.25 - lr: 0.100000\n","2022-02-16 19:44:47,092 epoch 17 - iter 11/19 - loss 0.59661278 - samples/sec: 466.97 - lr: 0.100000\n","2022-02-16 19:44:47,172 epoch 17 - iter 12/19 - loss 0.59960103 - samples/sec: 411.34 - lr: 0.100000\n","2022-02-16 19:44:47,262 epoch 17 - iter 13/19 - loss 0.59994183 - samples/sec: 417.50 - lr: 0.100000\n","2022-02-16 19:44:47,341 epoch 17 - iter 14/19 - loss 0.61238816 - samples/sec: 420.37 - lr: 0.100000\n","2022-02-16 19:44:47,416 epoch 17 - iter 15/19 - loss 0.62363921 - samples/sec: 442.62 - lr: 0.100000\n","2022-02-16 19:44:47,490 epoch 17 - iter 16/19 - loss 0.62694878 - samples/sec: 450.85 - lr: 0.100000\n","2022-02-16 19:44:47,570 epoch 17 - iter 17/19 - loss 0.66481164 - samples/sec: 410.94 - lr: 0.100000\n","2022-02-16 19:44:47,638 epoch 17 - iter 18/19 - loss 0.66814616 - samples/sec: 487.25 - lr: 0.100000\n","2022-02-16 19:44:47,682 epoch 17 - iter 19/19 - loss 0.67999951 - samples/sec: 821.67 - lr: 0.100000\n","2022-02-16 19:44:48,092 ----------------------------------------------------------------------------------------------------\n","2022-02-16 19:44:48,100 EPOCH 17 done: loss 0.6800 - lr 0.1000000\n","2022-02-16 19:44:49,725 DEV : loss 0.5834924578666687 - score 0.6308\n","Epoch    17: reducing learning rate of group 0 to 5.0000e-02.\n","2022-02-16 19:44:49,800 BAD EPOCHS (no improvement): 4\n","2022-02-16 19:44:49,812 ----------------------------------------------------------------------------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"output_type":"stream","name":"stdout","text":["2022-02-16 19:44:51,113 epoch 18 - iter 1/19 - loss 0.83781117 - samples/sec: 107.86 - lr: 0.050000\n","2022-02-16 19:44:51,273 epoch 18 - iter 2/19 - loss 0.64156985 - samples/sec: 312.79 - lr: 0.050000\n","2022-02-16 19:44:51,386 epoch 18 - iter 3/19 - loss 0.66930960 - samples/sec: 339.42 - lr: 0.050000\n","2022-02-16 19:44:51,473 epoch 18 - iter 4/19 - loss 0.66215286 - samples/sec: 395.79 - lr: 0.050000\n","2022-02-16 19:44:51,562 epoch 18 - iter 5/19 - loss 0.65170054 - samples/sec: 387.17 - lr: 0.050000\n","2022-02-16 19:44:51,664 epoch 18 - iter 6/19 - loss 0.67880145 - samples/sec: 409.27 - lr: 0.050000\n","2022-02-16 19:44:51,743 epoch 18 - iter 7/19 - loss 0.67556282 - samples/sec: 440.23 - lr: 0.050000\n","2022-02-16 19:44:51,817 epoch 18 - iter 8/19 - loss 0.64541766 - samples/sec: 455.44 - lr: 0.050000\n","2022-02-16 19:44:51,899 epoch 18 - iter 9/19 - loss 0.64085392 - samples/sec: 504.29 - lr: 0.050000\n","2022-02-16 19:44:51,970 epoch 18 - iter 10/19 - loss 0.62628732 - samples/sec: 468.30 - lr: 0.050000\n","2022-02-16 19:44:52,041 epoch 18 - iter 11/19 - loss 0.61279255 - samples/sec: 473.36 - lr: 0.050000\n","2022-02-16 19:44:52,142 epoch 18 - iter 12/19 - loss 0.62436221 - samples/sec: 419.16 - lr: 0.050000\n","2022-02-16 19:44:52,213 epoch 18 - iter 13/19 - loss 0.62471238 - samples/sec: 467.21 - lr: 0.050000\n","2022-02-16 19:44:52,287 epoch 18 - iter 14/19 - loss 0.62862433 - samples/sec: 456.21 - lr: 0.050000\n","2022-02-16 19:44:52,366 epoch 18 - iter 15/19 - loss 0.63080739 - samples/sec: 504.20 - lr: 0.050000\n","2022-02-16 19:44:52,444 epoch 18 - iter 16/19 - loss 0.63434187 - samples/sec: 444.52 - lr: 0.050000\n","2022-02-16 19:44:52,520 epoch 18 - iter 17/19 - loss 0.62781302 - samples/sec: 453.97 - lr: 0.050000\n","2022-02-16 19:44:52,597 epoch 18 - iter 18/19 - loss 0.62813518 - samples/sec: 478.84 - lr: 0.050000\n","2022-02-16 19:44:52,645 epoch 18 - iter 19/19 - loss 0.66054059 - samples/sec: 840.16 - lr: 0.050000\n","2022-02-16 19:44:53,035 ----------------------------------------------------------------------------------------------------\n","2022-02-16 19:44:53,038 EPOCH 18 done: loss 0.6605 - lr 0.0500000\n","2022-02-16 19:44:54,583 DEV : loss 0.5070539712905884 - score 0.6308\n","2022-02-16 19:44:54,674 BAD EPOCHS (no improvement): 1\n","2022-02-16 19:44:54,684 ----------------------------------------------------------------------------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"output_type":"stream","name":"stdout","text":["2022-02-16 19:44:55,935 epoch 19 - iter 1/19 - loss 0.64510417 - samples/sec: 140.12 - lr: 0.050000\n","2022-02-16 19:44:56,065 epoch 19 - iter 2/19 - loss 0.60078472 - samples/sec: 321.53 - lr: 0.050000\n","2022-02-16 19:44:56,154 epoch 19 - iter 3/19 - loss 0.57765961 - samples/sec: 384.76 - lr: 0.050000\n","2022-02-16 19:44:56,253 epoch 19 - iter 4/19 - loss 0.61656950 - samples/sec: 364.55 - lr: 0.050000\n","2022-02-16 19:44:56,367 epoch 19 - iter 5/19 - loss 0.66715466 - samples/sec: 352.62 - lr: 0.050000\n","2022-02-16 19:44:56,463 epoch 19 - iter 6/19 - loss 0.64061337 - samples/sec: 415.83 - lr: 0.050000\n","2022-02-16 19:44:56,542 epoch 19 - iter 7/19 - loss 0.61232509 - samples/sec: 427.18 - lr: 0.050000\n","2022-02-16 19:44:56,617 epoch 19 - iter 8/19 - loss 0.59366920 - samples/sec: 458.58 - lr: 0.050000\n","2022-02-16 19:44:56,716 epoch 19 - iter 9/19 - loss 0.59612400 - samples/sec: 438.41 - lr: 0.050000\n","2022-02-16 19:44:56,793 epoch 19 - iter 10/19 - loss 0.60694135 - samples/sec: 427.63 - lr: 0.050000\n","2022-02-16 19:44:56,867 epoch 19 - iter 11/19 - loss 0.61253275 - samples/sec: 542.88 - lr: 0.050000\n","2022-02-16 19:44:56,939 epoch 19 - iter 12/19 - loss 0.61009459 - samples/sec: 452.26 - lr: 0.050000\n","2022-02-16 19:44:57,017 epoch 19 - iter 13/19 - loss 0.60716487 - samples/sec: 475.76 - lr: 0.050000\n","2022-02-16 19:44:57,089 epoch 19 - iter 14/19 - loss 0.60119629 - samples/sec: 480.54 - lr: 0.050000\n","2022-02-16 19:44:57,165 epoch 19 - iter 15/19 - loss 0.60892715 - samples/sec: 522.55 - lr: 0.050000\n","2022-02-16 19:44:57,234 epoch 19 - iter 16/19 - loss 0.61287127 - samples/sec: 497.72 - lr: 0.050000\n","2022-02-16 19:44:57,314 epoch 19 - iter 17/19 - loss 0.61832261 - samples/sec: 467.94 - lr: 0.050000\n","2022-02-16 19:44:57,404 epoch 19 - iter 18/19 - loss 0.61155072 - samples/sec: 363.20 - lr: 0.050000\n","2022-02-16 19:44:57,451 epoch 19 - iter 19/19 - loss 0.59843341 - samples/sec: 711.05 - lr: 0.050000\n","2022-02-16 19:44:57,827 ----------------------------------------------------------------------------------------------------\n","2022-02-16 19:44:57,830 EPOCH 19 done: loss 0.5984 - lr 0.0500000\n","2022-02-16 19:44:59,378 DEV : loss 0.48597466945648193 - score 0.6308\n","2022-02-16 19:44:59,457 BAD EPOCHS (no improvement): 2\n","2022-02-16 19:44:59,466 ----------------------------------------------------------------------------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"output_type":"stream","name":"stdout","text":["2022-02-16 19:45:00,707 epoch 20 - iter 1/19 - loss 0.70388174 - samples/sec: 140.36 - lr: 0.050000\n","2022-02-16 19:45:00,850 epoch 20 - iter 2/19 - loss 0.70403934 - samples/sec: 316.80 - lr: 0.050000\n","2022-02-16 19:45:00,933 epoch 20 - iter 3/19 - loss 0.64243706 - samples/sec: 408.06 - lr: 0.050000\n","2022-02-16 19:45:01,020 epoch 20 - iter 4/19 - loss 0.61539641 - samples/sec: 387.95 - lr: 0.050000\n","2022-02-16 19:45:01,118 epoch 20 - iter 5/19 - loss 0.61543401 - samples/sec: 430.43 - lr: 0.050000\n","2022-02-16 19:45:01,217 epoch 20 - iter 6/19 - loss 0.62781106 - samples/sec: 407.62 - lr: 0.050000\n","2022-02-16 19:45:01,298 epoch 20 - iter 7/19 - loss 0.60948368 - samples/sec: 409.60 - lr: 0.050000\n","2022-02-16 19:45:01,377 epoch 20 - iter 8/19 - loss 0.60446569 - samples/sec: 442.82 - lr: 0.050000\n","2022-02-16 19:45:01,476 epoch 20 - iter 9/19 - loss 0.59191321 - samples/sec: 421.79 - lr: 0.050000\n","2022-02-16 19:45:01,552 epoch 20 - iter 10/19 - loss 0.60358883 - samples/sec: 435.25 - lr: 0.050000\n","2022-02-16 19:45:01,627 epoch 20 - iter 11/19 - loss 0.60218856 - samples/sec: 445.97 - lr: 0.050000\n","2022-02-16 19:45:01,703 epoch 20 - iter 12/19 - loss 0.59826384 - samples/sec: 502.64 - lr: 0.050000\n","2022-02-16 19:45:01,782 epoch 20 - iter 13/19 - loss 0.59529997 - samples/sec: 421.38 - lr: 0.050000\n","2022-02-16 19:45:01,856 epoch 20 - iter 14/19 - loss 0.59009475 - samples/sec: 446.87 - lr: 0.050000\n","2022-02-16 19:45:01,935 epoch 20 - iter 15/19 - loss 0.60263649 - samples/sec: 511.65 - lr: 0.050000\n","2022-02-16 19:45:02,009 epoch 20 - iter 16/19 - loss 0.59835094 - samples/sec: 454.32 - lr: 0.050000\n","2022-02-16 19:45:02,081 epoch 20 - iter 17/19 - loss 0.60283762 - samples/sec: 482.03 - lr: 0.050000\n","2022-02-16 19:45:02,160 epoch 20 - iter 18/19 - loss 0.60261568 - samples/sec: 498.88 - lr: 0.050000\n","2022-02-16 19:45:02,197 epoch 20 - iter 19/19 - loss 0.60633808 - samples/sec: 896.46 - lr: 0.050000\n","2022-02-16 19:45:02,564 ----------------------------------------------------------------------------------------------------\n","2022-02-16 19:45:02,566 EPOCH 20 done: loss 0.6063 - lr 0.0500000\n","2022-02-16 19:45:04,145 DEV : loss 0.4741630554199219 - score 0.6308\n","2022-02-16 19:45:04,221 BAD EPOCHS (no improvement): 3\n","2022-02-16 19:45:04,230 ----------------------------------------------------------------------------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"output_type":"stream","name":"stdout","text":["2022-02-16 19:45:05,497 epoch 21 - iter 1/19 - loss 0.58849025 - samples/sec: 147.74 - lr: 0.050000\n","2022-02-16 19:45:05,606 epoch 21 - iter 2/19 - loss 0.60447687 - samples/sec: 348.17 - lr: 0.050000\n","2022-02-16 19:45:05,704 epoch 21 - iter 3/19 - loss 0.55529365 - samples/sec: 371.84 - lr: 0.050000\n","2022-02-16 19:45:05,791 epoch 21 - iter 4/19 - loss 0.53065623 - samples/sec: 386.54 - lr: 0.050000\n","2022-02-16 19:45:05,903 epoch 21 - iter 5/19 - loss 0.56589164 - samples/sec: 407.68 - lr: 0.050000\n","2022-02-16 19:45:06,007 epoch 21 - iter 6/19 - loss 0.56540780 - samples/sec: 389.32 - lr: 0.050000\n","2022-02-16 19:45:06,101 epoch 21 - iter 7/19 - loss 0.57957891 - samples/sec: 451.46 - lr: 0.050000\n","2022-02-16 19:45:06,184 epoch 21 - iter 8/19 - loss 0.55943616 - samples/sec: 399.62 - lr: 0.050000\n","2022-02-16 19:45:06,263 epoch 21 - iter 9/19 - loss 0.57012781 - samples/sec: 416.48 - lr: 0.050000\n","2022-02-16 19:45:06,336 epoch 21 - iter 10/19 - loss 0.57890857 - samples/sec: 462.07 - lr: 0.050000\n","2022-02-16 19:45:06,420 epoch 21 - iter 11/19 - loss 0.58903557 - samples/sec: 446.10 - lr: 0.050000\n","2022-02-16 19:45:06,508 epoch 21 - iter 12/19 - loss 0.59011725 - samples/sec: 454.96 - lr: 0.050000\n","2022-02-16 19:45:06,585 epoch 21 - iter 13/19 - loss 0.58145906 - samples/sec: 482.21 - lr: 0.050000\n","2022-02-16 19:45:06,663 epoch 21 - iter 14/19 - loss 0.57654330 - samples/sec: 434.90 - lr: 0.050000\n","2022-02-16 19:45:06,738 epoch 21 - iter 15/19 - loss 0.58518255 - samples/sec: 553.38 - lr: 0.050000\n","2022-02-16 19:45:06,812 epoch 21 - iter 16/19 - loss 0.59493036 - samples/sec: 450.05 - lr: 0.050000\n","2022-02-16 19:45:06,883 epoch 21 - iter 17/19 - loss 0.59942953 - samples/sec: 460.47 - lr: 0.050000\n","2022-02-16 19:45:06,968 epoch 21 - iter 18/19 - loss 0.60740733 - samples/sec: 458.05 - lr: 0.050000\n","2022-02-16 19:45:07,013 epoch 21 - iter 19/19 - loss 0.60160259 - samples/sec: 863.62 - lr: 0.050000\n","2022-02-16 19:45:07,379 ----------------------------------------------------------------------------------------------------\n","2022-02-16 19:45:07,387 EPOCH 21 done: loss 0.6016 - lr 0.0500000\n","2022-02-16 19:45:08,941 DEV : loss 0.5541121959686279 - score 0.5538\n","Epoch    21: reducing learning rate of group 0 to 2.5000e-02.\n","2022-02-16 19:45:09,017 BAD EPOCHS (no improvement): 4\n","2022-02-16 19:45:09,027 ----------------------------------------------------------------------------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"output_type":"stream","name":"stdout","text":["2022-02-16 19:45:10,239 epoch 22 - iter 1/19 - loss 0.71528322 - samples/sec: 150.62 - lr: 0.025000\n","2022-02-16 19:45:10,372 epoch 22 - iter 2/19 - loss 0.58766599 - samples/sec: 265.57 - lr: 0.025000\n","2022-02-16 19:45:10,460 epoch 22 - iter 3/19 - loss 0.61668896 - samples/sec: 431.88 - lr: 0.025000\n","2022-02-16 19:45:10,561 epoch 22 - iter 4/19 - loss 0.60080961 - samples/sec: 355.01 - lr: 0.025000\n","2022-02-16 19:45:10,662 epoch 22 - iter 5/19 - loss 0.58959252 - samples/sec: 416.26 - lr: 0.025000\n","2022-02-16 19:45:10,771 epoch 22 - iter 6/19 - loss 0.55990095 - samples/sec: 422.18 - lr: 0.025000\n","2022-02-16 19:45:10,851 epoch 22 - iter 7/19 - loss 0.55793322 - samples/sec: 441.51 - lr: 0.025000\n","2022-02-16 19:45:10,924 epoch 22 - iter 8/19 - loss 0.54667852 - samples/sec: 465.12 - lr: 0.025000\n","2022-02-16 19:45:10,998 epoch 22 - iter 9/19 - loss 0.53056219 - samples/sec: 445.13 - lr: 0.025000\n","2022-02-16 19:45:11,069 epoch 22 - iter 10/19 - loss 0.56550019 - samples/sec: 463.96 - lr: 0.025000\n","2022-02-16 19:45:11,140 epoch 22 - iter 11/19 - loss 0.57704976 - samples/sec: 480.67 - lr: 0.025000\n","2022-02-16 19:45:11,218 epoch 22 - iter 12/19 - loss 0.58468998 - samples/sec: 498.05 - lr: 0.025000\n","2022-02-16 19:45:11,289 epoch 22 - iter 13/19 - loss 0.57461220 - samples/sec: 470.70 - lr: 0.025000\n","2022-02-16 19:45:11,387 epoch 22 - iter 14/19 - loss 0.58006634 - samples/sec: 439.48 - lr: 0.025000\n","2022-02-16 19:45:11,459 epoch 22 - iter 15/19 - loss 0.57070297 - samples/sec: 496.68 - lr: 0.025000\n","2022-02-16 19:45:11,533 epoch 22 - iter 16/19 - loss 0.56464057 - samples/sec: 446.00 - lr: 0.025000\n","2022-02-16 19:45:11,612 epoch 22 - iter 17/19 - loss 0.57290705 - samples/sec: 463.77 - lr: 0.025000\n","2022-02-16 19:45:11,693 epoch 22 - iter 18/19 - loss 0.58550729 - samples/sec: 470.93 - lr: 0.025000\n","2022-02-16 19:45:11,739 epoch 22 - iter 19/19 - loss 0.57733134 - samples/sec: 854.95 - lr: 0.025000\n","2022-02-16 19:45:12,111 ----------------------------------------------------------------------------------------------------\n","2022-02-16 19:45:12,116 EPOCH 22 done: loss 0.5773 - lr 0.0250000\n","2022-02-16 19:45:13,634 DEV : loss 0.4988442659378052 - score 0.6462\n","2022-02-16 19:45:13,716 BAD EPOCHS (no improvement): 1\n","2022-02-16 19:45:13,736 ----------------------------------------------------------------------------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"output_type":"stream","name":"stdout","text":["2022-02-16 19:45:14,972 epoch 23 - iter 1/19 - loss 0.66805106 - samples/sec: 122.96 - lr: 0.025000\n","2022-02-16 19:45:15,088 epoch 23 - iter 2/19 - loss 0.54307093 - samples/sec: 338.69 - lr: 0.025000\n","2022-02-16 19:45:15,182 epoch 23 - iter 3/19 - loss 0.60178694 - samples/sec: 422.69 - lr: 0.025000\n","2022-02-16 19:45:15,263 epoch 23 - iter 4/19 - loss 0.54628878 - samples/sec: 406.32 - lr: 0.025000\n","2022-02-16 19:45:15,358 epoch 23 - iter 5/19 - loss 0.54191372 - samples/sec: 438.08 - lr: 0.025000\n","2022-02-16 19:45:17,196 epoch 23 - iter 6/19 - loss 0.55571215 - samples/sec: 368.27 - lr: 0.025000\n","2022-02-16 19:45:17,275 epoch 23 - iter 7/19 - loss 0.53271474 - samples/sec: 456.39 - lr: 0.025000\n","2022-02-16 19:45:17,350 epoch 23 - iter 8/19 - loss 0.51744125 - samples/sec: 447.20 - lr: 0.025000\n","2022-02-16 19:45:17,426 epoch 23 - iter 9/19 - loss 0.54430774 - samples/sec: 447.32 - lr: 0.025000\n","2022-02-16 19:45:17,496 epoch 23 - iter 10/19 - loss 0.55847103 - samples/sec: 512.08 - lr: 0.025000\n","2022-02-16 19:45:17,563 epoch 23 - iter 11/19 - loss 0.58392374 - samples/sec: 536.96 - lr: 0.025000\n","2022-02-16 19:45:17,649 epoch 23 - iter 12/19 - loss 0.58581208 - samples/sec: 402.94 - lr: 0.025000\n","2022-02-16 19:45:17,725 epoch 23 - iter 13/19 - loss 0.57108080 - samples/sec: 441.46 - lr: 0.025000\n","2022-02-16 19:45:17,798 epoch 23 - iter 14/19 - loss 0.56749382 - samples/sec: 456.39 - lr: 0.025000\n","2022-02-16 19:45:17,877 epoch 23 - iter 15/19 - loss 0.57471827 - samples/sec: 500.07 - lr: 0.025000\n","2022-02-16 19:45:17,949 epoch 23 - iter 16/19 - loss 0.59307427 - samples/sec: 460.75 - lr: 0.025000\n","2022-02-16 19:45:18,021 epoch 23 - iter 17/19 - loss 0.59662345 - samples/sec: 455.02 - lr: 0.025000\n","2022-02-16 19:45:18,095 epoch 23 - iter 18/19 - loss 0.59876837 - samples/sec: 512.01 - lr: 0.025000\n","2022-02-16 19:45:18,140 epoch 23 - iter 19/19 - loss 0.58988433 - samples/sec: 808.47 - lr: 0.025000\n","2022-02-16 19:45:18,540 ----------------------------------------------------------------------------------------------------\n","2022-02-16 19:45:18,547 EPOCH 23 done: loss 0.5899 - lr 0.0250000\n","2022-02-16 19:45:20,114 DEV : loss 0.45780307054519653 - score 0.6308\n","2022-02-16 19:45:20,190 BAD EPOCHS (no improvement): 2\n","2022-02-16 19:45:20,201 ----------------------------------------------------------------------------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"output_type":"stream","name":"stdout","text":["2022-02-16 19:45:21,428 epoch 24 - iter 1/19 - loss 0.79379106 - samples/sec: 139.94 - lr: 0.025000\n","2022-02-16 19:45:21,555 epoch 24 - iter 2/19 - loss 0.72153777 - samples/sec: 303.34 - lr: 0.025000\n","2022-02-16 19:45:21,658 epoch 24 - iter 3/19 - loss 0.62424553 - samples/sec: 349.90 - lr: 0.025000\n","2022-02-16 19:45:21,763 epoch 24 - iter 4/19 - loss 0.55084220 - samples/sec: 347.99 - lr: 0.025000\n","2022-02-16 19:45:21,887 epoch 24 - iter 5/19 - loss 0.54149412 - samples/sec: 374.38 - lr: 0.025000\n","2022-02-16 19:45:22,001 epoch 24 - iter 6/19 - loss 0.53549312 - samples/sec: 296.28 - lr: 0.025000\n","2022-02-16 19:45:22,081 epoch 24 - iter 7/19 - loss 0.53734937 - samples/sec: 430.64 - lr: 0.025000\n","2022-02-16 19:45:22,157 epoch 24 - iter 8/19 - loss 0.54361966 - samples/sec: 450.32 - lr: 0.025000\n","2022-02-16 19:45:22,238 epoch 24 - iter 9/19 - loss 0.56426991 - samples/sec: 424.93 - lr: 0.025000\n","2022-02-16 19:45:22,310 epoch 24 - iter 10/19 - loss 0.55756313 - samples/sec: 476.58 - lr: 0.025000\n","2022-02-16 19:45:22,424 epoch 24 - iter 11/19 - loss 0.55909074 - samples/sec: 433.96 - lr: 0.025000\n","2022-02-16 19:45:22,516 epoch 24 - iter 12/19 - loss 0.55750329 - samples/sec: 381.25 - lr: 0.025000\n","2022-02-16 19:45:22,591 epoch 24 - iter 13/19 - loss 0.55944570 - samples/sec: 445.35 - lr: 0.025000\n","2022-02-16 19:45:22,666 epoch 24 - iter 14/19 - loss 0.55663404 - samples/sec: 439.72 - lr: 0.025000\n","2022-02-16 19:45:22,741 epoch 24 - iter 15/19 - loss 0.54745815 - samples/sec: 472.67 - lr: 0.025000\n","2022-02-16 19:45:22,812 epoch 24 - iter 16/19 - loss 0.54684451 - samples/sec: 483.35 - lr: 0.025000\n","2022-02-16 19:45:22,894 epoch 24 - iter 17/19 - loss 0.55455143 - samples/sec: 427.05 - lr: 0.025000\n","2022-02-16 19:45:22,975 epoch 24 - iter 18/19 - loss 0.55236679 - samples/sec: 415.13 - lr: 0.025000\n","2022-02-16 19:45:23,028 epoch 24 - iter 19/19 - loss 0.57207523 - samples/sec: 633.87 - lr: 0.025000\n","2022-02-16 19:45:23,385 ----------------------------------------------------------------------------------------------------\n","2022-02-16 19:45:23,387 EPOCH 24 done: loss 0.5721 - lr 0.0250000\n","2022-02-16 19:45:24,907 DEV : loss 0.48881667852401733 - score 0.6154\n","2022-02-16 19:45:24,985 BAD EPOCHS (no improvement): 3\n","2022-02-16 19:45:24,994 ----------------------------------------------------------------------------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"output_type":"stream","name":"stdout","text":["2022-02-16 19:45:26,187 epoch 25 - iter 1/19 - loss 0.62131077 - samples/sec: 136.45 - lr: 0.025000\n","2022-02-16 19:45:26,333 epoch 25 - iter 2/19 - loss 0.53893860 - samples/sec: 281.80 - lr: 0.025000\n","2022-02-16 19:45:26,431 epoch 25 - iter 3/19 - loss 0.51364211 - samples/sec: 394.69 - lr: 0.025000\n","2022-02-16 19:45:26,528 epoch 25 - iter 4/19 - loss 0.47935613 - samples/sec: 364.26 - lr: 0.025000\n","2022-02-16 19:45:26,633 epoch 25 - iter 5/19 - loss 0.52308127 - samples/sec: 404.14 - lr: 0.025000\n","2022-02-16 19:45:26,736 epoch 25 - iter 6/19 - loss 0.54817605 - samples/sec: 378.97 - lr: 0.025000\n","2022-02-16 19:45:26,816 epoch 25 - iter 7/19 - loss 0.54573283 - samples/sec: 410.27 - lr: 0.025000\n","2022-02-16 19:45:26,891 epoch 25 - iter 8/19 - loss 0.56435173 - samples/sec: 444.14 - lr: 0.025000\n","2022-02-16 19:45:26,986 epoch 25 - iter 9/19 - loss 0.56458739 - samples/sec: 403.70 - lr: 0.025000\n","2022-02-16 19:45:27,056 epoch 25 - iter 10/19 - loss 0.57301278 - samples/sec: 502.91 - lr: 0.025000\n","2022-02-16 19:45:27,139 epoch 25 - iter 11/19 - loss 0.56282026 - samples/sec: 511.05 - lr: 0.025000\n","2022-02-16 19:45:27,219 epoch 25 - iter 12/19 - loss 0.56419402 - samples/sec: 498.46 - lr: 0.025000\n","2022-02-16 19:45:27,301 epoch 25 - iter 13/19 - loss 0.56242365 - samples/sec: 420.64 - lr: 0.025000\n","2022-02-16 19:45:27,375 epoch 25 - iter 14/19 - loss 0.57357890 - samples/sec: 452.80 - lr: 0.025000\n","2022-02-16 19:45:27,461 epoch 25 - iter 15/19 - loss 0.56903966 - samples/sec: 477.64 - lr: 0.025000\n","2022-02-16 19:45:27,545 epoch 25 - iter 16/19 - loss 0.56339911 - samples/sec: 398.83 - lr: 0.025000\n","2022-02-16 19:45:27,618 epoch 25 - iter 17/19 - loss 0.55922918 - samples/sec: 455.64 - lr: 0.025000\n","2022-02-16 19:45:27,701 epoch 25 - iter 18/19 - loss 0.55081764 - samples/sec: 403.03 - lr: 0.025000\n","2022-02-16 19:45:27,746 epoch 25 - iter 19/19 - loss 0.55740643 - samples/sec: 802.74 - lr: 0.025000\n","2022-02-16 19:45:28,102 ----------------------------------------------------------------------------------------------------\n","2022-02-16 19:45:28,107 EPOCH 25 done: loss 0.5574 - lr 0.0250000\n","2022-02-16 19:45:29,645 DEV : loss 0.478870689868927 - score 0.6923\n","2022-02-16 19:45:29,728 BAD EPOCHS (no improvement): 0\n","saving best model\n","2022-02-16 19:45:45,661 ----------------------------------------------------------------------------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"output_type":"stream","name":"stdout","text":["2022-02-16 19:45:47,276 epoch 26 - iter 1/19 - loss 0.50959593 - samples/sec: 148.36 - lr: 0.025000\n","2022-02-16 19:45:47,371 epoch 26 - iter 2/19 - loss 0.58123693 - samples/sec: 363.06 - lr: 0.025000\n","2022-02-16 19:45:47,463 epoch 26 - iter 3/19 - loss 0.57630964 - samples/sec: 426.73 - lr: 0.025000\n","2022-02-16 19:45:47,564 epoch 26 - iter 4/19 - loss 0.53945547 - samples/sec: 397.33 - lr: 0.025000\n","2022-02-16 19:45:47,675 epoch 26 - iter 5/19 - loss 0.53754920 - samples/sec: 439.21 - lr: 0.025000\n","2022-02-16 19:45:47,766 epoch 26 - iter 6/19 - loss 0.55070171 - samples/sec: 361.86 - lr: 0.025000\n","2022-02-16 19:45:47,847 epoch 26 - iter 7/19 - loss 0.57542247 - samples/sec: 428.56 - lr: 0.025000\n","2022-02-16 19:45:47,946 epoch 26 - iter 8/19 - loss 0.55769919 - samples/sec: 331.85 - lr: 0.025000\n","2022-02-16 19:45:48,016 epoch 26 - iter 9/19 - loss 0.55529768 - samples/sec: 495.83 - lr: 0.025000\n","2022-02-16 19:45:48,097 epoch 26 - iter 10/19 - loss 0.54814468 - samples/sec: 405.15 - lr: 0.025000\n","2022-02-16 19:45:48,178 epoch 26 - iter 11/19 - loss 0.54538855 - samples/sec: 457.38 - lr: 0.025000\n","2022-02-16 19:45:48,268 epoch 26 - iter 12/19 - loss 0.54057593 - samples/sec: 487.86 - lr: 0.025000\n","2022-02-16 19:45:48,344 epoch 26 - iter 13/19 - loss 0.54735807 - samples/sec: 450.31 - lr: 0.025000\n","2022-02-16 19:45:48,428 epoch 26 - iter 14/19 - loss 0.55486063 - samples/sec: 413.49 - lr: 0.025000\n","2022-02-16 19:45:48,501 epoch 26 - iter 15/19 - loss 0.55442623 - samples/sec: 489.92 - lr: 0.025000\n","2022-02-16 19:45:48,573 epoch 26 - iter 16/19 - loss 0.56606113 - samples/sec: 540.93 - lr: 0.025000\n","2022-02-16 19:45:48,652 epoch 26 - iter 17/19 - loss 0.56469317 - samples/sec: 465.19 - lr: 0.025000\n","2022-02-16 19:45:48,729 epoch 26 - iter 18/19 - loss 0.55895572 - samples/sec: 490.56 - lr: 0.025000\n","2022-02-16 19:45:48,769 epoch 26 - iter 19/19 - loss 0.55230843 - samples/sec: 936.93 - lr: 0.025000\n","2022-02-16 19:45:49,303 ----------------------------------------------------------------------------------------------------\n","2022-02-16 19:45:49,310 EPOCH 26 done: loss 0.5523 - lr 0.0250000\n","2022-02-16 19:45:51,209 DEV : loss 0.4650909900665283 - score 0.7077\n","2022-02-16 19:45:51,294 BAD EPOCHS (no improvement): 0\n","saving best model\n","2022-02-16 19:46:06,572 ----------------------------------------------------------------------------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"output_type":"stream","name":"stdout","text":["2022-02-16 19:46:08,374 epoch 27 - iter 1/19 - loss 0.51884824 - samples/sec: 146.52 - lr: 0.025000\n","2022-02-16 19:46:08,491 epoch 27 - iter 2/19 - loss 0.49360396 - samples/sec: 379.42 - lr: 0.025000\n","2022-02-16 19:46:08,582 epoch 27 - iter 3/19 - loss 0.55840126 - samples/sec: 387.94 - lr: 0.025000\n","2022-02-16 19:46:08,691 epoch 27 - iter 4/19 - loss 0.54125699 - samples/sec: 342.31 - lr: 0.025000\n","2022-02-16 19:46:08,775 epoch 27 - iter 5/19 - loss 0.58305899 - samples/sec: 396.23 - lr: 0.025000\n","2022-02-16 19:46:08,897 epoch 27 - iter 6/19 - loss 0.59499295 - samples/sec: 412.88 - lr: 0.025000\n","2022-02-16 19:46:08,982 epoch 27 - iter 7/19 - loss 0.58570596 - samples/sec: 393.28 - lr: 0.025000\n","2022-02-16 19:46:09,056 epoch 27 - iter 8/19 - loss 0.56005076 - samples/sec: 499.92 - lr: 0.025000\n","2022-02-16 19:46:09,127 epoch 27 - iter 9/19 - loss 0.55310469 - samples/sec: 466.26 - lr: 0.025000\n","2022-02-16 19:46:09,202 epoch 27 - iter 10/19 - loss 0.54184858 - samples/sec: 473.12 - lr: 0.025000\n","2022-02-16 19:46:09,306 epoch 27 - iter 11/19 - loss 0.53943095 - samples/sec: 461.79 - lr: 0.025000\n","2022-02-16 19:46:09,380 epoch 27 - iter 12/19 - loss 0.55252947 - samples/sec: 479.57 - lr: 0.025000\n","2022-02-16 19:46:09,459 epoch 27 - iter 13/19 - loss 0.53879634 - samples/sec: 418.84 - lr: 0.025000\n","2022-02-16 19:46:09,535 epoch 27 - iter 14/19 - loss 0.54536977 - samples/sec: 462.94 - lr: 0.025000\n","2022-02-16 19:46:09,609 epoch 27 - iter 15/19 - loss 0.54943165 - samples/sec: 471.20 - lr: 0.025000\n","2022-02-16 19:46:09,710 epoch 27 - iter 16/19 - loss 0.55646680 - samples/sec: 322.76 - lr: 0.025000\n","2022-02-16 19:46:09,787 epoch 27 - iter 17/19 - loss 0.56009947 - samples/sec: 502.26 - lr: 0.025000\n","2022-02-16 19:46:09,860 epoch 27 - iter 18/19 - loss 0.56067563 - samples/sec: 456.00 - lr: 0.025000\n","2022-02-16 19:46:09,903 epoch 27 - iter 19/19 - loss 0.55324492 - samples/sec: 787.77 - lr: 0.025000\n","2022-02-16 19:46:10,375 ----------------------------------------------------------------------------------------------------\n","2022-02-16 19:46:10,380 EPOCH 27 done: loss 0.5532 - lr 0.0250000\n","2022-02-16 19:46:12,272 DEV : loss 0.4946536719799042 - score 0.6615\n","2022-02-16 19:46:12,349 BAD EPOCHS (no improvement): 1\n","2022-02-16 19:46:12,360 ----------------------------------------------------------------------------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"output_type":"stream","name":"stdout","text":["2022-02-16 19:46:14,246 epoch 28 - iter 1/19 - loss 0.73590994 - samples/sec: 43.83 - lr: 0.025000\n","2022-02-16 19:46:14,661 epoch 28 - iter 2/19 - loss 0.59985410 - samples/sec: 126.16 - lr: 0.025000\n","2022-02-16 19:46:14,925 epoch 28 - iter 3/19 - loss 0.64131688 - samples/sec: 123.76 - lr: 0.025000\n","2022-02-16 19:46:15,204 epoch 28 - iter 4/19 - loss 0.61781878 - samples/sec: 123.72 - lr: 0.025000\n","2022-02-16 19:46:15,399 epoch 28 - iter 5/19 - loss 0.56133364 - samples/sec: 174.85 - lr: 0.025000\n","2022-02-16 19:46:15,697 epoch 28 - iter 6/19 - loss 0.58266170 - samples/sec: 134.84 - lr: 0.025000\n","2022-02-16 19:46:15,853 epoch 28 - iter 7/19 - loss 0.58310569 - samples/sec: 219.48 - lr: 0.025000\n","2022-02-16 19:46:16,026 epoch 28 - iter 8/19 - loss 0.54958861 - samples/sec: 199.94 - lr: 0.025000\n","2022-02-16 19:46:16,297 epoch 28 - iter 9/19 - loss 0.55078384 - samples/sec: 123.95 - lr: 0.025000\n","2022-02-16 19:46:16,500 epoch 28 - iter 10/19 - loss 0.54196545 - samples/sec: 169.03 - lr: 0.025000\n","2022-02-16 19:46:16,687 epoch 28 - iter 11/19 - loss 0.53297014 - samples/sec: 177.45 - lr: 0.025000\n","2022-02-16 19:46:16,936 epoch 28 - iter 12/19 - loss 0.53129667 - samples/sec: 177.15 - lr: 0.025000\n","2022-02-16 19:46:17,115 epoch 28 - iter 13/19 - loss 0.53081377 - samples/sec: 199.58 - lr: 0.025000\n","2022-02-16 19:46:17,405 epoch 28 - iter 14/19 - loss 0.53394107 - samples/sec: 113.17 - lr: 0.025000\n","2022-02-16 19:46:17,657 epoch 28 - iter 15/19 - loss 0.53135550 - samples/sec: 129.26 - lr: 0.025000\n","2022-02-16 19:46:17,811 epoch 28 - iter 16/19 - loss 0.54154054 - samples/sec: 211.90 - lr: 0.025000\n","2022-02-16 19:46:17,983 epoch 28 - iter 17/19 - loss 0.56652993 - samples/sec: 191.10 - lr: 0.025000\n","2022-02-16 19:46:18,256 epoch 28 - iter 18/19 - loss 0.56275423 - samples/sec: 131.61 - lr: 0.025000\n","2022-02-16 19:46:18,351 epoch 28 - iter 19/19 - loss 0.55294953 - samples/sec: 347.87 - lr: 0.025000\n","2022-02-16 19:46:19,078 ----------------------------------------------------------------------------------------------------\n","2022-02-16 19:46:19,102 EPOCH 28 done: loss 0.5529 - lr 0.0250000\n","2022-02-16 19:46:22,908 DEV : loss 0.4510049819946289 - score 0.6615\n","2022-02-16 19:46:23,124 BAD EPOCHS (no improvement): 2\n","2022-02-16 19:46:23,136 ----------------------------------------------------------------------------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"output_type":"stream","name":"stdout","text":["2022-02-16 19:46:26,218 epoch 29 - iter 1/19 - loss 0.62244606 - samples/sec: 79.25 - lr: 0.025000\n","2022-02-16 19:46:26,483 epoch 29 - iter 2/19 - loss 0.57288623 - samples/sec: 151.05 - lr: 0.025000\n","2022-02-16 19:46:26,670 epoch 29 - iter 3/19 - loss 0.53320385 - samples/sec: 202.58 - lr: 0.025000\n","2022-02-16 19:46:26,865 epoch 29 - iter 4/19 - loss 0.56288183 - samples/sec: 175.65 - lr: 0.025000\n","2022-02-16 19:46:27,038 epoch 29 - iter 5/19 - loss 0.61755072 - samples/sec: 197.98 - lr: 0.025000\n","2022-02-16 19:46:27,147 epoch 29 - iter 6/19 - loss 0.62657992 - samples/sec: 417.31 - lr: 0.025000\n","2022-02-16 19:46:27,249 epoch 29 - iter 7/19 - loss 0.61753850 - samples/sec: 417.32 - lr: 0.025000\n","2022-02-16 19:46:27,325 epoch 29 - iter 8/19 - loss 0.58760135 - samples/sec: 435.60 - lr: 0.025000\n","2022-02-16 19:46:27,402 epoch 29 - iter 9/19 - loss 0.57557045 - samples/sec: 433.42 - lr: 0.025000\n","2022-02-16 19:46:27,475 epoch 29 - iter 10/19 - loss 0.57483823 - samples/sec: 450.99 - lr: 0.025000\n","2022-02-16 19:46:27,552 epoch 29 - iter 11/19 - loss 0.55505180 - samples/sec: 449.02 - lr: 0.025000\n","2022-02-16 19:46:27,627 epoch 29 - iter 12/19 - loss 0.56221777 - samples/sec: 522.31 - lr: 0.025000\n","2022-02-16 19:46:27,715 epoch 29 - iter 13/19 - loss 0.59130377 - samples/sec: 458.72 - lr: 0.025000\n","2022-02-16 19:46:27,793 epoch 29 - iter 14/19 - loss 0.58005831 - samples/sec: 464.10 - lr: 0.025000\n","2022-02-16 19:46:27,874 epoch 29 - iter 15/19 - loss 0.56434052 - samples/sec: 426.94 - lr: 0.025000\n","2022-02-16 19:46:27,948 epoch 29 - iter 16/19 - loss 0.57158668 - samples/sec: 451.20 - lr: 0.025000\n","2022-02-16 19:46:28,030 epoch 29 - iter 17/19 - loss 0.56547083 - samples/sec: 398.81 - lr: 0.025000\n","2022-02-16 19:46:28,108 epoch 29 - iter 18/19 - loss 0.55475361 - samples/sec: 442.97 - lr: 0.025000\n","2022-02-16 19:46:28,160 epoch 29 - iter 19/19 - loss 0.54899931 - samples/sec: 741.92 - lr: 0.025000\n","2022-02-16 19:46:28,597 ----------------------------------------------------------------------------------------------------\n","2022-02-16 19:46:28,604 EPOCH 29 done: loss 0.5490 - lr 0.0250000\n","2022-02-16 19:46:30,346 DEV : loss 0.454130619764328 - score 0.6615\n","2022-02-16 19:46:30,422 BAD EPOCHS (no improvement): 3\n","2022-02-16 19:46:30,432 ----------------------------------------------------------------------------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"output_type":"stream","name":"stdout","text":["2022-02-16 19:46:31,766 epoch 30 - iter 1/19 - loss 0.78247714 - samples/sec: 182.52 - lr: 0.025000\n","2022-02-16 19:46:31,865 epoch 30 - iter 2/19 - loss 0.61543797 - samples/sec: 406.94 - lr: 0.025000\n","2022-02-16 19:46:31,953 epoch 30 - iter 3/19 - loss 0.67193978 - samples/sec: 374.77 - lr: 0.025000\n","2022-02-16 19:46:32,035 epoch 30 - iter 4/19 - loss 0.66204771 - samples/sec: 407.09 - lr: 0.025000\n","2022-02-16 19:46:32,123 epoch 30 - iter 5/19 - loss 0.63926453 - samples/sec: 392.54 - lr: 0.025000\n","2022-02-16 19:46:32,237 epoch 30 - iter 6/19 - loss 0.60583293 - samples/sec: 440.02 - lr: 0.025000\n","2022-02-16 19:46:32,324 epoch 30 - iter 7/19 - loss 0.59198668 - samples/sec: 415.30 - lr: 0.025000\n","2022-02-16 19:46:34,065 epoch 30 - iter 8/19 - loss 0.58458836 - samples/sec: 478.58 - lr: 0.025000\n","2022-02-16 19:46:34,139 epoch 30 - iter 9/19 - loss 0.57470289 - samples/sec: 471.02 - lr: 0.025000\n","2022-02-16 19:46:34,209 epoch 30 - iter 10/19 - loss 0.56049385 - samples/sec: 480.64 - lr: 0.025000\n","2022-02-16 19:46:34,287 epoch 30 - iter 11/19 - loss 0.57669222 - samples/sec: 421.45 - lr: 0.025000\n","2022-02-16 19:46:34,368 epoch 30 - iter 12/19 - loss 0.57177522 - samples/sec: 497.82 - lr: 0.025000\n","2022-02-16 19:46:34,446 epoch 30 - iter 13/19 - loss 0.58352308 - samples/sec: 429.55 - lr: 0.025000\n","2022-02-16 19:46:34,515 epoch 30 - iter 14/19 - loss 0.58487221 - samples/sec: 482.07 - lr: 0.025000\n","2022-02-16 19:46:34,586 epoch 30 - iter 15/19 - loss 0.59688055 - samples/sec: 463.38 - lr: 0.025000\n","2022-02-16 19:46:34,669 epoch 30 - iter 16/19 - loss 0.59715545 - samples/sec: 399.14 - lr: 0.025000\n","2022-02-16 19:46:34,736 epoch 30 - iter 17/19 - loss 0.59524956 - samples/sec: 494.75 - lr: 0.025000\n","2022-02-16 19:46:34,804 epoch 30 - iter 18/19 - loss 0.58952551 - samples/sec: 522.92 - lr: 0.025000\n","2022-02-16 19:46:34,852 epoch 30 - iter 19/19 - loss 0.58513200 - samples/sec: 695.14 - lr: 0.025000\n","2022-02-16 19:46:35,313 ----------------------------------------------------------------------------------------------------\n","2022-02-16 19:46:35,319 EPOCH 30 done: loss 0.5851 - lr 0.0250000\n","2022-02-16 19:46:37,028 DEV : loss 0.4586939811706543 - score 0.6462\n","Epoch    30: reducing learning rate of group 0 to 1.2500e-02.\n","2022-02-16 19:46:37,104 BAD EPOCHS (no improvement): 4\n","2022-02-16 19:46:37,114 ----------------------------------------------------------------------------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"output_type":"stream","name":"stdout","text":["2022-02-16 19:46:38,449 epoch 31 - iter 1/19 - loss 0.60262972 - samples/sec: 124.69 - lr: 0.012500\n","2022-02-16 19:46:38,578 epoch 31 - iter 2/19 - loss 0.61807451 - samples/sec: 331.80 - lr: 0.012500\n","2022-02-16 19:46:38,700 epoch 31 - iter 3/19 - loss 0.66111231 - samples/sec: 294.25 - lr: 0.012500\n","2022-02-16 19:46:38,802 epoch 31 - iter 4/19 - loss 0.61214545 - samples/sec: 392.91 - lr: 0.012500\n","2022-02-16 19:46:38,891 epoch 31 - iter 5/19 - loss 0.57946833 - samples/sec: 412.05 - lr: 0.012500\n","2022-02-16 19:46:39,008 epoch 31 - iter 6/19 - loss 0.54536716 - samples/sec: 362.99 - lr: 0.012500\n","2022-02-16 19:46:39,090 epoch 31 - iter 7/19 - loss 0.52030148 - samples/sec: 408.83 - lr: 0.012500\n","2022-02-16 19:46:39,185 epoch 31 - iter 8/19 - loss 0.51365518 - samples/sec: 350.92 - lr: 0.012500\n","2022-02-16 19:46:39,267 epoch 31 - iter 9/19 - loss 0.52302063 - samples/sec: 408.34 - lr: 0.012500\n","2022-02-16 19:46:39,392 epoch 31 - iter 10/19 - loss 0.51419729 - samples/sec: 435.76 - lr: 0.012500\n","2022-02-16 19:46:39,468 epoch 31 - iter 11/19 - loss 0.52934993 - samples/sec: 440.40 - lr: 0.012500\n","2022-02-16 19:46:39,541 epoch 31 - iter 12/19 - loss 0.53449327 - samples/sec: 454.37 - lr: 0.012500\n","2022-02-16 19:46:39,625 epoch 31 - iter 13/19 - loss 0.54237968 - samples/sec: 393.32 - lr: 0.012500\n","2022-02-16 19:46:39,725 epoch 31 - iter 14/19 - loss 0.54885207 - samples/sec: 326.91 - lr: 0.012500\n","2022-02-16 19:46:39,795 epoch 31 - iter 15/19 - loss 0.55573673 - samples/sec: 494.30 - lr: 0.012500\n","2022-02-16 19:46:39,878 epoch 31 - iter 16/19 - loss 0.55364161 - samples/sec: 488.42 - lr: 0.012500\n","2022-02-16 19:46:39,951 epoch 31 - iter 17/19 - loss 0.54773628 - samples/sec: 475.75 - lr: 0.012500\n","2022-02-16 19:46:40,012 epoch 31 - iter 18/19 - loss 0.54424199 - samples/sec: 536.63 - lr: 0.012500\n","2022-02-16 19:46:40,055 epoch 31 - iter 19/19 - loss 0.54033245 - samples/sec: 870.42 - lr: 0.012500\n","2022-02-16 19:46:40,451 ----------------------------------------------------------------------------------------------------\n","2022-02-16 19:46:40,456 EPOCH 31 done: loss 0.5403 - lr 0.0125000\n","2022-02-16 19:46:42,094 DEV : loss 0.4525681138038635 - score 0.6462\n","2022-02-16 19:46:42,173 BAD EPOCHS (no improvement): 1\n","2022-02-16 19:46:42,183 ----------------------------------------------------------------------------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"output_type":"stream","name":"stdout","text":["2022-02-16 19:46:43,613 epoch 32 - iter 1/19 - loss 0.67376232 - samples/sec: 90.11 - lr: 0.012500\n","2022-02-16 19:46:43,758 epoch 32 - iter 2/19 - loss 0.68871674 - samples/sec: 312.03 - lr: 0.012500\n","2022-02-16 19:46:43,848 epoch 32 - iter 3/19 - loss 0.66216685 - samples/sec: 398.60 - lr: 0.012500\n","2022-02-16 19:46:43,947 epoch 32 - iter 4/19 - loss 0.65504342 - samples/sec: 383.73 - lr: 0.012500\n","2022-02-16 19:46:44,102 epoch 32 - iter 5/19 - loss 0.65130200 - samples/sec: 317.87 - lr: 0.012500\n","2022-02-16 19:46:44,200 epoch 32 - iter 6/19 - loss 0.60760225 - samples/sec: 343.66 - lr: 0.012500\n","2022-02-16 19:46:44,279 epoch 32 - iter 7/19 - loss 0.60022905 - samples/sec: 477.87 - lr: 0.012500\n","2022-02-16 19:46:44,353 epoch 32 - iter 8/19 - loss 0.58699878 - samples/sec: 446.93 - lr: 0.012500\n","2022-02-16 19:46:44,431 epoch 32 - iter 9/19 - loss 0.57060601 - samples/sec: 427.63 - lr: 0.012500\n","2022-02-16 19:46:44,503 epoch 32 - iter 10/19 - loss 0.56790549 - samples/sec: 461.30 - lr: 0.012500\n","2022-02-16 19:46:44,584 epoch 32 - iter 11/19 - loss 0.54948326 - samples/sec: 492.24 - lr: 0.012500\n","2022-02-16 19:46:44,662 epoch 32 - iter 12/19 - loss 0.57153373 - samples/sec: 439.38 - lr: 0.012500\n","2022-02-16 19:46:44,732 epoch 32 - iter 13/19 - loss 0.57458602 - samples/sec: 496.43 - lr: 0.012500\n","2022-02-16 19:46:44,798 epoch 32 - iter 14/19 - loss 0.57393978 - samples/sec: 505.32 - lr: 0.012500\n","2022-02-16 19:46:44,870 epoch 32 - iter 15/19 - loss 0.57334842 - samples/sec: 460.30 - lr: 0.012500\n","2022-02-16 19:46:44,945 epoch 32 - iter 16/19 - loss 0.57046769 - samples/sec: 439.04 - lr: 0.012500\n","2022-02-16 19:46:45,026 epoch 32 - iter 17/19 - loss 0.56086780 - samples/sec: 467.72 - lr: 0.012500\n","2022-02-16 19:46:45,103 epoch 32 - iter 18/19 - loss 0.54972442 - samples/sec: 486.36 - lr: 0.012500\n","2022-02-16 19:46:45,156 epoch 32 - iter 19/19 - loss 0.54272598 - samples/sec: 653.75 - lr: 0.012500\n","2022-02-16 19:46:45,531 ----------------------------------------------------------------------------------------------------\n","2022-02-16 19:46:45,538 EPOCH 32 done: loss 0.5427 - lr 0.0125000\n","2022-02-16 19:46:47,148 DEV : loss 0.46014851331710815 - score 0.6462\n","2022-02-16 19:46:47,228 BAD EPOCHS (no improvement): 2\n","2022-02-16 19:46:47,239 ----------------------------------------------------------------------------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"output_type":"stream","name":"stdout","text":["2022-02-16 19:46:48,561 epoch 33 - iter 1/19 - loss 0.64412886 - samples/sec: 113.12 - lr: 0.012500\n","2022-02-16 19:46:48,680 epoch 33 - iter 2/19 - loss 0.60211265 - samples/sec: 336.51 - lr: 0.012500\n","2022-02-16 19:46:48,823 epoch 33 - iter 3/19 - loss 0.59538740 - samples/sec: 387.24 - lr: 0.012500\n","2022-02-16 19:46:48,915 epoch 33 - iter 4/19 - loss 0.62039816 - samples/sec: 385.91 - lr: 0.012500\n","2022-02-16 19:46:49,002 epoch 33 - iter 5/19 - loss 0.61487304 - samples/sec: 398.42 - lr: 0.012500\n","2022-02-16 19:46:49,089 epoch 33 - iter 6/19 - loss 0.59477861 - samples/sec: 394.99 - lr: 0.012500\n","2022-02-16 19:46:49,170 epoch 33 - iter 7/19 - loss 0.60249843 - samples/sec: 415.23 - lr: 0.012500\n","2022-02-16 19:46:49,243 epoch 33 - iter 8/19 - loss 0.59552851 - samples/sec: 481.93 - lr: 0.012500\n","2022-02-16 19:46:49,318 epoch 33 - iter 9/19 - loss 0.57416181 - samples/sec: 523.09 - lr: 0.012500\n","2022-02-16 19:46:49,397 epoch 33 - iter 10/19 - loss 0.55493332 - samples/sec: 415.13 - lr: 0.012500\n","2022-02-16 19:46:49,468 epoch 33 - iter 11/19 - loss 0.55504403 - samples/sec: 465.09 - lr: 0.012500\n","2022-02-16 19:46:49,543 epoch 33 - iter 12/19 - loss 0.53899723 - samples/sec: 440.58 - lr: 0.012500\n","2022-02-16 19:46:49,631 epoch 33 - iter 13/19 - loss 0.52701785 - samples/sec: 382.52 - lr: 0.012500\n","2022-02-16 19:46:49,707 epoch 33 - iter 14/19 - loss 0.53296658 - samples/sec: 438.31 - lr: 0.012500\n","2022-02-16 19:46:49,784 epoch 33 - iter 15/19 - loss 0.52272156 - samples/sec: 515.24 - lr: 0.012500\n","2022-02-16 19:46:49,864 epoch 33 - iter 16/19 - loss 0.52340112 - samples/sec: 466.45 - lr: 0.012500\n","2022-02-16 19:46:49,939 epoch 33 - iter 17/19 - loss 0.52158640 - samples/sec: 510.47 - lr: 0.012500\n","2022-02-16 19:46:50,011 epoch 33 - iter 18/19 - loss 0.53121535 - samples/sec: 532.96 - lr: 0.012500\n","2022-02-16 19:46:50,054 epoch 33 - iter 19/19 - loss 0.52754208 - samples/sec: 872.88 - lr: 0.012500\n","2022-02-16 19:46:50,421 ----------------------------------------------------------------------------------------------------\n","2022-02-16 19:46:50,423 EPOCH 33 done: loss 0.5275 - lr 0.0125000\n","2022-02-16 19:46:51,981 DEV : loss 0.4439447820186615 - score 0.6769\n","2022-02-16 19:46:52,057 BAD EPOCHS (no improvement): 3\n","2022-02-16 19:46:52,068 ----------------------------------------------------------------------------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"output_type":"stream","name":"stdout","text":["2022-02-16 19:46:53,387 epoch 34 - iter 1/19 - loss 0.70489234 - samples/sec: 197.99 - lr: 0.012500\n","2022-02-16 19:46:53,504 epoch 34 - iter 2/19 - loss 0.61308265 - samples/sec: 306.72 - lr: 0.012500\n","2022-02-16 19:46:53,601 epoch 34 - iter 3/19 - loss 0.56997941 - samples/sec: 406.60 - lr: 0.012500\n","2022-02-16 19:46:53,704 epoch 34 - iter 4/19 - loss 0.59230654 - samples/sec: 322.36 - lr: 0.012500\n","2022-02-16 19:46:53,794 epoch 34 - iter 5/19 - loss 0.60525087 - samples/sec: 372.25 - lr: 0.012500\n","2022-02-16 19:46:53,931 epoch 34 - iter 6/19 - loss 0.55592753 - samples/sec: 372.21 - lr: 0.012500\n","2022-02-16 19:46:54,011 epoch 34 - iter 7/19 - loss 0.56874244 - samples/sec: 416.82 - lr: 0.012500\n","2022-02-16 19:46:54,082 epoch 34 - iter 8/19 - loss 0.58607943 - samples/sec: 468.38 - lr: 0.012500\n","2022-02-16 19:46:54,156 epoch 34 - iter 9/19 - loss 0.59757080 - samples/sec: 472.98 - lr: 0.012500\n","2022-02-16 19:46:54,240 epoch 34 - iter 10/19 - loss 0.58116174 - samples/sec: 399.70 - lr: 0.012500\n","2022-02-16 19:46:54,314 epoch 34 - iter 11/19 - loss 0.57899835 - samples/sec: 471.63 - lr: 0.012500\n","2022-02-16 19:46:54,395 epoch 34 - iter 12/19 - loss 0.55955750 - samples/sec: 485.60 - lr: 0.012500\n","2022-02-16 19:46:54,474 epoch 34 - iter 13/19 - loss 0.56990831 - samples/sec: 416.75 - lr: 0.012500\n","2022-02-16 19:46:54,544 epoch 34 - iter 14/19 - loss 0.55188420 - samples/sec: 491.24 - lr: 0.012500\n","2022-02-16 19:46:54,618 epoch 34 - iter 15/19 - loss 0.54489343 - samples/sec: 450.59 - lr: 0.012500\n","2022-02-16 19:46:54,693 epoch 34 - iter 16/19 - loss 0.53191861 - samples/sec: 438.12 - lr: 0.012500\n","2022-02-16 19:46:54,787 epoch 34 - iter 17/19 - loss 0.53109369 - samples/sec: 359.51 - lr: 0.012500\n","2022-02-16 19:46:54,872 epoch 34 - iter 18/19 - loss 0.53630474 - samples/sec: 480.24 - lr: 0.012500\n","2022-02-16 19:46:54,916 epoch 34 - iter 19/19 - loss 0.54107950 - samples/sec: 865.23 - lr: 0.012500\n","2022-02-16 19:46:55,285 ----------------------------------------------------------------------------------------------------\n","2022-02-16 19:46:55,286 EPOCH 34 done: loss 0.5411 - lr 0.0125000\n","2022-02-16 19:46:56,885 DEV : loss 0.4495058059692383 - score 0.6615\n","Epoch    34: reducing learning rate of group 0 to 6.2500e-03.\n","2022-02-16 19:46:56,964 BAD EPOCHS (no improvement): 4\n","2022-02-16 19:46:56,975 ----------------------------------------------------------------------------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"output_type":"stream","name":"stdout","text":["2022-02-16 19:46:58,285 epoch 35 - iter 1/19 - loss 0.75622547 - samples/sec: 153.08 - lr: 0.006250\n","2022-02-16 19:46:58,404 epoch 35 - iter 2/19 - loss 0.61952043 - samples/sec: 294.49 - lr: 0.006250\n","2022-02-16 19:46:58,500 epoch 35 - iter 3/19 - loss 0.62001421 - samples/sec: 370.78 - lr: 0.006250\n","2022-02-16 19:46:58,596 epoch 35 - iter 4/19 - loss 0.65674613 - samples/sec: 375.50 - lr: 0.006250\n","2022-02-16 19:46:58,694 epoch 35 - iter 5/19 - loss 0.62888505 - samples/sec: 334.49 - lr: 0.006250\n","2022-02-16 19:46:58,817 epoch 35 - iter 6/19 - loss 0.58175483 - samples/sec: 365.99 - lr: 0.006250\n","2022-02-16 19:46:58,899 epoch 35 - iter 7/19 - loss 0.56727892 - samples/sec: 403.13 - lr: 0.006250\n","2022-02-16 19:46:58,978 epoch 35 - iter 8/19 - loss 0.56936223 - samples/sec: 432.60 - lr: 0.006250\n","2022-02-16 19:46:59,061 epoch 35 - iter 9/19 - loss 0.56418037 - samples/sec: 424.90 - lr: 0.006250\n","2022-02-16 19:46:59,140 epoch 35 - iter 10/19 - loss 0.57552754 - samples/sec: 443.74 - lr: 0.006250\n","2022-02-16 19:46:59,213 epoch 35 - iter 11/19 - loss 0.56828461 - samples/sec: 466.40 - lr: 0.006250\n","2022-02-16 19:46:59,291 epoch 35 - iter 12/19 - loss 0.55836780 - samples/sec: 486.36 - lr: 0.006250\n","2022-02-16 19:46:59,393 epoch 35 - iter 13/19 - loss 0.56007730 - samples/sec: 394.57 - lr: 0.006250\n","2022-02-16 19:46:59,475 epoch 35 - iter 14/19 - loss 0.54964989 - samples/sec: 474.73 - lr: 0.006250\n","2022-02-16 19:46:59,553 epoch 35 - iter 15/19 - loss 0.54803523 - samples/sec: 428.98 - lr: 0.006250\n","2022-02-16 19:46:59,632 epoch 35 - iter 16/19 - loss 0.53594144 - samples/sec: 438.54 - lr: 0.006250\n","2022-02-16 19:46:59,710 epoch 35 - iter 17/19 - loss 0.52928307 - samples/sec: 425.16 - lr: 0.006250\n","2022-02-16 19:46:59,783 epoch 35 - iter 18/19 - loss 0.53320699 - samples/sec: 544.57 - lr: 0.006250\n","2022-02-16 19:46:59,827 epoch 35 - iter 19/19 - loss 0.54446056 - samples/sec: 889.43 - lr: 0.006250\n","2022-02-16 19:47:00,190 ----------------------------------------------------------------------------------------------------\n","2022-02-16 19:47:00,198 EPOCH 35 done: loss 0.5445 - lr 0.0062500\n","2022-02-16 19:47:01,766 DEV : loss 0.44845616817474365 - score 0.6462\n","2022-02-16 19:47:01,844 BAD EPOCHS (no improvement): 1\n","2022-02-16 19:47:01,853 ----------------------------------------------------------------------------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"output_type":"stream","name":"stdout","text":["2022-02-16 19:47:03,108 epoch 36 - iter 1/19 - loss 0.70704395 - samples/sec: 139.46 - lr: 0.006250\n","2022-02-16 19:47:03,244 epoch 36 - iter 2/19 - loss 0.64604291 - samples/sec: 296.41 - lr: 0.006250\n","2022-02-16 19:47:03,343 epoch 36 - iter 3/19 - loss 0.61368380 - samples/sec: 448.21 - lr: 0.006250\n","2022-02-16 19:47:03,436 epoch 36 - iter 4/19 - loss 0.56698924 - samples/sec: 371.28 - lr: 0.006250\n","2022-02-16 19:47:03,551 epoch 36 - iter 5/19 - loss 0.54360894 - samples/sec: 362.10 - lr: 0.006250\n","2022-02-16 19:47:03,679 epoch 36 - iter 6/19 - loss 0.51875426 - samples/sec: 374.60 - lr: 0.006250\n","2022-02-16 19:47:03,766 epoch 36 - iter 7/19 - loss 0.52210301 - samples/sec: 380.29 - lr: 0.006250\n","2022-02-16 19:47:03,845 epoch 36 - iter 8/19 - loss 0.51588075 - samples/sec: 460.31 - lr: 0.006250\n","2022-02-16 19:47:03,928 epoch 36 - iter 9/19 - loss 0.50070854 - samples/sec: 400.43 - lr: 0.006250\n","2022-02-16 19:47:03,994 epoch 36 - iter 10/19 - loss 0.54135755 - samples/sec: 511.76 - lr: 0.006250\n","2022-02-16 19:47:04,067 epoch 36 - iter 11/19 - loss 0.53675161 - samples/sec: 457.22 - lr: 0.006250\n","2022-02-16 19:47:04,150 epoch 36 - iter 12/19 - loss 0.53156297 - samples/sec: 463.53 - lr: 0.006250\n","2022-02-16 19:47:04,222 epoch 36 - iter 13/19 - loss 0.52267319 - samples/sec: 459.48 - lr: 0.006250\n","2022-02-16 19:47:04,296 epoch 36 - iter 14/19 - loss 0.52278929 - samples/sec: 444.29 - lr: 0.006250\n","2022-02-16 19:47:04,378 epoch 36 - iter 15/19 - loss 0.54252190 - samples/sec: 405.32 - lr: 0.006250\n","2022-02-16 19:47:04,455 epoch 36 - iter 16/19 - loss 0.54641526 - samples/sec: 439.20 - lr: 0.006250\n","2022-02-16 19:47:04,540 epoch 36 - iter 17/19 - loss 0.54231788 - samples/sec: 386.85 - lr: 0.006250\n","2022-02-16 19:47:04,622 epoch 36 - iter 18/19 - loss 0.53608496 - samples/sec: 501.56 - lr: 0.006250\n","2022-02-16 19:47:04,666 epoch 36 - iter 19/19 - loss 0.52992896 - samples/sec: 836.35 - lr: 0.006250\n","2022-02-16 19:47:05,045 ----------------------------------------------------------------------------------------------------\n","2022-02-16 19:47:05,052 EPOCH 36 done: loss 0.5299 - lr 0.0062500\n","2022-02-16 19:47:06,607 DEV : loss 0.4431389570236206 - score 0.6615\n","2022-02-16 19:47:06,689 BAD EPOCHS (no improvement): 2\n","2022-02-16 19:47:06,700 ----------------------------------------------------------------------------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"output_type":"stream","name":"stdout","text":["2022-02-16 19:47:07,993 epoch 37 - iter 1/19 - loss 0.58405048 - samples/sec: 163.03 - lr: 0.006250\n","2022-02-16 19:47:08,089 epoch 37 - iter 2/19 - loss 0.66580015 - samples/sec: 394.59 - lr: 0.006250\n","2022-02-16 19:47:08,192 epoch 37 - iter 3/19 - loss 0.60096347 - samples/sec: 379.32 - lr: 0.006250\n","2022-02-16 19:47:08,290 epoch 37 - iter 4/19 - loss 0.63226491 - samples/sec: 337.88 - lr: 0.006250\n","2022-02-16 19:47:08,400 epoch 37 - iter 5/19 - loss 0.57637403 - samples/sec: 455.18 - lr: 0.006250\n","2022-02-16 19:47:08,500 epoch 37 - iter 6/19 - loss 0.54541599 - samples/sec: 354.89 - lr: 0.006250\n","2022-02-16 19:47:08,577 epoch 37 - iter 7/19 - loss 0.56994446 - samples/sec: 465.21 - lr: 0.006250\n","2022-02-16 19:47:08,652 epoch 37 - iter 8/19 - loss 0.54647991 - samples/sec: 440.84 - lr: 0.006250\n","2022-02-16 19:47:08,725 epoch 37 - iter 9/19 - loss 0.55171637 - samples/sec: 480.20 - lr: 0.006250\n","2022-02-16 19:47:08,803 epoch 37 - iter 10/19 - loss 0.54391368 - samples/sec: 475.73 - lr: 0.006250\n","2022-02-16 19:47:08,881 epoch 37 - iter 11/19 - loss 0.53025893 - samples/sec: 457.33 - lr: 0.006250\n","2022-02-16 19:47:08,961 epoch 37 - iter 12/19 - loss 0.54526266 - samples/sec: 514.92 - lr: 0.006250\n","2022-02-16 19:47:09,047 epoch 37 - iter 13/19 - loss 0.54951876 - samples/sec: 382.49 - lr: 0.006250\n","2022-02-16 19:47:09,140 epoch 37 - iter 14/19 - loss 0.56049987 - samples/sec: 464.25 - lr: 0.006250\n","2022-02-16 19:47:09,215 epoch 37 - iter 15/19 - loss 0.55197818 - samples/sec: 443.15 - lr: 0.006250\n","2022-02-16 19:47:09,296 epoch 37 - iter 16/19 - loss 0.54895697 - samples/sec: 464.42 - lr: 0.006250\n","2022-02-16 19:47:09,404 epoch 37 - iter 17/19 - loss 0.55684765 - samples/sec: 304.72 - lr: 0.006250\n","2022-02-16 19:47:09,502 epoch 37 - iter 18/19 - loss 0.55424611 - samples/sec: 338.05 - lr: 0.006250\n","2022-02-16 19:47:09,560 epoch 37 - iter 19/19 - loss 0.54556404 - samples/sec: 574.32 - lr: 0.006250\n","2022-02-16 19:47:09,920 ----------------------------------------------------------------------------------------------------\n","2022-02-16 19:47:09,926 EPOCH 37 done: loss 0.5456 - lr 0.0062500\n","2022-02-16 19:47:13,185 DEV : loss 0.44684600830078125 - score 0.6615\n","2022-02-16 19:47:13,282 BAD EPOCHS (no improvement): 3\n","2022-02-16 19:47:13,292 ----------------------------------------------------------------------------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"output_type":"stream","name":"stdout","text":["2022-02-16 19:47:14,513 epoch 38 - iter 1/19 - loss 0.48256931 - samples/sec: 139.05 - lr: 0.006250\n","2022-02-16 19:47:14,625 epoch 38 - iter 2/19 - loss 0.43192317 - samples/sec: 319.97 - lr: 0.006250\n","2022-02-16 19:47:14,746 epoch 38 - iter 3/19 - loss 0.38839422 - samples/sec: 355.66 - lr: 0.006250\n","2022-02-16 19:47:14,842 epoch 38 - iter 4/19 - loss 0.39219885 - samples/sec: 378.33 - lr: 0.006250\n","2022-02-16 19:47:14,950 epoch 38 - iter 5/19 - loss 0.43820053 - samples/sec: 404.07 - lr: 0.006250\n","2022-02-16 19:47:15,062 epoch 38 - iter 6/19 - loss 0.46713713 - samples/sec: 318.08 - lr: 0.006250\n","2022-02-16 19:47:15,157 epoch 38 - iter 7/19 - loss 0.45094608 - samples/sec: 403.64 - lr: 0.006250\n","2022-02-16 19:47:15,237 epoch 38 - iter 8/19 - loss 0.47614678 - samples/sec: 411.83 - lr: 0.006250\n","2022-02-16 19:47:15,351 epoch 38 - iter 9/19 - loss 0.49530389 - samples/sec: 487.89 - lr: 0.006250\n","2022-02-16 19:47:15,429 epoch 38 - iter 10/19 - loss 0.47777049 - samples/sec: 424.71 - lr: 0.006250\n","2022-02-16 19:47:15,504 epoch 38 - iter 11/19 - loss 0.50814169 - samples/sec: 439.27 - lr: 0.006250\n","2022-02-16 19:47:15,581 epoch 38 - iter 12/19 - loss 0.51260711 - samples/sec: 446.35 - lr: 0.006250\n","2022-02-16 19:47:15,656 epoch 38 - iter 13/19 - loss 0.53612761 - samples/sec: 444.49 - lr: 0.006250\n","2022-02-16 19:47:15,728 epoch 38 - iter 14/19 - loss 0.54507541 - samples/sec: 468.78 - lr: 0.006250\n","2022-02-16 19:47:15,802 epoch 38 - iter 15/19 - loss 0.55400061 - samples/sec: 534.05 - lr: 0.006250\n","2022-02-16 19:47:15,881 epoch 38 - iter 16/19 - loss 0.55660213 - samples/sec: 424.79 - lr: 0.006250\n","2022-02-16 19:47:15,955 epoch 38 - iter 17/19 - loss 0.55153946 - samples/sec: 453.56 - lr: 0.006250\n","2022-02-16 19:47:16,028 epoch 38 - iter 18/19 - loss 0.54697502 - samples/sec: 456.65 - lr: 0.006250\n","2022-02-16 19:47:16,070 epoch 38 - iter 19/19 - loss 0.53640810 - samples/sec: 794.97 - lr: 0.006250\n","2022-02-16 19:47:16,409 ----------------------------------------------------------------------------------------------------\n","2022-02-16 19:47:16,417 EPOCH 38 done: loss 0.5364 - lr 0.0062500\n","2022-02-16 19:47:18,044 DEV : loss 0.44397255778312683 - score 0.6615\n","Epoch    38: reducing learning rate of group 0 to 3.1250e-03.\n","2022-02-16 19:47:18,123 BAD EPOCHS (no improvement): 4\n","2022-02-16 19:47:18,136 ----------------------------------------------------------------------------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"output_type":"stream","name":"stdout","text":["2022-02-16 19:47:19,441 epoch 39 - iter 1/19 - loss 0.61449659 - samples/sec: 108.64 - lr: 0.003125\n","2022-02-16 19:47:19,571 epoch 39 - iter 2/19 - loss 0.52346918 - samples/sec: 302.41 - lr: 0.003125\n","2022-02-16 19:47:19,662 epoch 39 - iter 3/19 - loss 0.62274816 - samples/sec: 410.17 - lr: 0.003125\n","2022-02-16 19:47:19,752 epoch 39 - iter 4/19 - loss 0.59142422 - samples/sec: 424.48 - lr: 0.003125\n","2022-02-16 19:47:19,892 epoch 39 - iter 5/19 - loss 0.62529461 - samples/sec: 396.96 - lr: 0.003125\n","2022-02-16 19:47:19,982 epoch 39 - iter 6/19 - loss 0.60538591 - samples/sec: 373.53 - lr: 0.003125\n","2022-02-16 19:47:20,058 epoch 39 - iter 7/19 - loss 0.61916307 - samples/sec: 442.10 - lr: 0.003125\n","2022-02-16 19:47:20,132 epoch 39 - iter 8/19 - loss 0.59201781 - samples/sec: 466.45 - lr: 0.003125\n","2022-02-16 19:47:20,205 epoch 39 - iter 9/19 - loss 0.59746841 - samples/sec: 453.05 - lr: 0.003125\n","2022-02-16 19:47:20,279 epoch 39 - iter 10/19 - loss 0.59749731 - samples/sec: 441.84 - lr: 0.003125\n","2022-02-16 19:47:20,354 epoch 39 - iter 11/19 - loss 0.59175972 - samples/sec: 520.51 - lr: 0.003125\n","2022-02-16 19:47:20,446 epoch 39 - iter 12/19 - loss 0.56880844 - samples/sec: 357.62 - lr: 0.003125\n","2022-02-16 19:47:20,524 epoch 39 - iter 13/19 - loss 0.56008642 - samples/sec: 488.43 - lr: 0.003125\n","2022-02-16 19:47:20,597 epoch 39 - iter 14/19 - loss 0.55490405 - samples/sec: 457.20 - lr: 0.003125\n","2022-02-16 19:47:20,676 epoch 39 - iter 15/19 - loss 0.55429266 - samples/sec: 420.27 - lr: 0.003125\n","2022-02-16 19:47:20,755 epoch 39 - iter 16/19 - loss 0.54040829 - samples/sec: 427.53 - lr: 0.003125\n","2022-02-16 19:47:20,830 epoch 39 - iter 17/19 - loss 0.53100519 - samples/sec: 510.47 - lr: 0.003125\n","2022-02-16 19:47:20,903 epoch 39 - iter 18/19 - loss 0.53661047 - samples/sec: 512.16 - lr: 0.003125\n","2022-02-16 19:47:20,956 epoch 39 - iter 19/19 - loss 0.54022896 - samples/sec: 790.64 - lr: 0.003125\n","2022-02-16 19:47:21,336 ----------------------------------------------------------------------------------------------------\n","2022-02-16 19:47:21,343 EPOCH 39 done: loss 0.5402 - lr 0.0031250\n","2022-02-16 19:47:22,893 DEV : loss 0.44248485565185547 - score 0.6615\n","2022-02-16 19:47:22,972 BAD EPOCHS (no improvement): 1\n","2022-02-16 19:47:22,981 ----------------------------------------------------------------------------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"output_type":"stream","name":"stdout","text":["2022-02-16 19:47:24,216 epoch 40 - iter 1/19 - loss 0.40037715 - samples/sec: 168.54 - lr: 0.003125\n","2022-02-16 19:47:24,358 epoch 40 - iter 2/19 - loss 0.47012466 - samples/sec: 299.84 - lr: 0.003125\n","2022-02-16 19:47:24,448 epoch 40 - iter 3/19 - loss 0.42536111 - samples/sec: 373.97 - lr: 0.003125\n","2022-02-16 19:47:24,544 epoch 40 - iter 4/19 - loss 0.43987393 - samples/sec: 344.71 - lr: 0.003125\n","2022-02-16 19:47:24,655 epoch 40 - iter 5/19 - loss 0.41512260 - samples/sec: 340.24 - lr: 0.003125\n","2022-02-16 19:47:24,770 epoch 40 - iter 6/19 - loss 0.42517170 - samples/sec: 390.35 - lr: 0.003125\n","2022-02-16 19:47:24,864 epoch 40 - iter 7/19 - loss 0.47120159 - samples/sec: 444.77 - lr: 0.003125\n","2022-02-16 19:47:24,934 epoch 40 - iter 8/19 - loss 0.51078728 - samples/sec: 480.94 - lr: 0.003125\n","2022-02-16 19:47:25,010 epoch 40 - iter 9/19 - loss 0.52908390 - samples/sec: 436.84 - lr: 0.003125\n","2022-02-16 19:47:25,081 epoch 40 - iter 10/19 - loss 0.52762648 - samples/sec: 512.14 - lr: 0.003125\n","2022-02-16 19:47:25,158 epoch 40 - iter 11/19 - loss 0.51794090 - samples/sec: 430.19 - lr: 0.003125\n","2022-02-16 19:47:25,237 epoch 40 - iter 12/19 - loss 0.54152746 - samples/sec: 421.50 - lr: 0.003125\n","2022-02-16 19:47:25,327 epoch 40 - iter 13/19 - loss 0.53667526 - samples/sec: 475.15 - lr: 0.003125\n","2022-02-16 19:47:25,402 epoch 40 - iter 14/19 - loss 0.53389289 - samples/sec: 437.90 - lr: 0.003125\n","2022-02-16 19:47:25,477 epoch 40 - iter 15/19 - loss 0.53251938 - samples/sec: 437.53 - lr: 0.003125\n","2022-02-16 19:47:25,551 epoch 40 - iter 16/19 - loss 0.52699061 - samples/sec: 472.63 - lr: 0.003125\n","2022-02-16 19:47:25,630 epoch 40 - iter 17/19 - loss 0.52585450 - samples/sec: 464.92 - lr: 0.003125\n","2022-02-16 19:47:25,707 epoch 40 - iter 18/19 - loss 0.52485835 - samples/sec: 425.41 - lr: 0.003125\n","2022-02-16 19:47:25,756 epoch 40 - iter 19/19 - loss 0.52424569 - samples/sec: 883.85 - lr: 0.003125\n","2022-02-16 19:47:26,094 ----------------------------------------------------------------------------------------------------\n","2022-02-16 19:47:26,096 EPOCH 40 done: loss 0.5242 - lr 0.0031250\n","2022-02-16 19:47:27,675 DEV : loss 0.44025835394859314 - score 0.6462\n","2022-02-16 19:47:27,764 BAD EPOCHS (no improvement): 2\n","2022-02-16 19:47:27,778 ----------------------------------------------------------------------------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"output_type":"stream","name":"stdout","text":["2022-02-16 19:47:29,056 epoch 41 - iter 1/19 - loss 0.52340579 - samples/sec: 114.83 - lr: 0.003125\n","2022-02-16 19:47:29,204 epoch 41 - iter 2/19 - loss 0.54135385 - samples/sec: 291.79 - lr: 0.003125\n","2022-02-16 19:47:29,290 epoch 41 - iter 3/19 - loss 0.51278428 - samples/sec: 424.78 - lr: 0.003125\n","2022-02-16 19:47:29,385 epoch 41 - iter 4/19 - loss 0.50301708 - samples/sec: 398.14 - lr: 0.003125\n","2022-02-16 19:47:29,488 epoch 41 - iter 5/19 - loss 0.53140795 - samples/sec: 409.67 - lr: 0.003125\n","2022-02-16 19:47:29,591 epoch 41 - iter 6/19 - loss 0.50683857 - samples/sec: 384.96 - lr: 0.003125\n","2022-02-16 19:47:29,671 epoch 41 - iter 7/19 - loss 0.48312699 - samples/sec: 434.90 - lr: 0.003125\n","2022-02-16 19:47:29,750 epoch 41 - iter 8/19 - loss 0.47909611 - samples/sec: 425.86 - lr: 0.003125\n","2022-02-16 19:47:29,824 epoch 41 - iter 9/19 - loss 0.51730073 - samples/sec: 449.77 - lr: 0.003125\n","2022-02-16 19:47:29,943 epoch 41 - iter 10/19 - loss 0.52145812 - samples/sec: 428.01 - lr: 0.003125\n","2022-02-16 19:47:30,016 epoch 41 - iter 11/19 - loss 0.51128417 - samples/sec: 458.97 - lr: 0.003125\n","2022-02-16 19:47:30,090 epoch 41 - iter 12/19 - loss 0.51173893 - samples/sec: 447.17 - lr: 0.003125\n","2022-02-16 19:47:30,167 epoch 41 - iter 13/19 - loss 0.49837222 - samples/sec: 427.17 - lr: 0.003125\n","2022-02-16 19:47:30,246 epoch 41 - iter 14/19 - loss 0.50359963 - samples/sec: 413.99 - lr: 0.003125\n","2022-02-16 19:47:30,320 epoch 41 - iter 15/19 - loss 0.50631947 - samples/sec: 464.28 - lr: 0.003125\n","2022-02-16 19:47:30,398 epoch 41 - iter 16/19 - loss 0.50882406 - samples/sec: 456.98 - lr: 0.003125\n","2022-02-16 19:47:30,479 epoch 41 - iter 17/19 - loss 0.50602237 - samples/sec: 427.85 - lr: 0.003125\n","2022-02-16 19:47:30,554 epoch 41 - iter 18/19 - loss 0.52080221 - samples/sec: 511.11 - lr: 0.003125\n","2022-02-16 19:47:30,603 epoch 41 - iter 19/19 - loss 0.54579241 - samples/sec: 732.07 - lr: 0.003125\n","2022-02-16 19:47:31,026 ----------------------------------------------------------------------------------------------------\n","2022-02-16 19:47:31,032 EPOCH 41 done: loss 0.5458 - lr 0.0031250\n","2022-02-16 19:47:32,634 DEV : loss 0.44448575377464294 - score 0.6462\n","2022-02-16 19:47:32,714 BAD EPOCHS (no improvement): 3\n","2022-02-16 19:47:32,723 ----------------------------------------------------------------------------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"output_type":"stream","name":"stdout","text":["2022-02-16 19:47:34,016 epoch 42 - iter 1/19 - loss 0.64329243 - samples/sec: 149.24 - lr: 0.003125\n","2022-02-16 19:47:34,144 epoch 42 - iter 2/19 - loss 0.56588219 - samples/sec: 322.44 - lr: 0.003125\n","2022-02-16 19:47:34,240 epoch 42 - iter 3/19 - loss 0.56044293 - samples/sec: 417.17 - lr: 0.003125\n","2022-02-16 19:47:34,333 epoch 42 - iter 4/19 - loss 0.52051216 - samples/sec: 364.99 - lr: 0.003125\n","2022-02-16 19:47:34,441 epoch 42 - iter 5/19 - loss 0.53375126 - samples/sec: 404.09 - lr: 0.003125\n","2022-02-16 19:47:34,546 epoch 42 - iter 6/19 - loss 0.52996388 - samples/sec: 361.27 - lr: 0.003125\n","2022-02-16 19:47:34,623 epoch 42 - iter 7/19 - loss 0.52247102 - samples/sec: 445.19 - lr: 0.003125\n","2022-02-16 19:47:34,719 epoch 42 - iter 8/19 - loss 0.52671823 - samples/sec: 507.98 - lr: 0.003125\n","2022-02-16 19:47:34,798 epoch 42 - iter 9/19 - loss 0.54190779 - samples/sec: 416.32 - lr: 0.003125\n","2022-02-16 19:47:34,873 epoch 42 - iter 10/19 - loss 0.54613585 - samples/sec: 479.48 - lr: 0.003125\n","2022-02-16 19:47:34,949 epoch 42 - iter 11/19 - loss 0.54409818 - samples/sec: 459.07 - lr: 0.003125\n","2022-02-16 19:47:35,021 epoch 42 - iter 12/19 - loss 0.54152696 - samples/sec: 478.85 - lr: 0.003125\n","2022-02-16 19:47:35,098 epoch 42 - iter 13/19 - loss 0.54739522 - samples/sec: 435.46 - lr: 0.003125\n","2022-02-16 19:47:35,188 epoch 42 - iter 14/19 - loss 0.53609375 - samples/sec: 417.71 - lr: 0.003125\n","2022-02-16 19:47:35,267 epoch 42 - iter 15/19 - loss 0.52562223 - samples/sec: 429.88 - lr: 0.003125\n","2022-02-16 19:47:35,341 epoch 42 - iter 16/19 - loss 0.52026630 - samples/sec: 457.29 - lr: 0.003125\n","2022-02-16 19:47:35,423 epoch 42 - iter 17/19 - loss 0.52510806 - samples/sec: 475.21 - lr: 0.003125\n","2022-02-16 19:47:35,498 epoch 42 - iter 18/19 - loss 0.51222383 - samples/sec: 497.88 - lr: 0.003125\n","2022-02-16 19:47:35,539 epoch 42 - iter 19/19 - loss 0.54085759 - samples/sec: 840.96 - lr: 0.003125\n","2022-02-16 19:47:35,908 ----------------------------------------------------------------------------------------------------\n","2022-02-16 19:47:35,916 EPOCH 42 done: loss 0.5409 - lr 0.0031250\n","2022-02-16 19:47:37,476 DEV : loss 0.4486459493637085 - score 0.6615\n","Epoch    42: reducing learning rate of group 0 to 1.5625e-03.\n","2022-02-16 19:47:37,554 BAD EPOCHS (no improvement): 4\n","2022-02-16 19:47:37,565 ----------------------------------------------------------------------------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"output_type":"stream","name":"stdout","text":["2022-02-16 19:47:38,823 epoch 43 - iter 1/19 - loss 0.55056447 - samples/sec: 146.66 - lr: 0.001563\n","2022-02-16 19:47:38,927 epoch 43 - iter 2/19 - loss 0.54566440 - samples/sec: 384.54 - lr: 0.001563\n","2022-02-16 19:47:39,009 epoch 43 - iter 3/19 - loss 0.50137646 - samples/sec: 425.03 - lr: 0.001563\n","2022-02-16 19:47:39,103 epoch 43 - iter 4/19 - loss 0.50798782 - samples/sec: 357.19 - lr: 0.001563\n","2022-02-16 19:47:39,198 epoch 43 - iter 5/19 - loss 0.48980324 - samples/sec: 390.32 - lr: 0.001563\n","2022-02-16 19:47:39,316 epoch 43 - iter 6/19 - loss 0.51809104 - samples/sec: 356.77 - lr: 0.001563\n","2022-02-16 19:47:39,410 epoch 43 - iter 7/19 - loss 0.51907607 - samples/sec: 361.95 - lr: 0.001563\n","2022-02-16 19:47:39,517 epoch 43 - iter 8/19 - loss 0.50499183 - samples/sec: 522.46 - lr: 0.001563\n","2022-02-16 19:47:39,594 epoch 43 - iter 9/19 - loss 0.50184850 - samples/sec: 426.43 - lr: 0.001563\n","2022-02-16 19:47:39,670 epoch 43 - iter 10/19 - loss 0.49286630 - samples/sec: 440.15 - lr: 0.001563\n","2022-02-16 19:47:39,745 epoch 43 - iter 11/19 - loss 0.48640471 - samples/sec: 441.85 - lr: 0.001563\n","2022-02-16 19:47:39,818 epoch 43 - iter 12/19 - loss 0.47976968 - samples/sec: 449.69 - lr: 0.001563\n","2022-02-16 19:47:39,902 epoch 43 - iter 13/19 - loss 0.48912995 - samples/sec: 392.23 - lr: 0.001563\n","2022-02-16 19:47:39,985 epoch 43 - iter 14/19 - loss 0.48675788 - samples/sec: 474.37 - lr: 0.001563\n","2022-02-16 19:47:40,062 epoch 43 - iter 15/19 - loss 0.49377962 - samples/sec: 453.22 - lr: 0.001563\n","2022-02-16 19:47:40,138 epoch 43 - iter 16/19 - loss 0.50086192 - samples/sec: 445.51 - lr: 0.001563\n","2022-02-16 19:47:40,220 epoch 43 - iter 17/19 - loss 0.50115763 - samples/sec: 400.60 - lr: 0.001563\n","2022-02-16 19:47:40,293 epoch 43 - iter 18/19 - loss 0.50132048 - samples/sec: 478.21 - lr: 0.001563\n","2022-02-16 19:47:40,336 epoch 43 - iter 19/19 - loss 0.48809184 - samples/sec: 788.58 - lr: 0.001563\n","2022-02-16 19:47:40,699 ----------------------------------------------------------------------------------------------------\n","2022-02-16 19:47:40,707 EPOCH 43 done: loss 0.4881 - lr 0.0015625\n","2022-02-16 19:47:42,231 DEV : loss 0.4470093846321106 - score 0.6615\n","2022-02-16 19:47:42,315 BAD EPOCHS (no improvement): 1\n","2022-02-16 19:47:42,324 ----------------------------------------------------------------------------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"output_type":"stream","name":"stdout","text":["2022-02-16 19:47:43,560 epoch 44 - iter 1/19 - loss 0.45528257 - samples/sec: 146.76 - lr: 0.001563\n","2022-02-16 19:47:43,684 epoch 44 - iter 2/19 - loss 0.51442075 - samples/sec: 269.63 - lr: 0.001563\n","2022-02-16 19:47:43,787 epoch 44 - iter 3/19 - loss 0.55808226 - samples/sec: 381.20 - lr: 0.001563\n","2022-02-16 19:47:43,877 epoch 44 - iter 4/19 - loss 0.58964773 - samples/sec: 404.52 - lr: 0.001563\n","2022-02-16 19:47:43,982 epoch 44 - iter 5/19 - loss 0.56951923 - samples/sec: 410.94 - lr: 0.001563\n","2022-02-16 19:47:44,105 epoch 44 - iter 6/19 - loss 0.57039169 - samples/sec: 373.36 - lr: 0.001563\n","2022-02-16 19:47:44,187 epoch 44 - iter 7/19 - loss 0.55269619 - samples/sec: 450.13 - lr: 0.001563\n","2022-02-16 19:47:44,259 epoch 44 - iter 8/19 - loss 0.54967361 - samples/sec: 466.00 - lr: 0.001563\n","2022-02-16 19:47:44,336 epoch 44 - iter 9/19 - loss 0.56021282 - samples/sec: 445.27 - lr: 0.001563\n","2022-02-16 19:47:44,418 epoch 44 - iter 10/19 - loss 0.54280508 - samples/sec: 408.67 - lr: 0.001563\n","2022-02-16 19:47:44,489 epoch 44 - iter 11/19 - loss 0.55236821 - samples/sec: 468.37 - lr: 0.001563\n","2022-02-16 19:47:44,576 epoch 44 - iter 12/19 - loss 0.54641342 - samples/sec: 484.23 - lr: 0.001563\n","2022-02-16 19:47:44,647 epoch 44 - iter 13/19 - loss 0.54414095 - samples/sec: 487.50 - lr: 0.001563\n","2022-02-16 19:47:44,723 epoch 44 - iter 14/19 - loss 0.53475403 - samples/sec: 435.21 - lr: 0.001563\n","2022-02-16 19:47:44,793 epoch 44 - iter 15/19 - loss 0.53689742 - samples/sec: 494.18 - lr: 0.001563\n","2022-02-16 19:47:44,862 epoch 44 - iter 16/19 - loss 0.53420207 - samples/sec: 476.89 - lr: 0.001563\n","2022-02-16 19:47:44,936 epoch 44 - iter 17/19 - loss 0.52872442 - samples/sec: 465.57 - lr: 0.001563\n","2022-02-16 19:47:45,018 epoch 44 - iter 18/19 - loss 0.51564209 - samples/sec: 480.29 - lr: 0.001563\n","2022-02-16 19:47:46,672 epoch 44 - iter 19/19 - loss 0.50850550 - samples/sec: 924.94 - lr: 0.001563\n","2022-02-16 19:47:47,044 ----------------------------------------------------------------------------------------------------\n","2022-02-16 19:47:47,048 EPOCH 44 done: loss 0.5085 - lr 0.0015625\n","2022-02-16 19:47:48,625 DEV : loss 0.44366997480392456 - score 0.6615\n","2022-02-16 19:47:48,702 BAD EPOCHS (no improvement): 2\n","2022-02-16 19:47:48,712 ----------------------------------------------------------------------------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"output_type":"stream","name":"stdout","text":["2022-02-16 19:47:50,024 epoch 45 - iter 1/19 - loss 0.51850241 - samples/sec: 124.06 - lr: 0.001563\n","2022-02-16 19:47:50,170 epoch 45 - iter 2/19 - loss 0.48953548 - samples/sec: 283.49 - lr: 0.001563\n","2022-02-16 19:47:50,266 epoch 45 - iter 3/19 - loss 0.48948758 - samples/sec: 345.15 - lr: 0.001563\n","2022-02-16 19:47:50,408 epoch 45 - iter 4/19 - loss 0.52360863 - samples/sec: 378.14 - lr: 0.001563\n","2022-02-16 19:47:50,499 epoch 45 - iter 5/19 - loss 0.53386052 - samples/sec: 360.92 - lr: 0.001563\n","2022-02-16 19:47:50,588 epoch 45 - iter 6/19 - loss 0.52883265 - samples/sec: 380.05 - lr: 0.001563\n","2022-02-16 19:47:50,665 epoch 45 - iter 7/19 - loss 0.51750918 - samples/sec: 436.63 - lr: 0.001563\n","2022-02-16 19:47:50,746 epoch 45 - iter 8/19 - loss 0.52048903 - samples/sec: 436.84 - lr: 0.001563\n","2022-02-16 19:47:50,821 epoch 45 - iter 9/19 - loss 0.51371551 - samples/sec: 441.37 - lr: 0.001563\n","2022-02-16 19:47:50,897 epoch 45 - iter 10/19 - loss 0.52752883 - samples/sec: 481.96 - lr: 0.001563\n","2022-02-16 19:47:50,972 epoch 45 - iter 11/19 - loss 0.52743163 - samples/sec: 460.75 - lr: 0.001563\n","2022-02-16 19:47:51,060 epoch 45 - iter 12/19 - loss 0.52640366 - samples/sec: 375.90 - lr: 0.001563\n","2022-02-16 19:47:51,145 epoch 45 - iter 13/19 - loss 0.51837111 - samples/sec: 423.65 - lr: 0.001563\n","2022-02-16 19:47:51,221 epoch 45 - iter 14/19 - loss 0.51024907 - samples/sec: 467.15 - lr: 0.001563\n","2022-02-16 19:47:51,296 epoch 45 - iter 15/19 - loss 0.52613182 - samples/sec: 464.57 - lr: 0.001563\n","2022-02-16 19:47:51,388 epoch 45 - iter 16/19 - loss 0.52475073 - samples/sec: 413.56 - lr: 0.001563\n","2022-02-16 19:47:51,467 epoch 45 - iter 17/19 - loss 0.51814051 - samples/sec: 459.58 - lr: 0.001563\n","2022-02-16 19:47:51,540 epoch 45 - iter 18/19 - loss 0.52291797 - samples/sec: 526.35 - lr: 0.001563\n","2022-02-16 19:47:51,587 epoch 45 - iter 19/19 - loss 0.52681711 - samples/sec: 823.91 - lr: 0.001563\n","2022-02-16 19:47:51,928 ----------------------------------------------------------------------------------------------------\n","2022-02-16 19:47:51,934 EPOCH 45 done: loss 0.5268 - lr 0.0015625\n","2022-02-16 19:47:53,480 DEV : loss 0.44096407294273376 - score 0.6615\n","2022-02-16 19:47:53,563 BAD EPOCHS (no improvement): 3\n","2022-02-16 19:47:53,573 ----------------------------------------------------------------------------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"output_type":"stream","name":"stdout","text":["2022-02-16 19:47:54,824 epoch 46 - iter 1/19 - loss 0.71186548 - samples/sec: 152.55 - lr: 0.001563\n","2022-02-16 19:47:54,947 epoch 46 - iter 2/19 - loss 0.55600867 - samples/sec: 316.51 - lr: 0.001563\n","2022-02-16 19:47:55,072 epoch 46 - iter 3/19 - loss 0.52220347 - samples/sec: 407.75 - lr: 0.001563\n","2022-02-16 19:47:55,163 epoch 46 - iter 4/19 - loss 0.50536075 - samples/sec: 358.59 - lr: 0.001563\n","2022-02-16 19:47:55,261 epoch 46 - iter 5/19 - loss 0.47560291 - samples/sec: 337.28 - lr: 0.001563\n","2022-02-16 19:47:55,352 epoch 46 - iter 6/19 - loss 0.47029567 - samples/sec: 365.24 - lr: 0.001563\n","2022-02-16 19:47:55,431 epoch 46 - iter 7/19 - loss 0.48392784 - samples/sec: 425.41 - lr: 0.001563\n","2022-02-16 19:47:55,521 epoch 46 - iter 8/19 - loss 0.48087353 - samples/sec: 371.22 - lr: 0.001563\n","2022-02-16 19:47:55,596 epoch 46 - iter 9/19 - loss 0.50105459 - samples/sec: 474.53 - lr: 0.001563\n","2022-02-16 19:47:55,670 epoch 46 - iter 10/19 - loss 0.48890534 - samples/sec: 476.50 - lr: 0.001563\n","2022-02-16 19:47:55,746 epoch 46 - iter 11/19 - loss 0.49813335 - samples/sec: 430.84 - lr: 0.001563\n","2022-02-16 19:47:55,824 epoch 46 - iter 12/19 - loss 0.50949322 - samples/sec: 498.08 - lr: 0.001563\n","2022-02-16 19:47:55,900 epoch 46 - iter 13/19 - loss 0.49719145 - samples/sec: 442.62 - lr: 0.001563\n","2022-02-16 19:47:55,977 epoch 46 - iter 14/19 - loss 0.49825728 - samples/sec: 428.63 - lr: 0.001563\n","2022-02-16 19:47:56,059 epoch 46 - iter 15/19 - loss 0.49965404 - samples/sec: 435.51 - lr: 0.001563\n","2022-02-16 19:47:56,145 epoch 46 - iter 16/19 - loss 0.50749159 - samples/sec: 458.14 - lr: 0.001563\n","2022-02-16 19:47:56,218 epoch 46 - iter 17/19 - loss 0.51600791 - samples/sec: 519.93 - lr: 0.001563\n","2022-02-16 19:47:56,299 epoch 46 - iter 18/19 - loss 0.53151869 - samples/sec: 472.38 - lr: 0.001563\n","2022-02-16 19:47:56,350 epoch 46 - iter 19/19 - loss 0.53810026 - samples/sec: 715.19 - lr: 0.001563\n","2022-02-16 19:47:56,719 ----------------------------------------------------------------------------------------------------\n","2022-02-16 19:47:56,726 EPOCH 46 done: loss 0.5381 - lr 0.0015625\n","2022-02-16 19:47:58,226 DEV : loss 0.4422890543937683 - score 0.6462\n","Epoch    46: reducing learning rate of group 0 to 7.8125e-04.\n","2022-02-16 19:47:58,304 BAD EPOCHS (no improvement): 4\n","2022-02-16 19:47:58,335 ----------------------------------------------------------------------------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"output_type":"stream","name":"stdout","text":["2022-02-16 19:47:59,598 epoch 47 - iter 1/19 - loss 0.64706677 - samples/sec: 128.32 - lr: 0.000781\n","2022-02-16 19:47:59,741 epoch 47 - iter 2/19 - loss 0.57750469 - samples/sec: 342.20 - lr: 0.000781\n","2022-02-16 19:47:59,835 epoch 47 - iter 3/19 - loss 0.57924477 - samples/sec: 389.07 - lr: 0.000781\n","2022-02-16 19:47:59,921 epoch 47 - iter 4/19 - loss 0.55546237 - samples/sec: 377.35 - lr: 0.000781\n","2022-02-16 19:48:00,025 epoch 47 - iter 5/19 - loss 0.53134179 - samples/sec: 419.06 - lr: 0.000781\n","2022-02-16 19:48:00,124 epoch 47 - iter 6/19 - loss 0.51705708 - samples/sec: 425.78 - lr: 0.000781\n","2022-02-16 19:48:00,193 epoch 47 - iter 7/19 - loss 0.52816130 - samples/sec: 501.15 - lr: 0.000781\n","2022-02-16 19:48:00,270 epoch 47 - iter 8/19 - loss 0.53219099 - samples/sec: 424.97 - lr: 0.000781\n","2022-02-16 19:48:00,345 epoch 47 - iter 9/19 - loss 0.53252477 - samples/sec: 450.85 - lr: 0.000781\n","2022-02-16 19:48:00,416 epoch 47 - iter 10/19 - loss 0.52721831 - samples/sec: 469.59 - lr: 0.000781\n","2022-02-16 19:48:00,513 epoch 47 - iter 11/19 - loss 0.51250469 - samples/sec: 410.35 - lr: 0.000781\n","2022-02-16 19:48:00,598 epoch 47 - iter 12/19 - loss 0.49487428 - samples/sec: 491.22 - lr: 0.000781\n","2022-02-16 19:48:00,666 epoch 47 - iter 13/19 - loss 0.50160756 - samples/sec: 490.60 - lr: 0.000781\n","2022-02-16 19:48:00,737 epoch 47 - iter 14/19 - loss 0.50905745 - samples/sec: 469.94 - lr: 0.000781\n","2022-02-16 19:48:00,817 epoch 47 - iter 15/19 - loss 0.51328508 - samples/sec: 411.45 - lr: 0.000781\n","2022-02-16 19:48:00,885 epoch 47 - iter 16/19 - loss 0.52388546 - samples/sec: 493.30 - lr: 0.000781\n","2022-02-16 19:48:00,958 epoch 47 - iter 17/19 - loss 0.51014709 - samples/sec: 532.91 - lr: 0.000781\n","2022-02-16 19:48:01,033 epoch 47 - iter 18/19 - loss 0.52252324 - samples/sec: 491.85 - lr: 0.000781\n","2022-02-16 19:48:01,076 epoch 47 - iter 19/19 - loss 0.52796281 - samples/sec: 816.26 - lr: 0.000781\n","2022-02-16 19:48:01,405 ----------------------------------------------------------------------------------------------------\n","2022-02-16 19:48:01,409 EPOCH 47 done: loss 0.5280 - lr 0.0007813\n","2022-02-16 19:48:02,897 DEV : loss 0.44186848402023315 - score 0.6462\n","2022-02-16 19:48:02,974 BAD EPOCHS (no improvement): 1\n","2022-02-16 19:48:02,982 ----------------------------------------------------------------------------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"output_type":"stream","name":"stdout","text":["2022-02-16 19:48:04,184 epoch 48 - iter 1/19 - loss 0.54723370 - samples/sec: 138.95 - lr: 0.000781\n","2022-02-16 19:48:04,305 epoch 48 - iter 2/19 - loss 0.54059184 - samples/sec: 345.82 - lr: 0.000781\n","2022-02-16 19:48:04,397 epoch 48 - iter 3/19 - loss 0.60530959 - samples/sec: 406.60 - lr: 0.000781\n","2022-02-16 19:48:04,488 epoch 48 - iter 4/19 - loss 0.60508266 - samples/sec: 414.92 - lr: 0.000781\n","2022-02-16 19:48:04,584 epoch 48 - iter 5/19 - loss 0.57195516 - samples/sec: 384.20 - lr: 0.000781\n","2022-02-16 19:48:04,680 epoch 48 - iter 6/19 - loss 0.56318893 - samples/sec: 448.20 - lr: 0.000781\n","2022-02-16 19:48:04,771 epoch 48 - iter 7/19 - loss 0.56181363 - samples/sec: 402.30 - lr: 0.000781\n","2022-02-16 19:48:04,840 epoch 48 - iter 8/19 - loss 0.55806183 - samples/sec: 499.16 - lr: 0.000781\n","2022-02-16 19:48:04,909 epoch 48 - iter 9/19 - loss 0.55264315 - samples/sec: 480.88 - lr: 0.000781\n","2022-02-16 19:48:05,007 epoch 48 - iter 10/19 - loss 0.56429332 - samples/sec: 476.74 - lr: 0.000781\n","2022-02-16 19:48:05,083 epoch 48 - iter 11/19 - loss 0.57015389 - samples/sec: 453.79 - lr: 0.000781\n","2022-02-16 19:48:05,152 epoch 48 - iter 12/19 - loss 0.57900235 - samples/sec: 486.86 - lr: 0.000781\n","2022-02-16 19:48:05,229 epoch 48 - iter 13/19 - loss 0.57243207 - samples/sec: 429.62 - lr: 0.000781\n","2022-02-16 19:48:05,304 epoch 48 - iter 14/19 - loss 0.55627087 - samples/sec: 447.86 - lr: 0.000781\n","2022-02-16 19:48:05,370 epoch 48 - iter 15/19 - loss 0.55849793 - samples/sec: 511.98 - lr: 0.000781\n","2022-02-16 19:48:05,442 epoch 48 - iter 16/19 - loss 0.56459288 - samples/sec: 501.78 - lr: 0.000781\n","2022-02-16 19:48:05,522 epoch 48 - iter 17/19 - loss 0.55877067 - samples/sec: 479.93 - lr: 0.000781\n","2022-02-16 19:48:05,602 epoch 48 - iter 18/19 - loss 0.55399733 - samples/sec: 472.30 - lr: 0.000781\n","2022-02-16 19:48:05,646 epoch 48 - iter 19/19 - loss 0.53834849 - samples/sec: 809.50 - lr: 0.000781\n","2022-02-16 19:48:05,998 ----------------------------------------------------------------------------------------------------\n","2022-02-16 19:48:06,004 EPOCH 48 done: loss 0.5383 - lr 0.0007813\n","2022-02-16 19:48:07,482 DEV : loss 0.4419337213039398 - score 0.6462\n","2022-02-16 19:48:07,568 BAD EPOCHS (no improvement): 2\n","2022-02-16 19:48:07,578 ----------------------------------------------------------------------------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"output_type":"stream","name":"stdout","text":["2022-02-16 19:48:08,784 epoch 49 - iter 1/19 - loss 0.65897876 - samples/sec: 150.43 - lr: 0.000781\n","2022-02-16 19:48:08,899 epoch 49 - iter 2/19 - loss 0.56749387 - samples/sec: 322.67 - lr: 0.000781\n","2022-02-16 19:48:09,024 epoch 49 - iter 3/19 - loss 0.53362668 - samples/sec: 455.29 - lr: 0.000781\n","2022-02-16 19:48:09,118 epoch 49 - iter 4/19 - loss 0.55804448 - samples/sec: 351.51 - lr: 0.000781\n","2022-02-16 19:48:09,210 epoch 49 - iter 5/19 - loss 0.56640491 - samples/sec: 392.40 - lr: 0.000781\n","2022-02-16 19:48:09,306 epoch 49 - iter 6/19 - loss 0.59544508 - samples/sec: 347.52 - lr: 0.000781\n","2022-02-16 19:48:09,381 epoch 49 - iter 7/19 - loss 0.56373520 - samples/sec: 469.41 - lr: 0.000781\n","2022-02-16 19:48:09,455 epoch 49 - iter 8/19 - loss 0.55387973 - samples/sec: 470.57 - lr: 0.000781\n","2022-02-16 19:48:09,526 epoch 49 - iter 9/19 - loss 0.53073318 - samples/sec: 552.27 - lr: 0.000781\n","2022-02-16 19:48:09,603 epoch 49 - iter 10/19 - loss 0.55474638 - samples/sec: 433.49 - lr: 0.000781\n","2022-02-16 19:48:09,677 epoch 49 - iter 11/19 - loss 0.56771662 - samples/sec: 482.69 - lr: 0.000781\n","2022-02-16 19:48:09,755 epoch 49 - iter 12/19 - loss 0.55641013 - samples/sec: 489.73 - lr: 0.000781\n","2022-02-16 19:48:09,832 epoch 49 - iter 13/19 - loss 0.56814068 - samples/sec: 431.25 - lr: 0.000781\n","2022-02-16 19:48:09,905 epoch 49 - iter 14/19 - loss 0.56710622 - samples/sec: 501.68 - lr: 0.000781\n","2022-02-16 19:48:09,988 epoch 49 - iter 15/19 - loss 0.56185943 - samples/sec: 450.65 - lr: 0.000781\n","2022-02-16 19:48:10,066 epoch 49 - iter 16/19 - loss 0.56302558 - samples/sec: 476.12 - lr: 0.000781\n","2022-02-16 19:48:10,139 epoch 49 - iter 17/19 - loss 0.55948715 - samples/sec: 501.01 - lr: 0.000781\n","2022-02-16 19:48:10,212 epoch 49 - iter 18/19 - loss 0.55758170 - samples/sec: 503.20 - lr: 0.000781\n","2022-02-16 19:48:10,253 epoch 49 - iter 19/19 - loss 0.55210007 - samples/sec: 872.47 - lr: 0.000781\n","2022-02-16 19:48:10,595 ----------------------------------------------------------------------------------------------------\n","2022-02-16 19:48:10,597 EPOCH 49 done: loss 0.5521 - lr 0.0007813\n","2022-02-16 19:48:12,077 DEV : loss 0.4419242739677429 - score 0.6462\n","2022-02-16 19:48:12,165 BAD EPOCHS (no improvement): 3\n","2022-02-16 19:48:12,176 ----------------------------------------------------------------------------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"output_type":"stream","name":"stdout","text":["2022-02-16 19:48:13,397 epoch 50 - iter 1/19 - loss 0.51231670 - samples/sec: 155.56 - lr: 0.000781\n","2022-02-16 19:48:13,522 epoch 50 - iter 2/19 - loss 0.48443456 - samples/sec: 318.26 - lr: 0.000781\n","2022-02-16 19:48:13,618 epoch 50 - iter 3/19 - loss 0.58433377 - samples/sec: 391.18 - lr: 0.000781\n","2022-02-16 19:48:13,710 epoch 50 - iter 4/19 - loss 0.55408576 - samples/sec: 387.56 - lr: 0.000781\n","2022-02-16 19:48:13,812 epoch 50 - iter 5/19 - loss 0.56159067 - samples/sec: 417.69 - lr: 0.000781\n","2022-02-16 19:48:13,911 epoch 50 - iter 6/19 - loss 0.57416271 - samples/sec: 361.84 - lr: 0.000781\n","2022-02-16 19:48:13,995 epoch 50 - iter 7/19 - loss 0.57191757 - samples/sec: 467.81 - lr: 0.000781\n","2022-02-16 19:48:14,070 epoch 50 - iter 8/19 - loss 0.55970182 - samples/sec: 442.72 - lr: 0.000781\n","2022-02-16 19:48:14,141 epoch 50 - iter 9/19 - loss 0.53832448 - samples/sec: 479.48 - lr: 0.000781\n","2022-02-16 19:48:14,229 epoch 50 - iter 10/19 - loss 0.53277541 - samples/sec: 492.39 - lr: 0.000781\n","2022-02-16 19:48:14,303 epoch 50 - iter 11/19 - loss 0.54534243 - samples/sec: 448.63 - lr: 0.000781\n","2022-02-16 19:48:14,367 epoch 50 - iter 12/19 - loss 0.53187318 - samples/sec: 536.00 - lr: 0.000781\n","2022-02-16 19:48:14,454 epoch 50 - iter 13/19 - loss 0.52213255 - samples/sec: 518.88 - lr: 0.000781\n","2022-02-16 19:48:14,523 epoch 50 - iter 14/19 - loss 0.51711214 - samples/sec: 500.75 - lr: 0.000781\n","2022-02-16 19:48:14,594 epoch 50 - iter 15/19 - loss 0.51922765 - samples/sec: 459.36 - lr: 0.000781\n","2022-02-16 19:48:14,676 epoch 50 - iter 16/19 - loss 0.52258260 - samples/sec: 456.86 - lr: 0.000781\n","2022-02-16 19:48:14,753 epoch 50 - iter 17/19 - loss 0.52234302 - samples/sec: 447.18 - lr: 0.000781\n","2022-02-16 19:48:14,824 epoch 50 - iter 18/19 - loss 0.51979027 - samples/sec: 471.86 - lr: 0.000781\n","2022-02-16 19:48:14,869 epoch 50 - iter 19/19 - loss 0.52864026 - samples/sec: 787.40 - lr: 0.000781\n","2022-02-16 19:48:15,227 ----------------------------------------------------------------------------------------------------\n","2022-02-16 19:48:15,232 EPOCH 50 done: loss 0.5286 - lr 0.0007813\n","2022-02-16 19:48:16,723 DEV : loss 0.44122475385665894 - score 0.6462\n","Epoch    50: reducing learning rate of group 0 to 3.9063e-04.\n","2022-02-16 19:48:16,796 BAD EPOCHS (no improvement): 4\n","2022-02-16 19:48:32,450 ----------------------------------------------------------------------------------------------------\n","2022-02-16 19:48:32,454 Testing using best model ...\n","2022-02-16 19:48:32,468 loading file ../resources/stance-semeval2016/flair_Legalization of Abortion/best-model.pt\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"output_type":"stream","name":"stdout","text":["2022-02-16 19:48:53,129 \t0.5429\n","2022-02-16 19:48:53,132 \n","Results:\n","- F-score (micro) 0.5429\n","- F-score (macro) 0.5033\n","- Accuracy 0.5429\n","\n","By class:\n","              precision    recall  f1-score   support\n","\n","     AGAINST     0.7823    0.5132    0.6198       189\n","       FAVOR     0.3537    0.6304    0.4531        46\n","        NONE     0.3514    0.5778    0.4370        45\n","\n","   micro avg     0.5429    0.5429    0.5429       280\n","   macro avg     0.4958    0.5738    0.5033       280\n","weighted avg     0.6426    0.5429    0.5630       280\n"," samples avg     0.5429    0.5429    0.5429       280\n","\n","2022-02-16 19:48:53,136 ----------------------------------------------------------------------------------------------------\n"]},{"output_type":"execute_result","data":{"text/plain":["{'dev_loss_history': [0.9600419998168945,\n","  0.9189927577972412,\n","  0.8694517612457275,\n","  1.098806381225586,\n","  0.8332707285881042,\n","  0.9058871269226074,\n","  0.7443398237228394,\n","  0.7582077383995056,\n","  0.7327412366867065,\n","  0.7486989498138428,\n","  0.6811479926109314,\n","  0.6298842430114746,\n","  0.6540738344192505,\n","  0.5862265825271606,\n","  0.5597807765007019,\n","  0.549913227558136,\n","  0.5834924578666687,\n","  0.5070539712905884,\n","  0.48597466945648193,\n","  0.4741630554199219,\n","  0.5541121959686279,\n","  0.4988442659378052,\n","  0.45780307054519653,\n","  0.48881667852401733,\n","  0.478870689868927,\n","  0.4650909900665283,\n","  0.4946536719799042,\n","  0.4510049819946289,\n","  0.454130619764328,\n","  0.4586939811706543,\n","  0.4525681138038635,\n","  0.46014851331710815,\n","  0.4439447820186615,\n","  0.4495058059692383,\n","  0.44845616817474365,\n","  0.4431389570236206,\n","  0.44684600830078125,\n","  0.44397255778312683,\n","  0.44248485565185547,\n","  0.44025835394859314,\n","  0.44448575377464294,\n","  0.4486459493637085,\n","  0.4470093846321106,\n","  0.44366997480392456,\n","  0.44096407294273376,\n","  0.4422890543937683,\n","  0.44186848402023315,\n","  0.4419337213039398,\n","  0.4419242739677429,\n","  0.44122475385665894],\n"," 'dev_score_history': [0.4769,\n","  0.4615,\n","  0.4923,\n","  0.3846,\n","  0.4769,\n","  0.4462,\n","  0.4923,\n","  0.4615,\n","  0.5538,\n","  0.5231,\n","  0.5692,\n","  0.6,\n","  0.6615,\n","  0.5846,\n","  0.6154,\n","  0.5538,\n","  0.6308,\n","  0.6308,\n","  0.6308,\n","  0.6308,\n","  0.5538,\n","  0.6462,\n","  0.6308,\n","  0.6154,\n","  0.6923,\n","  0.7077,\n","  0.6615,\n","  0.6615,\n","  0.6615,\n","  0.6462,\n","  0.6462,\n","  0.6462,\n","  0.6769,\n","  0.6615,\n","  0.6462,\n","  0.6615,\n","  0.6615,\n","  0.6615,\n","  0.6615,\n","  0.6462,\n","  0.6462,\n","  0.6615,\n","  0.6615,\n","  0.6615,\n","  0.6615,\n","  0.6462,\n","  0.6462,\n","  0.6462,\n","  0.6462,\n","  0.6462],\n"," 'test_score': 0.5429,\n"," 'train_loss_history': [0.9795707605387035,\n","  0.9835759087612754,\n","  0.9520999663754514,\n","  0.9266839905789024,\n","  0.9251887453229803,\n","  0.8675542662018224,\n","  0.845112963726646,\n","  0.8395240118629054,\n","  0.7946131511738426,\n","  0.7891482365758795,\n","  0.7927255850089224,\n","  0.7272435301228574,\n","  0.7362854700339468,\n","  0.7142310738563538,\n","  0.6820143900419536,\n","  0.688836019290121,\n","  0.6799995146299663,\n","  0.6605405854551416,\n","  0.5984334051609039,\n","  0.6063380790384192,\n","  0.6016025935348711,\n","  0.5773313406266665,\n","  0.5898843266462025,\n","  0.5720752273735247,\n","  0.5574064333187906,\n","  0.5523084260915455,\n","  0.553244915447737,\n","  0.5529495273765764,\n","  0.5489993095397949,\n","  0.5851319981248755,\n","  0.5403324459728441,\n","  0.5427259771447432,\n","  0.5275420828869468,\n","  0.5410794992195932,\n","  0.5444605570090445,\n","  0.5299289618667803,\n","  0.5455640381888339,\n","  0.5364080996889817,\n","  0.540228955055538,\n","  0.5242456903583125,\n","  0.5457924102482042,\n","  0.5408575911270944,\n","  0.488091841340065,\n","  0.5085055012451974,\n","  0.526817113161087,\n","  0.5381002598687222,\n","  0.5279628132518969,\n","  0.5383484881175192,\n","  0.5521000749186465,\n","  0.528640257684808]}"]},"metadata":{},"execution_count":13}]},{"cell_type":"markdown","source":["## Comparison"],"metadata":{"id":"vr8mi3W057Ou"}},{"cell_type":"code","source":["import pandas as pd\n","names = ['Atheism', 'Climate Change is a Real Concern', 'Feminist Movement', 'Hillary Clinton', 'Legalization of Abortion']\n","scores = [0.5890, 0.3989, 0.3265, 0.6602, 0.5033]\n","favor = [0.3636, 0.8385, 0.1972, 0.5405, 0.4531]\n","against = [0.8649, 0.0000, 0.7824, 0.8031, 0.6198]\n","none = [0.5385, 0.3582, 0.0000, 0.6370, 0.4370]\n","pd_results = pd.DataFrame({\"target\": names, \"f1-macro\": scores, \"f1-favor\": favor, \"f1-against\": against, \"f1-none\": none})\n","pd_results"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"nBrZJL5m6AlD","executionInfo":{"status":"ok","timestamp":1645042854340,"user_tz":-60,"elapsed":18,"user":{"displayName":"Julen Etxaniz Aragoneses","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GilpYDAmorj7KFdjK26TlsyH_HhFWhLqmESeKoCGsI=s64","userId":"06956422670240182492"}},"outputId":"6cfd7712-91ea-493a-b116-b7f0f64a1737"},"execution_count":24,"outputs":[{"output_type":"execute_result","data":{"text/html":["\n","  <div id=\"df-5bb8d4da-7a36-46ba-bf55-a7159b451d32\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>target</th>\n","      <th>f1-macro</th>\n","      <th>f1-favor</th>\n","      <th>f1-against</th>\n","      <th>f1-none</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Atheism</td>\n","      <td>0.5890</td>\n","      <td>0.3636</td>\n","      <td>0.8649</td>\n","      <td>0.5385</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Climate Change is a Real Concern</td>\n","      <td>0.3989</td>\n","      <td>0.8385</td>\n","      <td>0.0000</td>\n","      <td>0.3582</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Feminist Movement</td>\n","      <td>0.3265</td>\n","      <td>0.1972</td>\n","      <td>0.7824</td>\n","      <td>0.0000</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Hillary Clinton</td>\n","      <td>0.6602</td>\n","      <td>0.5405</td>\n","      <td>0.8031</td>\n","      <td>0.6370</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Legalization of Abortion</td>\n","      <td>0.5033</td>\n","      <td>0.4531</td>\n","      <td>0.6198</td>\n","      <td>0.4370</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5bb8d4da-7a36-46ba-bf55-a7159b451d32')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-5bb8d4da-7a36-46ba-bf55-a7159b451d32 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-5bb8d4da-7a36-46ba-bf55-a7159b451d32');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["                             target  f1-macro  f1-favor  f1-against  f1-none\n","0                           Atheism    0.5890    0.3636      0.8649   0.5385\n","1  Climate Change is a Real Concern    0.3989    0.8385      0.0000   0.3582\n","2                 Feminist Movement    0.3265    0.1972      0.7824   0.0000\n","3                   Hillary Clinton    0.6602    0.5405      0.8031   0.6370\n","4          Legalization of Abortion    0.5033    0.4531      0.6198   0.4370"]},"metadata":{},"execution_count":24}]},{"cell_type":"code","source":["pd_results.plot.bar(x='target', y=[\"f1-macro\", \"f1-favor\", \"f1-against\", \"f1-none\"], figsize=(14,6))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":564},"id":"rGZ5eYko6SED","executionInfo":{"status":"ok","timestamp":1645042856579,"user_tz":-60,"elapsed":26,"user":{"displayName":"Julen Etxaniz Aragoneses","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GilpYDAmorj7KFdjK26TlsyH_HhFWhLqmESeKoCGsI=s64","userId":"06956422670240182492"}},"outputId":"cf5b69e7-b3b7-457a-a7cd-6458f6abf501"},"execution_count":25,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<matplotlib.axes._subplots.AxesSubplot at 0x7fd8851bfbd0>"]},"metadata":{},"execution_count":25},{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAzIAAAISCAYAAAAX7vqvAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOzde7hWdZ3//+ebk5iClmaOR9BRAUFAN2qp5am+MpZleZzshx00FTvoaGk1Zh5mbKbpZxZoaqNlTHkqv1amjYqlY6WAKAiigqhEHrJJPIGA7+8f973xBjeykfvea6+1n4/r2pf7Xmvda7823tfe+3Wvz/p8IjORJEmSpDLpVXQASZIkSVpbFhlJkiRJpWORkSRJklQ6FhlJkiRJpWORkSRJklQ6fYr6wptuumkOGjSoqC8vSZIkqZubOnXqXzLznR3tK6zIDBo0iClTphT15SVJkiR1cxHx+Or2ObRMkiRJUulYZCRJkiSVjkVGkiRJUukUdo+MJEmSVEZLly5lwYIFLF68uOgoldG/f3+22mor+vbt2+nnWGQkSZKktbBgwQIGDBjAoEGDiIii45ReZvLcc8+xYMECBg8e3OnnObRMkiRJWguLFy9mk002scQ0SUSwySabrPUVLouMJEmStJYsMc31Vv49LTKSJEmSSsd7ZCRJkqR1MOiMXzX1fPMvOHiNx1x00UVcfPHFDBs2jIULFzJt2jTOP/98TjvttKZm6c4sMpIkSVLJTJw4kVtvvZV+/frx+OOPc8MNNxSaZ9myZfTp07XVwqFlkiRJUomccMIJzJs3j7FjxzJp0iTGjBmzxmmLzz77bMaNG8c+++zDtttuy89+9jO+9KUvMWLECA466CCWLl0KwDnnnMOYMWMYPnw4xx9/PJkJwKOPPsqBBx7IyJEj2XXXXZk7dy533HEH++yzD4cccgjDhg1j8eLFfPKTn2TEiBGMHj2ayZMnt/TfwSIjSZIklcgll1zCFltsweTJkznllFM6/by5c+dy++23c+ONN3LMMcew3377MWPGDNZff31+9ava8LiTTz6Ze++9l5kzZ/LKK6/wy1/+EoCPf/zjjB8/nvvvv5+7776bv/u7vwNg2rRpfOc73+Hhhx9mwoQJRAQzZszgJz/5CePGjWvpWjsWGUmSJKkHGDt2LH379mXEiBEsX76cgw46CIARI0Ywf/58ACZPnswee+zBiBEjuP3223nwwQd54YUX+NOf/sShhx4K1BavfNvb3gbA7rvvvmLtl7vuuotjjjkGgCFDhrDtttvy8MMPt+z7schIkiRJFTNhwgRGjRrFqFGjWLhwIQDrrbceAL169aJv374rpjzu1asXy5YtY/HixZx00klcd911zJgxg+OOO26NV1Q22GCD1n4jb8Kb/UtmxA9HNPV8M8bNaOr5JEmSVLzx48czfvz4tXpOe2nZdNNNefHFF7nuuus47LDDGDBgAFtttRU33HADH/nIR1iyZAnLly9/w/P32WcfJk2axP7778/DDz/ME088wU477dSU76cjFhlJkiRpHXRmuuRWeeqpp2hra2PRokX06tWLCy+8kFmzZjFw4MC1PtfGG2/Mcccdx/Dhw9l8880ZM2bMin1XXXUVn/3sZznrrLPo27cv11577Ruef9JJJ3HiiScyYsQI+vTpw5VXXrniKlArRPtMBF2tra0tp0yZUsjXLjOvyEiSJBVr9uzZDB06tOgYldPRv2tETM3Mto6O9x4ZSZIkSaVjkZEkSZJUOhYZSZIkSaVjkZEkSZJUOhYZSZIkSaVjkZEkSZJUOq4jI1XN2Rs18VzPN+9ckiRVVTN/90Knfv9edNFFXHzxxQwbNoyFCxcybdo0zj//fE477bQOj1+yZAkHH3wwf/nLXzjzzDM58sgjm5u5ABYZSZIkqWQmTpzIrbfeSr9+/Xj88ce54YYb3vT4++67D4Dp06e3LNPy5cvp3bt3y86/KoeWSZIkSSVywgknMG/ePMaOHcukSZMYM2YMffv2Xe3xzzzzDMcccwz33nsvo0aNYu7cuZxzzjmMGTOG4cOHc/zxx5OZPPTQQ+y+++4rnjd//nxGjKgtxn7bbbcxevRoRowYwac+9SmWLFkCwKBBg/jyl7/MrrvuyrXXXtvab3wVFhlJkiSpRC655BK22GILJk+ezCmnnLLG4zfbbDMuv/xy9tlnH6ZPn87222/PySefzL333svMmTN55ZVX+OUvf8mQIUN49dVXeeyxxwC4+uqrOfLII1m8eDHHHnssV199NTNmzGDZsmVcfPHFK86/ySabMG3aNI466qiWfc8dschIkiRJPczkyZPZY489GDFiBLfffjsPPvggAEcccQRXX3018HqRmTNnDoMHD2bHHXcEYNy4cfzud79bca6i7rexyEiSJEkVM2HCBEaNGsWoUaNYuHDhSvsWL17MSSedxHXXXceMGTM47rjjWLx4MVArJddccw0PP/wwEcEOO+ywxq+1wQYbtOR7WBOLjCRJklQx48ePZ/r06UyfPp0ttthipX3tpWXTTTflxRdf5Lrrrluxb/vtt6d3796ce+65K6607LTTTsyfP59HH30UgKuuuor3ve99XfSdrJ6zlkmSJEnrosDlCp566ina2tpYtGgRvXr14sILL2TWrFkMHDhwtc/ZeOONOe644xg+fDibb745Y8aMWWn/kUceyemnn77iXpn+/ftzxRVXcPjhh7Ns2TLGjBnDCSec0NLvqzMiMwv5wm1tbTllypRCvnaZjfjhiKaeb8a4GU09n7oB15GRJKmlZs+ezdChQ4uOUTkd/btGxNTMbOvoeIeWSZIkSSodi4wkSZKk0ulUkYmIgyJiTkQ8GhFndLB/m4iYHBH3RcQDEfEPzY8qSZIkSTVrLDIR0RuYAIwFhgFHR8SwVQ77GnBNZo4GjgImNjuoJEmSJLXrzKxluwOPZuY8gIj4KfBhYFbDMQm0T42wEbDyZNWSJEndTDMn0HHyHKnrdWZo2ZbAkw2PF9S3NTobOCYiFgA3AZ/r6EQRcXxETImIKc8+++xbiCtJkiRJzVtH5mjgysz8j4h4N3BVRAzPzNcaD8rMS4FLoTb9cpO+tiRJklSYIpbHuOiii7j44osZNmwYCxcuZNq0aZx//vmcdtppTc3Skc985jOceuqpDBu26t0mb2769OksXLiQf/iH5txO35ki8ydg64bHW9W3Nfo0cBBAZv4+IvoDmwLPNCOkJEmSpNdNnDiRW2+9lX79+vH4449zww03dNnXvvzyy9/S86ZPn86UKVOaVmQ6M7TsXmCHiBgcEf2o3cx/4yrHPAEcABARQ4H+gGPHJEmSpCY74YQTmDdvHmPHjmXSpEmMGTOGvn37vulz7rnnHt797nczevRo3vOe9zBnzhwAXn75ZY444giGDRvGoYceyh577EH7ovUnnngibW1t7Lzzznz9619fca599913xTEbbrghX/3qVxk5ciR77rknTz/9NADXXnstw4cPZ+TIkbz3ve/l1Vdf5ayzzuLqq69m1KhRXH311ev877DGKzKZuSwiTgZuAXoD/5mZD0bEOcCUzLwR+Cfgsog4hdqN/8dmpkPHJEmSpCa75JJLuPnmm5k8eTKbbrppp54zZMgQ7rzzTvr06cOtt97KV77yFa6//nomTpzI29/+dmbNmsXMmTMZNWrUiuecf/75vOMd72D58uUccMABPPDAA+yyyy4rnfell15izz335Pzzz+dLX/oSl112GV/72tc455xzuOWWW9hyyy3529/+Rr9+/TjnnHOYMmUK3/ve95ry79Cpe2Qy8yZqN/E3bjur4fNZwF5NSSRJkiSpqZ5//nnGjRvHI488QkSwdOlSAO666y6+8IUvADB8+PCViso111zDpZdeyrJly/jzn//MrFmz3lBk+vXrxwc/+EEAdtttN/77v/8bgL322otjjz2WI444go9+9KMt+Z46tSCmJEmSpPKYMGECo0aNYtSoUSxcuJB//ud/Zr/99mPmzJn84he/YPHixW/6/Mcee4xvfetb3HbbbTzwwAMcfPDBHT6nb9++RAQAvXv3ZtmyZUDtqtF5553Hk08+yW677cZzzz3X9O+xWbOWSZK0zlzXQ5KaY/z48YwfP37F4+eff54tt6ytoHLllVeu2L7XXntxzTXXsN9++zFr1ixmzKj97Fy0aBEbbLABG220EU8//TS//vWv2XfffTv99efOncsee+zBHnvswa9//WuefPJJBgwYwAsvvNCU7w8sMpIkSdI6KfKNk6eeeoq2tjYWLVpEr169uPDCC5k1axYDBw5c6bgvfelLjBs3jvPOO4+DDz54xfaTTjqJcePGMWzYMIYMGcLOO+/MRhttxA477MDo0aMZMmQIW2+9NXvttXZ3kZx++uk88sgjZCYHHHAAI0eOZJtttuGCCy5g1KhRnHnmmRx55JHr9L1HUffkt7W1ZftsB+q8IuYpV8mcvVETz/V8884ldYJXZNSVfL3prZo9ezZDhw4tOkZTLF++nKVLl9K/f3/mzp3LgQceyJw5c+jXr1+XZ+no3zUipmZmW0fHe0VGkiRJ6qFefvll9ttvP5YuXUpmMnHixEJKzFthkZEkSZJ6qAEDBlDWUVLOWiZJkiSpdCwykiRJkkrHIiNJkiSpdCwykiRJkkrHm/0lSZKkdTB7SHOnYh760Ow1HnPRRRdx8cUXM2zYMBYuXMi0adM4//zzOe2005qapTuzyEiSJEklM3HiRG699Vb69evH448/zg033FB0pC7n0DJJkiSpRE444QTmzZvH2LFjmTRpEmPGjKFv375v+pyzzz6bT33qU+y7775st912XHTRRSv2ffvb32b48OEMHz6cCy+8EID58+czdOhQjjvuOHbeeWc+8IEP8MorrwAwd+5cDjroIHbbbTf22WcfHnroodZ9s2/CIiNJkiSVyCWXXMIWW2zB5MmTOeWUUzr9vIceeohbbrmFe+65h2984xssXbqUqVOncsUVV/DHP/6RP/zhD1x22WXcd999ADzyyCOMHz+eBx98kI033pjrr78egOOPP57vfve7TJ06lW9961ucdNJJLfk+18ShZZIkSVIPcPDBB7Peeuux3nrrsdlmm/H0009z1113ceihh7LBBhsA8NGPfpQ777yTQw45hMGDBzNq1CgAdtttN+bPn8+LL77I3XffzeGHH77ivEuWLCnk+7HISJIkSRUzYcIELrvsMgBuuukmANZbb70V+3v37s2yZcve9ByrHv/KK6/w2muvsfHGGzN9+vQWpF47Di2TJEmSKmb8+PFMnz6d6dOns8UWW6z2uH322YcbbriBl19+mZdeeomf//zn7LPPPqs9fuDAgQwePJhrr70WgMzk/vvvb3r+zvCKjCRJkrQOOjNdcqs89dRTtLW1sWjRInr16sWFF17IrFmzGDhwYKeev+uuu3Lsscey++67A/CZz3yG0aNHM3/+/NU+Z9KkSZx44omcd955LF26lKOOOoqRI0c249tZKxYZSZIkqWQai8aCBQvWePzZZ5+90uOZM2eu+PzUU0/l1FNPXWn/oEGDVjqmcX2awYMHc/PNN69l4uZzaJkkSZKk0rHISJIkSSodi4wkSZK0ljKz6AiV8lb+PS0ykiRJ0lro378/zz33nGWmSTKT5557jv79+6/V87zZX5IkSVoLW221FQsWLODZZ58tOkpl9O/fn6222mqtnmORkSRJktZC3759GTx4cNExejyHlkmSJEkqHYuMJEmSpNKxyEiSJEkqHYuMJEmSpNKxyEiSJEkqHYuMJEmSpNKxyEiSJEkqHYuMJEmSpNKxyEiSJEkqHYuMJEmSpNKxyEiSJEkqHYuMJEmSpNKxyEiSJEkqHYuMJEmSpNKxyEiSJEkqHYuMJEmSpNKxyEiSJEkqHYuMJEmSpNKxyEiSJEkqnT5FB5AkSdU16IxfNe1c8y84uGnnklR+XpGRJEmSVDoWGUmSJEmlY5GRJEmSVDoWGUmSJEmlY5GRJEmSVDoWGUmSJEmlY5GRJEmSVDoWGUmSJEml44KYkiRJ62j2kKFNPd/Qh2Y39XxSFXlFRpIkSVLpWGQkSZIklY5FRpIkSVLpWGQkSZIklY5FRpIkSVLpOGuZJEmS1GIjfjiiqeebMW5GU89XRl6RkSRJklQ6FhlJkiRJpWORkSRJklQ6nSoyEXFQRMyJiEcj4ozVHHNERMyKiAcj4r+aG1OSJEmSXrfGm/0jojcwAXg/sAC4NyJuzMxZDcfsAJwJ7JWZ/xsRm7UqsCRJkiR15orM7sCjmTkvM18Ffgp8eJVjjgMmZOb/AmTmM82NKUmSJEmv60yR2RJ4suHxgvq2RjsCO0bE/0TEHyLioI5OFBHHR8SUiJjy7LPPvrXEkiRJknq8Zt3s3wfYAdgXOBq4LCI2XvWgzLw0M9sys+2d73xnk760JEmSpJ6mM0XmT8DWDY+3qm9rtAC4MTOXZuZjwMPUio0kSZIkNV1nisy9wA4RMTgi+gFHATeucswN1K7GEBGbUhtqNq+JOSVJkiRphTXOWpaZyyLiZOAWoDfwn5n5YEScA0zJzBvr+z4QEbOA5cDpmflcK4O30qAzftXU882/4OCmnk+SJEnq6dZYZAAy8ybgplW2ndXweQKn1j8kSZIkqaWadbO/JEmSJHUZi4wkSZKk0rHISJIkSSodi4wkSZKk0rHISJIkSSodi4wkSZKk0rHISJIkSSodi4wkSZKk0rHISJIkSSodi4wkSZKk0rHISJIkSSodi4wkSZKk0rHISJIkSSodi4wkSZKk0rHISJIkSSqdPkUHkCRJ6pSzN2ru+QZv09zzSepSFpkebvaQoU0719CHZjftXJIkSdKbcWiZJEmSpNKxyEiSJEkqHYuMJEmSpNKxyEiSJEkqHYuMJEmSpNKxyEiSJEkqHYuMJEmSpNKxyEiSJEkqHYuMJEmSpNKxyEiSJEkqHYuMJEmSpNKxyEiSJEkqnT5FB5AkSZKaYdAZv2rq+eZfcHBTz6fm8oqMJEmSpNKxyEiSJEkqHYuMJEmSpNKxyEiSJEkqHYuMJEmSpNKxyEiSJEkqHYuMJEmSpNKxyEiSJEkqHYuMJEmSpNKxyEiSJEkqHYuMJEmSpNKxyEiSJEkqHYuMJEmSpNKxyEiSJEkqHYuMJEmSpNKxyEiSJEkqHYuMJEmSpNLpU3QASZIkqVs6e6PmnWvwNs07lwCvyEiSJEkqIYuMJEmSpNKxyEiSJEkqHYuMJEmSpNKxyEiSJEkqHWctkyRJkkpm9pChTTvX0IdmN+1cXckrMpIkSZJKxyIjSZIkqXQsMpIkSZJKxyIjSZIkqXQsMpIkSZJKxyIjSZIkqXQsMpIkSZJKxyIjSZIkqXQsMpIkSZJKp1NFJiIOiog5EfFoRJzxJsd9LCIyItqaF1GSJEmSVrbGIhMRvYEJwFhgGHB0RAzr4LgBwBeAPzY7pCRJkiQ16swVmd2BRzNzXma+CvwU+HAHx50LfBNY3MR8kiRJkvQGfTpxzJbAkw2PFwB7NB4QEbsCW2fmryLi9NWdKCKOB44H2GabbdY+rVRBg874VVPPN79/U08nSZLULa3zzf4R0Qv4NvBPazo2My/NzLbMbHvnO9+5rl9akiRJUg/VmSLzJ2Drhsdb1be1GwAMB+6IiPnAnsCN3vAvSZIkqVU6U2TuBXaIiMER0Q84CrixfWdmPp+Zm2bmoMwcBPwBOCQzp7QksSRJkqQeb41FJjOXAScDtwCzgWsy88GIOCciDml1QEmSJElaVWdu9iczbwJuWmXbWas5dt91jyVJkiRJq7fON/tLkiRJUlezyEiSJEkqHYuMJEmSpNKxyEiSJEkqHYuMJEmSpNKxyEiSJEkqHYuMJEmSpNLp1DoyWkdnb9S8cw3epnnnkiRJkkrKKzKSJEmSSscrMpK6zOwhQ5t2rqEPzW7auSRJUvl4RUaSJElS6VhkJEmSJJWORUaSJElS6VhkJEmSJJWORUaSJElS6VhkJEmSJJWORUaSJElS6VhkJEmSJJWORUaSJElS6VhkJEmSJJVOn6IDSJK61qAzftW0c82/4OCmnUuSpLXhFRlJkiRJpWORkSRJklQ6FhlJkiRJpWORkSRJklQ6FhlJkiRJpWORkSRJklQ6FhlJkiRJpWORkSRJklQ6FhlJkiRJpWORkSRJklQ6FhlJkiRJpWORkSRJklQ6FhlJkiRJpWORkSRJklQ6FhlJkiRJpWORkSRJklQ6FhlJkiRJpWORkSRJklQ6FhlJkiRJpWORkSRJklQ6FhlJkiRJpWORkSRJklQ6FhlJkiRJpWORkSRJklQ6FhlJkiRJpWORkSRJklQ6FhlJkiRJpWORkSRJklQ6FhlJkiRJpWORkSRJklQ6FhlJkiRJpWORkSRJklQ6FhlJkiRJpWORkSRJklQ6FhlJkiRJpWORkSRJklQ6FhlJkiRJpWORkSRJklQ6FhlJkiRJpWORkSRJklQ6FhlJkiRJpWORkSRJklQ6nSoyEXFQRMyJiEcj4owO9p8aEbMi4oGIuC0itm1+VEmSJEmqWWORiYjewARgLDAMODoihq1y2H1AW2buAlwH/Fuzg0qSJElSu85ckdkdeDQz52Xmq8BPgQ83HpCZkzPz5frDPwBbNTemJEmSJL2uM0VmS+DJhscL6ttW59PArzvaERHHR8SUiJjy7LPPdj6lJEmSJDXo08yTRcQxQBvwvo72Z+alwKUAbW1t2cyvLUkqwNkbNfd8g7dp7vkkSZXVmSLzJ2Drhsdb1betJCIOBL4KvC8zlzQnniRJkiS9UWeGlt0L7BARgyOiH3AUcGPjARExGvg+cEhmPtP8mJIkSZL0ujUWmcxcBpwM3ALMBq7JzAcj4pyIOKR+2L8DGwLXRsT0iLhxNaeTJEmSpHXWqXtkMvMm4KZVtp3V8PmBTc4lSZIkSavVqQUxJUmSJKk7schIkiRJKh2LjCRJkqTSschIkiRJKh2LjCRJkqTSschIkiRJKh2LjCRJkqTSschIkiRJKh2LjCRJkqTSschIkiRJKh2LjCRJkqTSschIkiRJKh2LjCRJkqTSschIkiRJKh2LjCRJkqTSschIkiRJKh2LjCRJkqTSschIkiRJKh2LjCRJkqTSschIkiRJKh2LjCRJkqTSschIkiRJKh2LjCRJkqTSschIkiRJKh2LjCRJkqTSschIkiRJKh2LjCRJkqTSschIkiRJKh2LjCRJkqTSschIkiRJKh2LjCRJkqTSschIkiRJKh2LjCRJkqTSschIkiRJKh2LjCRJkqTSschIkiRJKh2LjCRJkqTSschIkiRJKh2LjCRJkqTSschIkiRJKh2LjCRJkqTSschIkiRJKh2LjCRJkqTSschIkiRJKh2LjCRJkqTSschIkiRJKh2LjCRJkqTSschIkiRJKh2LjCRJkqTSschIkiRJKh2LjCRJkqTSschIkiRJKh2LjCRJkqTSschIkiRJKh2LjCRJkqTSschIkiRJKh2LjCRJkqTSschIkiRJKh2LjCRJkqTSschIkiRJKh2LjCRJkqTSschIkiRJKp1OFZmIOCgi5kTEoxFxRgf714uIq+v7/xgRg5odVJIkSZLarbHIRERvYAIwFhgGHB0Rw1Y57NPA/2bm3wP/P/DNZgeVJEmSpHaduSKzO/BoZs7LzFeBnwIfXuWYDwM/rH9+HXBARETzYkqSJEnS6zpTZLYEnmx4vKC+rcNjMnMZ8DywSTMCSpIkSdKq+nTlF4uI44Hj6w9fjIg5Xfn1i9LcS1MzNwX+0qyzrTpGcJ14Ea5baOr/hW9EU19vTeXrrVto/v+F5v2Mi2N9jVRNd369NfX3Kfgzrpvwb7huYdvV7ehMkfkTsHXD463q2zo6ZkFE9AE2Ap5b9USZeSlwaSe+plYjIqZkZlvROdQz+HpTV/M1p67k601dyddb83VmaNm9wA4RMTgi+gFHATeucsyNwLj654cBt2dmNi+mJEmSJL1ujVdkMnNZRJwM3AL0Bv4zMx+MiHOAKZl5I/AD4KqIeBT4K7WyI0mSJEkt0al7ZDLzJuCmVbad1fD5YuDw5kbTajg0T13J15u6mq85dSVfb+pKvt6aLBwBJkmSJKlsOnOPjCRJkiR1KxYZSZIkSaVjkZEkFSYirurMNkmSVtWlC2LqrYuIgTT8/8rMvxYYRxUWEe8BBrHy6+1HhQVS1e3c+CAiegO7FZRFFRcROwKnU1tgr/Fn3P6FhVJlRcR6wMd44+/Uc4rKVDUWmW4uIj4LfANYDLTPzJDAdoWFUmXV3wnfHpgOLK9vTsAio6aKiDOBrwDrR8Si9s3Aqzizj1rnWuAS4DJe/xkntcr/BZ4HpgJLCs5SSc5a1s1FxCPAuzPzL0VnUfVFxGxgmAvaqqtExL9m5plF51DPEBFTM9MrfuoSETEzM4cXnaPKvCLT/c0FXi46hHqMmcDmwJ+LDqKeITPPjIgteeNQn98Vl0oV9ouIOAn4OQ3vkDtcWy1yd0SMyMwZRQepKq/IdHMRMRq4AvgjK//Q/XxhoVRZETEZGAXcw8qvt0MKC6VKi4gLgKOAWTQMZ/Q1p1aIiMc62JyZ6XBtNV1EzAL+HniM2u/UoPZ626XQYBVikenmIuIe4C5gBvBa+/bM/GFhoVRZEfG+jrZn5m+7Oot6hoiYA+ySmY4fl1QpEbFtR9sz8/GuzlJVDi3r/vpm5qlFh1D11WeL+n5mDik6i3qUeUBfvBFWXSAi+gInAu+tb7qD2s+9pYWFUmVl5uMRMRLYp77pzsy8v8hMVWOR6f5+HRHHA7/A8bxqocxcHhFzImKbzHyi6DzqMV4GpkfEbTh8Vq13MbXiPLH++BP1bZ8pLJEqKyK+ABwH/Ky+6ccRcWlmfrfAWJXi0LJuzvG86koR8TtgNLV7ZF5q3+79CmqViBjX0XaHz6oVIuL+zBy5pm1SM0TEA9Rmnn2p/ngD4PfeI9M8XpHp5jJzcNEZ1KP8c9EB1LNk5g8jYn1gm8ycU3QeVd7yiNg+M+cCRMR2uJ6MWidY+fW1vL5NTWKR6eYi4nDg5sx8ISK+BuwKnJuZ9xUcTRWUmb+t35y4Q2beGhFvA3oXnUvVFREfAr4F9HdxxmgAABypSURBVAMGR8Qo4ByvAqpFTgcmR8Q8an9Qbgt8qthIqrArgD9GxM/rjz8C/KDAPJXj0LJuLiIeyMxdImJv4Dzg34GzMnOPgqOpgiLiOOB44B2ZuX1E7ABckpkHFBxNFRURU4H9gTsyc3R9m4vIqSUiYr36pzvV/zsHwFnz1CoRsSuwd/3hnb4R3Vy9ig6gNWq/JHkwcGlm/oraO5dSK4wH9gIWAWTmI8BmhSZS1S3NzOdX2fZah0dK6+73mbkkMx+ofywBfl90KFVLRAys//cdwHzgx/WPx+vb1CQOLev+/hQR3wfeD3yz/m6SBVStsiQzX42oDeGNiD6Al23VSg9GxD8CvetXAD8P3F1wJlVMRGwObAmsX19ouv0+hYHA2woLpqr6L+CDwFRW/h0a9cdO2NQkDi3r5ur3KBwEzMjMRyLi74ARmfmbgqOpgiLi34C/Af8f8DngJGBWZn610GCqrPrPuK8CH6D2S/4WavcBLi40mCqlPjvesUAbMKVh1wvAlZn5s46eJ6l7s8h0UxExMDMXre4SpOvIqBUiohfwaVb+o/Ly9AeFpAqIiI9l5vVF51DPEBG3rXqPaUfb9NZZZLqpiPhlZn6wvo5MsvJ0fa4jo5aoz3G/ODOX1x/3BtbLzJeLTaaqiog24CvAIBqGO7vOglqhPjz7Y7zx9XZOUZlUPRHRn9qQxcnAvqw8lPHmzBxSULTK8R6ZbiozP1j/r+vIqCvdBhwIvFh/vD7wG+A9hSVS1U2iNiXuDLzJX633f4Hnqd274ExlapXPAl8EtqD2WmsvMouA7xUVqoq8ItPNRe2u648DgzPz3IjYBtg8M+8pOJoqKCKmZ+aoNW2TmiUi7srMvdd8pLTunNpbXaU+ouErmXlu0VmqzNmvur+JwLuBf6w/fgGYUFwcVdxL9TnvAYiI3YBXCsyj6vt6RFweEUdHxEfbP4oOpcq6OyJGFB1C1Vcfou3PshZzaFn3t0dm7hoR9wFk5v9GhOvIqFW+CFwbEQupXQrfHDiy2EiquE8CQ4C+vD60LAFnkVIr7A0cW7//dAn16XC9J0stcltEfAz4mZPmtIZFpvtbWr88mQAR8U4cR64Wycx7I2IIDateZ+bSIjOp8sZk5k5rPkxqirFFB1CP8lngVGB5RLzC68V5YLGxqsMi0/1dBPwc2CwizgcOA75WbCRV3Bhen9Fn14ggM39UbCRV2N0RMSwzZxUdRNXVvqQBteHZUpfIzAFFZ6g6b/Yvgfo75AdQa/K3ZebsgiOpoiLiKmB7YDqwvL45M/PzxaVSlUXEbGqvOYf6qGVc0kBFiYhDgPfWH96Rmb8sMk/VWGRKoD607F2sPOf9E8UlUlXV/6gc5lhedZWI2Laj7Zn5eFdnkaRmiogLqI1ymFTfdDQwJTPPLC5VtVhkurmI+BzwdeBpau+Q+26lWiYirgU+n5l/LjqLeo6I2BvYITOvqN8HuGFmPlZ0LlVH42yMHcnMaV2VRT1HRDwAjMrM1+qPewP3+Tdc83iPTPf3BWCnzHyu6CDqETYFZkXEPTQsFpeZhxQXSVUWEV8H2qhNMHEFtdnLfgzsVWQuVc5/vMm+BPbvqiDqcTYG/lr/fKMig1SRRab7e5LaKsRSVzi76ADqcQ4FRgPTADJzYUR4g6yaKjP3KzqDeqR/Be6LiMnURtS8Fzij2EjVYpHppiLi1Pqn84A7IuJXrPwO+bcLCaZKy8zfRsS7qI3pBbgnM58pMpMq79XMzIhon2J+g6IDqXoi4hhqw+mvWmX7J4DlmflfxSRTlWXmTyLiDmq/UxP4cmY+VWyqaulVdACt1oD6xxPAfwP9GrZtWGAuVVhEHAHcAxwOHAH8MSIOKzaVKu6aiPg+sHFEHAfcClxWcCZVz+eoLWWwqp8B/9TFWdSzvBvYt/7x7kKTVJA3+3dzEXF4Zl67pm1SM0TE/cD726/C1G+8vjUzRxabTFUWEe8HPkBt6MUtmfnfBUdSxUTEtMzs8Ib/iHjAm6/VChExEfh74Cf1TUcCczNzfHGpqsUi08119MP3zX4gS+siImZk5oiGx72A+xu3Sc1UH0Z7dWb+qegsqq761PJtmfnSKtsHAPdm5pBikqnKIuIhYGj7kgb136kPZubQYpNVh/fIdFMRMRb4B2DLiLioYdcAYGkxqdQD3BwRt7Dyu0e/LjCPqm8A8JuI+CtwNXBtZj5dcCZVzw+A6yLihPY1iiJiEDChvk9qhUeBbYD2dbG2rm9Tk3hFppuKiJHUZvL5BnBWw65tgXd5WVKtEhEfBfauP7wzMzsaVy41VUTsQq04fwxYkJkHFhxJFRMRJwBn8vp9pi8CF2TmxcWlUhVFxC+o3dy/EbUb/e+pP96D2iQ6+xaXrlosMt1cRPQFhgP/SO0G7MeA6zPze4UGU6VExN9TK8j/s8r2vYE/Z+bcYpKpp4iIzan9jDsKGOA9C2qV9um9M/OForOomiLifW+yOzPzd10WpuIcWtZNRcSOwNH1j79QG3IRzoWvFrmQ2juVq3q+vu9DXRtHPUVEnERthrx3AtcCx2XmrGJTqcosMGq1zPxtR9vrbw4eDVhkmsQi0309BNwJfDAzHwWIiFOKjaQKe1dmzlh1Y2bOqI8jl1pla+CLmTm96CCS1GwRMZpVRtUUm6haLDLd10epDbGYHBE3Az+lNjWp1Aobv8m+9bsshXqczDwzIkZGxMn1TXdm5v2FhpKkdeComq7jgpjdVGbekJlHAUOAycAXgc0i4uKI+ECx6VRBU+qLEa4kIj4DTC0gj3qIiPg8MAnYrP7x44j4XLGpVFURMTUixkfE24vOokp7CNif2qiavTPzu8DygjNVkjf7l0j9B+/hwJGZeUDReVQdEfEuaqtev8rrxaUN6AccmplPFZVN1RYRDwDvbl/fIyI2AH7vzf5qhfrEJp+kNkPeFOAK4DfpH0Nqooj4CLVRNXsB7aNqLs/MwYUGqyCLjKQVImI/arPkQW3RrtuLzKPqi4gZwJjMXFx/3J/aAoUuwqqWqS9M+EHgYmrvlF8BfCcz/1poMFVK/Y2ZD1MbYrY/8CPg55n5m0KDVYhFRpJUmIg4FRhH7YogwEeAKzPzwuJSqcrqaxZ9ktqi07dQG9q4N/CJzBxVZDZVl6NqWsMiI0kqVETsysqLsN5XZB5VV0RMBf4G/IDammxLGvb9LDM/Wlg4SWvNIiNJ6nIR8Y432+8QHzVbfTjZGZn5L0VnkdQcFhlJUpeLiNeABcCy9k0NuzMzt+v6VKq6iJiSmW1F51C1RcR6jVf71DoWGUlExAtARz8MgtoflQO7OJIqLiIuBPYD/gf4CXCXM0ep1SLiAl5f1+Ol9u1eAVQzRcS0zNw1Iq7KzE8UnafKLDKSpEJERAD7UpvRZ3fgN8DFmflYkblUXRHR0WvLK4BqqoiYCfwLcC5w+qr7M/NnXR6qovoUHUBS9xMRmwH92x9n5hMFxlFF1a/ATI6I+6ituXAu8AhwWaHBVFmu46EucgLwcWBj4EOr7EvAItMkXpGRtEJEHAL8B7AF8AywLTA7M3cuNJgqp2F9hSOBd1L7xX6NpVmtFhHDgWGs/GbNj4pLpKqKiE9n5g+KzlFlFhlJK0TE/dQW7bo1M0fXF8g8JjM/XXA0VUxEvETt6stP6/9d6ZeRQy/UChHxdWrDGYcBNwFjqd2fdViRuVRNEdGP2tWZ99Y3/Ra4JDOXFpeqWiwyklZon9GnXmhGZ+ZrEXF/Zo4sOpuqJSKupOMJJqA26uxTXRhHPUREzABGAvdl5siIeBfw48x8f8HRVEERcTnQF/hhfdMngOWZ+ZniUlWL98hIavS3iNgQuBOYFBHP0DCzj9QsmXls0RnUI71Sf4NmWUQMpDaEduuiQ6myxqzyRuDt9TcK1SS9ig4gqVv5MPAy8EXgZmAub7xRUZLKakpEbExtQompwDTg98VGUoUtj4jt2x9ExHbA8gLzVI5DyyStJCK2BXbIzFsj4m1A78x8oehcktRMETEIGJiZDxQcRRUVEQcAVwDzqK3Lti3wycycXGiwCrHISFohIo4DjgfekZnbR8QO1G5MPKDgaKqojlbAdlVsNVtE7Ppm+zNzWldlUc8SEesBO9UfzvFnW3NZZCStEBHTqS1M+MfMHF3fNiMzRxSbTFXVvgL2mrZJ6yIi3uwd8MzM/bssjKSm8WZ/SY2WZOartQXXISL6sPqZpaS3LCI2B7YE1o+I0dSGXQAMBN5WWDBVUmbuV3QGSc1nkZHU6LcR8RVqf1y+HzgJ+EXBmVRN/wc4FtiK2iKs7UXmBeArBWVSRUXER99sv+sWSeXk0DJJK0REL+DTwAeo/WF5S2ZeVmwqVVlEfCwzry86h6otIq54k92uW6SWiYgtqd3kv+LiQWb+rrhE1WKRkbRaEfEB4HQXi1OrRMQXqM3q8wK1KXF3Bc7IzN8UGkyS1lFEfBM4EpjF69MuZ2YeUlyqanFomSQiYn/gEmAL4Abgm9T+uAzg/AKjqfo+lZnfiYj/A2xCbeXrqwCLjJomIo7JzB9HxKkd7c/Mb3d1JvUIHwF2cqay1rHISILaPQrHU1sYbmz9v2dk5vcKTaWeoP3emH8AfpSZD0b7bBNS82xQ/++AQlOop5kH9AUsMi3i0DJJb5juNiLmZOZOb/YcqRnq9y5sCQwGRgK9gTsyc7dCg0nSOoqI66n9XLuNhjKTmZ8vLFTFeEVGEsDGq8zq06fxsTP6qIU+DYwC5mXmyxGxCfDJgjOpYiLiojfb7x+WapEb6x9qEa/ISHJGH3W5iBiSmQ+tbsV1V1pXM0XEuIaH3wC+3rg/M3/YtYnUU0REP2DH+sM5mbm0yDxVY5GRJHW5iLg0M49fzYrrrrSulomI+zJzdNE5VH0RsS/wQ2A+tfsBtwbGOf1y81hkJElSj7HqPYFSq0TEVOAfM3NO/fGOwE+8B7B5vEdGklSoiHgPMIiVF4z7UWGBJKk5+raXGIDMfDgi+hYZqGosMpKkwkTEVcD2wHQaFowDLDJqmoh4gdrrCuBtEbGofRe1oYwDi0mmipsSEZcDP64//jgwpcA8lePQMkkriYjhwDCgf/s23x1Xq0TEbGBY+stIUsVExHrAeGDv+qY7gYkukNk8FhlJK0TE14F9qRWZm6gtjnlXZh5WZC5VV0RcC3w+M/9cdBZJUrk4tExSo8OoLd51X2Z+MiLexeuXxKVW2BSYFRH3sPKCcYcUF0mS3rqIuCYzj4iIGbw+pHGFzNylgFiVZJGR1OiVzHwtIpZFxEDgGWrTRUqtcnbRASSpyb5Q/+8HC03RA1hkJDWaEhEbA5cBU4EXgd8XG0lVlpm/LTqDJDVTw1DZkzLzy437IuKbwJff+Cy9Fd4jI6lDETEIGJiZDxQcRRUUEXdl5t6rzCYFziIlqSI6WrMoIh5waFnzWGQkSZKkJomIE4GTgO2AuQ27BgD/k5nHFBKsgiwykqRCRcTbqd2L1bgg5rTiEknSWxcRGwFvB/4VOKNh1wuZ+ddiUlWTRUaSVJiIOBc4FpgHvFbfnJm5f2GhJKmJImIzVl6b7YkC41SKRUbSChGxPbAgM5dExL7ALsCPMvNvxSZTVUXEHGBEZr5adBZJaqaI+BDwbWALarOAbgvMzsydCw1WIb2KDiCpW7keWB4Rfw9cSm24z38VG0kVNxPYuOgQktQC5wF7Ag9n5mDgAOAPxUaqFqdfltTotcxcFhGHAt/NzO9GxH1Fh1Kl/StwX0TMxAUxJVXL0sx8LiJ6RUSvzJwcERcWHapKLDKSGi2NiKOBccCH6tv6FphH1fdD4JvADF6/R0aSquBvEbEh8DtgUkQ8A7xUcKZK8R4ZSStExDDgBOD3mfmTiBgMHJGZ3yw4mioqIu7NzDFF55CkZouIDYBXqN3K8XFgI2BSZj5XaLAKschIkgoTEd+mNqTsRlYeWub0y5JKLSL+GbgyM59s2HZ8Zl5aYKxKschIIiKuycwjImIGK6+yDoCrEKtVImJyB5udfllS6dWHkj0LnJyZk+vbpmXmrsUmqw6LjCQi4u8y888RsW1H+zPz8a7OJElSmdUny/kwcC1wXWb+e0Tcl5mjC45WGRYZSVJhIuJdwL8AW2Tm2Pp9Wu/OzB8UHE2S1kl7aYmI/sDFwIbU1s0aUnC0ynAdGUlSka4EbqG2YBzAw8AXC0sjSc0zBSAzF2fmJ4E7gH6FJqoYr8hIkgrTPmtZ43CLiJiemaOKziZJ6t5cR0bSSiJifWCbzJxTdBb1CC9FxCbUJ5mIiD2B54uNJElvnRPodB2vyEhaISI+BHwL6JeZgyNiFHCOq6yrVSJiV+C7wHBgJvBO4LDMfKDQYJL0FjmBTtexyEhaISKmAvsDdzQM85mRmSOKTaaqiYhtMvOJ+ud9gJ2AAOZk5tJCw0mSSsGhZZIaLc3M5yOicZvvdqgVbgDa11K4OjM/VmQYSWqWiHiBjn93BrV1sgZ2caTKsshIavRgRPwj0DsidgA+D9xdcCZVU2Nb3q6wFJLUZJk5oOgMPYXTL0tq9DlgZ2AJ8BNgEU6Fq9bI1XwuSZUSEZtFxDbtH0XnqRLvkZEkdbmIWA68RO3KzPrAy+27cOiFpAqIiEOA/6C2TtYzwLbA7MzcudBgFeLQMkkrRMQveOO7489TW9Tr+5m5uOtTqYoys3fRGSSpxc4F9gRuzczREbEfcEzBmSrFoWWSGs0DXgQuq38sAl4Adqw/liRJnbM0M58DekVEr8ycDLQVHapKvCIjqdF7MnNMw+NfNKy8/mBhqSRJKp+/RcSGwO+ASRHxDLUhtWoSr8hIarRh442I9c83rD98tZhIkiSV0oeBV4BTgJuBucCHCk1UMV6RkdTon4C7ImIutZuuBwMnRcQGwA8LTSZJUolkZuPVF3+HtoCzlklaSUSsBwypP5zjDf6SJK291SyM2T6Bzj9l5ryuT1UtFhlJK4mI9wCDaLhim5k/KiyQJEklFBHnAguA/6I2yuEoYHtgGnBiZu5bXLpqsMhIWiEirqL2Q3Y6sLy+OTPz88WlkiSpfCLi/swcucq26Zk5qqN9WnveIyOpURswLH2HQ5KkdfVyRBwBXFd/fBjQPlzb37NN4KxlkhrNBDYvOoQkSRXwceATwDPA0/XPj4mI9YGTiwxWFQ4tk7RCREwGRgH3AEvat2fmIYWFkiRJ6oBDyyQ1OrvoAJIkVUFE7AhcDLwrM4dHxC7AIZl5XsHRKsMrMpIkSVKTRcRvgdOB72fm6Pq2mZk5vNhk1eE9MpJWiIg9I+LeiHgxIl6NiOURsajoXJIkldDbMvOeVbYtKyRJRVlkJDX6HnA08AiwPvAZYEKhiSRJKqe/RMT21Gcoi4jDgD8XG6laHFomaYWImJKZbRHxQGbuUt92X/slcUmS1DkRsR1wKfAe4H+Bx4CPZ+bjhQarEG/2l9To5YjoB0yPiH+j9s6RV24lSVpLmTkPODAiNgB6ZeYLEfFF4MKCo1WGV2QkrRAR21Kb674fcAqwETAxMx8tNJgkSRUQEU9k5jZF56gKi4wkSZLUBSLiyczcuugcVeHQMkkrRMRe1NaS2ZaGnw+ZuV1RmSRJqhCvIDSRV2QkrRARD1EbUjYVWN6+PTOfKyyUJEklEhEv0HFhCWD9zPRCQpP4Dymp0fOZ+euiQ0iSVFaZOaDoDD2FV2QkERG71j89AugN/AxY0r4/M6cVkUuSJGl1LDKSiIjJb7I7M3P/Lgsj/b/27iZEzruOA/j3F9MkDWmN2hJtCwkUEWpIo61YLL7Ug6JVWwnBg6JCrIgglIJQxJMHERpKL4oUBcVL8YXSJBJ6URECEZuI3QasorH0IopgUlvTRvPzMJPNdN+ySLLPjPl8YJid/5PZ+e5ll2/+Lw8ArIIiAwAAzBw3ugNSVQ9U1b4lxveNb94FADBVzMgAqapjSe7o7rMLxjckeaq7dw2TDABgaWZkgCRZv7DEJEl3v5LRcZEAAFNFkQGSZF1VbVs4uNQYAMA0UGSAJHkoyU+r6r1Vdc348b4kh5LsHzYaAMBi9sgASZKq+lCSB5PszOiOxCeSfMMNMgGAaaTIAAAAM8fSMgAAYOYoMgAAwMxRZAAAgJmjyADzqmpbVX23qg6PX99SVfuGzgUAsJAiA0z6XpInk9wwfv37JPcPlgYAYBmKDDDpuu7+YZJzSdLd/07yn2EjAQAspsgAk16sqjdkdB+ZVNUdSU4NGwkAYLH1QwcApsoDSQ4kubmqjiS5PsneYSMBACzmhpjAvKramNFSsrckqSTPJlnX3S8PGgwAYAFFBphXVce7++0XGwMAGJqlZUCq6o1JbkxydVW9LaPZmCS5NsnmwYIBACxDkQGS5INJPpvkpiQPT4y/kOQrQwQCAFiJpWXAvKra090/GToHAMDFKDLAq1TV3UnemmTT+bHu/tpwiQAAFnMfGWBeVX07ySeSfCmjfTJ7k2wfNBQAwBLMyADzqurp7t418bwlyeHufvfQ2QAAJpmRASb9a/z8UlXdkORskjcNmAcAYElOLQMmHaqqrUkeSnI8SSf5zrCRAAAWs7QMWFJVbUyyqbtPDZ0FAGAhRQaYV1WvSXJ3kh2ZmLHt7oeXew8AwBAsLQMmHUxyJslcknMDZwEAWJYiA0y6qbt3DR0CAOBinFoGTDpcVR8YOgQAwMWYkQEmHU3yeFWty+jo5UrS3X3tsLEAAF7NZn9gXlWdTHJPkrn2ywEAmGKWlgGTnk/yjBIDAEw7S8uASX9K8ouqOpzk5fODjl8GAKaNIgNMOjl+bBg/AACmkj0yAADAzDEjA6SqHunu+6vqYJJF/7vR3R8bIBYAwLIUGSBJfjB+3j9oCgCAVbK0DAAAmDlmZIBU1VyWWFKWCzfE3LXGkQAAVmRGBkhVbV/penc/t1ZZAABWw4wMkCRXJdnW3UcmB6vqziR/GSYSAMDy1g0dAJgKjyQ5vcT46fE1AICposgAyWg2Zm7h4Hhsx9rHAQBYmSIDJMnWFa5dvWYpAABWSZEBkuSpqrpv4WBVfS7JsQHyAACsyKllQKpqW5LHk7ySC8Xl9iQbkny8u234BwCmiiIDzKuqu5LsHL880d0/GzIPAMByFBkAAGDm2CMDAADMHEUGAACYOYoMAJdUVW2tqi+uwefcW1W3XO7PAWA6KTIAXGpbk6y6yNTI//L36N4kigzAFcpmfwAuqap6LMk9SZ5N8vMku5K8LslVSb7a3U9U1Y4kTyb5VZLbknw4yaeTfCrJ35I8n+RYd++vqpuTfDPJ9UleSnJfktcnOZTk1Pixp7v/uEY/IgBTYP3QAQD4v/Ngkp3dvbuq1ifZ3N2nq+q6JEer6sD43705yWe6+2hVvSPJniS3ZlR4jufCPY0eTfKF7v5DVb0zybe6+/3j73Oou3+8lj8cANNBkQHgcqokX6+q9yQ5l+TGJNvG157r7qPjr+9M8kR3n0lypqoOJklVbUnyriQ/qqrz33PjWoUHYHopMgBcTp/MaEnYbd19tqr+nGTT+NqLq3j/uiT/6O7dlykfADPKZn8ALrUXklwz/vq1Sf46LjF3Jdm+zHuOJPloVW0az8J8JEm6+3SSk1W1N5k/GODWJT4HgCuMIgPAJdXdf09ypKqeSbI7ye1VNZfRZv7fLfOeXyc5kOTpJIeTzGW0iT8Zzersq6rfJjmR0UECSfJYki9X1W/GBwIAcAVxahkAU6GqtnT3P6tqc5JfJvl8dx8fOhcA08keGQCmxaPjG1xuSvJ9JQaAlZiRAQAAZo49MgAAwMxRZAAAgJmjyAAAADNHkQEAAGaOIgMAAMyc/wJuTT2AsSeyAgAAAABJRU5ErkJggg==\n","text/plain":["<Figure size 1008x432 with 1 Axes>"]},"metadata":{"needs_background":"light"}}]}]}