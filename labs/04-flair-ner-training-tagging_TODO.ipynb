{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"04-flair-ner-training-tagging_TODO.ipynb","provenance":[],"toc_visible":true,"authorship_tag":"ABX9TyNSlkFcabVJw0QaHY5g2PmI"},"kernelspec":{"display_name":"Python 3","name":"python3"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dbtb9NusdN1d","executionInfo":{"status":"ok","timestamp":1612954082030,"user_tz":-60,"elapsed":195013,"user":{"displayName":"Rodrigo Agerri","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhW2M3VpBFpNNhe0tx607nu7jJN85RXoeaB4nSw=s64","userId":"18226337086247956839"}},"outputId":"43802245-4945-4044-aca9-ff9aad32b47e"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KQCUHxFt3GYh","executionInfo":{"status":"ok","timestamp":1612954113077,"user_tz":-60,"elapsed":226028,"user":{"displayName":"Rodrigo Agerri","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhW2M3VpBFpNNhe0tx607nu7jJN85RXoeaB4nSw=s64","userId":"18226337086247956839"}},"outputId":"a8923479-a90e-4634-af21-3267cd97187c"},"source":["!pip install flair==0.8"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Collecting flair\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/68/a0/a1b41fa2fcb23ff71ba9148af75211dcccc35b256dea821b36e1ee871848/flair-0.7-py3-none-any.whl (448kB)\n","\r\u001b[K     |▊                               | 10kB 22.8MB/s eta 0:00:01\r\u001b[K     |█▌                              | 20kB 27.1MB/s eta 0:00:01\r\u001b[K     |██▏                             | 30kB 21.8MB/s eta 0:00:01\r\u001b[K     |███                             | 40kB 19.9MB/s eta 0:00:01\r\u001b[K     |███▋                            | 51kB 20.8MB/s eta 0:00:01\r\u001b[K     |████▍                           | 61kB 15.6MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 71kB 16.1MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 81kB 16.8MB/s eta 0:00:01\r\u001b[K     |██████▋                         | 92kB 15.0MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 102kB 16.1MB/s eta 0:00:01\r\u001b[K     |████████                        | 112kB 16.1MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 122kB 16.1MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 133kB 16.1MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 143kB 16.1MB/s eta 0:00:01\r\u001b[K     |███████████                     | 153kB 16.1MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 163kB 16.1MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 174kB 16.1MB/s eta 0:00:01\r\u001b[K     |█████████████▏                  | 184kB 16.1MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 194kB 16.1MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 204kB 16.1MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 215kB 16.1MB/s eta 0:00:01\r\u001b[K     |████████████████                | 225kB 16.1MB/s eta 0:00:01\r\u001b[K     |████████████████▉               | 235kB 16.1MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 245kB 16.1MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 256kB 16.1MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 266kB 16.1MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 276kB 16.1MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 286kB 16.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 296kB 16.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 307kB 16.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 317kB 16.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 327kB 16.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 337kB 16.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 348kB 16.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 358kB 16.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▎     | 368kB 16.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 378kB 16.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 389kB 16.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 399kB 16.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▎  | 409kB 16.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 419kB 16.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 430kB 16.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 440kB 16.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 450kB 16.1MB/s \n","\u001b[?25hCollecting langdetect\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/56/a3/8407c1e62d5980188b4acc45ef3d94b933d14a2ebc9ef3505f22cf772570/langdetect-1.0.8.tar.gz (981kB)\n","\u001b[K     |████████████████████████████████| 983kB 17.7MB/s \n","\u001b[?25hCollecting ftfy\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ff/e2/3b51c53dffb1e52d9210ebc01f1fb9f2f6eba9b3201fa971fd3946643c71/ftfy-5.8.tar.gz (64kB)\n","\u001b[K     |████████████████████████████████| 71kB 10.8MB/s \n","\u001b[?25hCollecting segtok>=1.5.7\n","  Downloading https://files.pythonhosted.org/packages/41/08/582dab5f4b1d5ca23bc6927b4bb977c8ff7f3a87a3b98844ef833e2f5623/segtok-1.5.10.tar.gz\n","Requirement already satisfied, skipping upgrade: torch>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from flair) (1.7.0+cu101)\n","Requirement already satisfied, skipping upgrade: gdown in /usr/local/lib/python3.6/dist-packages (from flair) (3.6.4)\n","Collecting sqlitedict>=1.6.0\n","  Downloading https://files.pythonhosted.org/packages/5c/2d/b1d99e9ad157dd7de9cd0d36a8a5876b13b55e4b75f7498bc96035fb4e96/sqlitedict-1.7.0.tar.gz\n","Requirement already satisfied, skipping upgrade: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from flair) (2.8.1)\n","Collecting bpemb>=0.3.2\n","  Downloading https://files.pythonhosted.org/packages/91/77/3f0f53856e86af32b1d3c86652815277f7b5f880002584eb30db115b6df5/bpemb-0.3.2-py3-none-any.whl\n","Requirement already satisfied, skipping upgrade: tqdm>=4.26.0 in /usr/local/lib/python3.6/dist-packages (from flair) (4.41.1)\n","Collecting deprecated>=1.2.4\n","  Downloading https://files.pythonhosted.org/packages/d4/56/7d4774533d2c119e1873993d34d313c9c9efc88c5e4ab7e33bdf915ad98c/Deprecated-1.2.11-py2.py3-none-any.whl\n","Requirement already satisfied, skipping upgrade: tabulate in /usr/local/lib/python3.6/dist-packages (from flair) (0.8.7)\n","Collecting konoha<5.0.0,>=4.0.0\n","  Downloading https://files.pythonhosted.org/packages/ea/01/47358efec5396fc80f98273c42cbdfe7aab056252b07884ffcc0f118978f/konoha-4.6.2-py3-none-any.whl\n","Requirement already satisfied, skipping upgrade: lxml in /usr/local/lib/python3.6/dist-packages (from flair) (4.2.6)\n","Requirement already satisfied, skipping upgrade: scikit-learn>=0.21.3 in /usr/local/lib/python3.6/dist-packages (from flair) (0.22.2.post1)\n","Collecting transformers<=3.5.1,>=3.5.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3a/83/e74092e7f24a08d751aa59b37a9fc572b2e4af3918cb66f7766c3affb1b4/transformers-3.5.1-py3-none-any.whl (1.3MB)\n","\u001b[K     |████████████████████████████████| 1.3MB 54.5MB/s \n","\u001b[?25hRequirement already satisfied, skipping upgrade: hyperopt>=0.1.1 in /usr/local/lib/python3.6/dist-packages (from flair) (0.1.2)\n","Requirement already satisfied, skipping upgrade: gensim<=3.8.3,>=3.4.0 in /usr/local/lib/python3.6/dist-packages (from flair) (3.6.0)\n","Requirement already satisfied, skipping upgrade: regex in /usr/local/lib/python3.6/dist-packages (from flair) (2019.12.20)\n","Collecting janome\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a8/63/98858cbead27df7536c7e300c169da0999e9704d02220dc6700b804eeff0/Janome-0.4.1-py2.py3-none-any.whl (19.7MB)\n","\u001b[K     |████████████████████████████████| 19.7MB 1.5MB/s \n","\u001b[?25hCollecting mpld3==0.3\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/91/95/a52d3a83d0a29ba0d6898f6727e9858fe7a43f6c2ce81a5fe7e05f0f4912/mpld3-0.3.tar.gz (788kB)\n","\u001b[K     |████████████████████████████████| 798kB 50.1MB/s \n","\u001b[?25hCollecting sentencepiece<=0.1.91\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/a4/d0a884c4300004a78cca907a6ff9a5e9fe4f090f5d95ab341c53d28cbc58/sentencepiece-0.1.91-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n","\u001b[K     |████████████████████████████████| 1.1MB 44.0MB/s \n","\u001b[?25hRequirement already satisfied, skipping upgrade: matplotlib>=2.2.3 in /usr/local/lib/python3.6/dist-packages (from flair) (3.2.2)\n","Requirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.6/dist-packages (from langdetect->flair) (1.15.0)\n","Requirement already satisfied, skipping upgrade: wcwidth in /usr/local/lib/python3.6/dist-packages (from ftfy->flair) (0.2.5)\n","Requirement already satisfied, skipping upgrade: typing-extensions in /usr/local/lib/python3.6/dist-packages (from torch>=1.1.0->flair) (3.7.4.3)\n","Requirement already satisfied, skipping upgrade: numpy in /usr/local/lib/python3.6/dist-packages (from torch>=1.1.0->flair) (1.19.5)\n","Requirement already satisfied, skipping upgrade: future in /usr/local/lib/python3.6/dist-packages (from torch>=1.1.0->flair) (0.16.0)\n","Requirement already satisfied, skipping upgrade: dataclasses in /usr/local/lib/python3.6/dist-packages (from torch>=1.1.0->flair) (0.8)\n","Requirement already satisfied, skipping upgrade: requests in /usr/local/lib/python3.6/dist-packages (from gdown->flair) (2.23.0)\n","Requirement already satisfied, skipping upgrade: wrapt<2,>=1.10 in /usr/local/lib/python3.6/dist-packages (from deprecated>=1.2.4->flair) (1.12.1)\n","Collecting overrides==3.0.0\n","  Downloading https://files.pythonhosted.org/packages/42/8d/caa729f809ecdf8e76fac3c1ff7d3f0b72c398c9dd8a6919927a30a873b3/overrides-3.0.0.tar.gz\n","Requirement already satisfied, skipping upgrade: scipy>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.21.3->flair) (1.4.1)\n","Requirement already satisfied, skipping upgrade: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.21.3->flair) (1.0.0)\n","Requirement already satisfied, skipping upgrade: protobuf in /usr/local/lib/python3.6/dist-packages (from transformers<=3.5.1,>=3.5.0->flair) (3.12.4)\n","Collecting sacremoses\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n","\u001b[K     |████████████████████████████████| 890kB 46.8MB/s \n","\u001b[?25hCollecting tokenizers==0.9.3\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4c/34/b39eb9994bc3c999270b69c9eea40ecc6f0e97991dba28282b9fd32d44ee/tokenizers-0.9.3-cp36-cp36m-manylinux1_x86_64.whl (2.9MB)\n","\u001b[K     |████████████████████████████████| 2.9MB 35.7MB/s \n","\u001b[?25hRequirement already satisfied, skipping upgrade: packaging in /usr/local/lib/python3.6/dist-packages (from transformers<=3.5.1,>=3.5.0->flair) (20.9)\n","Requirement already satisfied, skipping upgrade: filelock in /usr/local/lib/python3.6/dist-packages (from transformers<=3.5.1,>=3.5.0->flair) (3.0.12)\n","Requirement already satisfied, skipping upgrade: pymongo in /usr/local/lib/python3.6/dist-packages (from hyperopt>=0.1.1->flair) (3.11.3)\n","Requirement already satisfied, skipping upgrade: networkx in /usr/local/lib/python3.6/dist-packages (from hyperopt>=0.1.1->flair) (2.5)\n","Requirement already satisfied, skipping upgrade: smart-open>=1.2.1 in /usr/local/lib/python3.6/dist-packages (from gensim<=3.8.3,>=3.4.0->flair) (4.1.2)\n","Requirement already satisfied, skipping upgrade: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.2.3->flair) (1.3.1)\n","Requirement already satisfied, skipping upgrade: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.2.3->flair) (2.4.7)\n","Requirement already satisfied, skipping upgrade: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.2.3->flair) (0.10.0)\n","Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->gdown->flair) (1.24.3)\n","Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->gdown->flair) (2.10)\n","Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->gdown->flair) (3.0.4)\n","Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->gdown->flair) (2020.12.5)\n","Requirement already satisfied, skipping upgrade: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf->transformers<=3.5.1,>=3.5.0->flair) (53.0.0)\n","Requirement already satisfied, skipping upgrade: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers<=3.5.1,>=3.5.0->flair) (7.1.2)\n","Requirement already satisfied, skipping upgrade: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx->hyperopt>=0.1.1->flair) (4.4.2)\n","Building wheels for collected packages: langdetect, ftfy, segtok, sqlitedict, mpld3, overrides, sacremoses\n","  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for langdetect: filename=langdetect-1.0.8-cp36-none-any.whl size=993194 sha256=d0a74eb0723263cb86f46bfd3a2ff9cdfbb0590a35038693b7bfa097817c24af\n","  Stored in directory: /root/.cache/pip/wheels/8d/b3/aa/6d99de9f3841d7d3d40a60ea06e6d669e8e5012e6c8b947a57\n","  Building wheel for ftfy (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for ftfy: filename=ftfy-5.8-cp36-none-any.whl size=45613 sha256=b4909532f1b2be4d2804fb4199f3f07bc6dc6b20361df4ee4d7659464a88a7d8\n","  Stored in directory: /root/.cache/pip/wheels/ba/c0/ef/f28c4da5ac84a4e06ac256ca9182fc34fa57fefffdbc68425b\n","  Building wheel for segtok (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for segtok: filename=segtok-1.5.10-cp36-none-any.whl size=25019 sha256=3bf2e940a99e5fcf8dcb07bf136d6a6afa89bd8744104ed6d7381a19ddeb620e\n","  Stored in directory: /root/.cache/pip/wheels/b4/39/f6/9ca1c5cabde964d728023b5751c3a206a5c8cc40252321fb6b\n","  Building wheel for sqlitedict (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for sqlitedict: filename=sqlitedict-1.7.0-cp36-none-any.whl size=14376 sha256=a6f94b5909a6f95ec9640446ad1d7818cc3fabd087a3d7db9e7de5be2d33b8ba\n","  Stored in directory: /root/.cache/pip/wheels/cf/c6/4f/2c64a43f041415eb8b8740bd80e15e92f0d46c5e464d8e4b9b\n","  Building wheel for mpld3 (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for mpld3: filename=mpld3-0.3-cp36-none-any.whl size=116678 sha256=3fb6bc14f8224d9efc87a98927aa7c22a83041263263b8360d9741ea01412a53\n","  Stored in directory: /root/.cache/pip/wheels/c0/47/fb/8a64f89aecfe0059830479308ad42d62e898a3e3cefdf6ba28\n","  Building wheel for overrides (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for overrides: filename=overrides-3.0.0-cp36-none-any.whl size=5669 sha256=bb9dd35d1b7d0653442917ee28d08614c4f71fd63ef5ffdf0406ab626bef365d\n","  Stored in directory: /root/.cache/pip/wheels/6f/1b/ec/6c71a1eb823df7f850d956b2d8c50a6d49c191e1063d73b9be\n","  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893261 sha256=f689cf83670ad039a0fb0a05f3bf6666558058c979ccc234e560f1c8d346d6b5\n","  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n","Successfully built langdetect ftfy segtok sqlitedict mpld3 overrides sacremoses\n","Installing collected packages: langdetect, ftfy, segtok, sqlitedict, sentencepiece, bpemb, deprecated, overrides, konoha, sacremoses, tokenizers, transformers, janome, mpld3, flair\n","Successfully installed bpemb-0.3.2 deprecated-1.2.11 flair-0.7 ftfy-5.8 janome-0.4.1 konoha-4.6.2 langdetect-1.0.8 mpld3-0.3 overrides-3.0.0 sacremoses-0.0.43 segtok-1.5.10 sentencepiece-0.1.91 sqlitedict-1.7.0 tokenizers-0.9.3 transformers-3.5.1\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"XTngfHWr03JH"},"source":["# ASSIGNMENT 1: Training your own NER model\n","\n","In this lab we will train a NER model in a **language of your interest** and use it to tag texts for that language. To train a NER (SequenceTagger) model we need the following:\n","\n","\n","1. An annotated corpus in the IOB2 format. You can load your own or use one of the many available in Flair: https://github.com/flairNLP/flair/blob/master/resources/docs/TUTORIAL_6_CORPUS.md#named-entity-recognition\n","  + CoNLL 2003 for English and German are not publicly available but you can find the required files in the following google drive folder:\n","  '/content/drive/My Drive/Colab Notebooks/2021-ILTAPP/datasets/ner'\n","2. At least one WordEmbedding or FlairEmbeddings. You can check the ones available in the tutorial.\n","  + Static Word Embeddings:https://github.com/flairNLP/flair/blob/master/resources/docs/embeddings/CLASSIC_WORD_EMBEDDINGS.md\n","  + FlairEmbeddings: https://github.com/flairNLP/flair/blob/master/resources/docs/embeddings/FLAIR_EMBEDDINGS.md\n","  + NOTE: Remember that the embeddings can be combined (Stacked): https://github.com/flairNLP/flair/blob/master/resources/docs/TUTORIAL_3_WORD_EMBEDDING.md\n","3. Instantiate a SequenceTagger and a Model Trainer: https://github.com/flairNLP/flair/blob/master/resources/docs/TUTORIAL_7_TRAINING_A_MODEL.md\n","4. Run! (perhaps consider downsampling the training data and setting at first a lower number of epochs, just to check that the training works).\n","5. HINT: You can also print your corpus statistics using the corpus obtain_statistics() function. This will give you an idea of the size of your dataset."]},{"cell_type":"code","metadata":{"id":"zgcDJP7mcO2h"},"source":["from flair.data import Corpus\n","from flair.datasets import ColumnCorpus\n","from flair.embeddings import TokenEmbeddings, WordEmbeddings, StackedEmbeddings, FlairEmbeddings\n","from typing import List"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Wvgqo8ACc7DK","executionInfo":{"status":"ok","timestamp":1612954122007,"user_tz":-60,"elapsed":234927,"user":{"displayName":"Rodrigo Agerri","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhW2M3VpBFpNNhe0tx607nu7jJN85RXoeaB4nSw=s64","userId":"18226337086247956839"}},"outputId":"7c1f0f49-be72-4564-ad4e-7dedc637d120"},"source":["# if using your own corpus, define the existing columns in the dataset\n","#columns = {0:'text', 1:'ner'}\n","\n","# TODO get the corpus into a ColumnCorpus object\n","\n","# TODO obtain and print corpus statistics (output below obtained with the BASQUE NER corpus)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["2021-02-10 10:48:39,185 Reading data from /content/drive/My Drive/datasets/ner\n","2021-02-10 10:48:39,187 Train: /content/drive/My Drive/datasets/ner/eu-train.tsv\n","2021-02-10 10:48:39,188 Dev: /content/drive/My Drive/datasets/ner/eu-dev.tsv\n","2021-02-10 10:48:39,190 Test: /content/drive/My Drive/datasets/ner/eu-test.tsv\n","{\n","    \"TRAIN\": {\n","        \"dataset\": \"TRAIN\",\n","        \"total_number_of_documents\": 2552,\n","        \"number_of_documents_per_class\": {},\n","        \"number_of_tokens_per_tag\": {},\n","        \"number_of_tokens\": {\n","            \"total\": 44408,\n","            \"min\": 1,\n","            \"max\": 113,\n","            \"avg\": 17.401253918495296\n","        }\n","    },\n","    \"TEST\": {\n","        \"dataset\": \"TEST\",\n","        \"total_number_of_documents\": 842,\n","        \"number_of_documents_per_class\": {},\n","        \"number_of_tokens_per_tag\": {},\n","        \"number_of_tokens\": {\n","            \"total\": 15351,\n","            \"min\": 1,\n","            \"max\": 74,\n","            \"avg\": 18.231591448931116\n","        }\n","    },\n","    \"DEV\": {\n","        \"dataset\": \"DEV\",\n","        \"total_number_of_documents\": 2552,\n","        \"number_of_documents_per_class\": {},\n","        \"number_of_tokens_per_tag\": {},\n","        \"number_of_tokens\": {\n","            \"total\": 44408,\n","            \"min\": 1,\n","            \"max\": 113,\n","            \"avg\": 17.401253918495296\n","        }\n","    }\n","}\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dkY2N8eFd50c","executionInfo":{"status":"ok","timestamp":1612954122010,"user_tz":-60,"elapsed":234912,"user":{"displayName":"Rodrigo Agerri","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhW2M3VpBFpNNhe0tx607nu7jJN85RXoeaB4nSw=s64","userId":"18226337086247956839"}},"outputId":"81b5f8b5-1efc-41b1-ec31-2ca57f93488f"},"source":["# 2. what tag do we want to predict?\n","tag_type = 'ner'\n","\n","# 3. make the tag dictionary from the corpus\n","tag_dictionary = corpus.make_tag_dictionary(tag_type=tag_type)\n","print(tag_dictionary.idx2item)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[b'<unk>', b'O', b'B-ORG', b'B-PER', b'I-PER', b'I-ORG', b'B-LOC', b'I-LOC', b'B-MISC', b'I-MISC', b'<START>', b'<STOP>']\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xB172bjKeBlA","executionInfo":{"status":"ok","timestamp":1612954163973,"user_tz":-60,"elapsed":276862,"user":{"displayName":"Rodrigo Agerri","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhW2M3VpBFpNNhe0tx607nu7jJN85RXoeaB4nSw=s64","userId":"18226337086247956839"}},"outputId":"dccadaaa-2573-4a62-f8ca-c5ae3501fb93"},"source":["# TODO initialize embeddings (output below refers to WordEmbeddings('eu'), \n","# FlairEmbeddings('eu-forward') and FlairEmbeddings('eu-backward'))\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["2021-02-10 10:48:42,027 https://flair.informatik.hu-berlin.de/resources/embeddings/token/eu-wiki-fasttext-300d-1M.vectors.npy not found in cache, downloading to /tmp/tmpns7xu_c8\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 283358528/283358528 [00:11<00:00, 23748227.16B/s]"],"name":"stderr"},{"output_type":"stream","text":["2021-02-10 10:48:54,279 copying /tmp/tmpns7xu_c8 to cache at /root/.flair/embeddings/eu-wiki-fasttext-300d-1M.vectors.npy\n"],"name":"stdout"},{"output_type":"stream","text":["\n"],"name":"stderr"},{"output_type":"stream","text":["2021-02-10 10:48:54,773 removing temp file /tmp/tmpns7xu_c8\n","2021-02-10 10:48:55,424 https://flair.informatik.hu-berlin.de/resources/embeddings/token/eu-wiki-fasttext-300d-1M not found in cache, downloading to /tmp/tmp8ereptw5\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 9342871/9342871 [00:01<00:00, 8525419.00B/s]"],"name":"stderr"},{"output_type":"stream","text":["2021-02-10 10:48:56,838 copying /tmp/tmp8ereptw5 to cache at /root/.flair/embeddings/eu-wiki-fasttext-300d-1M\n","2021-02-10 10:48:56,850 removing temp file /tmp/tmp8ereptw5\n"],"name":"stdout"},{"output_type":"stream","text":["\n"],"name":"stderr"},{"output_type":"stream","text":["2021-02-10 10:48:58,047 https://flair.informatik.hu-berlin.de/resources/embeddings/flair/lm-eu-opus-large-forward-v0.2.pt not found in cache, downloading to /tmp/tmpr37ahcvm\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 109092471/109092471 [00:04<00:00, 23702269.90B/s]"],"name":"stderr"},{"output_type":"stream","text":["2021-02-10 10:49:02,969 copying /tmp/tmpr37ahcvm to cache at /root/.flair/embeddings/lm-eu-opus-large-forward-v0.2.pt\n"],"name":"stdout"},{"output_type":"stream","text":["\n"],"name":"stderr"},{"output_type":"stream","text":["2021-02-10 10:49:03,171 removing temp file /tmp/tmpr37ahcvm\n","2021-02-10 10:49:18,217 https://flair.informatik.hu-berlin.de/resources/embeddings/flair/lm-eu-opus-large-backward-v0.2.pt not found in cache, downloading to /tmp/tmp9rg1rqvk\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 109092471/109092471 [00:04<00:00, 22932737.80B/s]"],"name":"stderr"},{"output_type":"stream","text":["2021-02-10 10:49:23,291 copying /tmp/tmp9rg1rqvk to cache at /root/.flair/embeddings/lm-eu-opus-large-backward-v0.2.pt\n"],"name":"stdout"},{"output_type":"stream","text":["\n"],"name":"stderr"},{"output_type":"stream","text":["2021-02-10 10:49:23,470 removing temp file /tmp/tmp9rg1rqvk\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"b-NkS26pePfi"},"source":["# TODO initialize sequence tagger\n","from flair.models import SequenceTagger\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"tt3MGEkZeX2b"},"source":["# TODO initialize trainer\n","from flair.trainers import ModelTrainer\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"23a9h5ipeetW","executionInfo":{"status":"ok","timestamp":1612954517787,"user_tz":-60,"elapsed":630634,"user":{"displayName":"Rodrigo Agerri","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhW2M3VpBFpNNhe0tx607nu7jJN85RXoeaB4nSw=s64","userId":"18226337086247956839"}},"outputId":"1d77430c-8325-439d-cb23-46e98d2ff066"},"source":["# TODO train \n","# saving the model into your drive (need to provide the full path of the folder in which you want to save the model)\n","# results obtained with the BASQUE NER corpus over 10 epochs (inspect the output generated below)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["2021-02-10 10:49:24,070 ----------------------------------------------------------------------------------------------------\n","2021-02-10 10:49:24,071 Model: \"SequenceTagger(\n","  (embeddings): StackedEmbeddings(\n","    (list_embedding_0): WordEmbeddings('eu')\n","    (list_embedding_1): FlairEmbeddings(\n","      (lm): LanguageModel(\n","        (drop): Dropout(p=0.1, inplace=False)\n","        (encoder): Embedding(4488, 100)\n","        (rnn): LSTM(100, 2048)\n","        (decoder): Linear(in_features=2048, out_features=4488, bias=True)\n","      )\n","    )\n","    (list_embedding_2): FlairEmbeddings(\n","      (lm): LanguageModel(\n","        (drop): Dropout(p=0.1, inplace=False)\n","        (encoder): Embedding(4488, 100)\n","        (rnn): LSTM(100, 2048)\n","        (decoder): Linear(in_features=2048, out_features=4488, bias=True)\n","      )\n","    )\n","  )\n","  (word_dropout): WordDropout(p=0.05)\n","  (locked_dropout): LockedDropout(p=0.5)\n","  (embedding2nn): Linear(in_features=4396, out_features=4396, bias=True)\n","  (rnn): LSTM(4396, 256, batch_first=True, bidirectional=True)\n","  (linear): Linear(in_features=512, out_features=12, bias=True)\n","  (beta): 1.0\n","  (weights): None\n","  (weight_tensor) None\n",")\"\n","2021-02-10 10:49:24,073 ----------------------------------------------------------------------------------------------------\n","2021-02-10 10:49:24,074 Corpus: \"Corpus: 2552 train + 2552 dev + 842 test sentences\"\n","2021-02-10 10:49:24,075 ----------------------------------------------------------------------------------------------------\n","2021-02-10 10:49:24,076 Parameters:\n","2021-02-10 10:49:24,077  - learning_rate: \"0.1\"\n","2021-02-10 10:49:24,079  - mini_batch_size: \"32\"\n","2021-02-10 10:49:24,080  - patience: \"3\"\n","2021-02-10 10:49:24,082  - anneal_factor: \"0.5\"\n","2021-02-10 10:49:24,083  - max_epochs: \"10\"\n","2021-02-10 10:49:24,084  - shuffle: \"True\"\n","2021-02-10 10:49:24,084  - train_with_dev: \"False\"\n","2021-02-10 10:49:24,086  - batch_growth_annealing: \"False\"\n","2021-02-10 10:49:24,087 ----------------------------------------------------------------------------------------------------\n","2021-02-10 10:49:24,087 Model training base path: \"eu-flair-model\"\n","2021-02-10 10:49:24,088 ----------------------------------------------------------------------------------------------------\n","2021-02-10 10:49:24,089 Device: cuda:0\n","2021-02-10 10:49:24,090 ----------------------------------------------------------------------------------------------------\n","2021-02-10 10:49:24,090 Embeddings storage mode: cpu\n","2021-02-10 10:49:24,092 ----------------------------------------------------------------------------------------------------\n","2021-02-10 10:49:28,941 epoch 1 - iter 8/80 - loss 16.33899581 - samples/sec: 53.05 - lr: 0.100000\n","2021-02-10 10:49:34,037 epoch 1 - iter 16/80 - loss 13.04210630 - samples/sec: 50.25 - lr: 0.100000\n","2021-02-10 10:49:38,683 epoch 1 - iter 24/80 - loss 11.10210788 - samples/sec: 55.15 - lr: 0.100000\n","2021-02-10 10:49:43,508 epoch 1 - iter 32/80 - loss 9.97337659 - samples/sec: 53.07 - lr: 0.100000\n","2021-02-10 10:49:47,499 epoch 1 - iter 40/80 - loss 8.92417012 - samples/sec: 64.17 - lr: 0.100000\n","2021-02-10 10:49:52,610 epoch 1 - iter 48/80 - loss 8.18620882 - samples/sec: 50.10 - lr: 0.100000\n","2021-02-10 10:49:57,882 epoch 1 - iter 56/80 - loss 7.57930984 - samples/sec: 48.57 - lr: 0.100000\n","2021-02-10 10:50:02,836 epoch 1 - iter 64/80 - loss 7.10101545 - samples/sec: 51.70 - lr: 0.100000\n","2021-02-10 10:50:08,925 epoch 1 - iter 72/80 - loss 6.74201127 - samples/sec: 42.05 - lr: 0.100000\n","2021-02-10 10:50:14,194 epoch 1 - iter 80/80 - loss 6.38364365 - samples/sec: 48.61 - lr: 0.100000\n","2021-02-10 10:50:14,195 ----------------------------------------------------------------------------------------------------\n","2021-02-10 10:50:14,195 EPOCH 1 done: loss 6.3836 - lr 0.1000000\n","2021-02-10 10:50:58,344 DEV : loss 2.4706127643585205 - score 0.6683\n","2021-02-10 10:50:58,516 BAD EPOCHS (no improvement): 0\n","saving best model\n","2021-02-10 10:51:02,661 ----------------------------------------------------------------------------------------------------\n","2021-02-10 10:51:04,241 epoch 2 - iter 8/80 - loss 2.93205860 - samples/sec: 162.29 - lr: 0.100000\n","2021-02-10 10:51:05,800 epoch 2 - iter 16/80 - loss 3.15991668 - samples/sec: 164.35 - lr: 0.100000\n","2021-02-10 10:51:07,212 epoch 2 - iter 24/80 - loss 3.17940945 - samples/sec: 181.72 - lr: 0.100000\n","2021-02-10 10:51:08,682 epoch 2 - iter 32/80 - loss 3.11360362 - samples/sec: 174.30 - lr: 0.100000\n","2021-02-10 10:51:10,246 epoch 2 - iter 40/80 - loss 3.04244127 - samples/sec: 163.80 - lr: 0.100000\n","2021-02-10 10:51:11,725 epoch 2 - iter 48/80 - loss 2.99519153 - samples/sec: 173.49 - lr: 0.100000\n","2021-02-10 10:51:13,317 epoch 2 - iter 56/80 - loss 2.96902223 - samples/sec: 160.98 - lr: 0.100000\n","2021-02-10 10:51:14,747 epoch 2 - iter 64/80 - loss 2.94023487 - samples/sec: 179.21 - lr: 0.100000\n","2021-02-10 10:51:16,177 epoch 2 - iter 72/80 - loss 2.93641756 - samples/sec: 179.22 - lr: 0.100000\n","2021-02-10 10:51:17,354 epoch 2 - iter 80/80 - loss 2.88983739 - samples/sec: 217.72 - lr: 0.100000\n","2021-02-10 10:51:17,355 ----------------------------------------------------------------------------------------------------\n","2021-02-10 10:51:17,356 EPOCH 2 done: loss 2.8898 - lr 0.1000000\n","2021-02-10 10:51:25,282 DEV : loss 1.973453402519226 - score 0.7406\n","2021-02-10 10:51:25,470 BAD EPOCHS (no improvement): 0\n","saving best model\n","2021-02-10 10:51:29,086 ----------------------------------------------------------------------------------------------------\n","2021-02-10 10:51:30,670 epoch 3 - iter 8/80 - loss 2.62426962 - samples/sec: 161.89 - lr: 0.100000\n","2021-02-10 10:51:32,030 epoch 3 - iter 16/80 - loss 2.35295798 - samples/sec: 188.63 - lr: 0.100000\n","2021-02-10 10:51:33,344 epoch 3 - iter 24/80 - loss 2.45143727 - samples/sec: 195.15 - lr: 0.100000\n","2021-02-10 10:51:34,765 epoch 3 - iter 32/80 - loss 2.51601519 - samples/sec: 180.37 - lr: 0.100000\n","2021-02-10 10:51:35,991 epoch 3 - iter 40/80 - loss 2.46818792 - samples/sec: 208.99 - lr: 0.100000\n","2021-02-10 10:51:37,261 epoch 3 - iter 48/80 - loss 2.47263331 - samples/sec: 201.79 - lr: 0.100000\n","2021-02-10 10:51:38,806 epoch 3 - iter 56/80 - loss 2.49241593 - samples/sec: 165.90 - lr: 0.100000\n","2021-02-10 10:51:40,158 epoch 3 - iter 64/80 - loss 2.43271771 - samples/sec: 189.67 - lr: 0.100000\n","2021-02-10 10:51:41,551 epoch 3 - iter 72/80 - loss 2.33261069 - samples/sec: 184.08 - lr: 0.100000\n","2021-02-10 10:51:42,917 epoch 3 - iter 80/80 - loss 2.33092052 - samples/sec: 187.78 - lr: 0.100000\n","2021-02-10 10:51:42,918 ----------------------------------------------------------------------------------------------------\n","2021-02-10 10:51:42,919 EPOCH 3 done: loss 2.3309 - lr 0.1000000\n","2021-02-10 10:51:51,280 DEV : loss 1.417188048362732 - score 0.7925\n","2021-02-10 10:51:51,465 BAD EPOCHS (no improvement): 0\n","saving best model\n","2021-02-10 10:51:55,080 ----------------------------------------------------------------------------------------------------\n","2021-02-10 10:51:56,537 epoch 4 - iter 8/80 - loss 2.10394364 - samples/sec: 176.28 - lr: 0.100000\n","2021-02-10 10:51:58,262 epoch 4 - iter 16/80 - loss 2.18342977 - samples/sec: 148.81 - lr: 0.100000\n","2021-02-10 10:51:59,641 epoch 4 - iter 24/80 - loss 2.09653468 - samples/sec: 185.95 - lr: 0.100000\n","2021-02-10 10:52:01,186 epoch 4 - iter 32/80 - loss 2.11880790 - samples/sec: 165.82 - lr: 0.100000\n","2021-02-10 10:52:02,619 epoch 4 - iter 40/80 - loss 2.07989609 - samples/sec: 178.79 - lr: 0.100000\n","2021-02-10 10:52:04,127 epoch 4 - iter 48/80 - loss 2.06074427 - samples/sec: 169.86 - lr: 0.100000\n","2021-02-10 10:52:05,852 epoch 4 - iter 56/80 - loss 2.09765937 - samples/sec: 148.67 - lr: 0.100000\n","2021-02-10 10:52:07,267 epoch 4 - iter 64/80 - loss 2.07179478 - samples/sec: 181.00 - lr: 0.100000\n","2021-02-10 10:52:08,867 epoch 4 - iter 72/80 - loss 2.06814896 - samples/sec: 160.19 - lr: 0.100000\n","2021-02-10 10:52:10,136 epoch 4 - iter 80/80 - loss 2.07960731 - samples/sec: 202.00 - lr: 0.100000\n","2021-02-10 10:52:10,137 ----------------------------------------------------------------------------------------------------\n","2021-02-10 10:52:10,142 EPOCH 4 done: loss 2.0796 - lr 0.1000000\n","2021-02-10 10:52:17,591 DEV : loss 1.2640093564987183 - score 0.8185\n","2021-02-10 10:52:17,753 BAD EPOCHS (no improvement): 0\n","saving best model\n","2021-02-10 10:52:21,396 ----------------------------------------------------------------------------------------------------\n","2021-02-10 10:52:23,035 epoch 5 - iter 8/80 - loss 1.82837752 - samples/sec: 156.54 - lr: 0.100000\n","2021-02-10 10:52:24,419 epoch 5 - iter 16/80 - loss 1.90212995 - samples/sec: 185.75 - lr: 0.100000\n","2021-02-10 10:52:25,907 epoch 5 - iter 24/80 - loss 1.75730332 - samples/sec: 172.21 - lr: 0.100000\n","2021-02-10 10:52:27,481 epoch 5 - iter 32/80 - loss 1.74438723 - samples/sec: 162.90 - lr: 0.100000\n","2021-02-10 10:52:28,852 epoch 5 - iter 40/80 - loss 1.80873171 - samples/sec: 186.85 - lr: 0.100000\n","2021-02-10 10:52:30,587 epoch 5 - iter 48/80 - loss 1.79243524 - samples/sec: 147.72 - lr: 0.100000\n","2021-02-10 10:52:31,877 epoch 5 - iter 56/80 - loss 1.75591367 - samples/sec: 198.69 - lr: 0.100000\n","2021-02-10 10:52:33,437 epoch 5 - iter 64/80 - loss 1.74437148 - samples/sec: 164.21 - lr: 0.100000\n","2021-02-10 10:52:35,058 epoch 5 - iter 72/80 - loss 1.76920508 - samples/sec: 158.10 - lr: 0.100000\n","2021-02-10 10:52:36,639 epoch 5 - iter 80/80 - loss 1.79148270 - samples/sec: 162.30 - lr: 0.100000\n","2021-02-10 10:52:36,642 ----------------------------------------------------------------------------------------------------\n","2021-02-10 10:52:36,643 EPOCH 5 done: loss 1.7915 - lr 0.1000000\n","2021-02-10 10:52:44,843 DEV : loss 1.1267646551132202 - score 0.8321\n","2021-02-10 10:52:45,005 BAD EPOCHS (no improvement): 0\n","saving best model\n","2021-02-10 10:52:48,849 ----------------------------------------------------------------------------------------------------\n","2021-02-10 10:52:50,527 epoch 6 - iter 8/80 - loss 1.64629877 - samples/sec: 152.73 - lr: 0.100000\n","2021-02-10 10:52:52,141 epoch 6 - iter 16/80 - loss 1.62519744 - samples/sec: 158.78 - lr: 0.100000\n","2021-02-10 10:52:53,501 epoch 6 - iter 24/80 - loss 1.67571003 - samples/sec: 188.44 - lr: 0.100000\n","2021-02-10 10:52:55,030 epoch 6 - iter 32/80 - loss 1.78767321 - samples/sec: 167.65 - lr: 0.100000\n","2021-02-10 10:52:56,470 epoch 6 - iter 40/80 - loss 1.75865906 - samples/sec: 177.89 - lr: 0.100000\n","2021-02-10 10:52:57,837 epoch 6 - iter 48/80 - loss 1.74054030 - samples/sec: 187.72 - lr: 0.100000\n","2021-02-10 10:52:59,434 epoch 6 - iter 56/80 - loss 1.70968859 - samples/sec: 160.51 - lr: 0.100000\n","2021-02-10 10:53:00,868 epoch 6 - iter 64/80 - loss 1.66358613 - samples/sec: 178.81 - lr: 0.100000\n","2021-02-10 10:53:02,462 epoch 6 - iter 72/80 - loss 1.64403985 - samples/sec: 160.80 - lr: 0.100000\n","2021-02-10 10:53:03,902 epoch 6 - iter 80/80 - loss 1.67036992 - samples/sec: 178.22 - lr: 0.100000\n","2021-02-10 10:53:03,904 ----------------------------------------------------------------------------------------------------\n","2021-02-10 10:53:03,906 EPOCH 6 done: loss 1.6704 - lr 0.1000000\n","2021-02-10 10:53:12,113 DEV : loss 0.9220086932182312 - score 0.8526\n","2021-02-10 10:53:12,280 BAD EPOCHS (no improvement): 0\n","saving best model\n","2021-02-10 10:53:16,004 ----------------------------------------------------------------------------------------------------\n","2021-02-10 10:53:17,323 epoch 7 - iter 8/80 - loss 1.44379347 - samples/sec: 194.65 - lr: 0.100000\n","2021-02-10 10:53:18,744 epoch 7 - iter 16/80 - loss 1.63266899 - samples/sec: 180.95 - lr: 0.100000\n","2021-02-10 10:53:20,307 epoch 7 - iter 24/80 - loss 1.70779425 - samples/sec: 163.91 - lr: 0.100000\n","2021-02-10 10:53:21,781 epoch 7 - iter 32/80 - loss 1.68379132 - samples/sec: 173.85 - lr: 0.100000\n","2021-02-10 10:53:23,165 epoch 7 - iter 40/80 - loss 1.62816703 - samples/sec: 185.10 - lr: 0.100000\n","2021-02-10 10:53:24,820 epoch 7 - iter 48/80 - loss 1.60183592 - samples/sec: 154.84 - lr: 0.100000\n","2021-02-10 10:53:26,455 epoch 7 - iter 56/80 - loss 1.61345778 - samples/sec: 156.74 - lr: 0.100000\n","2021-02-10 10:53:27,653 epoch 7 - iter 64/80 - loss 1.55049623 - samples/sec: 213.80 - lr: 0.100000\n","2021-02-10 10:53:29,169 epoch 7 - iter 72/80 - loss 1.52455344 - samples/sec: 169.10 - lr: 0.100000\n","2021-02-10 10:53:30,821 epoch 7 - iter 80/80 - loss 1.49909899 - samples/sec: 155.08 - lr: 0.100000\n","2021-02-10 10:53:30,822 ----------------------------------------------------------------------------------------------------\n","2021-02-10 10:53:30,824 EPOCH 7 done: loss 1.4991 - lr 0.1000000\n","2021-02-10 10:53:38,994 DEV : loss 0.7579891085624695 - score 0.8854\n","2021-02-10 10:53:39,184 BAD EPOCHS (no improvement): 0\n","saving best model\n","2021-02-10 10:53:42,858 ----------------------------------------------------------------------------------------------------\n","2021-02-10 10:53:44,378 epoch 8 - iter 8/80 - loss 1.34099647 - samples/sec: 168.71 - lr: 0.100000\n","2021-02-10 10:53:45,770 epoch 8 - iter 16/80 - loss 1.40810237 - samples/sec: 184.01 - lr: 0.100000\n","2021-02-10 10:53:47,254 epoch 8 - iter 24/80 - loss 1.44774723 - samples/sec: 172.85 - lr: 0.100000\n","2021-02-10 10:53:48,590 epoch 8 - iter 32/80 - loss 1.45762312 - samples/sec: 192.00 - lr: 0.100000\n","2021-02-10 10:53:50,095 epoch 8 - iter 40/80 - loss 1.46903206 - samples/sec: 170.42 - lr: 0.100000\n","2021-02-10 10:53:51,476 epoch 8 - iter 48/80 - loss 1.45601468 - samples/sec: 185.61 - lr: 0.100000\n","2021-02-10 10:53:52,938 epoch 8 - iter 56/80 - loss 1.41779150 - samples/sec: 175.25 - lr: 0.100000\n","2021-02-10 10:53:54,316 epoch 8 - iter 64/80 - loss 1.43505466 - samples/sec: 185.91 - lr: 0.100000\n","2021-02-10 10:53:55,709 epoch 8 - iter 72/80 - loss 1.44743775 - samples/sec: 184.00 - lr: 0.100000\n","2021-02-10 10:53:56,986 epoch 8 - iter 80/80 - loss 1.43289489 - samples/sec: 200.69 - lr: 0.100000\n","2021-02-10 10:53:56,989 ----------------------------------------------------------------------------------------------------\n","2021-02-10 10:53:56,991 EPOCH 8 done: loss 1.4329 - lr 0.1000000\n","2021-02-10 10:54:05,162 DEV : loss 0.7111393809318542 - score 0.8923\n","2021-02-10 10:54:05,349 BAD EPOCHS (no improvement): 0\n","saving best model\n","2021-02-10 10:54:08,977 ----------------------------------------------------------------------------------------------------\n","2021-02-10 10:54:10,451 epoch 9 - iter 8/80 - loss 1.21296349 - samples/sec: 173.96 - lr: 0.100000\n","2021-02-10 10:54:11,861 epoch 9 - iter 16/80 - loss 1.28775589 - samples/sec: 181.69 - lr: 0.100000\n","2021-02-10 10:54:13,489 epoch 9 - iter 24/80 - loss 1.32001771 - samples/sec: 157.50 - lr: 0.100000\n","2021-02-10 10:54:15,020 epoch 9 - iter 32/80 - loss 1.30740571 - samples/sec: 167.47 - lr: 0.100000\n","2021-02-10 10:54:16,576 epoch 9 - iter 40/80 - loss 1.33419413 - samples/sec: 164.64 - lr: 0.100000\n","2021-02-10 10:54:17,958 epoch 9 - iter 48/80 - loss 1.34320038 - samples/sec: 185.48 - lr: 0.100000\n","2021-02-10 10:54:19,363 epoch 9 - iter 56/80 - loss 1.34087335 - samples/sec: 182.34 - lr: 0.100000\n","2021-02-10 10:54:20,695 epoch 9 - iter 64/80 - loss 1.37502729 - samples/sec: 192.42 - lr: 0.100000\n","2021-02-10 10:54:21,982 epoch 9 - iter 72/80 - loss 1.35158460 - samples/sec: 199.19 - lr: 0.100000\n","2021-02-10 10:54:23,465 epoch 9 - iter 80/80 - loss 1.34787700 - samples/sec: 172.73 - lr: 0.100000\n","2021-02-10 10:54:23,468 ----------------------------------------------------------------------------------------------------\n","2021-02-10 10:54:23,470 EPOCH 9 done: loss 1.3479 - lr 0.1000000\n","2021-02-10 10:54:30,917 DEV : loss 0.702093780040741 - score 0.8912\n","2021-02-10 10:54:31,079 BAD EPOCHS (no improvement): 1\n","2021-02-10 10:54:31,080 ----------------------------------------------------------------------------------------------------\n","2021-02-10 10:54:32,555 epoch 10 - iter 8/80 - loss 1.16828442 - samples/sec: 173.74 - lr: 0.100000\n","2021-02-10 10:54:33,919 epoch 10 - iter 16/80 - loss 1.14204822 - samples/sec: 187.87 - lr: 0.100000\n","2021-02-10 10:54:35,444 epoch 10 - iter 24/80 - loss 1.13287410 - samples/sec: 168.08 - lr: 0.100000\n","2021-02-10 10:54:37,220 epoch 10 - iter 32/80 - loss 1.13358198 - samples/sec: 144.23 - lr: 0.100000\n","2021-02-10 10:54:38,703 epoch 10 - iter 40/80 - loss 1.15698920 - samples/sec: 172.78 - lr: 0.100000\n","2021-02-10 10:54:40,573 epoch 10 - iter 48/80 - loss 1.22571976 - samples/sec: 137.02 - lr: 0.100000\n","2021-02-10 10:54:42,095 epoch 10 - iter 56/80 - loss 1.21867298 - samples/sec: 168.38 - lr: 0.100000\n","2021-02-10 10:54:43,823 epoch 10 - iter 64/80 - loss 1.23843943 - samples/sec: 148.40 - lr: 0.100000\n","2021-02-10 10:54:45,291 epoch 10 - iter 72/80 - loss 1.24395890 - samples/sec: 174.47 - lr: 0.100000\n","2021-02-10 10:54:46,823 epoch 10 - iter 80/80 - loss 1.25126048 - samples/sec: 167.29 - lr: 0.100000\n","2021-02-10 10:54:46,824 ----------------------------------------------------------------------------------------------------\n","2021-02-10 10:54:46,826 EPOCH 10 done: loss 1.2513 - lr 0.1000000\n","2021-02-10 10:54:54,314 DEV : loss 0.5791354775428772 - score 0.9156\n","2021-02-10 10:54:54,507 BAD EPOCHS (no improvement): 0\n","saving best model\n","2021-02-10 10:55:01,954 ----------------------------------------------------------------------------------------------------\n","2021-02-10 10:55:01,955 Testing using best model ...\n","2021-02-10 10:55:01,963 loading file eu-flair-model/best-model.pt\n","2021-02-10 10:55:17,410 0.8379\t0.7830\t0.8096\n","2021-02-10 10:55:17,411 \n","Results:\n","- F1-score (micro) 0.8096\n","- F1-score (macro) 0.6652\n","\n","By class:\n","LOC        tp: 268 - fp: 60 - fn: 47 - precision: 0.8171 - recall: 0.8508 - f1-score: 0.8336\n","MISC       tp: 4 - fp: 6 - fn: 26 - precision: 0.4000 - recall: 0.1333 - f1-score: 0.2000\n","ORG        tp: 195 - fp: 44 - fn: 98 - precision: 0.8159 - recall: 0.6655 - f1-score: 0.7331\n","PER        tp: 262 - fp: 31 - fn: 31 - precision: 0.8942 - recall: 0.8942 - f1-score: 0.8942\n","2021-02-10 10:55:17,412 ----------------------------------------------------------------------------------------------------\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["{'dev_loss_history': [2.4706127643585205,\n","  1.973453402519226,\n","  1.417188048362732,\n","  1.2640093564987183,\n","  1.1267646551132202,\n","  0.9220086932182312,\n","  0.7579891085624695,\n","  0.7111393809318542,\n","  0.702093780040741,\n","  0.5791354775428772],\n"," 'dev_score_history': [0.6683239565615595,\n","  0.7406077348066298,\n","  0.7924778175076149,\n","  0.8184758700996249,\n","  0.832110948126417,\n","  0.852569067906016,\n","  0.8854399579113509,\n","  0.892291720737088,\n","  0.8911725955204216,\n","  0.9155742003146303],\n"," 'test_score': 0.8095502498611883,\n"," 'train_loss_history': [6.383643648028373,\n","  2.8898373886942865,\n","  2.3309205174446106,\n","  2.0796073146164415,\n","  1.7914827004075051,\n","  1.6703699238598346,\n","  1.4990989871323108,\n","  1.4328948929905891,\n","  1.3478769950568676,\n","  1.2512604843825101]}"]},"metadata":{"tags":[]},"execution_count":9}]},{"cell_type":"code","metadata":{"id":"4CZCD00xeqI9"},"source":["# TODO plot training loss and weights\n","# HINT Check documentation on training models with Flair"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"14_7gL-vlyxu"},"source":["# ASSIGNMENT 2\n","\n","In this assignment we will use the model trained in the previous step to automatically tag a document of your choice.\n","\n","1. HINT: Revise the TUTORIAL_2_TAGGING to see how to use a SequenceTagger to tag texts. Remember that to use your own model you need to instantiate the SequenceTagger providing the full path of your model, like so:\n","\n","```\n","ner_tagger = SequenceTagger.load('/content/drive/My Drive/Colab Notebooks/2021-ILTAPP/eu-flair-model/final-model.pt')\n","```\n","\n","2. Save the document in your drive as a plain text file.\n","3. Load the file and instantiate the SequenceTagger with your model.\n","4. Predict the NER tags with your model.\n","5. Inspect the annotations obtained. You can do this in various ways:\n","  + By saving the annotated file to a text document in your drive.\n","  + By inspecting the annotations via iteration over the Sentence objects to extract the ner annotations for each token.\n"]}]}